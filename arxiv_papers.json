[{"title": "Deceptive Games", "abstract": "Deceptive games are games where the reward structure or other aspects of the\ngame are designed to lead the agent away from a globally optimal policy. While\nmany games are already deceptive to some extent, we designed a series of games\nin the Video Game Description Language (VGDL) implementing specific types of\ndeception, classified by the cognitive biases they exploit. VGDL games can be\nrun in the General Video Game Artificial Intelligence (GVGAI) Framework, making\nit possible to test a variety of existing AI agents that have been submitted to\nthe GVGAI Competition on these deceptive games. Our results show that all\ntested agents are vulnerable to several kinds of deception, but that different\nagents have different weaknesses. This suggests that we can use deception to\nunderstand the capabilities of a game-playing algorithm, and game-playing\nalgorithms to characterize the deception displayed by a game.", "category": "cs.AI"}, {"title": "Recursive Feature Generation for Knowledge-based Learning", "abstract": "When humans perform inductive learning, they often enhance the process with\nbackground knowledge. With the increasing availability of well-formed\ncollaborative knowledge bases, the performance of learning algorithms could be\nsignificantly enhanced if a way were found to exploit these knowledge bases. In\nthis work, we present a novel algorithm for injecting external knowledge into\ninduction algorithms using feature generation. Given a feature, the algorithm\ndefines a new learning task over its set of values, and uses the knowledge base\nto solve the constructed learning task. The resulting classifier is then used\nas a new feature for the original problem. We have applied our algorithm to the\ndomain of text classification using large semantic knowledge bases. We have\nshown that the generated features significantly improve the performance of\nexisting learning algorithms.", "category": "cs.AI"}, {"title": "A Semantic Model for Historical Manuscripts", "abstract": "The study and publication of historical scientific manuscripts are com- plex\ntasks that involve, among others, the explicit representation of the text mean-\nings and reasoning on temporal entities. In this paper we present the first\nresults of an interdisciplinary project dedicated to the study of Saussure's\nmanuscripts. These results aim to fulfill requirements elaborated with\nSaussurean humanists. They comprise a model for the representation of\ntime-varying statements and time-varying domain knowledge (in particular\nterminologies) as well as imple- mentation techniques for the semantic indexing\nof manuscripts and for temporal reasoning on knowledge extracted from the\nmanuscripts.", "category": "cs.AI"}, {"title": "Cross-City Transfer Learning for Deep Spatio-Temporal Prediction", "abstract": "Spatio-temporal prediction is a key type of tasks in urban computing, e.g.,\ntraffic flow and air quality. Adequate data is usually a prerequisite,\nespecially when deep learning is adopted. However, the development levels of\ndifferent cities are unbalanced, and still many cities suffer from data\nscarcity. To address the problem, we propose a novel cross-city transfer\nlearning method for deep spatio-temporal prediction tasks, called RegionTrans.\nRegionTrans aims to effectively transfer knowledge from a data-rich source city\nto a data-scarce target city. More specifically, we first learn an inter-city\nregion matching function to match each target city region to a similar source\ncity region. A neural network is designed to effectively extract region-level\nrepresentation for spatio-temporal prediction. Finally, an optimization\nalgorithm is proposed to transfer learned features from the source city to the\ntarget city with the region matching function. Using citywide crowd flow\nprediction as a demonstration experiment, we verify the effectiveness of\nRegionTrans. Results show that RegionTrans can outperform the state-of-the-art\nfine-tuning deep spatio-temporal prediction models by reducing up to 10.7%\nprediction error.", "category": "cs.AI"}, {"title": "How do Humans Understand Explanations from Machine Learning Systems? An Evaluation of the Human-Interpretability of Explanation", "abstract": "Recent years have seen a boom in interest in machine learning systems that\ncan provide a human-understandable rationale for their predictions or\ndecisions. However, exactly what kinds of explanation are truly\nhuman-interpretable remains poorly understood. This work advances our\nunderstanding of what makes explanations interpretable in the specific context\nof verification. Suppose we have a machine learning system that predicts X, and\nwe provide rationale for this prediction X. Given an input, an explanation, and\nan output, is the output consistent with the input and the supposed rationale?\nVia a series of user-studies, we identify what kinds of increases in complexity\nhave the greatest effect on the time it takes for humans to verify the\nrationale, and which seem relatively insensitive.", "category": "cs.AI"}, {"title": "Modelling contextuality by probabilistic programs with hypergraph semantics", "abstract": "Models of a phenomenon are often developed by examining it under different\nexperimental conditions, or measurement contexts. The resultant probabilistic\nmodels assume that the underlying random variables, which define a measurable\nset of outcomes, can be defined independent of the measurement context. The\nphenomenon is deemed contextual when this assumption fails. Contextuality is an\nimportant issue in quantum physics. However, there has been growing speculation\nthat it manifests outside the quantum realm with human cognition being a\nparticularly prominent area of investigation. This article contributes the\nfoundations of a probabilistic programming language that allows convenient\nexploration of contextuality in wide range of applications relevant to\ncognitive science and artificial intelligence. Specific syntax is proposed to\nallow the specification of \"measurement contexts\". Each such context delivers a\npartial model of the phenomenon based on the associated experimental condition\ndescribed by the measurement context. The probabilistic program is translated\ninto a hypergraph in a modular way. Recent theoretical results from the field\nof quantum physics show that contextuality can be equated with the possibility\nof constructing a probabilistic model on the resulting hypergraph. The use of\nhypergraphs opens the door for a theoretically succinct and efficient\ncomputational semantics sensitive to modelling both contextual and\nnon-contextual phenomena. Finally, this article raises awareness of\ncontextuality beyond quantum physics and to contribute formal methods to detect\nits presence by means of hypergraph semantics.", "category": "cs.AI"}, {"title": "Plan Explanations as Model Reconciliation -- An Empirical Study", "abstract": "Recent work in explanation generation for decision making agents has looked\nat how unexplained behavior of autonomous systems can be understood in terms of\ndifferences in the model of the system and the human's understanding of the\nsame, and how the explanation process as a result of this mismatch can be then\nseen as a process of reconciliation of these models. Existing algorithms in\nsuch settings, while having been built on contrastive, selective and social\nproperties of explanations as studied extensively in the psychology literature,\nhave not, to the best of our knowledge, been evaluated in settings with actual\nhumans in the loop. As such, the applicability of such explanations to human-AI\nand human-robot interactions remains suspect. In this paper, we set out to\nevaluate these explanation generation algorithms in a series of studies in a\nmock search and rescue scenario with an internal semi-autonomous robot and an\nexternal human commander. We demonstrate to what extent the properties of these\nalgorithms hold as they are evaluated by humans, and how the dynamics of trust\nbetween the human and the robot evolve during the process of these\ninteractions.", "category": "cs.AI"}, {"title": "Tunneling Neural Perception and Logic Reasoning through Abductive Learning", "abstract": "Perception and reasoning are basic human abilities that are seamlessly\nconnected as part of human intelligence. However, in current machine learning\nsystems, the perception and reasoning modules are incompatible. Tasks requiring\njoint perception and reasoning ability are difficult to accomplish autonomously\nand still demand human intervention. Inspired by the way language experts\ndecoded Mayan scripts by joining two abilities in an abductive manner, this\npaper proposes the abductive learning framework. The framework learns\nperception and reasoning simultaneously with the help of a trial-and-error\nabductive process. We present the Neural-Logical Machine as an implementation\nof this novel learning framework. We demonstrate that--using human-like\nabductive learning--the machine learns from a small set of simple hand-written\nequations and then generalizes well to complex equations, a feat that is beyond\nthe capability of state-of-the-art neural network models. The abductive\nlearning framework explores a new direction for approaching human-level\nlearning ability.", "category": "cs.AI"}, {"title": "Coordinated Exploration in Concurrent Reinforcement Learning", "abstract": "We consider a team of reinforcement learning agents that concurrently learn\nto operate in a common environment. We identify three properties - adaptivity,\ncommitment, and diversity - which are necessary for efficient coordinated\nexploration and demonstrate that straightforward extensions to single-agent\noptimistic and posterior sampling approaches fail to satisfy them. As an\nalternative, we propose seed sampling, which extends posterior sampling in a\nmanner that meets these requirements. Simulation results investigate how\nper-agent regret decreases as the number of agents grows, establishing\nsubstantial advantages of seed sampling over alternative exploration schemes.", "category": "cs.AI"}, {"title": "The Sea Exploration Problem: Data-driven Orienteering on a Continuous Surface", "abstract": "This paper describes a problem arising in sea exploration, where the aim is\nto schedule the expedition of a ship for collecting information about the\nresources on the seafloor. The aim is to collect data by probing on a set of\ncarefully chosen locations, so that the information available is optimally\nenriched. This problem has similarities with the orienteering problem, where\nthe aim is to plan a time-limited trip for visiting a set of vertices,\ncollecting a prize at each of them, in such a way that the total value\ncollected is maximum. In our problem, the score at each vertex is associated\nwith an estimation of the level of the resource on the given surface, which is\ndone by regression using Gaussian processes. Hence, there is a correlation\namong scores on the selected vertices; this is a first difference with respect\nto the standard orienteering problem. The second difference is the location of\neach vertex, which in our problem is a freely chosen point on a given surface.", "category": "cs.AI"}, {"title": "Guided Policy Exploration for Markov Decision Processes using an Uncertainty-Based Value-of-Information Criterion", "abstract": "Reinforcement learning in environments with many action-state pairs is\nchallenging. At issue is the number of episodes needed to thoroughly search the\npolicy space. Most conventional heuristics address this search problem in a\nstochastic manner. This can leave large portions of the policy space unvisited\nduring the early training stages. In this paper, we propose an\nuncertainty-based, information-theoretic approach for performing guided\nstochastic searches that more effectively cover the policy space. Our approach\nis based on the value of information, a criterion that provides the optimal\ntrade-off between expected costs and the granularity of the search process. The\nvalue of information yields a stochastic routine for choosing actions during\nlearning that can explore the policy space in a coarse to fine manner. We\naugment this criterion with a state-transition uncertainty factor, which guides\nthe search process into previously unexplored regions of the policy space.", "category": "cs.AI"}, {"title": "Abstractly Interpreting Argumentation Frameworks for Sharpening Extensions", "abstract": "Cycles of attacking arguments pose non-trivial issues in Dung style\nargumentation theory, apparent behavioural difference between odd and even\nlength cycles being a notable one. While a few methods were proposed for\ntreating them, to - in particular - enable selection of acceptable arguments in\nan odd-length cycle when Dung semantics could select none, so far the issues\nhave been observed from a purely argument-graph-theoretic perspective. Per\ncontra, we consider argument graphs together with a certain lattice like\nsemantic structure over arguments e.g. ontology. As we show, the\nsemantic-argumentgraphic hybrid theory allows us to apply abstract\ninterpretation, a widely known methodology in static program analysis, to\nformal argumentation. With this, even where no arguments in a cycle could be\nselected sensibly, we could say more about arguments acceptability of an\nargument framework that contains it. In a certain sense, we can verify Dung\nextensions with respect to a semantic structure in this hybrid theory, to\nconsolidate our confidence in their suitability. By defining the theory, and by\nmaking comparisons to existing approaches, we ultimately discover that whether\nDung semantics, or an alternative semantics such as cf2, is adequate or\nproblematic depends not just on an argument graph but also on the semantic\nrelation among the arguments in the graph.", "category": "cs.AI"}, {"title": "Learning from Richer Human Guidance: Augmenting Comparison-Based Learning with Feature Queries", "abstract": "We focus on learning the desired objective function for a robot. Although\ntrajectory demonstrations can be very informative of the desired objective,\nthey can also be difficult for users to provide. Answers to comparison queries,\nasking which of two trajectories is preferable, are much easier for users, and\nhave emerged as an effective alternative. Unfortunately, comparisons are far\nless informative. We propose that there is much richer information that users\ncan easily provide and that robots ought to leverage. We focus on augmenting\ncomparisons with feature queries, and introduce a unified formalism for\ntreating all answers as observations about the true desired reward. We derive\nan active query selection algorithm, and test these queries in simulation and\non real users. We find that richer, feature-augmented queries can extract more\ninformation faster, leading to robots that better match user preferences in\ntheir behavior.", "category": "cs.AI"}, {"title": "Augmented Artificial Intelligence: a Conceptual Framework", "abstract": "All artificial Intelligence (AI) systems make errors. These errors are\nunexpected, and differ often from the typical human mistakes (\"non-human\"\nerrors). The AI errors should be corrected without damage of existing skills\nand, hopefully, avoiding direct human expertise. This paper presents an initial\nsummary report of project taking new and systematic approach to improving the\nintellectual effectiveness of the individual AI by communities of AIs. We\ncombine some ideas of learning in heterogeneous multiagent systems with new and\noriginal mathematical approaches for non-iterative corrections of errors of\nlegacy AI systems. The mathematical foundations of AI non-destructive\ncorrection are presented and a series of new stochastic separation theorems is\nproven. These theorems provide a new instrument for the development, analysis,\nand assessment of machine learning methods and algorithms in high dimension.\nThey demonstrate that in high dimensions and even for exponentially large\nsamples, linear classifiers in their classical Fisher's form are powerful\nenough to separate errors from correct responses with high probability and to\nprovide efficient solution to the non-destructive corrector problem. In\nparticular, we prove some hypotheses formulated in our paper `Stochastic\nSeparation Theorems' (Neural Networks, 94, 255--259, 2017), and answer one\ngeneral problem published by Donoho and Tanner in 2009.", "category": "cs.AI"}, {"title": "Evolutionary Computation plus Dynamic Programming for the Bi-Objective Travelling Thief Problem", "abstract": "This research proposes a novel indicator-based hybrid evolutionary approach\nthat combines approximate and exact algorithms. We apply it to a new\nbi-criteria formulation of the travelling thief problem, which is known to the\nEvolutionary Computation community as a benchmark multi-component optimisation\nproblem that interconnects two classical NP-hard problems: the travelling\nsalesman problem and the 0-1 knapsack problem. Our approach employs the exact\ndynamic programming algorithm for the underlying Packing-While-Travelling (PWT)\nproblem as a subroutine within a bi-objective evolutionary algorithm. This\ndesign takes advantage of the data extracted from Pareto fronts generated by\nthe dynamic program to achieve better solutions. Furthermore, we develop a\nnumber of novel indicators and selection mechanisms to strengthen synergy of\nthe two algorithmic components of our approach. The results of computational\nexperiments show that the approach is capable to outperform the\nstate-of-the-art results for the single-objective case of the problem.", "category": "cs.AI"}, {"title": "Efficient Learning of Bounded-Treewidth Bayesian Networks from Complete and Incomplete Data Sets", "abstract": "Learning a Bayesian networks with bounded treewidth is important for reducing\nthe complexity of the inferences. We present a novel anytime algorithm (k-MAX)\nmethod for this task, which scales up to thousands of variables. Through\nextensive experiments we show that it consistently yields higher-scoring\nstructures than its competitors on complete data sets. We then consider the\nproblem of structure learning from incomplete data sets. This can be addressed\nby structural EM, which however is computationally very demanding. We thus\nadopt the novel k-MAX algorithm in the maximization step of structural EM,\nobtaining an efficient computation of the expected sufficient statistics. We\ntest the resulting structural EM method on the task of imputing missing data,\ncomparing it against the state-of-the-art approach based on random forests. Our\napproach achieves the same imputation accuracy of the competitors, but in about\none tenth of the time. Furthermore we show that it has worst-case complexity\nlinear in the input size, and that it is easily parallelizable.", "category": "cs.AI"}, {"title": "Balancing Two-Player Stochastic Games with Soft Q-Learning", "abstract": "Within the context of video games the notion of perfectly rational agents can\nbe undesirable as it leads to uninteresting situations, where humans face tough\nadversarial decision makers. Current frameworks for stochastic games and\nreinforcement learning prohibit tuneable strategies as they seek optimal\nperformance. In this paper, we enable such tuneable behaviour by generalising\nsoft Q-learning to stochastic games, where more than one agent interact\nstrategically. We contribute both theoretically and empirically. On the theory\nside, we show that games with soft Q-learning exhibit a unique value and\ngeneralise team games and zero-sum games far beyond these two extremes to cover\na continuous spectrum of gaming behaviour. Experimentally, we show how tuning\nagents' constraints affect performance and demonstrate, through a neural\nnetwork architecture, how to reliably balance games with high-dimensional\nrepresentations.", "category": "cs.AI"}, {"title": "Narrow Artificial Intelligence with Machine Learning for Real-Time Estimation of a Mobile Agents Location Using Hidden Markov Models", "abstract": "We propose to use a supervised machine learning technique to track the\nlocation of a mobile agent in real time. Hidden Markov Models are used to build\nartificial intelligence that estimates the unknown position of a mobile target\nmoving in a defined environment. This narrow artificial intelligence performs\ntwo distinct tasks. First, it provides real-time estimation of the mobile\nagent's position using the forward algorithm. Second, it uses the Baum-Welch\nalgorithm as a statistical learning tool to gain knowledge of the mobile\ntarget. Finally, an experimental environment is proposed, namely a video game\nthat we use to test our artificial intelligence. We present statistical and\ngraphical results to illustrate the efficiency of our method.", "category": "cs.AI"}, {"title": "More Robust Doubly Robust Off-policy Evaluation", "abstract": "We study the problem of off-policy evaluation (OPE) in reinforcement learning\n(RL), where the goal is to estimate the performance of a policy from the data\ngenerated by another policy(ies). In particular, we focus on the doubly robust\n(DR) estimators that consist of an importance sampling (IS) component and a\nperformance model, and utilize the low (or zero) bias of IS and low variance of\nthe model at the same time. Although the accuracy of the model has a huge\nimpact on the overall performance of DR, most of the work on using the DR\nestimators in OPE has been focused on improving the IS part, and not much on\nhow to learn the model. In this paper, we propose alternative DR estimators,\ncalled more robust doubly robust (MRDR), that learn the model parameter by\nminimizing the variance of the DR estimator. We first present a formulation for\nlearning the DR model in RL. We then derive formulas for the variance of the DR\nestimator in both contextual bandits and RL, such that their gradients\nw.r.t.~the model parameters can be estimated from the samples, and propose\nmethods to efficiently minimize the variance. We prove that the MRDR estimators\nare strongly consistent and asymptotically optimal. Finally, we evaluate MRDR\nin bandits and RL benchmark problems, and compare its performance with the\nexisting methods.", "category": "cs.AI"}, {"title": "Graph Planning with Expected Finite Horizon", "abstract": "Graph planning gives rise to fundamental algorithmic questions such as\nshortest path, traveling salesman problem, etc. A classical problem in discrete\nplanning is to consider a weighted graph and construct a path that maximizes\nthe sum of weights for a given time horizon $T$. However, in many scenarios,\nthe time horizon is not fixed, but the stopping time is chosen according to\nsome distribution such that the expected stopping time is $T$. If the stopping\ntime distribution is not known, then to ensure robustness, the distribution is\nchosen by an adversary, to represent the worst-case scenario.\n  A stationary plan for every vertex always chooses the same outgoing edge. For\nfixed horizon or fixed stopping-time distribution, stationary plans are not\nsufficient for optimality. Quite surprisingly we show that when an adversary\nchooses the stopping-time distribution with expected stopping time $T$, then\nstationary plans are sufficient. While computing optimal stationary plans for\nfixed horizon is NP-complete, we show that computing optimal stationary plans\nunder adversarial stopping-time distribution can be achieved in polynomial\ntime. Consequently, our polynomial-time algorithm for adversarial stopping time\nalso computes an optimal plan among all possible plans.", "category": "cs.AI"}, {"title": "Distinguishing Question Subjectivity from Difficulty for Improved Crowdsourcing", "abstract": "The questions in a crowdsourcing task typically exhibit varying degrees of\ndifficulty and subjectivity. Their joint effects give rise to the variation in\nresponses to the same question by different crowd-workers. This variation is\nlow when the question is easy to answer and objective, and high when it is\ndifficult and subjective. Unfortunately, current quality control methods for\ncrowdsourcing consider only the question difficulty to account for the\nvariation. As a result,these methods cannot distinguish workers personal\npreferences for different correct answers of a partially subjective question\nfrom their ability/expertise to avoid objectively wrong answers for that\nquestion. To address this issue, we present a probabilistic model which (i)\nexplicitly encodes question difficulty as a model parameter and (ii) implicitly\nencodes question subjectivity via latent preference factors for crowd-workers.\nWe show that question subjectivity induces grouping of crowd-workers, revealed\nthrough clustering of their latent preferences. Moreover, we develop a\nquantitative measure of the subjectivity of a question. Experiments show that\nour model(1) improves the performance of both quality control for crowd-sourced\nanswers and next answer prediction for crowd-workers,and (2) can potentially\nprovide coherent rankings of questions in terms of their difficulty and\nsubjectivity, so that task providers can refine their designs of the\ncrowdsourcing tasks, e.g. by removing highly subjective questions or\ninappropriately difficult questions.", "category": "cs.AI"}, {"title": "The Complex Event Recognition Group", "abstract": "The Complex Event Recognition (CER) group is a research team, affiliated with\nthe National Centre of Scientific Research \"Demokritos\" in Greece. The CER\ngroup works towards advanced and efficient methods for the recognition of\ncomplex events in a multitude of large, heterogeneous and interdependent data\nstreams. Its research covers multiple aspects of complex event recognition,\nfrom efficient detection of patterns on event streams to handling uncertainty\nand noise in streams, and machine learning techniques for inferring interesting\npatterns. Lately, it has expanded to methods for forecasting the occurrence of\nevents. It was founded in 2009 and currently hosts 3 senior researchers, 5 PhD\nstudents and works regularly with under-graduate students.", "category": "cs.AI"}, {"title": "Reasoning in a Hierarchical System with Missing Group Size Information", "abstract": "The paper analyzes the problem of judgments or preferences subsequent to\ninitial analysis by autonomous agents in a hierarchical system where the higher\nlevel agents does not have access to group size information. We propose methods\nthat reduce instances of preference reversal of the kind encountered in\nSimpson's paradox.", "category": "cs.AI"}, {"title": "A New Multi Criteria Decision Making Method: Approach of Logarithmic Concept (APLOCO)", "abstract": "The primary aim of the study is to introduce APLOCO method which is developed\nfor the solution of multicriteria decision making problems both theoretically\nand practically. In this context, application subject of APLACO constitutes\nevaluation of investment potential of different cities in metropolitan status\nin Turkey. The secondary purpose of the study is to identify the independent\nvariables affecting the factories in the operating phase and to estimate the\neffect levels of independent variables on the dependent variable in the\norganized industrial zones (OIZs), whose mission is to reduce regional\ndevelopment disparities and to mobilize local production dynamics. For this\npurpose, the effect levels of independent variables on dependent variables have\nbeen determined using the multilayer perceptron (MLP) method, which has a wide\nuse in artificial neural networks (ANNs). The effect levels derived from MLP\nhave been then used as the weight levels of the decision criteria in APLOCO.\nThe independent variables included in MLP are also used as the decision\ncriteria in APLOCO. According to the results obtained from APLOCO, Istanbul\ncity is the best alternative in term of the investment potential and other\nalternatives are Manisa, Denizli, Izmir, Kocaeli, Bursa, Ankara, Adana, and\nAntalya, respectively. Although APLOCO is used to solve the ranking problem in\norder to show application process in the paper, it can be employed easily in\nthe solution of classification and selection problems. On the other hand, the\nstudy also shows a rare example of the nested usage of APLOCO which is one of\nthe methods of operation research as well as MLP used in determination of\nweights.", "category": "cs.AI"}, {"title": "Blockchain and Artificial Intelligence", "abstract": "It is undeniable that artificial intelligence (AI) and blockchain concepts\nare spreading at a phenomenal rate. Both technologies have distinct degree of\ntechnological complexity and multi-dimensional business implications. However,\na common misunderstanding about blockchain concept, in particular, is that\nblockchain is decentralized and is not controlled by anyone. But the underlying\ndevelopment of a blockchain system is still attributed to a cluster of core\ndevelopers. Take smart contract as an example, it is essentially a collection\nof codes (or functions) and data (or states) that are programmed and deployed\non a blockchain (say, Ethereum) by different human programmers. It is thus,\nunfortunately, less likely to be free of loopholes and flaws. In this article,\nthrough a brief overview about how artificial intelligence could be used to\ndeliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we\nto emphasize that the blockchain implementation can be assisted or enhanced via\nvarious AI techniques. The alliance of AI and blockchain is expected to create\nnumerous possibilities.", "category": "cs.AI"}, {"title": "Learning Robust and Adaptive Real-World Continuous Control Using Simulation and Transfer Learning", "abstract": "We use model-free reinforcement learning, extensive simulation, and transfer\nlearning to develop a continuous control algorithm that has good zero-shot\nperformance in a real physical environment. We train a simulated agent to act\noptimally across a set of similar environments, each with dynamics drawn from a\nprior distribution. We propose that the agent is able to adjust its actions\nalmost immediately, based on small set of observations. This robust and\nadaptive behavior is enabled by using a policy gradient algorithm with an Long\nShort Term Memory (LSTM) function approximation. Finally, we train an agent to\nnavigate a two-dimensional environment with uncertain dynamics and noisy\nobservations. We demonstrate that this agent has good zero-shot performance in\na real physical environment. Our preliminary results indicate that the agent is\nable to infer the environmental dynamics after only a few timesteps, and adjust\nits actions accordingly.", "category": "cs.AI"}, {"title": "A Deep Reinforcement Learning Framework for Rebalancing Dockless Bike Sharing Systems", "abstract": "Bike sharing provides an environment-friendly way for traveling and is\nbooming all over the world. Yet, due to the high similarity of user travel\npatterns, the bike imbalance problem constantly occurs, especially for dockless\nbike sharing systems, causing significant impact on service quality and company\nrevenue. Thus, it has become a critical task for bike sharing systems to\nresolve such imbalance efficiently. In this paper, we propose a novel deep\nreinforcement learning framework for incentivizing users to rebalance such\nsystems. We model the problem as a Markov decision process and take both\nspatial and temporal features into consideration. We develop a novel deep\nreinforcement learning algorithm called Hierarchical Reinforcement Pricing\n(HRP), which builds upon the Deep Deterministic Policy Gradient algorithm.\nDifferent from existing methods that often ignore spatial information and rely\nheavily on accurate prediction, HRP captures both spatial and temporal\ndependencies using a divide-and-conquer structure with an embedded localized\nmodule. We conduct extensive experiments to evaluate HRP, based on a dataset\nfrom Mobike, a major Chinese dockless bike sharing company. Results show that\nHRP performs close to the 24-timeslot look-ahead optimization, and outperforms\nstate-of-the-art methods in both service level and bike distribution. It also\ntransfers well when applied to unseen areas.", "category": "cs.AI"}, {"title": "Story Generation and Aviation Incident Representation", "abstract": "This working note discusses the topic of story generation, with a view to\nidentifying the knowledge required to understand aviation incident narratives\n(which have structural similarities to stories), following the premise that to\nunderstand aviation incidents, one should at least be able to generate examples\nof them. We give a brief overview of aviation incidents and their relation to\nstories, and then describe two of our earlier attempts (using `scripts' and\n`story grammars') at incident generation which did not evolve promisingly.\nFollowing this, we describe a simple incident generator which did work (at a\n`toy' level), using a `world simulation' approach. This generator is based on\nMeehan's TALE-SPIN story generator (1977). We conclude with a critique of the\napproach.", "category": "cs.AI"}, {"title": "Morphologic for knowledge dynamics: revision, fusion, abduction", "abstract": "Several tasks in artificial intelligence require to be able to find models\nabout knowledge dynamics. They include belief revision, fusion and belief\nmerging, and abduction. In this paper we exploit the algebraic framework of\nmathematical morphology in the context of propositional logic, and define\noperations such as dilation or erosion of a set of formulas. We derive concrete\noperators, based on a semantic approach, that have an intuitive interpretation\nand that are formally well behaved, to perform revision, fusion and abduction.\nComputation and tractability are addressed, and simple examples illustrate the\ntypical results that can be obtained.", "category": "cs.AI"}, {"title": "Who Killed Albert Einstein? From Open Data to Murder Mystery Games", "abstract": "This paper presents a framework for generating adventure games from open\ndata. Focusing on the murder mystery type of adventure games, the generator is\nable to transform open data from Wikipedia articles, OpenStreetMap and images\nfrom Wikimedia Commons into WikiMysteries. Every WikiMystery game revolves\naround the murder of a person with a Wikipedia article and populates the game\nwith suspects who must be arrested by the player if guilty of the murder or\nabsolved if innocent. Starting from only one person as the victim, an extensive\ngenerative pipeline finds suspects, their alibis, and paths connecting them\nfrom open data, transforms open data into cities, buildings, non-player\ncharacters, locks and keys and dialog options. The paper describes in detail\neach generative step, provides a specific playthrough of one WikiMystery where\nAlbert Einstein is murdered, and evaluates the outcomes of games generated for\nthe 100 most influential people of the 20th century.", "category": "cs.AI"}, {"title": "From Gameplay to Symbolic Reasoning: Learning SAT Solver Heuristics in the Style of Alpha(Go) Zero", "abstract": "Despite the recent successes of deep neural networks in various fields such\nas image and speech recognition, natural language processing, and reinforcement\nlearning, we still face big challenges in bringing the power of numeric\noptimization to symbolic reasoning. Researchers have proposed different avenues\nsuch as neural machine translation for proof synthesis, vectorization of\nsymbols and expressions for representing symbolic patterns, and coupling of\nneural back-ends for dimensionality reduction with symbolic front-ends for\ndecision making. However, these initial explorations are still only point\nsolutions, and bear other shortcomings such as lack of correctness guarantees.\nIn this paper, we present our approach of casting symbolic reasoning as games,\nand directly harnessing the power of deep reinforcement learning in the style\nof Alpha(Go) Zero on symbolic problems. Using the Boolean Satisfiability (SAT)\nproblem as showcase, we demonstrate the feasibility of our method, and the\nadvantages of modularity, efficiency, and correctness guarantees.", "category": "cs.AI"}, {"title": "Reliable Uncertain Evidence Modeling in Bayesian Networks by Credal Networks", "abstract": "A reliable modeling of uncertain evidence in Bayesian networks based on a\nset-valued quantification is proposed. Both soft and virtual evidences are\nconsidered. We show that evidence propagation in this setup can be reduced to\nstandard updating in an augmented credal network, equivalent to a set of\nconsistent Bayesian networks. A characterization of the computational\ncomplexity for this task is derived together with an efficient exact procedure\nfor a subclass of instances. In the case of multiple uncertain evidences over\nthe same variable, the proposed procedure can provide a set-valued version of\nthe geometric approach to opinion pooling.", "category": "cs.AI"}, {"title": "An Anytime Algorithm for Task and Motion MDPs", "abstract": "Integrated task and motion planning has emerged as a challenging problem in\nsequential decision making, where a robot needs to compute high-level strategy\nand low-level motion plans for solving complex tasks. While high-level\nstrategies require decision making over longer time-horizons and scales, their\nfeasibility depends on low-level constraints based upon the geometries and\ncontinuous dynamics of the environment. The hybrid nature of this problem makes\nit difficult to scale; most existing approaches focus on deterministic, fully\nobservable scenarios. We present a new approach where the high-level decision\nproblem occurs in a stochastic setting and can be modeled as a Markov decision\nprocess. In contrast to prior efforts, we show that complete MDP policies, or\ncontingent behaviors, can be computed effectively in an anytime fashion. Our\nalgorithm continuously improves the quality of the solution and is guaranteed\nto be probabilistically complete. We evaluate the performance of our approach\non a challenging, realistic test problem: autonomous aircraft inspection. Our\nresults show that we can effectively compute consistent task and motion\npolicies for the most likely execution-time outcomes using only a fraction of\nthe computation required to develop the complete task and motion policy.", "category": "cs.AI"}, {"title": "Detecting truth, just on parts", "abstract": "We introduce and discuss, through a computational algebraic geometry\napproach, the automatic reasoning handling of propositions that are\nsimultaneously true and false over some relevant collections of instances. A\nrigorous, algorithmic criterion is presented for detecting such cases, and its\nperformance is exemplified through the implementation of this test on the\ndynamic geometry program GeoGebra.", "category": "cs.AI"}, {"title": "Monte Carlo Q-learning for General Game Playing", "abstract": "After the recent groundbreaking results of AlphaGo, we have seen a strong\ninterest in reinforcement learning in game playing. General Game Playing (GGP)\nprovides a good testbed for reinforcement learning. In GGP, a specification of\ngames rules is given. GGP problems can be solved by reinforcement learning.\nQ-learning is one of the canonical reinforcement learning methods, and has been\nused by (Banerjee & Stone, IJCAI 2007) in GGP. In this paper we implement\nQ-learning in GGP for three small-board games (Tic-Tac-Toe, Connect Four, Hex),\nto allow comparison to Banerjee et al. As expected, Q-learning converges,\nalthough much slower than MCTS. Borrowing an idea from MCTS, we enhance\nQ-learning with Monte Carlo Search, to give QM-learning. This enhancement\nimproves the performance of pure Q-learning. We believe that QM-learning can\nalso be used to improve performance of reinforcement learning further for\nlarger games, something which we will test in future work.", "category": "cs.AI"}, {"title": "Artificial intelligence and pediatrics: A synthetic mini review", "abstract": "The use of artificial intelligence intelligencein medicine can be traced back\nto 1968 when Paycha published his paper Le diagnostic a l'aide d'intelligences\nartificielle, presentation de la premiere machine diagnostri. Few years later\nShortliffe et al. presented an expert system named Mycin which was able to\nidentify bacteria causing severe blood infections and to recommend antibiotics.\nDespite the fact that Mycin outperformed members of the Stanford medical school\nin the reliability of diagnosis it was never used in practice due to a legal\nissue who do you sue if it gives a wrong diagnosis?. However only in 2016 when\nthe artificial intelligence software built into the IBM Watson AI platform\ncorrectly diagnosed and proposed an effective treatment for a 60-year-old\nwomans rare form of leukemia the AI use in medicine become really popular.On of\nfirst papers presenting the use of AI in paediatrics was published in 1984. The\npaper introduced a computer-assisted medical decision making system called\nSHELP.", "category": "cs.AI"}, {"title": "A Unified Framework for Planning in Adversarial and Cooperative Environments", "abstract": "Users of AI systems may rely upon them to produce plans for achieving desired\nobjectives. Such AI systems should be able to compute obfuscated plans whose\nexecution in adversarial situations protects privacy, as well as legible plans\nwhich are easy for team members to understand in cooperative situations. We\ndevelop a unified framework that addresses these dual problems by computing\nplans with a desired level of comprehensibility from the point of view of a\npartially informed observer. For adversarial settings, our approach produces\nobfuscated plans with observations that are consistent with at least k goals\nfrom a set of decoy goals. By slightly varying our framework, we present an\napproach for goal legibility in cooperative settings which produces plans that\nachieve a goal while being consistent with at most j goals from a set of\nconfounding goals. In addition, we show how the observability of the observer\ncan be controlled to either obfuscate or clarify the next actions in a plan\nwhen the goal is known to the observer. We present theoretical results on the\ncomplexity analysis of our problems. We demonstrate the execution of obfuscated\nand legible plans in a cooking domain using a physical robot Fetch. We also\nprovide an empirical evaluation to show the feasibility and usefulness of our\napproaches using IPC domains.", "category": "cs.AI"}, {"title": "HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under Uncertainty", "abstract": "Planning under uncertainty is critical for robust robot performance in\nuncertain, dynamic environments, but it incurs high computational cost.\nState-of-the-art online search algorithms, such as DESPOT, have vastly improved\nthe computational efficiency of planning under uncertainty and made it a\nvaluable tool for robotics in practice. This work takes one step further by\nleveraging both CPU and GPU parallelization in order to achieve near real-time\nonline planning performance for complex tasks with large state, action, and\nobservation spaces. Specifically, we propose Hybrid Parallel DESPOT\n(HyP-DESPOT), a massively parallel online planning algorithm that integrates\nCPU and GPU parallelism in a multi-level scheme. It performs parallel DESPOT\ntree search by simultaneously traversing multiple independent paths using\nmulti-core CPUs and performs parallel Monte-Carlo simulations at the leaf nodes\nof the search tree using GPUs. Experimental results show that HyP-DESPOT speeds\nup online planning by up to several hundred times, compared with the original\nDESPOT algorithm, in several challenging robotic tasks in simulation.", "category": "cs.AI"}, {"title": "Large Neighborhood-Based Metaheuristic and Branch-and-Price for the Pickup and Delivery Problem with Split Loads", "abstract": "We consider the multi-vehicle one-to-one pickup and delivery problem with\nsplit loads, a NP-hard problem linked with a variety of applications for bulk\nproduct transportation, bike-sharing systems and inventory re-balancing. This\nproblem is notoriously difficult due to the interaction of two challenging\nvehicle routing attributes, \"pickups and deliveries\" and \"split deliveries\".\nThis possibly leads to optimal solutions of a size that grows exponentially\nwith the instance size, containing multiple visits per customer pair, even in\nthe same route. To solve this problem, we propose an iterated local search\nmetaheuristic as well as a branch-and-price algorithm. The core of the\nmetaheuristic consists of a new large neighborhood search, which reduces the\nproblem of finding the best insertion combination of a pickup and delivery pair\ninto a route (with possible splits) to a resource-constrained shortest path and\nknapsack problem. Similarly, the branch-and-price algorithm uses sophisticated\nlabeling techniques, route relaxations, pre-processing and branching rules for\nan efficient resolution. Our computational experiments on classical\nsingle-vehicle instances demonstrate the excellent performance of the\nmetaheuristic, which produces new best known solutions for 92 out of 93 test\ninstances, and outperforms all previous algorithms. Experimental results on new\nmulti-vehicle instances with distance constraints are also reported. The\nbranch-and-price algorithm produces optimal solutions for instances with up to\n20 pickup-and-delivery pairs, and very accurate solutions are found by the\nmetaheuristic.", "category": "cs.AI"}, {"title": "A Machine Learning Approach to Air Traffic Route Choice Modelling", "abstract": "Air Traffic Flow and Capacity Management (ATFCM) is one of the constituent\nparts of Air Traffic Management (ATM). The goal of ATFCM is to make airport and\nairspace capacity meet traffic demand and, when capacity opportunities are\nexhausted, optimise traffic flows to meet the available capacity. One of the\nkey enablers of ATFCM is the accurate estimation of future traffic demand. The\navailable information (schedules, flight plans, etc.) and its associated level\nof uncertainty differ across the different ATFCM planning phases, leading to\nqualitative differences between the types of forecasting that are feasible at\neach time horizon. While abundant research has been conducted on tactical\ntrajectory prediction (i.e., during the day of operations), trajectory\nprediction in the pre-tactical phase, when few or no flight plans are\navailable, has received much less attention. As a consequence, the methods\ncurrently in use for pre-tactical traffic forecast are still rather\nrudimentary, often resulting in suboptimal ATFCM decision making. This paper\nproposes a machine learning approach for the prediction of airlines route\nchoices between two airports as a function of route characteristics, such as\nflight efficiency, air navigation charges and expected level of congestion.\nDifferent predictive models based on multinomial logistic regression and\ndecision trees are formulated and calibrated with historical traffic data, and\na critical evaluation of each model is conducted. We analyse the predictive\npower of each model in terms of its ability to forecast traffic volumes at the\nlevel of charging zones, proving significant potential to enhance pre-tactical\ntraffic forecast. We conclude by discussing the limitations and room for\nimprovement of the proposed approach, as well as the future developments\nrequired to produce reliable traffic forecasts at a higher spatial and temporal\nresolution.", "category": "cs.AI"}, {"title": "Learning High-level Representations from Demonstrations", "abstract": "Hierarchical learning (HL) is key to solving complex sequential decision\nproblems with long horizons and sparse rewards. It allows learning agents to\nbreak-up large problems into smaller, more manageable subtasks. A common\napproach to HL, is to provide the agent with a number of high-level skills that\nsolve small parts of the overall problem. A major open question, however, is\nhow to identify a suitable set of reusable skills. We propose a principled\napproach that uses human demonstrations to infer a set of subgoals based on\nchanges in the demonstration dynamics. Using these subgoals, we decompose the\nlearning problem into an abstract high-level representation and a set of\nlow-level subtasks. The abstract description captures the overall problem\nstructure, while subtasks capture desired skills. We demonstrate that we can\njointly optimize over both levels of learning. We show that the resulting\nmethod significantly outperforms previous baselines on two challenging\nproblems: the Atari 2600 game Montezuma's Revenge, and a simulated robotics\nproblem moving the ant robot through a maze.", "category": "cs.AI"}, {"title": "Analysis of cause-effect inference by comparing regression errors", "abstract": "We address the problem of inferring the causal direction between two\nvariables by comparing the least-squares errors of the predictions in both\npossible directions. Under the assumption of an independence between the\nfunction relating cause and effect, the conditional noise distribution, and the\ndistribution of the cause, we show that the errors are smaller in causal\ndirection if both variables are equally scaled and the causal relation is close\nto deterministic. Based on this, we provide an easily applicable algorithm that\nonly requires a regression in both possible causal directions and a comparison\nof the errors. The performance of the algorithm is compared with various\nrelated causal inference methods in different artificial and real-world data\nsets.", "category": "cs.AI"}, {"title": "The problem of the development ontology-driven architecture of intellectual software systems", "abstract": "The paper describes the architecture of the intelligence system for automated\ndesign of ontological knowledge bases of domain areas and the software model of\nthe management GUI (Graphical User Interface) subsystem", "category": "cs.AI"}, {"title": "Design and software implementation of subsystems for creating and using the ontological base of a research scientist", "abstract": "Creation of the information systems and tools for scientific research and\ndevelopment support has always been one of the central directions of the\ndevelopment of computer science. The main features of the modern evolution of\nscientific research and development are the transdisciplinary approach and the\ndeep intellectualisation of all stages of the life cycle of formulation and\nsolution of scientific problems. The theoretical and practical aspects of the\ndevelopment of perspective complex knowledge-oriented information systems and\ntheir components are considered in the paper. The analysis of existing\nscientific information systems (or current research information systems, CRIS)\nand synthesis of general principles of design of the research and development\nworkstation environment of a researcher and its components are carried out in\nthe work. The functional components of knowledge-oriented information system\nresearch and development workstation environment of a researcher are designed.\nDesigned and developed functional components of knowledge-oriented information\nsystem developing research and development workstation environment,including\nfunctional models and software implementation of the software subsystem for\ncreation and use of ontological knowledge base for research fellow\npublications, as part of personalized knowledge base of scientific researcher.\nResearch in modern conditions of e-Science paradigm requires pooling scientific\ncommunity and intensive exchange of research results that may be achieved\nthrough the use of scientific information systems. research and development\nworkstation environment allows to solve problems of contructivisation and\nformalisation of knowledge representation, obtained during the research process\nand collective accomplices interaction.", "category": "cs.AI"}, {"title": "Technique for designing a domain ontology", "abstract": "The article describes the technique for designing a domain ontology, shows\nthe flowchart of algorithm design and example of constructing a fragment of the\nontology of the subject area of Computer Science is considered.", "category": "cs.AI"}, {"title": "Integrated Tools for Engineering Ontologies", "abstract": "The article presents an overview of current specialized ontology engineering\ntools, as well as texts' annotation tools based on ontologies. The main\nfunctions and features of these tools, their advantages and disadvantages are\ndiscussed. A systematic comparative analysis of means for engineering\nontologies is presented.", "category": "cs.AI"}, {"title": "Principles of design and software development models of ontological-driven computer systems", "abstract": "This paper describes the design principles of methodology of\nknowledge-oriented information systems based on ontological approach. Such\nsystems implement technology subject-oriented extraction of knowledge from the\nset of natural language texts and their formal and logical presentation and\napplication processing", "category": "cs.AI"}, {"title": "Expert System for Diagnosis of Chest Diseases Using Neural Networks", "abstract": "This article represents one of the contemporary trends in the application of\nthe latest methods of information and communication technology for medicine\nthrough an expert system helps the doctor to diagnose some chest diseases which\nis important because of the frequent spread of chest diseases nowadays in\naddition to the overlap symptoms of these diseases, which is difficult to right\ndiagnose by doctors with several algorithms: Forward Chaining, Backward\nChaining, Neural Network(Back Propagation). However, this system cannot replace\nthe doctor function, but it can help the doctor to avoid wrong diagnosis and\ntreatments. It can also be developed in such a way to help the novice doctors.", "category": "cs.AI"}, {"title": "Automated Playtesting with Procedural Personas through MCTS with Evolved Heuristics", "abstract": "This paper describes a method for generative player modeling and its\napplication to the automatic testing of game content using archetypal player\nmodels called procedural personas. Theoretically grounded in psychological\ndecision theory, procedural personas are implemented using a variation of Monte\nCarlo Tree Search (MCTS) where the node selection criteria are developed using\nevolutionary computation, replacing the standard UCB1 criterion of MCTS. Using\nthese personas we demonstrate how generative player models can be applied to a\nvaried corpus of game levels and demonstrate how different play styles can be\nenacted in each level. In short, we use artificially intelligent personas to\nconstruct synthetic playtesters. The proposed approach could be used as a tool\nfor automatic play testing when human feedback is not readily available or when\nquick visualization of potential interactions is necessary. Possible\napplications include interactive tools during game development or procedural\ncontent generation systems where many evaluations must be conducted within a\nshort time span.", "category": "cs.AI"}, {"title": "Superrational types", "abstract": "We present a formal analysis of Douglas Hofstadter's concept of\n\\emph{superrationality}. We start by defining superrationally justifiable\nactions, and study them in symmetric games. We then model the beliefs of the\nplayers, in a way that leads them to different choices than the usual\nassumption of rationality by restricting the range of conceivable choices.\nThese beliefs are captured in the formal notion of \\emph{type} drawn from\nepistemic game theory. The theory of coalgebras is used to frame type spaces\nand to account for the existence of some of them. We find conditions that\nguarantee superrational outcomes.", "category": "cs.AI"}, {"title": "Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior Explanations", "abstract": "There is a growing interest within the AI research community to develop\nautonomous systems capable of explaining their behavior to users. One aspect of\nthe explanation generation problem that has yet to receive much attention is\nthe task of explaining plans to users whose level of expertise differ from that\nof the explainer. We propose an approach for addressing this problem by\nrepresenting the user's model as an abstraction of the domain model that the\nplanner uses. We present algorithms for generating minimal explanations in\ncases where this abstract human model is not known. We reduce the problem of\ngenerating explanation to a search over the space of abstract models and\ninvestigate possible greedy approximations for minimal explanations. We also\nempirically show that our approach can efficiently compute explanations for a\nvariety of problems.", "category": "cs.AI"}, {"title": "Using Automatic Generation of Relaxation Constraints to Improve the Preimage Attack on 39-step MD4", "abstract": "In this paper we construct preimage attack on the truncated variant of the\nMD4 hash function. Specifically, we study the MD4-39 function defined by the\nfirst 39 steps of the MD4 algorithm. We suggest a new attack on MD4-39, which\ndevelops the ideas proposed by H. Dobbertin in 1998. Namely, the special\nrelaxation constraints are introduced in order to simplify the equations\ncorresponding to the problem of finding a preimage for an arbitrary MD4-39 hash\nvalue. The equations supplemented with the relaxation constraints are then\nreduced to the Boolean Satisfiability Problem (SAT) and solved using the\nstate-of-the-art SAT solvers. We show that the effectiveness of a set of\nrelaxation constraints can be evaluated using the black-box function of a\nspecial kind. Thus, we suggest automatic method of relaxation constraints\ngeneration by applying the black-box optimization to this function. The\nproposed method made it possible to find new relaxation constraints that\ncontribute to a SAT-based preimage attack on MD4-39 which significantly\noutperforms the competition.", "category": "cs.AI"}, {"title": "Epistemic Graphs for Representing and Reasoning with Positive and Negative Influences of Arguments", "abstract": "This paper introduces epistemic graphs as a generalization of the epistemic\napproach to probabilistic argumentation. In these graphs, an argument can be\nbelieved or disbelieved up to a given degree, thus providing a more\nfine--grained alternative to the standard Dung's approaches when it comes to\ndetermining the status of a given argument. Furthermore, the flexibility of the\nepistemic approach allows us to both model the rationale behind the existing\nsemantics as well as completely deviate from them when required. Epistemic\ngraphs can model both attack and support as well as relations that are neither\nsupport nor attack. The way other arguments influence a given argument is\nexpressed by the epistemic constraints that can restrict the belief we have in\nan argument with a varying degree of specificity. The fact that we can specify\nthe rules under which arguments should be evaluated and we can include\nconstraints between unrelated arguments permits the framework to be more\ncontext--sensitive. It also allows for better modelling of imperfect agents,\nwhich can be important in multi--agent applications.", "category": "cs.AI"}, {"title": "Machine Theory of Mind", "abstract": "Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'\nability to represent the mental states of others, including their desires,\nbeliefs, and intentions. We propose to train a machine to build such models\ntoo. We design a Theory of Mind neural network -- a ToMnet -- which uses\nmeta-learning to build models of the agents it encounters, from observations of\ntheir behaviour alone. Through this process, it acquires a strong prior model\nfor agents' behaviour, as well as the ability to bootstrap to richer\npredictions about agents' characteristics and mental states using only a small\nnumber of behavioural observations. We apply the ToMnet to agents behaving in\nsimple gridworld environments, showing that it learns to model random,\nalgorithmic, and deep reinforcement learning agents from varied populations,\nand that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer &\nPerner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold\nfalse beliefs about the world. We argue that this system -- which autonomously\nlearns how to model other agents in its world -- is an important step forward\nfor developing multi-agent AI systems, for building intermediating technology\nfor machine-human interaction, and for advancing the progress on interpretable\nAI.", "category": "cs.AI"}, {"title": "Convergent Actor-Critic Algorithms Under Off-Policy Training and Function Approximation", "abstract": "We present the first class of policy-gradient algorithms that work with both\nstate-value and policy function-approximation, and are guaranteed to converge\nunder off-policy training. Our solution targets problems in reinforcement\nlearning where the action representation adds to the-curse-of-dimensionality;\nthat is, with continuous or large action sets, thus making it infeasible to\nestimate state-action value functions (Q functions). Using state-value\nfunctions helps to lift the curse and as a result naturally turn our\npolicy-gradient solution into classical Actor-Critic architecture whose Actor\nuses state-value function for the update. Our algorithms, Gradient Actor-Critic\nand Emphatic Actor-Critic, are derived based on the exact gradient of averaged\nstate-value function objective and thus are guaranteed to converge to its\noptimal solution, while maintaining all the desirable properties of classical\nActor-Critic methods with no additional hyper-parameters. To our knowledge,\nthis is the first time that convergent off-policy learning methods have been\nextended to classical Actor-Critic methods with function approximation.", "category": "cs.AI"}, {"title": "A Polynomial Time Subsumption Algorithm for Nominal Safe $\\mathcal{ELO}_\\bot$ under Rational Closure", "abstract": "Description Logics (DLs) under Rational Closure (RC) is a well-known\nframework for non-monotonic reasoning in DLs. In this paper, we address the\nconcept subsumption decision problem under RC for nominal safe\n$\\mathcal{ELO}_\\bot$, a notable and practically important DL representative of\nthe OWL 2 profile OWL 2 EL.\n  Our contribution here is to define a polynomial time subsumption procedure\nfor nominal safe $\\mathcal{ELO}_\\bot$ under RC that relies entirely on a series\nof classical, monotonic $\\mathcal{EL}_\\bot$ subsumption tests. Therefore, any\nexisting classical monotonic $\\mathcal{EL}_\\bot$ reasoner can be used as a\nblack box to implement our method. We then also adapt the method to one of the\nknown extensions of RC for DLs, namely Defeasible Inheritance-based DLs without\nlosing the computational tractability.", "category": "cs.AI"}, {"title": "On Looking for Local Expansion Invariants in Argumentation Semantics: a Preliminary Report", "abstract": "We study invariant local expansion operators for conflict-free and admissible\nsets in Abstract Argumentation Frameworks (AFs). Such operators are directly\napplied on AFs, and are invariant with respect to a chosen \"semantics\" (that is\nw.r.t. each of the conflict free/admissible set of arguments). Accordingly, we\nderive a definition of robustness for AFs in terms of the number of times such\noperators can be applied without producing any change in the chosen semantics.", "category": "cs.AI"}, {"title": "Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising", "abstract": "Real-time bidding (RTB) is an important mechanism in online display\nadvertising, where a proper bid for each page view plays an essential role for\ngood marketing results. Budget constrained bidding is a typical scenario in RTB\nwhere the advertisers hope to maximize the total value of the winning\nimpressions under a pre-set budget constraint. However, the optimal bidding\nstrategy is hard to be derived due to the complexity and volatility of the\nauction environment. To address these challenges, in this paper, we formulate\nbudget constrained bidding as a Markov Decision Process and propose a\nmodel-free reinforcement learning framework to resolve the optimization\nproblem. Our analysis shows that the immediate reward from environment is\nmisleading under a critical resource constraint. Therefore, we innovate a\nreward function design methodology for the reinforcement learning problems with\nconstraints. Based on the new reward design, we employ a deep neural network to\nlearn the appropriate reward so that the optimal policy can be learned\neffectively. Different from the prior model-based work, which suffers from the\nscalability problem, our framework is easy to be deployed in large-scale\nindustrial applications. The experimental evaluations demonstrate the\neffectiveness of our framework on large-scale real datasets.", "category": "cs.AI"}, {"title": "A Matrix Approach for Weighted Argumentation Frameworks: a Preliminary Report", "abstract": "The assignment of weights to attacks in a classical Argumentation Framework\nallows to compute semantics by taking into account the different importance of\neach argument. We represent a Weighted Argumentation Framework by a non-binary\nmatrix, and we characterize the basic extensions (such as w-admissible, w-\nstable, w-complete) by analysing sub-blocks of this matrix. Also, we show how\nto reduce the matrix into another one of smaller size, that is equivalent to\nthe original one for the determination of extensions. Furthermore, we provide\ntwo algorithms that allow to build incrementally w-grounded and w-preferred\nextensions starting from a w-admissible extension.", "category": "cs.AI"}, {"title": "Optimal Stochastic Delivery Planning in Full-Truckload and Less-Than-Truckload Delivery", "abstract": "With an increasing demand from emerging logistics businesses, Vehicle Routing\nProblem with Private fleet and common Carrier (VRPPC) has been introduced to\nmanage package delivery services from a supplier to customers. However, almost\nall of existing studies focus on the deterministic problem that assumes all\nparameters are known perfectly at the time when the planning and routing\ndecisions are made. In reality, some parameters are random and unknown.\nTherefore, in this paper, we consider VRPPC with hard time windows and random\ndemand, called Optimal Delivery Planning (ODP). The proposed ODP aims to\nminimize the total package delivery cost while meeting the customer time window\nconstraints. We use stochastic integer programming to formulate the\noptimization problem incorporating the customer demand uncertainty. Moreover,\nwe evaluate the performance of the ODP using test data from benchmark dataset\nand from actual Singapore road map.", "category": "cs.AI"}, {"title": "Semantic Vector Spaces for Broadening Consideration of Consequences", "abstract": "Reasoning systems with too simple a model of the world and human intent are\nunable to consider potential negative side effects of their actions and modify\ntheir plans to avoid them (e.g., avoiding potential errors). However,\nhand-encoding the enormous and subtle body of facts that constitutes common\nsense into a knowledge base has proved too difficult despite decades of work.\nDistributed semantic vector spaces learned from large text corpora, on the\nother hand, can learn representations that capture shades of meaning of\ncommon-sense concepts and perform analogical and associational reasoning in\nways that knowledge bases are too rigid to perform, by encoding concepts and\nthe relations between them as geometric structures. These have, however, the\ndisadvantage of being unreliable, poorly understood, and biased in their view\nof the world by the source material. This chapter will discuss how these\napproaches may be combined in a way that combines the best properties of each\nfor understanding the world and human intentions in a richer way.", "category": "cs.AI"}, {"title": "Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration", "abstract": "Reinforcement learning (RL) agents improve through trial-and-error, but when\nreward is sparse and the agent cannot discover successful action sequences,\nlearning stagnates. This has been a notable problem in training deep RL agents\nto perform web-based tasks, such as booking flights or replying to emails,\nwhere a single mistake can ruin the entire sequence of actions. A common remedy\nis to \"warm-start\" the agent by pre-training it to mimic expert demonstrations,\nbut this is prone to overfitting. Instead, we propose to constrain exploration\nusing demonstrations. From each demonstration, we induce high-level \"workflows\"\nwhich constrain the allowable actions at each time step to be similar to those\nin the demonstration (e.g., \"Step 1: click on a textbox; Step 2: enter some\ntext\"). Our exploration policy then learns to identify successful workflows and\nsamples actions that satisfy these workflows. Workflows prune out bad\nexploration directions and accelerate the agent's ability to discover rewards.\nWe use our approach to train a novel neural policy designed to handle the\nsemi-structured nature of websites, and evaluate on a suite of web tasks,\nincluding the recent World of Bits benchmark. We achieve new state-of-the-art\nresults, and show that workflow-guided exploration improves sample efficiency\nover behavioral cloning by more than 100x.", "category": "cs.AI"}, {"title": "PSO-based Fuzzy Markup Language for Student Learning Performance Evaluation and Educational Application", "abstract": "This paper proposes an agent with particle swarm optimization (PSO) based on\na Fuzzy Markup Language (FML) for students learning performance evaluation and\neducational applications, and the proposed agent is according to the response\ndata from a conventional test and an item response theory. First, we apply a\nGS-based parameter estimation mechanism to estimate the items parameters\naccording to the response data, and then to compare its results with those of\nan IRT-based Bayesian parameter estimation mechanism. In addition, we propose a\nstatic-IRT test assembly mechanism to assemble a form for the conventional\ntest. The presented FML-based dynamic assessment mechanism infers the\nprobability of making a correct response to the item for a student with various\nabilities. Moreover, this paper also proposes a novel PFML learning mechanism\nfor optimizing the parameters between items and students. Finally, we adopt a\nK-fold cross validation mechanism to evaluate the performance of the proposed\nagent. Experimental results show that the novel PFML learning mechanism for the\nparameter estimation and learning optimization performs favorably. We believe\nthe proposed PFML will be a reference for education research and pedagogy and\nan important co-learning mechanism for future human-machine educational\napplications.", "category": "cs.AI"}, {"title": "One Big Net For Everything", "abstract": "I apply recent work on \"learning to think\" (2015) and on PowerPlay (2011) to\nthe incremental training of an increasingly general problem solver, continually\nlearning to solve new tasks without forgetting previous skills. The problem\nsolver is a single recurrent neural network (or similar general purpose\ncomputer) called ONE. ONE is unusual in the sense that it is trained in various\nways, e.g., by black box optimization / reinforcement learning / artificial\nevolution as well as supervised / unsupervised learning. For example, ONE may\nlearn through neuroevolution to control a robot through environment-changing\nactions, and learn through unsupervised gradient descent to predict future\ninputs and vector-valued reward signals as suggested in 1990. User-given tasks\ncan be defined through extra goal-defining input patterns, also proposed in\n1990. Suppose ONE has already learned many skills. Now a copy of ONE can be\nre-trained to learn a new skill, e.g., through neuroevolution without a\nteacher. Here it may profit from re-using previously learned subroutines, but\nit may also forget previous skills. Then ONE is retrained in PowerPlay style\n(2011) on stored input/output traces of (a) ONE's copy executing the new skill\nand (b) previous instances of ONE whose skills are still considered worth\nmemorizing. Simultaneously, ONE is retrained on old traces (even those of\nunsuccessful trials) to become a better predictor, without additional expensive\ninteraction with the enviroment. More and more control and prediction skills\nare thus collapsed into ONE, like in the chunker-automatizer system of the\nneural history compressor (1991). This forces ONE to relate partially analogous\nskills (with shared algorithmic information) to each other, creating common\nsubroutines in form of shared subnetworks of ONE, to greatly speed up\nsubsequent learning of additional, novel but algorithmically related skills.", "category": "cs.AI"}, {"title": "Prototyping Virtual Reality Serious Games for Building Earthquake Preparedness: The Auckland City Hospital Case Study", "abstract": "Enhancing evacuee safety is a key factor in reducing the number of injuries\nand deaths that result from earthquakes. One way this can be achieved is by\ntraining occupants. Virtual Reality (VR) and Serious Games (SGs), represent\nnovel techniques that may overcome the limitations of traditional training\napproaches. VR and SGs have been examined in the fire emergency context,\nhowever, their application to earthquake preparedness has not yet been\nextensively examined. We provide a theoretical discussion of the advantages and\nlimitations of using VR SGs to investigate how building occupants behave during\nearthquake evacuations and to train building occupants to cope with such\nemergencies. We explore key design components for developing a VR SG framework:\n(a) what features constitute an earthquake event, (b) which building types can\nbe selected and represented within the VR environment, (c) how damage to the\nbuilding can be determined and represented, (d) how non-player characters (NPC)\ncan be designed, and (e) what level of interaction there can be between NPC and\nthe human participants. We illustrate the above by presenting the Auckland City\nHospital, New Zealand as a case study, and propose a possible VR SG training\ntool to enhance earthquake preparedness in public buildings.", "category": "cs.AI"}, {"title": "Antifragility for Intelligent Autonomous Systems", "abstract": "Antifragile systems grow measurably better in the presence of hazards. This\nis in contrast to fragile systems which break down in the presence of hazards,\nrobust systems that tolerate hazards up to a certain degree, and resilient\nsystems that -- like self-healing systems -- revert to their earlier expected\nbehavior after a period of convalescence. The notion of antifragility was\nintroduced by Taleb for economics systems, but its applicability has been\nillustrated in biological and engineering domains as well. In this paper, we\npropose an architecture that imparts antifragility to intelligent autonomous\nsystems, specifically those that are goal-driven and based on AI-planning. We\nargue that this architecture allows the system to self-improve by uncovering\nnew capabilities obtained either through the hazards themselves (opportunistic)\nor through deliberation (strategic). An AI planning-based case study of an\nautonomous wheeled robot is presented. We show that with the proposed\narchitecture, the robot develops antifragile behaviour with respect to an oil\nspill hazard.", "category": "cs.AI"}, {"title": "A Multi-Disciplinary Review of Knowledge Acquisition Methods: From Human to Autonomous Eliciting Agents", "abstract": "This paper offers a multi-disciplinary review of knowledge acquisition\nmethods in human activity systems. The review captures the degree of\ninvolvement of various types of agencies in the knowledge acquisition process,\nand proposes a classification with three categories of methods: the human\nagent, the human-inspired agent, and the autonomous machine agent methods. In\nthe first two categories, the acquisition of knowledge is seen as a cognitive\ntask analysis exercise, while in the third category knowledge acquisition is\ntreated as an autonomous knowledge-discovery endeavour. The motivation for this\nclassification stems from the continuous change over time of the structure,\nmeaning and purpose of human activity systems, which are seen as the factor\nthat fuelled researchers' and practitioners' efforts in knowledge acquisition\nfor more than a century.\n  We show through this review that the KA field is increasingly active due to\nthe higher and higher pace of change in human activity, and conclude by\ndiscussing the emergence of a fourth category of knowledge acquisition methods,\nwhich are based on red-teaming and co-evolution.", "category": "cs.AI"}, {"title": "Human-in-the-Loop Synthesis for Partially Observable Markov Decision Processes", "abstract": "We study planning problems where autonomous agents operate inside\nenvironments that are subject to uncertainties and not fully observable.\nPartially observable Markov decision processes (POMDPs) are a natural formal\nmodel to capture such problems. Because of the potentially huge or even\ninfinite belief space in POMDPs, synthesis with safety guarantees is, in\ngeneral, computationally intractable. We propose an approach that aims to\ncircumvent this difficulty: in scenarios that can be partially or fully\nsimulated in a virtual environment, we actively integrate a human user to\ncontrol an agent. While the user repeatedly tries to safely guide the agent in\nthe simulation, we collect data from the human input. Via behavior cloning, we\ntranslate the data into a strategy for the POMDP. The strategy resolves all\nnondeterminism and non-observability of the POMDP, resulting in a discrete-time\nMarkov chain (MC). The efficient verification of this MC gives quantitative\ninsights into the quality of the inferred human strategy by proving or\ndisproving given system specifications. For the case that the quality of the\nstrategy is not sufficient, we propose a refinement method using\ncounterexamples presented to the human. Experiments show that by including\nhumans into the POMDP verification loop we improve the state of the art by\norders of magnitude in terms of scalability.", "category": "cs.AI"}, {"title": "Introduction to the SP theory of intelligence", "abstract": "This article provides a brief introduction to the \"Theory of Intelligence\"\nand its realisation in the \"SP Computer Model\". The overall goal of the SP\nprogramme of research, in accordance with long-established principles in\nscience, has been the simplification and integration of observations and\nconcepts across artificial intelligence, mainstream computing, mathematics, and\nhuman learning, perception, and cognition. In broad terms, the SP system is a\nbrain-like system that takes in \"New\" information through its senses and stores\nsome or all of it as \"Old\" information. A central idea in the system is the\npowerful concept of \"SP-multiple-alignment\", borrowed and adapted from\nbioinformatics. This the key to the system's versatility in aspects of\nintelligence, in the representation of diverse kinds of knowledge, and in the\nseamless integration of diverse aspects of intelligence and diverse kinds of\nknowledge, in any combination. There are many potential benefits and\napplications of the SP system. It is envisaged that the system will be\ndeveloped as the \"SP Machine\", which will initially be a software virtual\nmachine, hosted on a high-performance computer, a vehicle for further research\nand a step towards the development of an industrial-strength SP Machine.", "category": "cs.AI"}, {"title": "Domain Modelling in Computational Persuasion for Behaviour Change in Healthcare", "abstract": "The aim of behaviour change is to help people to change aspects of their\nbehaviour for the better (e.g., to decrease calorie intake, to drink in\nmoderation, to take more exercise, to complete a course of antibiotics once\nstarted, etc.). In current persuasion technology for behaviour change, the\nemphasis is on helping people to explore their issues (e.g., through\nquestionnaires or game playing) or to remember to follow a behaviour change\nplan (e.g., diaries and email reminders). However, recent developments in\ncomputational persuasion are leading to an argument-centric approach to\npersuasion that can potentially be harnessed in behaviour change applications.\nIn this paper, we review developments in computational persuasion, and then\nfocus on domain modelling as a key component. We present a multi-dimensional\napproach to domain modelling. At the core of this proposal is an ontology which\nprovides a representation of key factors, in particular kinds of belief, which\nwe have identified in the behaviour change literature as being important in\ndiverse behaviour change initiatives. Our proposal for domain modelling is\nintended to facilitate the acquisition and representation of the arguments that\ncan be used in persuasion dialogues, together with meta-level information about\nthem which can be used by the persuader to make strategic choices of argument\nto present.", "category": "cs.AI"}, {"title": "Selective Experience Replay for Lifelong Learning", "abstract": "Deep reinforcement learning has emerged as a powerful tool for a variety of\nlearning tasks, however deep nets typically exhibit forgetting when learning\nmultiple tasks in sequence. To mitigate forgetting, we propose an experience\nreplay process that augments the standard FIFO buffer and selectively stores\nexperiences in a long-term memory. We explore four strategies for selecting\nwhich experiences will be stored: favoring surprise, favoring reward, matching\nthe global training distribution, and maximizing coverage of the state space.\nWe show that distribution matching successfully prevents catastrophic\nforgetting, and is consistently the best approach on all domains tested. While\ndistribution matching has better and more consistent performance, we identify\none case in which coverage maximization is beneficial - when tasks that receive\nless trained are more important. Overall, our results show that selective\nexperience replay, when suitable selection algorithms are employed, can prevent\ncatastrophic forgetting.", "category": "cs.AI"}, {"title": "General Video Game AI: a Multi-Track Framework for Evaluating Agents, Games and Content Generation Algorithms", "abstract": "General Video Game Playing (GVGP) aims at designing an agent that is capable\nof playing multiple video games with no human intervention. In 2014, The\nGeneral Video Game AI (GVGAI) competition framework was created and released\nwith the purpose of providing researchers a common open-source and easy to use\nplatform for testing their AI methods with potentially infinity of games\ncreated using Video Game Description Language (VGDL). The framework has been\nexpanded into several tracks during the last few years to meet the demand of\ndifferent research directions. The agents are required either to play multiple\nunknown games with or without access to game simulations, or to design new game\nlevels or rules. This survey paper presents the VGDL, the GVGAI framework,\nexisting tracks, and reviews the wide use of GVGAI framework in research,\neducation and competitions five years after its birth. A future plan of\nframework improvements is also described.", "category": "cs.AI"}, {"title": "Deep Reinforcement Learning for Sponsored Search Real-time Bidding", "abstract": "Bidding optimization is one of the most critical problems in online\nadvertising. Sponsored search (SS) auction, due to the randomness of user query\nbehavior and platform nature, usually adopts keyword-level bidding strategies.\nIn contrast, the display advertising (DA), as a relatively simpler scenario for\nauction, has taken advantage of real-time bidding (RTB) to boost the\nperformance for advertisers. In this paper, we consider the RTB problem in\nsponsored search auction, named SS-RTB. SS-RTB has a much more complex dynamic\nenvironment, due to stochastic user query behavior and more complex bidding\npolicies based on multiple keywords of an ad. Most previous methods for DA\ncannot be applied. We propose a reinforcement learning (RL) solution for\nhandling the complex dynamic environment. Although some RL methods have been\nproposed for online advertising, they all fail to address the \"environment\nchanging\" problem: the state transition probabilities vary between two days.\nMotivated by the observation that auction sequences of two days share similar\ntransition patterns at a proper aggregation level, we formulate a robust MDP\nmodel at hour-aggregation level of the auction data and propose a\ncontrol-by-model framework for SS-RTB. Rather than generating bid prices\ndirectly, we decide a bidding model for impressions of each hour and perform\nreal-time bidding accordingly. We also extend the method to handle the\nmulti-agent problem. We deployed the SS-RTB system in the e-commerce search\nauction platform of Alibaba. Empirical experiments of offline evaluation and\nonline A/B test demonstrate the effectiveness of our method.", "category": "cs.AI"}, {"title": "Composable Planning with Attributes", "abstract": "The tasks that an agent will need to solve often are not known during\ntraining. However, if the agent knows which properties of the environment are\nimportant then, after learning how its actions affect those properties, it may\nbe able to use this knowledge to solve complex tasks without training\nspecifically for them. Towards this end, we consider a setup in which an\nenvironment is augmented with a set of user defined attributes that\nparameterize the features of interest. We propose a method that learns a policy\nfor transitioning between \"nearby\" sets of attributes, and maintains a graph of\npossible transitions. Given a task at test time that can be expressed in terms\nof a target set of attributes, and a current state, our model infers the\nattributes of the current state and searches over paths through attribute space\nto get a high level plan, and then uses its low level policy to execute the\nplan. We show in 3D block stacking, grid-world games, and StarCraft that our\nmodel is able to generalize to longer, more complex tasks at test time by\ncomposing simpler learned policies.", "category": "cs.AI"}, {"title": "Knowledge Base Relation Detection via Multi-View Matching", "abstract": "Relation detection is a core component for Knowledge Base Question Answering\n(KBQA). In this paper, we propose a KB relation detection model via multi-view\nmatching which utilizes more useful information extracted from question and KB.\nThe matching inside each view is through multiple perspectives to compare two\ninput texts thoroughly. All these components are designed in an end-to-end\ntrainable neural network model. Experiments on SimpleQuestions and WebQSP yield\nstate-of-the-art results.", "category": "cs.AI"}, {"title": "Estimating Total Search Space Size for Specific Piece Sets in Chess", "abstract": "Automatic chess problem or puzzle composition typically involves generating\nand testing various different positions, sometimes using particular piece sets.\nOnce a position has been generated, it is then usually tested for positional\nlegality based on the game rules. However, it is useful to be able to estimate\nwhat the search space size for particular piece combinations is to begin with.\nSo if a desirable chess problem was successfully generated by examining\n'merely' 100,000 or so positions in a theoretical search space of about 100\nbillion, this would imply the composing approach used was quite viable and\nperhaps even impressive. In this article, I explain a method of calculating the\nsize of this search space using a combinatorics and permutations approach.\nWhile the mathematics itself may already be established, a precise method and\njustification of applying it with regard to the chessboard and chess pieces has\nnot been documented, to the best of our knowledge. Additionally, the method\ncould serve as a useful starting point for further estimations of search space\nsize which filter out positions for legality and rotation, depending on how the\nautomatic composer is allowed to place pieces on the board (because this\naffects its total search space size).", "category": "cs.AI"}, {"title": "Multi-Agent Imitation Learning for Driving Simulation", "abstract": "Simulation is an appealing option for validating the safety of autonomous\nvehicles. Generative Adversarial Imitation Learning (GAIL) has recently been\nshown to learn representative human driver models. These human driver models\nwere learned through training in single-agent environments, but they have\ndifficulty in generalizing to multi-agent driving scenarios. We argue these\ndifficulties arise because observations at training and test time are sampled\nfrom different distributions. This difference makes such models unsuitable for\nthe simulation of driving scenes, where multiple agents must interact\nrealistically over long time horizons. We extend GAIL to address these\nshortcomings through a parameter-sharing approach grounded in curriculum\nlearning. Compared with single-agent GAIL policies, policies generated by our\nPS-GAIL method prove superior at interacting stably in a multi-agent setting\nand capturing the emergent behavior of human drivers.", "category": "cs.AI"}, {"title": "Analyzing Business Process Anomalies Using Autoencoders", "abstract": "Businesses are naturally interested in detecting anomalies in their internal\nprocesses, because these can be indicators for fraud and inefficiencies. Within\nthe domain of business intelligence, classic anomaly detection is not very\nfrequently researched. In this paper, we propose a method, using autoencoders,\nfor detecting and analyzing anomalies occurring in the execution of a business\nprocess. Our method does not rely on any prior knowledge about the process and\ncan be trained on a noisy dataset already containing the anomalies. We\ndemonstrate its effectiveness by evaluating it on 700 different datasets and\ntesting its performance against three state-of-the-art anomaly detection\nmethods. This paper is an extension of our previous work from 2016 [30].\nCompared to the original publication we have further refined the approach in\nterms of performance and conducted an elaborate evaluation on more\nsophisticated datasets including real-life event logs from the Business Process\nIntelligence Challenges of 2012 and 2017. In our experiments our approach\nreached an F1 score of 0.87, whereas the best unaltered state-of-the-art\napproach reached an F1 score of 0.72. Furthermore, our approach can be used to\nanalyze the detected anomalies in terms of which event within one execution of\nthe process causes the anomaly.", "category": "cs.AI"}, {"title": "Some Considerations on Learning to Explore via Meta-Reinforcement Learning", "abstract": "We consider the problem of exploration in meta reinforcement learning. Two\nnew meta reinforcement learning algorithms are suggested: E-MAML and\nE-$\\text{RL}^2$. Results are presented on a novel environment we call `Krazy\nWorld' and a set of maze environments. We show E-MAML and E-$\\text{RL}^2$\ndeliver better performance on tasks where exploration is important.", "category": "cs.AI"}, {"title": "A Swift Heuristic Method for Work Order Scheduling under the Skilled-Workforce Constraint", "abstract": "The considered problem is how to optimally allocate a set of jobs to\ntechnicians of different skills such that the number of technicians of each\nskill does not exceed the number of persons with that skill designation. The\nkey motivation is the quick sensitivity analysis in terms of the workforce size\nwhich is quite necessary in many industries in the presence of unexpected work\norders. A time-indexed mathematical model is proposed to minimize the total\nweighted completion time of the jobs. The proposed model is decomposed into a\nnumber of single-skill sub-problems so that each one is a combination of a\nseries of nested binary Knapsack problems. A heuristic procedure is proposed to\nsolve the problem. Our experimental results, based on a real-world case study,\nreveal that the proposed method quickly produces a schedule statistically close\nto the optimal one while the classical optimal procedure is very\ntime-consuming.", "category": "cs.AI"}, {"title": "Exploring Novel Game Spaces with Fluidic Games", "abstract": "With the growing integration of smartphones into our daily lives, and their\nincreased ease of use, mobile games have become highly popular across all\ndemographics. People listen to music, play games or read the news while in\ntransit or bridging gap times. While mobile gaming is gaining popularity,\nmobile expression of creativity is still in its early stages. We present here a\nnew type of mobile app -- fluidic games -- and illustrate our iterative\napproach to their design. This new type of app seamlessly integrates\nexploration of the design space into the actual user experience of playing the\ngame, and aims to enrich the user experience. To better illustrate the game\ndomain and our approach, we discuss one specific fluidic game, which is\navailable as a commercial product. We also briefly discuss open challenges such\nas player support and how generative techniques can aid the exploration of the\ngame space further.", "category": "cs.AI"}, {"title": "A real-time decision support system for bridge management based on the rules generalized by CART decision tree and SMO algorithms", "abstract": "Under dynamic conditions on bridges, we need a real-time management. To this\nend, this paper presents a rule-based decision support system in which the\nnecessary rules are extracted from simulation results made by Aimsun traffic\nmicro-simulation software. Then, these rules are generalized by the aid of\nfuzzy rule generation algorithms. Then, they are trained by a set of supervised\nand the unsupervised learning algorithms to get an ability to make decision in\nreal cases. As a pilot case study, Nasr Bridge in Tehran is simulated in Aimsun\nand WEKA data mining software is used to execute the learning algorithms. Based\non this experiment, the accuracy of the supervised algorithms to generalize the\nrules is greater than 80%. In addition, CART decision tree and sequential\nminimal optimization (SMO) provides 100% accuracy for normal data and these\nalgorithms are so reliable for crisis management on bridge. This means that, it\nis possible to use such machine learning methods to manage bridges in the\nreal-time conditions.", "category": "cs.AI"}, {"title": "Explanatory relations in arbitrary logics based on satisfaction systems, cutting and retraction", "abstract": "The aim of this paper is to introduce a new framework for defining abductive\nreasoning operators based on a notion of retraction in arbitrary logics defined\nas satisfaction systems. We show how this framework leads to the design of\nexplanatory relations satisfying properties of abductive reasoning, and discuss\nits application to several logics. This extends previous work on propositional\nlogics where retraction was defined as a morphological erosion. Here weaker\nproperties are required for retraction, leading to a larger set of suitable\noperators for abduction for different logics.", "category": "cs.AI"}, {"title": "A Genetic Programming Framework for 2D Platform AI", "abstract": "There currently exists a wide range of techniques to model and evolve\nartificial players for games. Existing techniques range from black box neural\nnetworks to entirely hand-designed solutions. In this paper, we demonstrate the\nfeasibility of a genetic programming framework using human controller input to\nderive meaningful artificial players which can, later on, be optimised by hand.\nThe current state of the art in game character design relies heavily on human\ndesigners to manually create and edit scripts and rules for game characters. To\naddress this manual editing bottleneck, current computational intelligence\ntechniques approach the issue with fully autonomous character generators,\nreplacing most of the design process using black box solutions such as neural\nnetworks or the like. Our GP approach to this problem creates character\ncontrollers which can be further authored and developed by a designer it also\noffers designers to included their play style without the need to use a\nprogramming language. This keeps the designer in the loop while reducing\nrepetitive manual labour. Our system also provides insights into how players\nexpress themselves in games and into deriving appropriate models for\nrepresenting those insights. We present our framework, supporting findings and\nopen challenges.", "category": "cs.AI"}, {"title": "New Ideas for Brain Modelling 5", "abstract": "This paper describes a process for combining patterns and features, to guide\na search process and make predictions. It is based on the functionality that a\nhuman brain might have, which is a highly distributed network of simple\nneuronal components that can apply some level of matching and cross-referencing\nover retrieved patterns. The process uses memory in a dynamic way and it is\ndirected through the pattern matching. The paper firstly describes the\nmechanisms for neuronal search, memory and prediction. The paper then presents\na formal language for defining cognitive processes, that is, pattern-based\nsequences and transitions. The language can define an outer framework for\nconcept sets that are linked to perform the cognitive act. The language also\nhas a mathematical basis, allowing for the rule construction to be consistent.\nNow, both static memory and dynamic process hierarchies can be built as tree\nstructures. The new information can also be used to further integrate the\ncognitive model and the ensemble-hierarchy structure becomes an essential part.\nA theory about linking can suggest that nodes in different regions link\ntogether when generally they represent the same thing.", "category": "cs.AI"}, {"title": "Intent-aware Multi-agent Reinforcement Learning", "abstract": "This paper proposes an intent-aware multi-agent planning framework as well as\na learning algorithm. Under this framework, an agent plans in the goal space to\nmaximize the expected utility. The planning process takes the belief of other\nagents' intents into consideration. Instead of formulating the learning problem\nas a partially observable Markov decision process (POMDP), we propose a simple\nbut effective linear function approximation of the utility function. It is\nbased on the observation that for humans, other people's intents will pose an\ninfluence on our utility for a goal. The proposed framework has several major\nadvantages: i) it is computationally feasible and guaranteed to converge. ii)\nIt can easily integrate existing intent prediction and low-level planning\nalgorithms. iii) It does not suffer from sparse feedbacks in the action space.\nWe experiment our algorithm in a real-world problem that is non-episodic, and\nthe number of agents and goals can vary over time. Our algorithm is trained in\na scene in which aerial robots and humans interact, and tested in a novel scene\nwith a different environment. Experimental results show that our algorithm\nachieves the best performance and human-like behaviors emerge during the\ndynamic process.", "category": "cs.AI"}, {"title": "Discovering Underlying Plans Based on Shallow Models", "abstract": "Plan recognition aims to discover target plans (i.e., sequences of actions)\nbehind observed actions, with history plan libraries or domain models in hand.\nPrevious approaches either discover plans by maximally \"matching\" observed\nactions to plan libraries, assuming target plans are from plan libraries, or\ninfer plans by executing domain models to best explain the observed actions,\nassuming that complete domain models are available. In real world applications,\nhowever, target plans are often not from plan libraries, and complete domain\nmodels are often not available, since building complete sets of plans and\ncomplete domain models are often difficult or expensive. In this paper we view\nplan libraries as corpora and learn vector representations of actions using the\ncorpora, we then discover target plans based on the vector representations.\nSpecifically, we propose two approaches, DUP and RNNPlanner, to discover target\nplans based on vector representations of actions. DUP explores the EM-style\nframework to capture local contexts of actions and discover target plans by\noptimizing the probability of target plans, while RNNPlanner aims to leverage\nlong-short term contexts of actions based on RNNs (recurrent neural networks)\nframework to help recognize target plans. In the experiments, we empirically\nshow that our approaches are capable of discovering underlying plans that are\nnot from plan libraries, without requiring domain models provided. We\ndemonstrate the effectiveness of our approaches by comparing its performance to\ntraditional plan recognition approaches in three planning domains. We also\ncompare DUP and RNNPlanner to see their advantages and disadvantages.", "category": "cs.AI"}, {"title": "Decision-making processes in the Cognitive Theory of True Conditions", "abstract": "The Cognitive Theory of True Conditions (CTTC) is a proposal to design the\nimplementation of cognitive abilities and to describe the model-theoretic\nsemantics of symbolic cognitive architectures. The CTTC is formulated\nmathematically using the multi-optional many-sorted past present future(MMPPF)\nstructures. This article discussed how decision-making processes are described\nin the CTTC.", "category": "cs.AI"}, {"title": "OntoWind: An Improved and Extended Wind Energy Ontology", "abstract": "Ontologies are critical sources of semantic information for many application\ndomains. Hence, there are ontologies proposed and utilized for domains such as\nmedicine, chemical engineering, and electrical energy. In this paper, we\npresent an improved and extended version of a wind energy ontology previously\nproposed. First, the ontology is restructured to increase its understandability\nand coverage. Secondly, it is enriched with new concepts, crisp/fuzzy\nattributes, and instances to increase its usability in semantic applications\nregarding wind energy. The ultimate ontology is utilized within a Web-based\nsemantic portal application for wind energy, in order to showcase its\ncontribution in a genuine application. Hence, the current study is a\nsignificant to wind and thereby renewable energy informatics, with the\npresented publicly-available wind energy ontology and the implemented\nproof-of-concept system.", "category": "cs.AI"}, {"title": "A Brandom-ian view of Reinforcement Learning towards strong-AI", "abstract": "The analytic philosophy of Robert Brandom, based on the ideas of pragmatism,\npaints a picture of sapience, through inferentialism. In this paper, we present\na theory, that utilizes essential elements of Brandom's philosophy, towards the\nobjective of achieving strong-AI. We do this by connecting the constitutive\nelements of reinforcement learning and the Game Of Giving and Asking For\nReasons. Further, following Brandom's prescriptive thoughts, we restructure the\npopular reinforcement learning algorithm A3C, and show that RL algorithms can\nbe tuned towards the objective of strong-AI.", "category": "cs.AI"}, {"title": "SA-IGA: A Multiagent Reinforcement Learning Method Towards Socially Optimal Outcomes", "abstract": "In multiagent environments, the capability of learning is important for an\nagent to behave appropriately in face of unknown opponents and dynamic\nenvironment. From the system designer's perspective, it is desirable if the\nagents can learn to coordinate towards socially optimal outcomes, while also\navoiding being exploited by selfish opponents. To this end, we propose a novel\ngradient ascent based algorithm (SA-IGA) which augments the basic\ngradient-ascent algorithm by incorporating social awareness into the policy\nupdate process. We theoretically analyze the learning dynamics of SA-IGA using\ndynamical system theory and SA-IGA is shown to have linear dynamics for a wide\nrange of games including symmetric games. The learning dynamics of two\nrepresentative games (the prisoner's dilemma game and the coordination game)\nare analyzed in details. Based on the idea of SA-IGA, we further propose a\npractical multiagent learning algorithm, called SA-PGA, based on Q-learning\nupdate rule. Simulation results show that SA-PGA agent can achieve higher\nsocial welfare than previous social-optimality oriented Conditional Joint\nAction Learner (CJAL) and also is robust against individually rational\nopponents by reaching Nash equilibrium solutions.", "category": "cs.AI"}, {"title": "Compositional Attention Networks for Machine Reasoning", "abstract": "We present the MAC network, a novel fully differentiable neural network\narchitecture, designed to facilitate explicit and expressive reasoning. MAC\nmoves away from monolithic black-box neural architectures towards a design that\nencourages both transparency and versatility. The model approaches problems by\ndecomposing them into a series of attention-based reasoning steps, each\nperformed by a novel recurrent Memory, Attention, and Composition (MAC) cell\nthat maintains a separation between control and memory. By stringing the cells\ntogether and imposing structural constraints that regulate their interaction,\nMAC effectively learns to perform iterative reasoning processes that are\ndirectly inferred from the data in an end-to-end approach. We demonstrate the\nmodel's strength, robustness and interpretability on the challenging CLEVR\ndataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy,\nhalving the error rate of the previous best model. More importantly, we show\nthat the model is computationally-efficient and data-efficient, in particular\nrequiring 5x less data than existing models to achieve strong results.", "category": "cs.AI"}, {"title": "Concise Fuzzy Planar Embedding of Graphs: a Dimensionality Reduction Approach", "abstract": "The enormous amount of data to be represented using large graphs exceeds in\nsome cases the resources of a conventional computer. Edges in particular can\ntake up a considerable amount of memory as compared to the number of nodes.\nHowever, rigorous edge storage might not always be essential to be able to draw\nthe needed conclusions. A similar problem takes records with many variables and\nattempts to extract the most discernible features. It is said that the\n``dimension'' of this data is reduced. Following an approach with the same\nobjective in mind, we can map a graph representation to a $k$-dimensional space\nand answer queries of neighboring nodes mainly by measuring Euclidean\ndistances. The accuracy of our answers would decrease but would be compensated\nfor by fuzzy logic which gives an idea about the likelihood of error. This\nmethod allows for reasonable representation in memory while maintaining a fair\namount of useful information, and allows for concise embedding in\n$k$-dimensional Euclidean space as well as solving some problems without having\nto decompress the graph. Of particular interest is the case where $k=2$.\nPromising highly accurate experimental results are obtained and reported.", "category": "cs.AI"}, {"title": "Institutional Metaphors for Designing Large-Scale Distributed AI versus AI Techniques for Running Institutions", "abstract": "Artificial Intelligence (AI) started out with an ambition to reproduce the\nhuman mind, but, as the sheer scale of that ambition became manifest, it\nquickly retreated into either studying specialized intelligent behaviours, or\nproposing over-arching architectural concepts for interfacing specialized\nintelligent behaviour components, conceived of as agents in a kind of\norganization. This agent-based modeling paradigm, in turn, proves to have\ninteresting applications in understanding, simulating, and predicting the\nbehaviour of social and legal structures on an aggregate level. For these\nreasons, this chapter examines a number of relevant cross-cutting concerns,\nconceptualizations, modeling problems and design challenges in large-scale\ndistributed Artificial Intelligence, as well as in institutional systems, and\nidentifies potential grounds for novel advances.", "category": "cs.AI"}, {"title": "Highly Automated Learning for Improved Active Safety of Vulnerable Road Users", "abstract": "Highly automated driving requires precise models of traffic participants.\nMany state of the art models are currently based on machine learning\ntechniques. Among others, the required amount of labeled data is one major\nchallenge. An autonomous learning process addressing this problem is proposed.\nThe initial models are iteratively refined in three steps: (1) detection and\ncontext identification, (2) novelty detection and active learning and (3)\nonline model adaption.", "category": "cs.AI"}, {"title": "Learning and analyzing vector encoding of symbolic representations", "abstract": "We present a formal language with expressions denoting general symbol\nstructures and queries which access information in those structures. A\nsequence-to-sequence network processing this language learns to encode symbol\nstructures and query them. The learned representation (approximately) shares a\nsimple linearity property with theoretical techniques for performing this task.", "category": "cs.AI"}, {"title": "The Challenge of Crafting Intelligible Intelligence", "abstract": "Since Artificial Intelligence (AI) software uses techniques like deep\nlookahead search and stochastic optimization of huge neural networks to fit\nmammoth datasets, it often results in complex behavior that is difficult for\npeople to understand. Yet organizations are deploying AI algorithms in many\nmission-critical settings. To trust their behavior, we must make AI\nintelligible, either by using inherently interpretable models or by developing\nnew methods for explaining and controlling otherwise overwhelmingly complex\ndecisions using local approximation, vocabulary alignment, and interactive\nexplanation. This paper argues that intelligibility is essential, surveys\nrecent work on building such systems, and highlights key directions for\nresearch.", "category": "cs.AI"}, {"title": "On the Algebra in Boole's Laws of Thought", "abstract": "This article explores the ideas that went into George Boole's development of\nan algebra for logical inference in his book The Laws of Thought. We explore in\nparticular his wife Mary Boole's claim that he was deeply influenced by Indian\nlogic and argue that his work was more than a framework for processing\npropositions. By exploring parallels between his work and Indian logic, we are\nable to explain several peculiarities of this work.", "category": "cs.AI"}, {"title": "Solving the Course-timetabling Problem of Cairo University Using Max-SAT", "abstract": "Due to the good performance of current SAT (satisfiability) and Max-SAT\n(maximum ssatisfiability) solvers, many real-life optimization problems such as\nscheduling can be solved by encoding them into Max-SAT. In this paper we tackle\nthe course timetabling problem of the department of mathematics, Cairo\nUniversity by encoding it into Max-SAT. Generating timetables for the\ndepartment by hand has proven to be cumbersome and the generated timetable\nalmost always contains conflicts. We show how the constraints can be modelled\nas a Max-SAT instance.", "category": "cs.AI"}, {"title": "Fractal AI: A fragile theory of intelligence", "abstract": "Fractal AI is a theory for general artificial intelligence. It allows\nderiving new mathematical tools that constitute the foundations for a new kind\nof stochastic calculus, by modelling information using cellular automaton-like\nstructures instead of smooth functions. In the repository included we are\npresenting a new Agent, derived from the first principles of the theory, which\nis capable of solving Atari games several orders of magnitude more efficiently\nthan other similar techniques, like Monte Carlo Tree Search. The code provided\nshows how it is now possible to beat some of the current State of The Art\nbenchmarks on Atari games, without previous learning and using less than 1000\nsamples to calculate each one of the actions when standard MCTS uses 3 Million\nsamples. Among other things, Fractal AI makes it possible to generate a huge\ndatabase of top performing examples with a very little amount of computation\nrequired, transforming Reinforcement Learning into a supervised problem. The\nalgorithm presented is capable of solving the exploration vs exploitation\ndilemma on both the discrete and continuous cases, while maintaining control\nover any aspect of the behaviour of the Agent. From a general approach, new\ntechniques presented here have direct applications to other areas such as\nNon-equilibrium thermodynamics, chemistry, quantum physics, economics,\ninformation theory, and non-linear control theory.", "category": "cs.AI"}, {"title": "Deep Learning of Nonnegativity-Constrained Autoencoders for Enhanced Understanding of Data", "abstract": "Unsupervised feature extractors are known to perform an efficient and\ndiscriminative representation of data. Insight into the mappings they perform\nand human ability to understand them, however, remain very limited. This is\nespecially prominent when multilayer deep learning architectures are used. This\npaper demonstrates how to remove these bottlenecks within the architecture of\nNonnegativity Constrained Autoencoder (NCSAE). It is shown that by using both\nL1 and L2 regularization that induce nonnegativity of weights, most of the\nweights in the network become constrained to be nonnegative thereby resulting\ninto a more understandable structure with minute deterioration in\nclassification accuracy. Also, this proposed approach extracts features that\nare more sparse and produces additional output layer sparsification. The method\nis analyzed for accuracy and feature interpretation on the MNIST data, the NORB\nnormalized uniform object data, and the Reuters text categorization dataset.", "category": "cs.LG"}, {"title": "A New Backpropagation Algorithm without Gradient Descent", "abstract": "The backpropagation algorithm, which had been originally introduced in the\n1970s, is the workhorse of learning in neural networks. This backpropagation\nalgorithm makes use of the famous machine learning algorithm known as Gradient\nDescent, which is a first-order iterative optimization algorithm for finding\nthe minimum of a function. To find a local minimum of a function using gradient\ndescent, one takes steps proportional to the negative of the gradient (or of\nthe approximate gradient) of the function at the current point. In this paper,\nwe develop an alternative to the backpropagation without the use of the\nGradient Descent Algorithm, but instead we are going to devise a new algorithm\nto find the error in the weights and biases of an artificial neuron using\nMoore-Penrose Pseudo Inverse. The numerical studies and the experiments\nperformed on various datasets are used to verify the working of this\nalternative algorithm.", "category": "cs.LG"}, {"title": "Rethinking the Smaller-Norm-Less-Informative Assumption in Channel Pruning of Convolution Layers", "abstract": "Model pruning has become a useful technique that improves the computational\nefficiency of deep learning, making it possible to deploy solutions in\nresource-limited scenarios. A widely-used practice in relevant work assumes\nthat a smaller-norm parameter or feature plays a less informative role at the\ninference time. In this paper, we propose a channel pruning technique for\naccelerating the computations of deep convolutional neural networks (CNNs) that\ndoes not critically rely on this assumption. Instead, it focuses on direct\nsimplification of the channel-to-channel computation graph of a CNN without the\nneed of performing a computationally difficult and not-always-useful task of\nmaking high-dimensional tensors of CNN structured sparse. Our approach takes\ntwo stages: first to adopt an end-to- end stochastic training method that\neventually forces the outputs of some channels to be constant, and then to\nprune those constant channels from the original neural network by adjusting the\nbiases of their impacting layers such that the resulting compact model can be\nquickly fine-tuned. Our approach is mathematically appealing from an\noptimization perspective and easy to reproduce. We experimented our approach\nthrough several image learning benchmarks and demonstrate its interesting\naspects and competitive performance.", "category": "cs.LG"}, {"title": "Bootstrapping and Multiple Imputation Ensemble Approaches for Missing Data", "abstract": "Presence of missing values in a dataset can adversely affect the performance\nof a classifier. Single and Multiple Imputation are normally performed to fill\nin the missing values. In this paper, we present several variants of combining\nsingle and multiple imputation with bootstrapping to create ensembles that can\nmodel uncertainty and diversity in the data, and that are robust to high\nmissingness in the data. We present three ensemble strategies: bootstrapping on\nincomplete data followed by (i) single imputation and (ii) multiple imputation,\nand (iii) multiple imputation ensemble without bootstrapping. We perform an\nextensive evaluation of the performance of the these ensemble strategies on 8\ndatasets by varying the missingness ratio. Our results show that bootstrapping\nfollowed by multiple imputation using expectation maximization is the most\nrobust method even at high missingness ratio (up to 30%). For small missingness\nratio (up to 10%) most of the ensemble methods perform quivalently but better\nthan single imputation. Kappa-error plots suggest that accurate classifiers\nwith reasonable diversity is the reason for this behaviour. A consistent\nobservation in all the datasets suggests that for small missingness (up to\n10%), bootstrapping on incomplete data without any imputation produces\nequivalent results to other ensemble methods.", "category": "cs.LG"}, {"title": "Augmented Space Linear Model", "abstract": "The linear model uses the space defined by the input to project the target or\ndesired signal and find the optimal set of model parameters. When the problem\nis nonlinear, the adaption requires nonlinear models for good performance, but\nit becomes slower and more cumbersome. In this paper, we propose a linear model\ncalled Augmented Space Linear Model (ASLM), which uses the full joint space of\ninput and desired signal as the projection space and approaches the performance\nof nonlinear models. This new algorithm takes advantage of the linear solution,\nand corrects the estimate for the current testing phase input with the error\nassigned to the input space neighborhood in the training phase. This algorithm\ncan solve the nonlinear problem with the computational efficiency of linear\nmethods, which can be regarded as a trade off between accuracy and\ncomputational complexity. Making full use of the training data, the proposed\naugmented space model may provide a new way to improve many modeling tasks.", "category": "cs.LG"}, {"title": "Clustering and Unsupervised Anomaly Detection with L2 Normalized Deep Auto-Encoder Representations", "abstract": "Clustering is essential to many tasks in pattern recognition and computer\nvision. With the advent of deep learning, there is an increasing interest in\nlearning deep unsupervised representations for clustering analysis. Many works\non this domain rely on variants of auto-encoders and use the encoder outputs as\nrepresentations/features for clustering. In this paper, we show that an l2\nnormalization constraint on these representations during auto-encoder training,\nmakes the representations more separable and compact in the Euclidean space\nafter training. This greatly improves the clustering accuracy when k-means\nclustering is employed on the representations. We also propose a clustering\nbased unsupervised anomaly detection method using l2 normalized deep\nauto-encoder representations. We show the effect of l2 normalization on anomaly\ndetection accuracy. We further show that the proposed anomaly detection method\ngreatly improves accuracy compared to previously proposed deep methods such as\nreconstruction error based anomaly detection.", "category": "cs.LG"}, {"title": "Training Neural Networks by Using Power Linear Units (PoLUs)", "abstract": "In this paper, we introduce \"Power Linear Unit\" (PoLU) which increases the\nnonlinearity capacity of a neural network and thus helps improving its\nperformance. PoLU adopts several advantages of previously proposed activation\nfunctions. First, the output of PoLU for positive inputs is designed to be\nidentity to avoid the gradient vanishing problem. Second, PoLU has a non-zero\noutput for negative inputs such that the output mean of the units is close to\nzero, hence reducing the bias shift effect. Thirdly, there is a saturation on\nthe negative part of PoLU, which makes it more noise-robust for negative\ninputs. Furthermore, we prove that PoLU is able to map more portions of every\nlayer's input to the same space by using the power function and thus increases\nthe number of response regions of the neural network. We use image\nclassification for comparing our proposed activation function with others. In\nthe experiments, MNIST, CIFAR-10, CIFAR-100, Street View House Numbers (SVHN)\nand ImageNet are used as benchmark datasets. The neural networks we implemented\ninclude widely-used ELU-Network, ResNet-50, and VGG16, plus a couple of shallow\nnetworks. Experimental results show that our proposed activation function\noutperforms other state-of-the-art models with most networks.", "category": "cs.LG"}, {"title": "Analysis of Fast Alternating Minimization for Structured Dictionary Learning", "abstract": "Methods exploiting sparsity have been popular in imaging and signal\nprocessing applications including compression, denoising, and imaging inverse\nproblems. Data-driven approaches such as dictionary learning and transform\nlearning enable one to discover complex image features from datasets and\nprovide promising performance over analytical models. Alternating minimization\nalgorithms have been particularly popular in dictionary or transform learning.\nIn this work, we study the properties of alternating minimization for\nstructured (unitary) sparsifying operator learning. While the algorithm\nconverges to the stationary points of the non-convex problem in general, we\nprove rapid local linear convergence to the underlying generative model under\nmild assumptions. Our experiments show that the unitary operator learning\nalgorithm is robust to initialization.", "category": "cs.LG"}, {"title": "GeniePath: Graph Neural Networks with Adaptive Receptive Paths", "abstract": "We present, GeniePath, a scalable approach for learning adaptive receptive\nfields of neural networks defined on permutation invariant graph data. In\nGeniePath, we propose an adaptive path layer consists of two complementary\nfunctions designed for breadth and depth exploration respectively, where the\nformer learns the importance of different sized neighborhoods, while the latter\nextracts and filters signals aggregated from neighbors of different hops away.\nOur method works in both transductive and inductive settings, and extensive\nexperiments compared with competitive methods show that our approaches yield\nstate-of-the-art results on large graphs.", "category": "cs.LG"}, {"title": "Online Compact Convexified Factorization Machine", "abstract": "Factorization Machine (FM) is a supervised learning approach with a powerful\ncapability of feature engineering. It yields state-of-the-art performance in\nvarious batch learning tasks where all the training data is made available\nprior to the training. However, in real-world applications where the data\narrives sequentially in a streaming manner, the high cost of re-training with\nbatch learning algorithms has posed formidable challenges in the online\nlearning scenario. The initial challenge is that no prior formulations of FM\ncould fulfill the requirements in Online Convex Optimization (OCO) -- the\nparamount framework for online learning algorithm design. To address the\naforementioned challenge, we invent a new convexification scheme leading to a\nCompact Convexified FM (CCFM) that seamlessly meets the requirements in OCO.\nHowever for learning Compact Convexified FM (CCFM) in the online learning\nsetting, most existing algorithms suffer from expensive projection operations.\nTo address this subsequent challenge, we follow the general projection-free\nalgorithmic framework of Online Conditional Gradient and propose an Online\nCompact Convex Factorization Machine (OCCFM) algorithm that eschews the\nprojection operation with efficient linear optimization steps. In support of\nthe proposed OCCFM in terms of its theoretical foundation, we prove that the\ndeveloped algorithm achieves a sub-linear regret bound. To evaluate the\nempirical performance of OCCFM, we conduct extensive experiments on 6\nreal-world datasets for online recommendation and binary classification tasks.\nThe experimental results show that OCCFM outperforms the state-of-art online\nlearning algorithms.", "category": "cs.LG"}, {"title": "Explicit Inductive Bias for Transfer Learning with Convolutional Networks", "abstract": "In inductive transfer learning, fine-tuning pre-trained convolutional\nnetworks substantially outperforms training from scratch. When using\nfine-tuning, the underlying assumption is that the pre-trained model extracts\ngeneric features, which are at least partially relevant for solving the target\ntask, but would be difficult to extract from the limited amount of data\navailable on the target task. However, besides the initialization with the\npre-trained model and the early stopping, there is no mechanism in fine-tuning\nfor retaining the features learned on the source task. In this paper, we\ninvestigate several regularization schemes that explicitly promote the\nsimilarity of the final solution with the initial model. We show the benefit of\nhaving an explicit inductive bias towards the initial model, and we eventually\nrecommend a simple $L^2$ penalty with the pre-trained model being a reference\nas the baseline of penalty for transfer learning tasks.", "category": "cs.LG"}, {"title": "Selective Sampling and Mixture Models in Generative Adversarial Networks", "abstract": "In this paper, we propose a multi-generator extension to the adversarial\ntraining framework, in which the objective of each generator is to represent a\nunique component of a target mixture distribution. In the training phase, the\ngenerators cooperate to represent, as a mixture, the target distribution while\nmaintaining distinct manifolds. As opposed to traditional generative models,\ninference from a particular generator after training resembles selective\nsampling from a unique component in the target distribution. We demonstrate the\nfeasibility of the proposed architecture both analytically and with basic\nMulti-Layer Perceptron (MLP) models trained on the MNIST dataset.", "category": "cs.LG"}, {"title": "MotifNet: a motif-based Graph Convolutional Network for directed graphs", "abstract": "Deep learning on graphs and in particular, graph convolutional neural\nnetworks, have recently attracted significant attention in the machine learning\ncommunity. Many of such techniques explore the analogy between the graph\nLaplacian eigenvectors and the classical Fourier basis, allowing to formulate\nthe convolution as a multiplication in the spectral domain. One of the key\ndrawback of spectral CNNs is their explicit assumption of an undirected graph,\nleading to a symmetric Laplacian matrix with orthogonal eigendecomposition. In\nthis work we propose MotifNet, a graph CNN capable of dealing with directed\ngraphs by exploiting local graph motifs. We present experimental evidence\nshowing the advantage of our approach on real data.", "category": "cs.LG"}, {"title": "Re-Weighted Learning for Sparsifying Deep Neural Networks", "abstract": "This paper addresses the topic of sparsifying deep neural networks (DNN's).\nWhile DNN's are powerful models that achieve state-of-the-art performance on a\nlarge number of tasks, the large number of model parameters poses serious\nstorage and computational challenges. To combat these difficulties, a growing\nline of work focuses on pruning network weights without sacrificing\nperformance. We propose a general affine scaling transformation (AST) algorithm\nto sparsify DNN's. Our approach follows in the footsteps of popular sparse\nrecovery techniques, which have yet to be explored in the context of DNN's. We\ndescribe a principled framework for transforming densely connected DNN's into\nsparsely connected ones without sacrificing network performance. Unlike\nexisting methods, our approach is able to learn sparse connections at each\nlayer simultaneously, and achieves comparable pruning results on the\narchitecture tested.", "category": "cs.LG"}, {"title": "Mixed Link Networks", "abstract": "Basing on the analysis by revealing the equivalence of modern networks, we\nfind that both ResNet and DenseNet are essentially derived from the same \"dense\ntopology\", yet they only differ in the form of connection -- addition (dubbed\n\"inner link\") vs. concatenation (dubbed \"outer link\"). However, both two forms\nof connections have the superiority and insufficiency. To combine their\nadvantages and avoid certain limitations on representation learning, we present\na highly efficient and modularized Mixed Link Network (MixNet) which is\nequipped with flexible inner link and outer link modules. Consequently, ResNet,\nDenseNet and Dual Path Network (DPN) can be regarded as a special case of\nMixNet, respectively. Furthermore, we demonstrate that MixNets can achieve\nsuperior efficiency in parameter over the state-of-the-art architectures on\nmany competitive datasets like CIFAR-10/100, SVHN and ImageNet.", "category": "cs.LG"}, {"title": "Directly and Efficiently Optimizing Prediction Error and AUC of Linear Classifiers", "abstract": "The predictive quality of machine learning models is typically measured in\nterms of their (approximate) expected prediction error or the so-called Area\nUnder the Curve (AUC) for a particular data distribution. However, when the\nmodels are constructed by the means of empirical risk minimization, surrogate\nfunctions such as the logistic loss are optimized instead. This is done because\nthe empirical approximations of the expected error and AUC functions are\nnonconvex and nonsmooth, and more importantly have zero derivative almost\neverywhere. In this work, we show that in the case of linear predictors, and\nunder the assumption that the data has normal distribution, the expected error\nand the expected AUC are not only smooth, but have closed form expressions,\nwhich depend on the first and second moments of the normal distribution. Hence,\nwe derive derivatives of these two functions and use these derivatives in an\noptimization algorithm to directly optimize the expected error and the AUC. In\nthe case of real data sets, the derivatives can be approximated using empirical\nmoments. We show that even when data is not normally distributed, computed\nderivatives are sufficiently useful to render an efficient optimization method\nand high quality solutions. Thus, we propose a gradient-based optimization\nmethod for direct optimization of the prediction error and AUC. Moreover, the\nper-iteration complexity of the proposed algorithm has no dependence on the\nsize of the data set, unlike those for optimizing logistic regression and all\nother well known empirical risk minimization problems.", "category": "cs.LG"}, {"title": "Improving the Universality and Learnability of Neural Programmer-Interpreters with Combinator Abstraction", "abstract": "To overcome the limitations of Neural Programmer-Interpreters (NPI) in its\nuniversality and learnability, we propose the incorporation of combinator\nabstraction into neural programing and a new NPI architecture to support this\nabstraction, which we call Combinatory Neural Programmer-Interpreter (CNPI).\nCombinator abstraction dramatically reduces the number and complexity of\nprograms that need to be interpreted by the core controller of CNPI, while\nstill allowing the CNPI to represent and interpret arbitrary complex programs\nby the collaboration of the core with the other components. We propose a small\nset of four combinators to capture the most pervasive programming patterns. Due\nto the finiteness and simplicity of this combinator set and the offloading of\nsome burden of interpretation from the core, we are able construct a CNPI that\nis universal with respect to the set of all combinatorizable programs, which is\nadequate for solving most algorithmic tasks. Moreover, besides supervised\ntraining on execution traces, CNPI can be trained by policy gradient\nreinforcement learning with appropriately designed curricula.", "category": "cs.LG"}, {"title": "Online Learning: A Comprehensive Survey", "abstract": "Online learning represents an important family of machine learning\nalgorithms, in which a learner attempts to resolve an online prediction (or any\ntype of decision-making) task by learning a model/hypothesis from a sequence of\ndata instances one at a time. The goal of online learning is to ensure that the\nonline learner would make a sequence of accurate predictions (or correct\ndecisions) given the knowledge of correct answers to previous prediction or\nlearning tasks and possibly additional information. This is in contrast to many\ntraditional batch learning or offline machine learning algorithms that are\noften designed to train a model in batch from a given collection of training\ndata instances. This survey aims to provide a comprehensive survey of the\nonline machine learning literatures through a systematic review of basic ideas\nand key principles and a proper categorization of different algorithms and\ntechniques. Generally speaking, according to the learning type and the forms of\nfeedback information, the existing online learning works can be classified into\nthree major categories: (i) supervised online learning where full feedback\ninformation is always available, (ii) online learning with limited feedback,\nand (iii) unsupervised online learning where there is no feedback available.\nDue to space limitation, the survey will be mainly focused on the first\ncategory, but also briefly cover some basics of the other two categories.\nFinally, we also discuss some open issues and attempt to shed light on\npotential future research directions in this field.", "category": "cs.LG"}, {"title": "Learning and Querying Fast Generative Models for Reinforcement Learning", "abstract": "A key challenge in model-based reinforcement learning (RL) is to synthesize\ncomputationally efficient and accurate environment models. We show that\ncarefully designed generative models that learn and operate on compact state\nrepresentations, so-called state-space models, substantially reduce the\ncomputational costs for predicting outcomes of sequences of actions. Extensive\nexperiments establish that state-space models accurately capture the dynamics\nof Atari games from the Arcade Learning Environment from raw pixels. The\ncomputational speed-up of state-space models while maintaining high accuracy\nmakes their application in RL feasible: We demonstrate that agents which query\nthese models for decision making outperform strong model-free baselines on the\ngame MSPACMAN, demonstrating the potential of using learned environment models\nfor planning.", "category": "cs.LG"}, {"title": "Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits", "abstract": "Regret bounds in online learning compare the player's performance to $L^*$,\nthe optimal performance in hindsight with a fixed strategy. Typically such\nbounds scale with the square root of the time horizon $T$. The more refined\nconcept of first-order regret bound replaces this with a scaling $\\sqrt{L^*}$,\nwhich may be much smaller than $\\sqrt{T}$. It is well known that minor variants\nof standard algorithms satisfy first-order regret bounds in the full\ninformation and multi-armed bandit settings. In a COLT 2017 open problem,\nAgarwal, Krishnamurthy, Langford, Luo, and Schapire raised the issue that\nexisting techniques do not seem sufficient to obtain first-order regret bounds\nfor the contextual bandit problem. In the present paper, we resolve this open\nproblem by presenting a new strategy based on augmenting the policy space.", "category": "cs.LG"}, {"title": "Learning Local Metrics and Influential Regions for Classification", "abstract": "The performance of distance-based classifiers heavily depends on the\nunderlying distance metric, so it is valuable to learn a suitable metric from\nthe data. To address the problem of multimodality, it is desirable to learn\nlocal metrics. In this short paper, we define a new intuitive distance with\nlocal metrics and influential regions, and subsequently propose a novel local\nmetric learning method for distance-based classification. Our key intuition is\nto partition the metric space into influential regions and a background region,\nand then regulate the effectiveness of each local metric to be within the\nrelated influential regions. We learn local metrics and influential regions to\nreduce the empirical hinge loss, and regularize the parameters on the basis of\na resultant learning bound. Encouraging experimental results are obtained from\nvarious public and popular data sets.", "category": "cs.LG"}, {"title": "Metric Learning via Maximizing the Lipschitz Margin Ratio", "abstract": "In this paper, we propose the Lipschitz margin ratio and a new metric\nlearning framework for classification through maximizing the ratio. This\nframework enables the integration of both the inter-class margin and the\nintra-class dispersion, as well as the enhancement of the generalization\nability of a classifier. To introduce the Lipschitz margin ratio and its\nassociated learning bound, we elaborate the relationship between metric\nlearning and Lipschitz functions, as well as the representability and\nlearnability of the Lipschitz functions. After proposing the new metric\nlearning framework based on the introduced Lipschitz margin ratio, we also\nprove that some well known metric learning algorithms can be shown as special\ncases of the proposed framework. In addition, we illustrate the framework by\nimplementing it for learning the squared Mahalanobis metric, and by\ndemonstrating its encouraging results on eight popular datasets of machine\nlearning.", "category": "cs.LG"}, {"title": "A Continuation Method for Discrete Optimization and its Application to Nearest Neighbor Classification", "abstract": "The continuation method is a popular approach in non-convex optimization and\ncomputer vision. The main idea is to start from a simple function that can be\nminimized efficiently, and gradually transform it to the more complicated\noriginal objective function. The solution of the simpler problem is used as the\nstarting point to solve the original problem. We show a continuation method for\ndiscrete optimization problems. Ideally, we would like the evolved function to\nbe hill-climbing friendly and to have the same global minima as the original\nfunction. We show that the proposed continuation method is the best affine\napproximation of a transformation that is guaranteed to transform the function\nto a hill-climbing friendly function and to have the same global minima.\n  We show the effectiveness of the proposed technique in the problem of nearest\nneighbor classification. Although nearest neighbor methods are often\ncompetitive in terms of sample efficiency, the computational complexity in the\ntest phase has been a major obstacle in their applicability in big data\nproblems. Using the proposed continuation method, we show an improved\ngraph-based nearest neighbor algorithm. The method is readily understood and\neasy to implement. We show how the computational complexity of the method in\nthe test phase scales gracefully with the size of the training set, a property\nthat is particularly important in big data applications.", "category": "cs.LG"}, {"title": "Disturbance Grassmann Kernels for Subspace-Based Learning", "abstract": "In this paper, we focus on subspace-based learning problems, where data\nelements are linear subspaces instead of vectors. To handle this kind of data,\nGrassmann kernels were proposed to measure the space structure and used with\nclassifiers, e.g., Support Vector Machines (SVMs). However, the existing\ndiscriminative algorithms mostly ignore the instability of subspaces, which\nwould cause the classifiers misled by disturbed instances. Thus we propose\nconsidering all potential disturbance of subspaces in learning processes to\nobtain more robust classifiers. Firstly, we derive the dual optimization of\nlinear classifiers with disturbance subject to a known distribution, resulting\nin a new kernel, Disturbance Grassmann (DG) kernel. Secondly, we research into\ntwo kinds of disturbance, relevant to the subspace matrix and singular values\nof bases, with which we extend the Projection kernel on Grassmann manifolds to\ntwo new kernels. Experiments on action data indicate that the proposed kernels\nperform better compared to state-of-the-art subspace-based methods, even in a\nworse environment.", "category": "cs.LG"}, {"title": "The Importance of Norm Regularization in Linear Graph Embedding: Theoretical Analysis and Empirical Demonstration", "abstract": "Learning distributed representations for nodes in graphs is a crucial\nprimitive in network analysis with a wide spectrum of applications. Linear\ngraph embedding methods learn such representations by optimizing the likelihood\nof both positive and negative edges while constraining the dimension of the\nembedding vectors. We argue that the generalization performance of these\nmethods is not due to the dimensionality constraint as commonly believed, but\nrather the small norm of embedding vectors. Both theoretical and empirical\nevidence are provided to support this argument: (a) we prove that the\ngeneralization error of these methods can be bounded by limiting the norm of\nvectors, regardless of the embedding dimension; (b) we show that the\ngeneralization performance of linear graph embedding methods is correlated with\nthe norm of embedding vectors, which is small due to the early stopping of SGD\nand the vanishing gradients. We performed extensive experiments to validate our\nanalysis and showcased the importance of proper norm regularization in\npractice.", "category": "cs.LG"}, {"title": "Tips, guidelines and tools for managing multi-label datasets: the mldr.datasets R package and the Cometa data repository", "abstract": "New proposals in the field of multi-label learning algorithms have been\ngrowing in number steadily over the last few years. The experimentation\nassociated with each of them always goes through the same phases: selection of\ndatasets, partitioning, training, analysis of results and, finally, comparison\nwith existing methods. This last step is often hampered since it involves using\nexactly the same datasets, partitioned in the same way and using the same\nvalidation strategy. In this paper we present a set of tools whose objective is\nto facilitate the management of multi-label datasets, aiming to standardize the\nexperimentation procedure. The two main tools are an R package, mldr.datasets,\nand a web repository with datasets, Cometa. Together, these tools will simplify\nthe collection of datasets, their partitioning, documentation and export to\nmultiple formats, among other functions. Some tips, recommendations and\nguidelines for a good experimental analysis of multi-label methods are also\npresented.", "category": "cs.LG"}, {"title": "Deep Meta-Learning: Learning to Learn in the Concept Space", "abstract": "Few-shot learning remains challenging for meta-learning that learns a\nlearning algorithm (meta-learner) from many related tasks. In this work, we\nargue that this is due to the lack of a good representation for meta-learning,\nand propose deep meta-learning to integrate the representation power of deep\nlearning into meta-learning. The framework is composed of three modules, a\nconcept generator, a meta-learner, and a concept discriminator, which are\nlearned jointly. The concept generator, e.g. a deep residual net, extracts a\nrepresentation for each instance that captures its high-level concept, on which\nthe meta-learner performs few-shot learning, and the concept discriminator\nrecognizes the concepts. By learning to learn in the concept space rather than\nin the complicated instance space, deep meta-learning can substantially improve\nvanilla meta-learning, which is demonstrated on various few-shot image\nrecognition problems. For example, on 5-way-1-shot image recognition on\nCIFAR-100 and CUB-200, it improves Matching Nets from 50.53% and 56.53% to\n58.18% and 63.47%, improves MAML from 49.28% and 50.45% to 56.65% and 64.63%,\nand improves Meta-SGD from 53.83% and 53.34% to 61.62% and 66.95%,\nrespectively.", "category": "cs.LG"}, {"title": "Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks", "abstract": "We provide theoretical investigation of curriculum learning in the context of\nstochastic gradient descent when optimizing the convex linear regression loss.\nWe prove that the rate of convergence of an ideal curriculum learning method is\nmonotonically increasing with the difficulty of the examples. Moreover, among\nall equally difficult points, convergence is faster when using points which\nincur higher loss with respect to the current hypothesis. We then analyze\ncurriculum learning in the context of training a CNN. We describe a method\nwhich infers the curriculum by way of transfer learning from another network,\npre-trained on a different task. While this approach can only approximate the\nideal curriculum, we observe empirically similar behavior to the one predicted\nby the theory, namely, a significant boost in convergence speed at the\nbeginning of training. When the task is made more difficult, improvement in\ngeneralization performance is also observed. Finally, curriculum learning\nexhibits robustness against unfavorable conditions such as excessive\nregularization.", "category": "cs.LG"}, {"title": "PRIL: Perceptron Ranking Using Interval Labeled Data", "abstract": "In this paper, we propose an online learning algorithm PRIL for learning\nranking classifiers using interval labeled data and show its correctness. We\nshow its convergence in finite number of steps if there exists an ideal\nclassifier such that the rank given by it for an example always lies in its\nlabel interval. We then generalize this mistake bound result for the general\ncase. We also provide regret bound for the proposed algorithm. We propose a\nmultiplicative update algorithm for PRIL called M-PRIL. We provide its\ncorrectness and convergence results. We show the effectiveness of PRIL by\nshowing its performance on various datasets.", "category": "cs.LG"}, {"title": "On the Needs for Rotations in Hypercubic Quantization Hashing", "abstract": "The aim of this paper is to endow the well-known family of hypercubic\nquantization hashing methods with theoretical guarantees. In hypercubic\nquantization, applying a suitable (random or learned) rotation after\ndimensionality reduction has been experimentally shown to improve the results\naccuracy in the nearest neighbors search problem. We prove in this paper that\nthe use of these rotations is optimal under some mild assumptions: getting\noptimal binary sketches is equivalent to applying a rotation uniformizing the\ndiagonal of the covariance matrix between data points. Moreover, for two closed\npoints, the probability to have dissimilar binary sketches is upper bounded by\na factor of the initial distance between the data points. Relaxing these\nassumptions, we obtain a general concentration result for random matrices. We\nalso provide some experiments illustrating these theoretical points and compare\na set of algorithms in both the batch and online settings.", "category": "cs.LG"}, {"title": "Policy Gradients for Contextual Recommendations", "abstract": "Decision making is a challenging task in online recommender systems. The\ndecision maker often needs to choose a contextual item at each step from a set\nof candidates. Contextual bandit algorithms have been successfully deployed to\nsuch applications, for the trade-off between exploration and exploitation and\nthe state-of-art performance on minimizing online costs. However, the\napplicability of existing contextual bandit methods is limited by the\nover-simplified assumptions of the problem, such as assuming a simple form of\nthe reward function or assuming a static environment where the states are not\naffected by previous actions. In this work, we put forward Policy Gradients for\nContextual Recommendations (PGCR) to solve the problem without those\nunrealistic assumptions. It optimizes over a restricted class of policies where\nthe marginal probability of choosing an item (in expectation of other items)\nhas a simple closed form, and the gradient of the expected return over the\npolicy in this class is in a succinct form. Moreover, PGCR leverages two useful\nheuristic techniques called Time-Dependent Greed and Actor-Dropout. The former\nensures PGCR to be empirically greedy in the limit, and the latter addresses\nthe trade-off between exploration and exploitation by using the policy network\nwith Dropout as a Bayesian approximation. PGCR can solve the standard\ncontextual bandits as well as its Markov Decision Process generalization.\nTherefore it can be applied to a wide range of realistic settings of\nrecommendations, such as personalized advertising. We evaluate PGCR on toy\ndatasets as well as a real-world dataset of personalized music recommendations.\nExperiments show that PGCR enables fast convergence and low regret, and\noutperforms both classic contextual-bandits and vanilla policy gradient\nmethods.", "category": "cs.LG"}, {"title": "Electric Vehicle Driver Clustering using Statistical Model and Machine Learning", "abstract": "Electric Vehicle (EV) is playing a significant role in the distribution\nenergy management systems since the power consumption level of the EVs is much\nhigher than the other regular home appliances. The randomness of the EV driver\nbehaviors make the optimal charging or discharging scheduling even more\ndifficult due to the uncertain charging session parameters. To minimize the\nimpact of behavioral uncertainties, it is critical to develop effective methods\nto predict EV load for smart EV energy management. Using the EV smart charging\ninfrastructures on UCLA campus and city of Santa Monica as testbeds, we have\ncollected real-world datasets of EV charging behaviors, based on which we\nproposed an EV user modeling technique which combines statistical analysis and\nmachine learning approaches. Specifically, unsupervised clustering algorithm,\nand multilayer perceptron are applied to historical charging record to make the\nday-ahead EV parking and load prediction. Experimental results with\ncross-validation show that our model can achieve good performance for charging\ncontrol scheduling and online EV load forecasting.", "category": "cs.LG"}, {"title": "Sparse Reject Option Classifier Using Successive Linear Programming", "abstract": "In this paper, we propose an approach for learning sparse reject option\nclassifiers using double ramp loss $L_{dr}$. We use DC programming to find the\nrisk minimizer. The algorithm solves a sequence of linear programs to learn the\nreject option classifier. We show that the loss $L_{dr}$ is Fisher consistent.\nWe also show that the excess risk of loss $L_d$ is upper bounded by the excess\nrisk of $L_{dr}$. We derive the generalization error bounds for the proposed\napproach. We show the effectiveness of the proposed approach by experimenting\nit on several real world datasets. The proposed approach not only performs\ncomparable to the state of the art but it also successfully learns sparse\nclassifiers.", "category": "cs.LG"}, {"title": "Multi-Armed Bandits on Partially Revealed Unit Interval Graphs", "abstract": "A stochastic multi-armed bandit problem with side information on the\nsimilarity and dissimilarity across different arms is considered. The action\nspace of the problem can be represented by a unit interval graph (UIG) where\neach node represents an arm and the presence (absence) of an edge between two\nnodes indicates similarity (dissimilarity) between their mean rewards. Two\nsettings of complete and partial side information based on whether the UIG is\nfully revealed are studied and a general two-step learning structure consisting\nof an offline reduction of the action space and online aggregation of reward\nobservations from similar arms is proposed to fully exploit the topological\nstructure of the side information. In both cases, the computation efficiency\nand the order optimality of the proposed learning policies in terms of both the\nsize of the action space and the time length are established.", "category": "cs.LG"}, {"title": "Classification from Pairwise Similarity and Unlabeled Data", "abstract": "Supervised learning needs a huge amount of labeled data, which can be a big\nbottleneck under the situation where there is a privacy concern or labeling\ncost is high. To overcome this problem, we propose a new weakly-supervised\nlearning setting where only similar (S) data pairs (two examples belong to the\nsame class) and unlabeled (U) data points are needed instead of fully labeled\ndata, which is called SU classification. We show that an unbiased estimator of\nthe classification risk can be obtained only from SU data, and the estimation\nerror of its empirical risk minimizer achieves the optimal parametric\nconvergence rate. Finally, we demonstrate the effectiveness of the proposed\nmethod through experiments.", "category": "cs.LG"}, {"title": "Neural Tensor Factorization", "abstract": "Neural collaborative filtering (NCF) and recurrent recommender systems (RRN)\nhave been successful in modeling user-item relational data. However, they are\nalso limited in their assumption of static or sequential modeling of relational\ndata as they do not account for evolving users' preference over time as well as\nchanges in the underlying factors that drive the change in user-item\nrelationship over time. We address these limitations by proposing a Neural\nTensor Factorization (NTF) model for predictive tasks on dynamic relational\ndata. The NTF model generalizes conventional tensor factorization from two\nperspectives: First, it leverages the long short-term memory architecture to\ncharacterize the multi-dimensional temporal interactions on relational data.\nSecond, it incorporates the multi-layer perceptron structure for learning the\nnon-linearities between different latent factors. Our extensive experiments\ndemonstrate the significant improvement in rating prediction and link\nprediction on dynamic relational data by our NTF model over both neural network\nbased factorization models and other traditional methods.", "category": "cs.LG"}, {"title": "Flipped-Adversarial AutoEncoders", "abstract": "We propose a flipped-Adversarial AutoEncoder (FAAE) that simultaneously\ntrains a generative model G that maps an arbitrary latent code distribution to\na data distribution and an encoder E that embodies an \"inverse mapping\" that\nencodes a data sample into a latent code vector. Unlike previous hybrid\napproaches that leverage adversarial training criterion in constructing\nautoencoders, FAAE minimizes re-encoding errors in the latent space and\nexploits adversarial criterion in the data space. Experimental evaluations\ndemonstrate that the proposed framework produces sharper reconstructed images\nwhile at the same time enabling inference that captures rich semantic\nrepresentation of data.", "category": "cs.LG"}, {"title": "Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring", "abstract": "Deep Neural Networks have recently gained lots of success after enabling\nseveral breakthroughs in notoriously challenging problems. Training these\nnetworks is computationally expensive and requires vast amounts of training\ndata. Selling such pre-trained models can, therefore, be a lucrative business\nmodel. Unfortunately, once the models are sold they can be easily copied and\nredistributed. To avoid this, a tracking mechanism to identify models as the\nintellectual property of a particular vendor is necessary.\n  In this work, we present an approach for watermarking Deep Neural Networks in\na black-box way. Our scheme works for general classification tasks and can\neasily be combined with current learning algorithms. We show experimentally\nthat such a watermark has no noticeable impact on the primary task that the\nmodel is designed for and evaluate the robustness of our proposal against a\nmultitude of practical attacks. Moreover, we provide a theoretical analysis,\nrelating our approach to previous work on backdooring.", "category": "cs.LG"}, {"title": "Training and Inference with Integers in Deep Neural Networks", "abstract": "Researches on deep neural networks with discrete parameters and their\ndeployment in embedded systems have been active and promising topics. Although\nprevious works have successfully reduced precision in inference, transferring\nboth training and inference processes to low-bitwidth integers has not been\ndemonstrated simultaneously. In this work, we develop a new method termed as\n\"WAGE\" to discretize both training and inference, where weights (W),\nactivations (A), gradients (G) and errors (E) among layers are shifted and\nlinearly constrained to low-bitwidth integers. To perform pure discrete\ndataflow for fixed-point devices, we further replace batch normalization by a\nconstant scaling layer and simplify other components that are arduous for\ninteger implementation. Improved accuracies can be obtained on multiple\ndatasets, which indicates that WAGE somehow acts as a type of regularization.\nEmpirically, we demonstrate the potential to deploy training in hardware\nsystems such as integer-based deep learning accelerators and neuromorphic chips\nwith comparable accuracy and higher energy efficiency, which is crucial to\nfuture AI applications in variable scenarios with transfer and continual\nlearning demands.", "category": "cs.LG"}, {"title": "Predict and Constrain: Modeling Cardinality in Deep Structured Prediction", "abstract": "Many machine learning problems require the prediction of multi-dimensional\nlabels. Such structured prediction models can benefit from modeling\ndependencies between labels. Recently, several deep learning approaches to\nstructured prediction have been proposed. Here we focus on capturing\ncardinality constraints in such models. Namely, constraining the number of\nnon-zero labels that the model outputs. Such constraints have proven very\nuseful in previous structured prediction approaches, but it is a challenge to\nintroduce them into a deep learning framework. Here we show how to do this via\na novel deep architecture. Our approach outperforms strong baselines, achieving\nstate-of-the-art results on multi-label classification benchmarks.", "category": "cs.LG"}, {"title": "Identify Susceptible Locations in Medical Records via Adversarial Attacks on Deep Predictive Models", "abstract": "The surging availability of electronic medical records (EHR) leads to\nincreased research interests in medical predictive modeling. Recently many deep\nlearning based predicted models are also developed for EHR data and\ndemonstrated impressive performance. However, a series of recent studies showed\nthat these deep models are not safe: they suffer from certain vulnerabilities.\nIn short, a well-trained deep network can be extremely sensitive to inputs with\nnegligible changes. These inputs are referred to as adversarial examples. In\nthe context of medical informatics, such attacks could alter the result of a\nhigh performance deep predictive model by slightly perturbing a patient's\nmedical records. Such instability not only reflects the weakness of deep\narchitectures, more importantly, it offers guide on detecting susceptible parts\non the inputs. In this paper, we propose an efficient and effective framework\nthat learns a time-preferential minimum attack targeting the LSTM model with\nEHR inputs, and we leverage this attack strategy to screen medical records of\npatients and identify susceptible events and measurements. The efficient\nscreening procedure can assist decision makers to pay extra attentions to the\nlocations that can cause severe consequence if not measured correctly. We\nconduct extensive empirical studies on a real-world urgent care cohort and\ndemonstrate the effectiveness of the proposed screening approach.", "category": "cs.LG"}, {"title": "Geometry-Based Data Generation", "abstract": "Many generative models attempt to replicate the density of their input data.\nHowever, this approach is often undesirable, since data density is highly\naffected by sampling biases, noise, and artifacts. We propose a method called\nSUGAR (Synthesis Using Geometrically Aligned Random-walks) that uses a\ndiffusion process to learn a manifold geometry from the data. Then, it\ngenerates new points evenly along the manifold by pulling randomly generated\npoints into its intrinsic structure using a diffusion kernel. SUGAR equalizes\nthe density along the manifold by selectively generating points in sparse areas\nof the manifold. We demonstrate how the approach corrects sampling biases and\nartifacts, while also revealing intrinsic patterns (e.g. progression) and\nrelations in the data. The method is applicable for correcting missing data,\nfinding hypothetical data points, and learning relationships between data\nfeatures.", "category": "cs.LG"}, {"title": "Attack RMSE Leaderboard: An Introduction and Case Study", "abstract": "In this manuscript, we briefly introduce several tricks to climb the\nleaderboards which use RMSE for evaluation without exploiting any training\ndata.", "category": "cs.LG"}, {"title": "Graph2Seq: Scalable Learning Dynamics for Graphs", "abstract": "Neural networks have been shown to be an effective tool for learning\nalgorithms over graph-structured data. However, graph representation\ntechniques---that convert graphs to real-valued vectors for use with neural\nnetworks---are still in their infancy. Recent works have proposed several\napproaches (e.g., graph convolutional networks), but these methods have\ndifficulty scaling and generalizing to graphs with different sizes and shapes.\nWe present Graph2Seq, a new technique that represents vertices of graphs as\ninfinite time-series. By not limiting the representation to a fixed dimension,\nGraph2Seq scales naturally to graphs of arbitrary sizes and shapes. Graph2Seq\nis also reversible, allowing full recovery of the graph structure from the\nsequences. By analyzing a formal computational model for graph representation,\nwe show that an unbounded sequence is necessary for scalability. Our\nexperimental results with Graph2Seq show strong generalization and new\nstate-of-the-art performance on a variety of graph combinatorial optimization\nproblems.", "category": "cs.LG"}, {"title": "DESlib: A Dynamic ensemble selection library in Python", "abstract": "DESlib is an open-source python library providing the implementation of\nseveral dynamic selection techniques. The library is divided into three\nmodules: (i) \\emph{dcs}, containing the implementation of dynamic classifier\nselection methods (DCS); (ii) \\emph{des}, containing the implementation of\ndynamic ensemble selection methods (DES); (iii) \\emph{static}, with the\nimplementation of static ensemble techniques. The library is fully documented\n(documentation available online on Read the Docs), has a high test coverage\n(codecov.io) and is part of the scikit-learn-contrib supported projects.\nDocumentation, code and examples can be found on its GitHub page:\nhttps://github.com/scikit-learn-contrib/DESlib.", "category": "cs.LG"}, {"title": "Tackling Multilabel Imbalance through Label Decoupling and Data Resampling Hybridization", "abstract": "The learning from imbalanced data is a deeply studied problem in standard\nclassification and, in recent times, also in multilabel classification. A\nhandful of multilabel resampling methods have been proposed in late years,\naiming to balance the labels distribution. However these methods have to face a\nnew obstacle, specific for multilabel data, as is the joint appearance of\nminority and majority labels in the same data patterns. We proposed recently a\nnew algorithm designed to decouple imbalanced labels concurring in the same\ninstance, called REMEDIAL (\\textit{REsampling MultilabEl datasets by Decoupling\nhighly ImbAlanced Labels}). The goal of this work is to propose a procedure to\nhybridize this method with some of the best resampling algorithms available in\nthe literature, including random oversampling, heuristic undersampling and\nsynthetic sample generation techniques. These hybrid methods are then\nempirically analyzed, determining how their behavior is influenced by the label\ndecoupling process. As a result, a noteworthy set of guidelines on the combined\nuse of these techniques can be drawn from the conducted experimentation.", "category": "cs.LG"}, {"title": "Dealing with Difficult Minority Labels in Imbalanced Mutilabel Data Sets", "abstract": "Multilabel classification is an emergent data mining task with a broad range\nof real world applications. Learning from imbalanced multilabel data is being\ndeeply studied latterly, and several resampling methods have been proposed in\nthe literature. The unequal label distribution in most multilabel datasets,\nwith disparate imbalance levels, could be a handicap while learning new\nclassifiers. In addition, this characteristic challenges many of the existent\npreprocessing algorithms. Furthermore, the concurrence between imbalanced\nlabels can make harder the learning from certain labels. These are what we call\n\\textit{difficult} labels. In this work, the problem of difficult labels is\ndeeply analyzed, its influence in multilabel classifiers is studied, and a\nnovel way to solve this problem is proposed. Specific metrics to assess this\ntrait in multilabel datasets, called \\textit{SCUMBLE} (\\textit{Score of\nConcUrrence among iMBalanced LabEls}) and \\textit{SCUMBLELbl}, are presented\nalong with REMEDIAL (\\textit{REsampling MultilabEl datasets by Decoupling\nhighly ImbAlanced Labels}), a new algorithm aimed to relax label concurrence.\nHow to deal with this problem using the R mldr package is also outlined.", "category": "cs.LG"}, {"title": "GEP-PG: Decoupling Exploration and Exploitation in Deep Reinforcement Learning Algorithms", "abstract": "In continuous action domains, standard deep reinforcement learning algorithms\nlike DDPG suffer from inefficient exploration when facing sparse or deceptive\nreward problems. Conversely, evolutionary and developmental methods focusing on\nexploration like Novelty Search, Quality-Diversity or Goal Exploration\nProcesses explore more robustly but are less efficient at fine-tuning policies\nusing gradient descent. In this paper, we present the GEP-PG approach, taking\nthe best of both worlds by sequentially combining a Goal Exploration Process\nand two variants of DDPG. We study the learning performance of these components\nand their combination on a low dimensional deceptive reward problem and on the\nlarger Half-Cheetah benchmark. We show that DDPG fails on the former and that\nGEP-PG improves over the best DDPG variant in both environments. Supplementary\nvideos and discussion can be found at http://frama.link/gep_pg, the code at\nhttp://github.com/flowersteam/geppg.", "category": "cs.LG"}, {"title": "Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners", "abstract": "In real-world applications of education, an effective teacher adaptively\nchooses the next example to teach based on the learner's current state.\nHowever, most existing work in algorithmic machine teaching focuses on the\nbatch setting, where adaptivity plays no role. In this paper, we study the case\nof teaching consistent, version space learners in an interactive setting. At\nany time step, the teacher provides an example, the learner performs an update,\nand the teacher observes the learner's new state. We highlight that adaptivity\ndoes not speed up the teaching process when considering existing models of\nversion space learners, such as \"worst-case\" (the learner picks the next\nhypothesis randomly from the version space) and \"preference-based\" (the learner\npicks hypothesis according to some global preference). Inspired by human\nteaching, we propose a new model where the learner picks hypotheses according\nto some local preference defined by the current hypothesis. We show that our\nmodel exhibits several desirable properties, e.g., adaptivity plays a key role,\nand the learner's transitions over hypotheses are smooth/interpretable. We\ndevelop efficient teaching algorithms and demonstrate our results via\nsimulation and user studies.", "category": "cs.LG"}, {"title": "Stronger generalization bounds for deep nets via a compression approach", "abstract": "Deep nets generalize well despite having more parameters than the number of\ntraining samples. Recent works try to give an explanation using PAC-Bayes and\nMargin-based analyses, but do not as yet result in sample complexity bounds\nbetter than naive parameter counting. The current paper shows generalization\nbounds that're orders of magnitude better in practice. These rely upon new\nsuccinct reparametrizations of the trained net --- a compression that is\nexplicit and efficient. These yield generalization bounds via a simple\ncompression-based framework introduced here. Our results also provide some\ntheoretical justification for widespread empirical success in compressing deep\nnets. Analysis of correctness of our compression relies upon some newly\nidentified \\textquotedblleft noise stability\\textquotedblright properties of\ntrained deep nets, which are also experimentally verified. The study of these\nproperties and resulting generalization bounds are also extended to\nconvolutional nets, which had eluded earlier attempts on proving\ngeneralization.", "category": "cs.LG"}, {"title": "Semi-Supervised Learning on Graphs Based on Local Label Distributions", "abstract": "Most approaches that tackle the problem of node classification consider nodes\nto be similar, if they have shared neighbors or are close to each other in the\ngraph. Recent methods for attributed graphs additionally take attributes of\nneighboring nodes into account. We argue that the class labels of the neighbors\nbear important information and considering them helps to improve classification\nquality. Two nodes which are similar based on class labels in their\nneighborhood do not need to be close-by in the graph and may even belong to\ndifferent connected components. In this work, we propose a novel approach for\nthe semi-supervised node classification. Precisely, we propose a new node\nembedding which is based on the class labels in the local neighborhood of a\nnode. We show that this is a different setting from attribute-based embeddings\nand thus, we propose a new method to learn label-based node embeddings which\ncan mirror a variety of relations between the class labels of neighboring\nnodes. Our experimental evaluation demonstrates that our new methods can\nsignificantly improve the prediction quality on real world data sets.", "category": "cs.LG"}, {"title": "Gradient Boosting With Piece-Wise Linear Regression Trees", "abstract": "Gradient Boosted Decision Trees (GBDT) is a very successful ensemble learning\nalgorithm widely used across a variety of applications. Recently, several\nvariants of GBDT training algorithms and implementations have been designed and\nheavily optimized in some very popular open sourced toolkits including XGBoost,\nLightGBM and CatBoost. In this paper, we show that both the accuracy and\nefficiency of GBDT can be further enhanced by using more complex base learners.\nSpecifically, we extend gradient boosting to use piecewise linear regression\ntrees (PL Trees), instead of piecewise constant regression trees, as base\nlearners. We show that PL Trees can accelerate convergence of GBDT and improve\nthe accuracy. We also propose some optimization tricks to substantially reduce\nthe training time of PL Trees, with little sacrifice of accuracy. Moreover, we\npropose several implementation techniques to speedup our algorithm on modern\ncomputer architectures with powerful Single Instruction Multiple Data (SIMD)\nparallelism. The experimental results show that GBDT with PL Trees can provide\nvery competitive testing accuracy with comparable or less training time.", "category": "cs.LG"}, {"title": "Learning Determinantal Point Processes by Corrective Negative Sampling", "abstract": "Determinantal Point Processes (DPPs) have attracted significant interest from\nthe machine-learning community due to their ability to elegantly and tractably\nmodel the delicate balance between quality and diversity of sets. DPPs are\ncommonly learned from data using maximum likelihood estimation (MLE). While\nfitting observed sets well, MLE for DPPs may also assign high likelihoods to\nunobserved sets that are far from the true generative distribution of the data.\nTo address this issue, which reduces the quality of the learned model, we\nintroduce a novel optimization problem, Contrastive Estimation (CE), which\nencodes information about \"negative\" samples into the basic learning model. CE\nis grounded in the successful use of negative information in machine-vision and\nlanguage modeling. Depending on the chosen negative distribution (which may be\nstatic or evolve during optimization), CE assumes two different forms, which we\nanalyze theoretically and experimentally. We evaluate our new model on\nreal-world datasets; on a challenging dataset, CE learning delivers a\nconsiderable improvement in predictive performance over a DPP learned without\nusing contrastive information.", "category": "cs.LG"}, {"title": "MPC-Inspired Neural Network Policies for Sequential Decision Making", "abstract": "In this paper we investigate the use of MPC-inspired neural network policies\nfor sequential decision making. We introduce an extension to the DAgger\nalgorithm for training such policies and show how they have improved training\nperformance and generalization capabilities. We take advantage of this\nextension to show scalable and efficient training of complex planning policy\narchitectures in continuous state and action spaces. We provide an extensive\ncomparison of neural network policies by considering feed forward policies,\nrecurrent policies, and recurrent policies with planning structure inspired by\nthe Path Integral control framework. Our results suggest that MPC-type\nrecurrent policies have better robustness to disturbances and modeling error.", "category": "cs.LG"}, {"title": "Constrained Convolutional-Recurrent Networks to Improve Speech Quality with Low Impact on Recognition Accuracy", "abstract": "For a speech-enhancement algorithm, it is highly desirable to simultaneously\nimprove perceptual quality and recognition rate. Thanks to computational costs\nand model complexities, it is challenging to train a model that effectively\noptimizes both metrics at the same time. In this paper, we propose a method for\nspeech enhancement that combines local and global contextual structures\ninformation through convolutional-recurrent neural networks that improves\nperceptual quality. At the same time, we introduce a new constraint on the\nobjective function using a language model/decoder that limits the impact on\nrecognition rate. Based on experiments conducted with real user data, we\ndemonstrate that our new context-augmented machine-learning approach for speech\nenhancement improves PESQ and WER by an additional 24.5% and 51.3%,\nrespectively, when compared to the best-performing methods in the literature.", "category": "cs.LG"}, {"title": "Variance-based Gradient Compression for Efficient Distributed Deep Learning", "abstract": "Due to the substantial computational cost, training state-of-the-art deep\nneural networks for large-scale datasets often requires distributed training\nusing multiple computation workers. However, by nature, workers need to\nfrequently communicate gradients, causing severe bottlenecks, especially on\nlower bandwidth connections. A few methods have been proposed to compress\ngradient for efficient communication, but they either suffer a low compression\nratio or significantly harm the resulting model accuracy, particularly when\napplied to convolutional neural networks. To address these issues, we propose a\nmethod to reduce the communication overhead of distributed deep learning. Our\nkey observation is that gradient updates can be delayed until an unambiguous\n(high amplitude, low variance) gradient has been calculated. We also present an\nefficient algorithm to compute the variance with negligible additional cost. We\nexperimentally show that our method can achieve very high compression ratio\nwhile maintaining the result model accuracy. We also analyze the efficiency\nusing computation and communication cost models and provide the evidence that\nthis method enables distributed deep learning for many scenarios with commodity\nenvironments.", "category": "cs.LG"}, {"title": "An Alternative View: When Does SGD Escape Local Minima?", "abstract": "Stochastic gradient descent (SGD) is widely used in machine learning.\nAlthough being commonly viewed as a fast but not accurate version of gradient\ndescent (GD), it always finds better solutions than GD for modern neural\nnetworks.\n  In order to understand this phenomenon, we take an alternative view that SGD\nis working on the convolved (thus smoothed) version of the loss function. We\nshow that, even if the function $f$ has many bad local minima or saddle points,\nas long as for every point $x$, the weighted average of the gradients of its\nneighborhoods is one point convex with respect to the desired solution $x^*$,\nSGD will get close to, and then stay around $x^*$ with constant probability.\nMore specifically, SGD will not get stuck at \"sharp\" local minima with small\ndiameters, as long as the neighborhoods of these regions contain enough\ngradient information. The neighborhood size is controlled by step size and\ngradient noise.\n  Our result identifies a set of functions that SGD provably works, which is\nmuch larger than the set of convex functions. Empirically, we observe that the\nloss surface of neural networks enjoys nice one point convexity properties\nlocally, therefore our theorem helps explain why SGD works so well for neural\nnetworks.", "category": "cs.LG"}, {"title": "Sequence-to-Sequence Prediction of Vehicle Trajectory via LSTM Encoder-Decoder Architecture", "abstract": "In this paper, we propose a deep learning based vehicle trajectory prediction\ntechnique which can generate the future trajectory sequence of surrounding\nvehicles in real time. We employ the encoder-decoder architecture which\nanalyzes the pattern underlying in the past trajectory using the long\nshort-term memory (LSTM) based encoder and generates the future trajectory\nsequence using the LSTM based decoder. This structure produces the $K$ most\nlikely trajectory candidates over occupancy grid map by employing the beam\nsearch technique which keeps the $K$ locally best candidates from the decoder\noutput. The experiments conducted on highway traffic scenarios show that the\nprediction accuracy of the proposed method is significantly higher than the\nconventional trajectory prediction techniques.", "category": "cs.LG"}, {"title": "Inductive Framework for Multi-Aspect Streaming Tensor Completion with Side Information", "abstract": "Low rank tensor completion is a well studied problem and has applications in\nvarious fields. However, in many real world applications the data is dynamic,\ni.e., new data arrives at different time intervals. As a result, the tensors\nused to represent the data grow in size. Besides the tensors, in many real\nworld scenarios, side information is also available in the form of matrices\nwhich also grow in size with time. The problem of predicting missing values in\nthe dynamically growing tensor is called dynamic tensor completion. Most of the\nprevious work in dynamic tensor completion make an assumption that the tensor\ngrows only in one mode. To the best of our Knowledge, there is no previous work\nwhich incorporates side information with dynamic tensor completion. We bridge\nthis gap in this paper by proposing a dynamic tensor completion framework\ncalled Side Information infused Incremental Tensor Analysis (SIITA), which\nincorporates side information and works for general incremental tensors. We\nalso show how non-negative constraints can be incorporated with SIITA, which is\nessential for mining interpretable latent clusters. We carry out extensive\nexperiments on multiple real world datasets to demonstrate the effectiveness of\nSIITA in various different settings.", "category": "cs.LG"}, {"title": "Online convex optimization for cumulative constraints", "abstract": "We propose the algorithms for online convex optimization which lead to\ncumulative squared constraint violations of the form\n$\\sum\\limits_{t=1}^T\\big([g(x_t)]_+\\big)^2=O(T^{1-\\beta})$, where\n$\\beta\\in(0,1)$. Previous literature has focused on long-term constraints of\nthe form $\\sum\\limits_{t=1}^Tg(x_t)$. There, strictly feasible solutions can\ncancel out the effects of violated constraints. In contrast, the new form\nheavily penalizes large constraint violations and cancellation effects cannot\noccur.\n  Furthermore, useful bounds on the single step constraint violation\n$[g(x_t)]_+$ are derived.\n  For convex objectives, our regret bounds generalize existing bounds, and for\nstrongly convex objectives we give improved regret bounds.\n  In numerical experiments, we show that our algorithm closely follows the\nconstraint boundary leading to low cumulative violation.", "category": "cs.LG"}, {"title": "EA-CG: An Approximate Second-Order Method for Training Fully-Connected Neural Networks", "abstract": "For training fully-connected neural networks (FCNNs), we propose a practical\napproximate second-order method including: 1) an approximation of the Hessian\nmatrix and 2) a conjugate gradient (CG) based method. Our proposed approximate\nHessian matrix is memory-efficient and can be applied to any FCNNs where the\nactivation and criterion functions are twice differentiable. We devise a\nCG-based method incorporating one-rank approximation to derive Newton\ndirections for training FCNNs, which significantly reduces both space and time\ncomplexity. This CG-based method can be employed to solve any linear equation\nwhere the coefficient matrix is Kronecker-factored, symmetric and positive\ndefinite. Empirical studies show the efficacy and efficiency of our proposed\nmethod.", "category": "cs.LG"}, {"title": "On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization", "abstract": "Conventional wisdom in deep learning states that increasing depth improves\nexpressiveness but complicates optimization. This paper suggests that,\nsometimes, increasing depth can speed up optimization. The effect of depth on\noptimization is decoupled from expressiveness by focusing on settings where\nadditional layers amount to overparameterization - linear neural networks, a\nwell-studied model. Theoretical analysis, as well as experiments, show that\nhere depth acts as a preconditioner which may accelerate convergence. Even on\nsimple convex problems such as linear regression with $\\ell_p$ loss, $p>2$,\ngradient descent can benefit from transitioning to a non-convex\noverparameterized objective, more than it would from some common acceleration\nschemes. We also prove that it is mathematically impossible to obtain the\nacceleration effect of overparametrization via gradients of any regularizer.", "category": "cs.LG"}, {"title": "Deep Echo State Networks for Diagnosis of Parkinson's Disease", "abstract": "In this paper, we introduce a novel approach for diagnosis of Parkinson's\nDisease (PD) based on deep Echo State Networks (ESNs). The identification of PD\nis performed by analyzing the whole time-series collected from a tablet device\nduring the sketching of spiral tests, without the need for feature extraction\nand data preprocessing. We evaluated the proposed approach on a public dataset\nof spiral tests. The results of experimental analysis show that DeepESNs\nperform significantly better than shallow ESN model. Overall, the proposed\napproach obtains state-of-the-art results in the identification of PD on this\nkind of temporal data.", "category": "cs.LG"}, {"title": "Leveraged volume sampling for linear regression", "abstract": "Suppose an $n \\times d$ design matrix in a linear regression problem is\ngiven, but the response for each point is hidden unless explicitly requested.\nThe goal is to sample only a small number $k \\ll n$ of the responses, and then\nproduce a weight vector whose sum of squares loss over all points is at most\n$1+\\epsilon$ times the minimum. When $k$ is very small (e.g., $k=d$), jointly\nsampling diverse subsets of points is crucial. One such method called volume\nsampling has a unique and desirable property that the weight vector it produces\nis an unbiased estimate of the optimum. It is therefore natural to ask if this\nmethod offers the optimal unbiased estimate in terms of the number of responses\n$k$ needed to achieve a $1+\\epsilon$ loss approximation.\n  Surprisingly we show that volume sampling can have poor behavior when we\nrequire a very accurate approximation -- indeed worse than some i.i.d. sampling\ntechniques whose estimates are biased, such as leverage score sampling. We then\ndevelop a new rescaled variant of volume sampling that produces an unbiased\nestimate which avoids this bad behavior and has at least as good a tail bound\nas leverage score sampling: sample size $k=O(d\\log d + d/\\epsilon)$ suffices to\nguarantee total loss at most $1+\\epsilon$ times the minimum with high\nprobability. Thus, we improve on the best previously known sample size for an\nunbiased estimator, $k=O(d^2/\\epsilon)$.\n  Our rescaling procedure leads to a new efficient algorithm for volume\nsampling which is based on a determinantal rejection sampling technique with\npotentially broader applications to determinantal point processes. Other\ncontributions include introducing the combinatorics needed for rescaled volume\nsampling and developing tail bounds for sums of dependent random matrices which\narise in the process.", "category": "cs.LG"}, {"title": "Multi-resolution Tensor Learning for Large-Scale Spatial Data", "abstract": "High-dimensional tensor models are notoriously computationally expensive to\ntrain. We present a meta-learning algorithm, MMT, that can significantly speed\nup the process for spatial tensor models. MMT leverages the property that\nspatial data can be viewed at multiple resolutions, which are related by\ncoarsening and finegraining from one resolution to another. Using this\nproperty, MMT learns a tensor model by starting from a coarse resolution and\niteratively increasing the model complexity. In order to not \"over-train\" on\ncoarse resolution models, we investigate an information-theoretic fine-graining\ncriterion to decide when to transition into higher-resolution models. We\nprovide both theoretical and empirical evidence for the advantages of this\napproach. When applied to two real-world large-scale spatial datasets for\nbasketball player and animal behavior modeling, our approach demonstrate 3 key\nbenefits: 1) it efficiently captures higher-order interactions (i.e., tensor\nlatent factors), 2) it is orders of magnitude faster than fixed resolution\nlearning and scales to very fine-grained spatial resolutions, and 3) it\nreliably yields accurate and interpretable models.", "category": "cs.LG"}, {"title": "Online Learning with an Unknown Fairness Metric", "abstract": "We consider the problem of online learning in the linear contextual bandits\nsetting, but in which there are also strong individual fairness constraints\ngoverned by an unknown similarity metric. These constraints demand that we\nselect similar actions or individuals with approximately equal probability\n(arXiv:1104.3913), which may be at odds with optimizing reward, thus modeling\nsettings where profit and social policy are in tension. We assume we learn\nabout an unknown Mahalanobis similarity metric from only weak feedback that\nidentifies fairness violations, but does not quantify their extent. This is\nintended to represent the interventions of a regulator who \"knows unfairness\nwhen he sees it\" but nevertheless cannot enunciate a quantitative fairness\nmetric over individuals. Our main result is an algorithm in the adversarial\ncontext setting that has a number of fairness violations that depends only\nlogarithmically on $T$, while obtaining an optimal $O(\\sqrt{T})$ regret bound\nto the best fair policy.", "category": "cs.LG"}, {"title": "Constant Regret, Generalized Mixability, and Mirror Descent", "abstract": "We consider the setting of prediction with expert advice; a learner makes\npredictions by aggregating those of a group of experts. Under this setting, and\nfor the right choice of loss function and \"mixing\" algorithm, it is possible\nfor the learner to achieve a constant regret regardless of the number of\nprediction rounds. For example, a constant regret can be achieved for\n\\emph{mixable} losses using the \\emph{aggregating algorithm}. The\n\\emph{Generalized Aggregating Algorithm} (GAA) is a name for a family of\nalgorithms parameterized by convex functions on simplices (entropies), which\nreduce to the aggregating algorithm when using the \\emph{Shannon entropy}\n$\\operatorname{S}$. For a given entropy $\\Phi$, losses for which a constant\nregret is possible using the \\textsc{GAA} are called $\\Phi$-mixable. Which\nlosses are $\\Phi$-mixable was previously left as an open question. We fully\ncharacterize $\\Phi$-mixability and answer other open questions posed by\n\\cite{Reid2015}. We show that the Shannon entropy $\\operatorname{S}$ is\nfundamental in nature when it comes to mixability; any $\\Phi$-mixable loss is\nnecessarily $\\operatorname{S}$-mixable, and the lowest worst-case regret of the\n\\textsc{GAA} is achieved using the Shannon entropy. Finally, by leveraging the\nconnection between the \\emph{mirror descent algorithm} and the update step of\nthe GAA, we suggest a new \\emph{adaptive} generalized aggregating algorithm and\nanalyze its performance in terms of the regret bound.", "category": "cs.LG"}, {"title": "The Description Length of Deep Learning Models", "abstract": "Solomonoff's general theory of inference and the Minimum Description Length\nprinciple formalize Occam's razor, and hold that a good model of data is a\nmodel that is good at losslessly compressing the data, including the cost of\ndescribing the model itself. Deep neural networks might seem to go against this\nprinciple given the large number of parameters to be encoded.\n  We demonstrate experimentally the ability of deep neural networks to compress\nthe training data even when accounting for parameter encoding. The compression\nviewpoint originally motivated the use of variational methods in neural\nnetworks. Unexpectedly, we found that these variational methods provide\nsurprisingly poor compression bounds, despite being explicitly built to\nminimize such bounds. This might explain the relatively poor practical\nperformance of variational methods in deep learning. On the other hand, simple\nincremental encoding methods yield excellent compression values on deep\nnetworks, vindicating Solomonoff's approach.", "category": "cs.LG"}, {"title": "Local Differential Privacy for Evolving Data", "abstract": "There are now several large scale deployments of differential privacy used to\ncollect statistical information about users. However, these deployments\nperiodically recollect the data and recompute the statistics using algorithms\ndesigned for a single use. As a result, these systems do not provide meaningful\nprivacy guarantees over long time scales. Moreover, existing techniques to\nmitigate this effect do not apply in the \"local model\" of differential privacy\nthat these systems use.\n  In this paper, we introduce a new technique for local differential privacy\nthat makes it possible to maintain up-to-date statistics over time, with\nprivacy guarantees that degrade only in the number of changes in the underlying\ndistribution rather than the number of collection periods. We use our technique\nfor tracking a changing statistic in the setting where users are partitioned\ninto an unknown collection of groups, and at every time period each user draws\na single bit from a common (but changing) group-specific distribution. We also\nprovide an application to frequency and heavy-hitter estimation.", "category": "cs.LG"}, {"title": "Scalable Label Propagation for Multi-relational Learning on the Tensor Product of Graphs", "abstract": "Multi-relational learning on knowledge graphs infers high-order relations\namong the entities across the graphs. This learning task can be solved by label\npropagation on the tensor product of the knowledge graphs to learn the\nhigh-order relations as a tensor. In this paper, we generalize a widely used\nlabel propagation model to the normalized tensor product graph, and propose an\noptimization formulation and a scalable Low-rank Tensor-based Label Propagation\nalgorithm (LowrankTLP) to infer multi-relations for two learning tasks,\nhyperlink prediction and multiple graph alignment. The optimization formulation\nminimizes the upper bound of the noisy tensor estimation error for multiple\ngraph alignment, by learning with a subset of the eigen-pairs in the spectrum\nof the normalized tensor product graph. We also provide a data-dependent\ntransductive Rademacher bound for binary hyperlink prediction. We accelerate\nLowrankTLP with parallel tensor computation which enables label propagation on\na tensor product of 100 graphs each of size 1000 in less than half hour in the\nsimulation. LowrankTLP was also applied to predicting the author-paper-venue\nhyperlinks in publication records, alignment of segmented regions across up to\n26 CT-scan images and alignment of protein-protein interaction networks across\nmultiple species. The experiments demonstrate that LowrankTLP indeed well\napproximates the original label propagation with better scalability and\naccuracy.", "category": "cs.LG"}, {"title": "Breaking the gridlock in Mixture-of-Experts: Consistent and Efficient Algorithms", "abstract": "Mixture-of-Experts (MoE) is a widely popular model for ensemble learning and\nis a basic building block of highly successful modern neural networks as well\nas a component in Gated Recurrent Units (GRU) and Attention networks. However,\npresent algorithms for learning MoE including the EM algorithm, and gradient\ndescent are known to get stuck in local optima. From a theoretical viewpoint,\nfinding an efficient and provably consistent algorithm to learn the parameters\nremains a long standing open problem for more than two decades. In this paper,\nwe introduce the first algorithm that learns the true parameters of a MoE model\nfor a wide class of non-linearities with global consistency guarantees. While\nexisting algorithms jointly or iteratively estimate the expert parameters and\nthe gating paramters in the MoE, we propose a novel algorithm that breaks the\ndeadlock and can directly estimate the expert parameters by sensing its echo in\na carefully designed cross-moment tensor between the inputs and the output.\nOnce the experts are known, the recovery of gating parameters still requires an\nEM algorithm; however, we show that the EM algorithm for this simplified\nproblem, unlike the joint EM algorithm, converges to the true parameters. We\nempirically validate our algorithm on both the synthetic and real data sets in\na variety of settings, and show superior performance to standard baselines.", "category": "cs.LG"}, {"title": "Active Learning with Partial Feedback", "abstract": "While many active learning papers assume that the learner can simply ask for\na label and receive it, real annotation often presents a mismatch between the\nform of a label (say, one among many classes), and the form of an annotation\n(typically yes/no binary feedback). To annotate examples corpora for multiclass\nclassification, we might need to ask multiple yes/no questions, exploiting a\nlabel hierarchy if one is available. To address this more realistic setting, we\npropose active learning with partial feedback (ALPF), where the learner must\nactively choose both which example to label and which binary question to ask.\nAt each step, the learner selects an example, asking if it belongs to a chosen\n(possibly composite) class. Each answer eliminates some classes, leaving the\nlearner with a partial label. The learner may then either ask more questions\nabout the same example (until an exact label is uncovered) or move on\nimmediately, leaving the first example partially labeled. Active learning with\npartial labels requires (i) a sampling strategy to choose (example, class)\npairs, and (ii) learning from partial labels between rounds. Experiments on\nTiny ImageNet demonstrate that our most effective method improves 26%\n(relative) in top-1 classification accuracy compared to i.i.d. baselines and\nstandard active learners given 30% of the annotation budget that would be\nrequired (naively) to annotate the dataset. Moreover, ALPF-learners fully\nannotate TinyImageNet at 42% lower cost. Surprisingly, we observe that\naccounting for per-example annotation costs can alter the conventional wisdom\nthat active learners should solicit labels for hard examples.", "category": "cs.LG"}, {"title": "Smooth Loss Functions for Deep Top-k Classification", "abstract": "The top-k error is a common measure of performance in machine learning and\ncomputer vision. In practice, top-k classification is typically performed with\ndeep neural networks trained with the cross-entropy loss. Theoretical results\nindeed suggest that cross-entropy is an optimal learning objective for such a\ntask in the limit of infinite data. In the context of limited and noisy data\nhowever, the use of a loss function that is specifically designed for top-k\nclassification can bring significant improvements. Our empirical evidence\nsuggests that the loss function must be smooth and have non-sparse gradients in\norder to work well with deep neural networks. Consequently, we introduce a\nfamily of smoothed loss functions that are suited to top-k optimization via\ndeep learning. The widely used cross-entropy is a special case of our family.\nEvaluating our smooth loss functions is computationally challenging: a na\\\"ive\nalgorithm would require $\\mathcal{O}(\\binom{n}{k})$ operations, where n is the\nnumber of classes. Thanks to a connection to polynomial algebra and a\ndivide-and-conquer approach, we provide an algorithm with a time complexity of\n$\\mathcal{O}(k n)$. Furthermore, we present a novel approximation to obtain\nfast and stable algorithms on GPUs with single floating point precision. We\ncompare the performance of the cross-entropy loss and our margin-based losses\nin various regimes of noise and data size, for the predominant use case of k=5.\nOur investigation reveals that our loss is more robust to noise and overfitting\nthan cross-entropy.", "category": "cs.LG"}, {"title": "Protecting Sensory Data against Sensitive Inferences", "abstract": "There is growing concern about how personal data are used when users grant\napplications direct access to the sensors of their mobile devices. In fact,\nhigh resolution temporal data generated by motion sensors reflect directly the\nactivities of a user and indirectly physical and demographic attributes. In\nthis paper, we propose a feature learning architecture for mobile devices that\nprovides flexible and negotiable privacy-preserving sensor data transmission by\nappropriately transforming raw sensor data. The objective is to move from the\ncurrent binary setting of granting or not permission to an application, toward\na model that allows users to grant each application permission over a limited\nrange of inferences according to the provided services. The internal structure\nof each component of the proposed architecture can be flexibly changed and the\ntrade-off between privacy and utility can be negotiated between the constraints\nof the user and the underlying application. We validated the proposed\narchitecture in an activity recognition application using two real-world\ndatasets, with the objective of recognizing an activity without disclosing\ngender as an example of private information. Results show that the proposed\nframework maintains the usefulness of the transformed data for activity\nrecognition, with an average loss of only around three percentage points, while\nreducing the possibility of gender classification to around 50\\%, the target\nrandom guess, from more than 90\\% when using raw sensor data. We also present\nand distribute MotionSense, a new dataset for activity and attribute\nrecognition collected from motion sensors.", "category": "cs.LG"}, {"title": "Diversity regularization in deep ensembles", "abstract": "Calibrating the confidence of supervised learning models is important for a\nvariety of contexts where the certainty over predictions should be reliable.\nHowever, it has been reported that deep neural network models are often too\npoorly calibrated for achieving complex tasks requiring reliable uncertainty\nestimates in their prediction. In this work, we are proposing a strategy for\ntraining deep ensembles with a diversity function regularization, which\nimproves the calibration property while maintaining a similar prediction\naccuracy.", "category": "cs.LG"}, {"title": "Nonlinear Online Learning with Adaptive Nyström Approximation", "abstract": "Use of nonlinear feature maps via kernel approximation has led to success in\nmany online learning tasks. As a popular kernel approximation method,\nNystr\\\"{o}m approximation, has been well investigated, and various landmark\npoints selection methods have been proposed to improve the approximation\nquality. However, these improved Nystr\\\"{o}m methods cannot be directly applied\nto the online learning setting as they need to access the entire dataset to\nlearn the landmark points, while we need to update model on-the-fly in the\nonline setting. To address this challenge, we propose Adaptive Nystr\\\"{o}m\napproximation for solving nonlinear online learning problems. The key idea is\nto adaptively modify the landmark points via online kmeans and adjust the model\naccordingly via solving least square problem followed by a gradient descent\nstep. We show that the resulting algorithm outperforms state-of-the-art online\nlearning methods under the same budget.", "category": "cs.LG"}, {"title": "Learning Mixtures of Linear Regressions with Nearly Optimal Complexity", "abstract": "Mixtures of Linear Regressions (MLR) is an important mixture model with many\napplications. In this model, each observation is generated from one of the\nseveral unknown linear regression components, where the identity of the\ngenerated component is also unknown. Previous works either assume strong\nassumptions on the data distribution or have high complexity. This paper\nproposes a fixed parameter tractable algorithm for the problem under general\nconditions, which achieves global convergence and the sample complexity scales\nnearly linearly in the dimension. In particular, different from previous works\nthat require the data to be from the standard Gaussian, the algorithm allows\nthe data from Gaussians with different covariances. When the conditional number\nof the covariances and the number of components are fixed, the algorithm has\nnearly optimal sample complexity $N = \\tilde{O}(d)$ as well as nearly optimal\ncomputational complexity $\\tilde{O}(Nd)$, where $d$ is the dimension of the\ndata space. To the best of our knowledge, this approach provides the first such\nrecovery guarantee for this general setting.", "category": "cs.LG"}, {"title": "Actigraphy-based Sleep/Wake Pattern Detection using Convolutional Neural Networks", "abstract": "Common medical conditions are often associated with sleep abnormalities.\nPatients with medical disorders often suffer from poor sleep quality compared\nto healthy individuals, which in turn may worsen the symptoms of the disorder.\nAccurate detection of sleep/wake patterns is important in developing\npersonalized digital markers, which can be used for objective measurements and\nefficient disease management. Big Data technologies and advanced analytics\nmethods hold the promise to revolutionize clinical research processes, enabling\nthe effective blending of digital data into clinical trials. Actigraphy, a\nnon-invasive activity monitoring method is heavily used to detect and evaluate\nactivities and movement disorders, and assess sleep/wake behavior. In order to\nstudy the connection between sleep/wake patterns and a cluster headache\ndisorder, activity data was collected using a wearable device in the course of\na clinical trial. This study presents two novel modeling schemes that utilize\nDeep Convolutional Neural Networks (CNN) to identify sleep/wake states. The\nproposed methods are a sequential CNN, reminiscent of the bi-directional CNN\nfor slot filling, and a Multi-Task Learning (MTL) based model. Furthermore, we\nexpand standard \"Sleep\" and \"Wake\" activity states space by adding the \"Falling\nasleep\" and \"Siesta\" states. We show that the proposed methods provide\npromising results in accurate detection of the expanded sleep/wake states.\nFinally, we explore the relations between the detected sleep/wake patterns and\nonset of cluster headache attacks, and present preliminary observations.", "category": "cs.LG"}, {"title": "Learning to Route with Sparse Trajectory Sets---Extended Version", "abstract": "Motivated by the increasing availability of vehicle trajectory data, we\npropose learn-to-route, a comprehensive trajectory-based routing solution.\nSpecifically, we first construct a graph-like structure from trajectories as\nthe routing infrastructure. Second, we enable trajectory-based routing given an\narbitrary (source, destination) pair.\n  In the first step, given a road network and a collection of trajectories, we\npropose a trajectory-based clustering method that identifies regions in a road\nnetwork. If a pair of regions are connected by trajectories, we maintain the\npaths used by these trajectories and learn a routing preference for travel\nbetween the regions. As trajectories are skewed and sparse, many region pairs\nare not connected by trajectories. We thus transfer routing preferences from\nregion pairs with sufficient trajectories to such region pairs and then use the\ntransferred preferences to identify paths between the regions. In the second\nstep, we exploit the above graph-like structure to achieve a comprehensive\ntrajectory-based routing solution. Empirical studies with two substantial\ntrajectory data sets offer insight into the proposed solution, indicating that\nit is practical. A comparison with a leading routing service offers evidence\nthat the paper's proposal is able to enhance routing quality.\n  This is an extended version of \"Learning to Route with Sparse Trajectory\nSets\" [1], to appear in IEEE ICDE 2018.", "category": "cs.LG"}, {"title": "Unicorn: Continual Learning with a Universal, Off-policy Agent", "abstract": "Some real-world domains are best characterized as a single task, but for\nothers this perspective is limiting. Instead, some tasks continually grow in\ncomplexity, in tandem with the agent's competence. In continual learning, also\nreferred to as lifelong learning, there are no explicit task boundaries or\ncurricula. As learning agents have become more powerful, continual learning\nremains one of the frontiers that has resisted quick progress. To test\ncontinual learning capabilities we consider a challenging 3D domain with an\nimplicit sequence of tasks and sparse rewards. We propose a novel agent\narchitecture called Unicorn, which demonstrates strong continual learning and\noutperforms several baseline agents on the proposed domain. The agent achieves\nthis by jointly representing and learning multiple policies efficiently, using\na parallel off-policy learning setup.", "category": "cs.LG"}, {"title": "Diverse Exploration for Fast and Safe Policy Improvement", "abstract": "We study an important yet under-addressed problem of quickly and safely\nimproving policies in online reinforcement learning domains. As its solution,\nwe propose a novel exploration strategy - diverse exploration (DE), which\nlearns and deploys a diverse set of safe policies to explore the environment.\nWe provide DE theory explaining why diversity in behavior policies enables\neffective exploration without sacrificing exploitation. Our empirical study\nshows that an online policy improvement algorithm framework implementing the DE\nstrategy can achieve both fast policy improvement and safe online performance.", "category": "cs.LG"}, {"title": "Loss-aware Weight Quantization of Deep Networks", "abstract": "The huge size of deep networks hinders their use in small computing devices.\nIn this paper, we consider compressing the network by weight quantization. We\nextend a recently proposed loss-aware weight binarization scheme to\nternarization, with possibly different scaling parameters for the positive and\nnegative weights, and m-bit (where m > 2) quantization. Experiments on\nfeedforward and recurrent neural networks show that the proposed scheme\noutperforms state-of-the-art weight quantization algorithms, and is as accurate\n(or even more accurate) than the full-precision network.", "category": "cs.LG"}, {"title": "Asynchronous Stochastic Proximal Methods for Nonconvex Nonsmooth Optimization", "abstract": "We study stochastic algorithms for solving nonconvex optimization problems\nwith a convex yet possibly nonsmooth regularizer, which find wide applications\nin many practical machine learning applications. However, compared to\nasynchronous parallel stochastic gradient descent (AsynSGD), an algorithm\ntargeting smooth optimization, the understanding of the behavior of stochastic\nalgorithms for nonsmooth regularized optimization problems is limited,\nespecially when the objective function is nonconvex. To fill this theoretical\ngap, in this paper, we propose and analyze asynchronous parallel stochastic\nproximal gradient (Asyn-ProxSGD) methods for nonconvex problems. We establish\nan ergodic convergence rate of $O(1/\\sqrt{K})$ for the proposed Asyn-ProxSGD,\nwhere $K$ is the number of updates made on the model, matching the convergence\nrate currently known for AsynSGD (for smooth problems). To our knowledge, this\nis the first work that provides convergence rates of asynchronous parallel\nProxSGD algorithms for nonconvex problems. Furthermore, our results are also\nthe first to show the convergence of any stochastic proximal methods without\nassuming an increasing batch size or the use of additional variance reduction\ntechniques. We implement the proposed algorithms on Parameter Server and\ndemonstrate its convergence behavior and near-linear speedup, as the number of\nworkers increases, on two real-world datasets.", "category": "cs.LG"}, {"title": "A Block-wise, Asynchronous and Distributed ADMM Algorithm for General Form Consensus Optimization", "abstract": "Many machine learning models, including those with non-smooth regularizers,\ncan be formulated as consensus optimization problems, which can be solved by\nthe alternating direction method of multipliers (ADMM). Many recent efforts\nhave been made to develop asynchronous distributed ADMM to handle large amounts\nof training data. However, all existing asynchronous distributed ADMM methods\nare based on full model updates and require locking all global model parameters\nto handle concurrency, which essentially serializes the updates from different\nworkers. In this paper, we present a novel block-wise, asynchronous and\ndistributed ADMM algorithm, which allows different blocks of model parameters\nto be updated in parallel. The lock-free block-wise algorithm may greatly\nspeedup sparse optimization problems, a common scenario in reality, in which\nmost model updates only modify a subset of all decision variables. We\ntheoretically prove the convergence of our proposed algorithm to stationary\npoints for non-convex general form consensus problems with possibly non-smooth\nregularizers. We implement the proposed ADMM algorithm on the Parameter Server\nframework and demonstrate its convergence and near-linear speedup performance\nas the number of workers increases.", "category": "cs.LG"}, {"title": "Time Series Learning using Monotonic Logical Properties", "abstract": "Cyber-physical systems of today are generating large volumes of time-series\ndata. As manual inspection of such data is not tractable, the need for learning\nmethods to help discover logical structure in the data has increased. We\npropose a logic-based framework that allows domain-specific knowledge to be\nembedded into formulas in a parametric logical specification over time-series\ndata. The key idea is to then map a time series to a surface in the parameter\nspace of the formula. Given this mapping, we identify the Hausdorff distance\nbetween boundaries as a natural distance metric between two time-series data\nunder the lens of the parametric specification. This enables embedding\nnon-trivial domain-specific knowledge into the distance metric and then using\noff-the-shelf machine learning tools to label the data. After labeling the\ndata, we demonstrate how to extract a logical specification for each label.\nFinally, we showcase our technique on real world traffic data to learn\nclassifiers/monitors for slow-downs and traffic jams.", "category": "cs.LG"}, {"title": "Temporal Difference Models: Model-Free Deep RL for Model-Based Control", "abstract": "Model-free reinforcement learning (RL) is a powerful, general tool for\nlearning complex behaviors. However, its sample efficiency is often\nimpractically large for solving challenging real-world problems, even with\noff-policy algorithms such as Q-learning. A limiting factor in classic\nmodel-free RL is that the learning signal consists only of scalar rewards,\nignoring much of the rich information contained in state transition tuples.\nModel-based RL uses this information, by training a predictive model, but often\ndoes not achieve the same asymptotic performance as model-free RL due to model\nbias. We introduce temporal difference models (TDMs), a family of\ngoal-conditioned value functions that can be trained with model-free learning\nand used for model-based control. TDMs combine the benefits of model-free and\nmodel-based RL: they leverage the rich information in state transitions to\nlearn very efficiently, while still attaining asymptotic performance that\nexceeds that of direct model-based RL methods. Our experimental results show\nthat, on a range of continuous control tasks, TDMs provide a substantial\nimprovement in efficiency compared to state-of-the-art model-based and\nmodel-free methods.", "category": "cs.LG"}, {"title": "Max-Mahalanobis Linear Discriminant Analysis Networks", "abstract": "A deep neural network (DNN) consists of a nonlinear transformation from an\ninput to a feature representation, followed by a common softmax linear\nclassifier. Though many efforts have been devoted to designing a proper\narchitecture for nonlinear transformation, little investigation has been done\non the classifier part. In this paper, we show that a properly designed\nclassifier can improve robustness to adversarial attacks and lead to better\nprediction results. Specifically, we define a Max-Mahalanobis distribution\n(MMD) and theoretically show that if the input distributes as a MMD, the linear\ndiscriminant analysis (LDA) classifier will have the best robustness to\nadversarial examples. We further propose a novel Max-Mahalanobis linear\ndiscriminant analysis (MM-LDA) network, which explicitly maps a complicated\ndata distribution in the input space to a MMD in the latent feature space and\nthen applies LDA to make predictions. Our results demonstrate that the MM-LDA\nnetworks are significantly more robust to adversarial attacks, and have better\nperformance in class-biased classification.", "category": "cs.LG"}, {"title": "Stochastic Hyperparameter Optimization through Hypernetworks", "abstract": "Machine learning models are often tuned by nesting optimization of model\nweights inside the optimization of hyperparameters. We give a method to\ncollapse this nested optimization into joint stochastic optimization of weights\nand hyperparameters. Our process trains a neural network to output\napproximately optimal weights as a function of hyperparameters. We show that\nour technique converges to locally optimal weights and hyperparameters for\nsufficiently large hypernetworks. We compare this method to standard\nhyperparameter optimization strategies and demonstrate its effectiveness for\ntuning thousands of hyperparameters.", "category": "cs.LG"}, {"title": "Retrieval-Augmented Convolutional Neural Networks for Improved Robustness against Adversarial Examples", "abstract": "We propose a retrieval-augmented convolutional network and propose to train\nit with local mixup, a novel variant of the recently proposed mixup algorithm.\nThe proposed hybrid architecture combining a convolutional network and an\noff-the-shelf retrieval engine was designed to mitigate the adverse effect of\noff-manifold adversarial examples, while the proposed local mixup addresses\non-manifold ones by explicitly encouraging the classifier to locally behave\nlinearly on the data manifold. Our evaluation of the proposed approach against\nfive readily-available adversarial attacks on three datasets--CIFAR-10, SVHN\nand ImageNet--demonstrate the improved robustness compared to the vanilla\nconvolutional network.", "category": "cs.LG"}, {"title": "Multi-Observation Regression", "abstract": "Recent work introduced loss functions which measure the error of a prediction\nbased on multiple simultaneous observations or outcomes. In this paper, we\nexplore the theoretical and practical questions that arise when using such\nmulti-observation losses for regression on data sets of $(x,y)$ pairs. When a\nloss depends on only one observation, the average empirical loss decomposes by\napplying the loss to each pair, but for the multi-observation case, empirical\nloss is not even well-defined, and the possibility of statistical guarantees is\nunclear without several $(x,y)$ pairs with exactly the same $x$ value. We\npropose four algorithms formalizing the concept of empirical risk minimization\nfor this problem, two of which have statistical guarantees in settings allowing\nboth slow and fast convergence rates, but which are out-performed empirically\nby the other two. Empirical results demonstrate practicality of these\nalgorithms in low-dimensional settings, while lower bounds demonstrate\nintrinsic difficulty in higher dimensions. Finally, we demonstrate the\npotential benefit of the algorithms over natural baselines that use traditional\nsingle-observation losses via both lower bounds and simulations.", "category": "cs.LG"}, {"title": "Robust Actor-Critic Contextual Bandit for Mobile Health (mHealth) Interventions", "abstract": "We consider the actor-critic contextual bandit for the mobile health\n(mHealth) intervention. State-of-the-art decision-making algorithms generally\nignore the outliers in the dataset. In this paper, we propose a novel robust\ncontextual bandit method for the mHealth. It can achieve the conflicting goal\nof reducing the influence of outliers while seeking for a similar solution\ncompared with the state-of-the-art contextual bandit methods on the datasets\nwithout outliers. Such performance relies on two technologies: (1) the\ncapped-$\\ell_{2}$ norm; (2) a reliable method to set the thresholding\nhyper-parameter, which is inspired by one of the most fundamental techniques in\nthe statistics. Although the model is non-convex and non-differentiable, we\npropose an effective reweighted algorithm and provide solid theoretical\nanalyses. We prove that the proposed algorithm can find sufficiently decreasing\npoints after each iteration and finally converges after a finite number of\niterations. Extensive experiment results on two datasets demonstrate that our\nmethod can achieve almost identical results compared with state-of-the-art\ncontextual bandit methods on the dataset without outliers, and significantly\noutperform those state-of-the-art methods on the badly noised dataset with\noutliers in a variety of parameter settings.", "category": "cs.LG"}, {"title": "L1-Norm Batch Normalization for Efficient Training of Deep Neural Networks", "abstract": "Batch Normalization (BN) has been proven to be quite effective at\naccelerating and improving the training of deep neural networks (DNNs).\nHowever, BN brings additional computation, consumes more memory and generally\nslows down the training process by a large margin, which aggravates the\ntraining effort. Furthermore, the nonlinear square and root operations in BN\nalso impede the low bit-width quantization techniques, which draws much\nattention in deep learning hardware community. In this work, we propose an\nL1-norm BN (L1BN) with only linear operations in both the forward and the\nbackward propagations during training. L1BN is shown to be approximately\nequivalent to the original L2-norm BN (L2BN) by multiplying a scaling factor.\nExperiments on various convolutional neural networks (CNNs) and generative\nadversarial networks (GANs) reveal that L1BN maintains almost the same\naccuracies and convergence rates compared to L2BN but with higher computational\nefficiency. On FPGA platform, the proposed signum and absolute operations in\nL1BN can achieve 1.5$\\times$ speedup and save 50\\% power consumption, compared\nwith the original costly square and root operations, respectively. This\nhardware-friendly normalization method not only surpasses L2BN in speed, but\nalso simplify the hardware design of ASIC accelerators with higher energy\nefficiency. Last but not the least, L1BN promises a fully quantized training of\nDNNs, which is crucial to future adaptive terminal devices.", "category": "cs.LG"}, {"title": "Time-sensitive Customer Churn Prediction based on PU Learning", "abstract": "With the fast development of Internet companies throughout the world,\ncustomer churn has become a serious concern. To better help the companies\nretain their customers, it is important to build a customer churn prediction\nmodel to identify the customers who are most likely to churn ahead of time. In\nthis paper, we propose a Time-sensitive Customer Churn Prediction (TCCP)\nframework based on Positive and Unlabeled (PU) learning technique.\nSpecifically, we obtain the recent data by shortening the observation period,\nand start to train model as long as enough positive samples are collected,\nignoring the absence of the negative examples. We conduct thoroughly\nexperiments on real industry data from Alipay.com. The experimental results\ndemonstrate that TCCP outperforms the rule-based models and the traditional\nsupervised learning models.", "category": "cs.LG"}, {"title": "Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data", "abstract": "Learning inter-domain mappings from unpaired data can improve performance in\nstructured prediction tasks, such as image segmentation, by reducing the need\nfor paired data. CycleGAN was recently proposed for this problem, but\ncritically assumes the underlying inter-domain mapping is approximately\ndeterministic and one-to-one. This assumption renders the model ineffective for\ntasks requiring flexible, many-to-many mappings. We propose a new model, called\nAugmented CycleGAN, which learns many-to-many mappings between domains. We\nexamine Augmented CycleGAN qualitatively and quantitatively on several image\ndatasets.", "category": "cs.LG"}, {"title": "Cluster Naturalistic Driving Encounters Using Deep Unsupervised Learning", "abstract": "Learning knowledge from driving encounters could help self-driving cars make\nappropriate decisions when driving in complex settings with nearby vehicles\nengaged. This paper develops an unsupervised classifier to group naturalistic\ndriving encounters into distinguishable clusters by combining an auto-encoder\nwith k-means clustering (AE-kMC). The effectiveness of AE-kMC was validated\nusing the data of 10,000 naturalistic driving encounters which were collected\nby the University of Michigan, Ann Arbor in the past five years. We compare our\ndeveloped method with the $k$-means clustering methods and experimental results\ndemonstrate that the AE-kMC method outperforms the original k-means clustering\nmethod.", "category": "cs.LG"}, {"title": "Tensor Decomposition for Compressing Recurrent Neural Network", "abstract": "In the machine learning fields, Recurrent Neural Network (RNN) has become a\npopular architecture for sequential data modeling. However, behind the\nimpressive performance, RNNs require a large number of parameters for both\ntraining and inference. In this paper, we are trying to reduce the number of\nparameters and maintain the expressive power from RNN simultaneously. We\nutilize several tensor decompositions method including CANDECOMP/PARAFAC (CP),\nTucker decomposition and Tensor Train (TT) to re-parameterize the Gated\nRecurrent Unit (GRU) RNN. We evaluate all tensor-based RNNs performance on\nsequence modeling tasks with a various number of parameters. Based on our\nexperiment results, TT-GRU achieved the best results in a various number of\nparameters compared to other decomposition methods.", "category": "cs.LG"}, {"title": "Diversity and degrees of freedom in regression ensembles", "abstract": "Ensemble methods are a cornerstone of modern machine learning. The\nperformance of an ensemble depends crucially upon the level of diversity\nbetween its constituent learners. This paper establishes a connection between\ndiversity and degrees of freedom (i.e. the capacity of the model), showing that\ndiversity may be viewed as a form of inverse regularisation. This is achieved\nby focusing on a previously published algorithm Negative Correlation Learning\n(NCL), in which model diversity is explicitly encouraged through a diversity\npenalty term in the loss function. We provide an exact formula for the\neffective degrees of freedom in an NCL ensemble with fixed basis functions,\nshowing that it is a continuous, convex and monotonically increasing function\nof the diversity parameter. We demonstrate a connection to Tikhonov\nregularisation and show that, with an appropriately chosen diversity parameter,\nan NCL ensemble can always outperform the unregularised ensemble in the\npresence of noise. We demonstrate the practical utility of our approach by\nderiving a method to efficiently tune the diversity parameter. Finally, we use\na Monte-Carlo estimator to extend the connection between diversity and degrees\nof freedom to ensembles of deep neural networks.", "category": "cs.LG"}, {"title": "Reinforcement Learning to Rank in E-Commerce Search Engine: Formalization, Analysis, and Application", "abstract": "In e-commerce platforms such as Amazon and TaoBao, ranking items in a search\nsession is a typical multi-step decision-making problem. Learning to rank (LTR)\nmethods have been widely applied to ranking problems. However, such methods\noften consider different ranking steps in a session to be independent, which\nconversely may be highly correlated to each other. For better utilizing the\ncorrelation between different ranking steps, in this paper, we propose to use\nreinforcement learning (RL) to learn an optimal ranking policy which maximizes\nthe expected accumulative rewards in a search session. Firstly, we formally\ndefine the concept of search session Markov decision process (SSMDP) to\nformulate the multi-step ranking problem. Secondly, we analyze the property of\nSSMDP and theoretically prove the necessity of maximizing accumulative rewards.\nLastly, we propose a novel policy gradient algorithm for learning an optimal\nranking policy, which is able to deal with the problem of high reward variance\nand unbalanced reward distribution of an SSMDP. Experiments are conducted in\nsimulation and TaoBao search engine. The results demonstrate that our algorithm\nperforms much better than online LTR methods, with more than 40% and 30% growth\nof total transaction amount in the simulation and the real application,\nrespectively.", "category": "cs.LG"}, {"title": "A more globally accurate dimensionality reduction method using triplets", "abstract": "We first show that the commonly used dimensionality reduction (DR) methods\nsuch as t-SNE and LargeVis poorly capture the global structure of the data in\nthe low dimensional embedding. We show this via a number of tests for the DR\nmethods that can be easily applied by any practitioner to the dataset at hand.\nSurprisingly enough, t-SNE performs the best w.r.t. the commonly used measures\nthat reward the local neighborhood accuracy such as precision-recall while\nhaving the worst performance in our tests for global structure. We then\ncontrast the performance of these two DR method against our new method called\nTriMap. The main idea behind TriMap is to capture higher orders of structure\nwith triplet information (instead of pairwise information used by t-SNE and\nLargeVis), and to minimize a robust loss function for satisfying the chosen\ntriplets. We provide compelling experimental evidence on large natural datasets\nfor the clear advantage of the TriMap DR results. As LargeVis, TriMap scales\nlinearly with the number of data points.", "category": "cs.LG"}, {"title": "Impact of Biases in Big Data", "abstract": "The underlying paradigm of big data-driven machine learning reflects the\ndesire of deriving better conclusions from simply analyzing more data, without\nthe necessity of looking at theory and models. Is having simply more data\nalways helpful? In 1936, The Literary Digest collected 2.3M filled in\nquestionnaires to predict the outcome of that year's US presidential election.\nThe outcome of this big data prediction proved to be entirely wrong, whereas\nGeorge Gallup only needed 3K handpicked people to make an accurate prediction.\nGenerally, biases occur in machine learning whenever the distributions of\ntraining set and test set are different. In this work, we provide a review of\ndifferent sorts of biases in (big) data sets in machine learning. We provide\ndefinitions and discussions of the most commonly appearing biases in machine\nlearning: class imbalance and covariate shift. We also show how these biases\ncan be quantified and corrected. This work is an introductory text for both\nresearchers and practitioners to become more aware of this topic and thus to\nderive more reliable models for their learning problems.", "category": "cs.LG"}, {"title": "Generalizations of Banach and Kannan Fixed point theorems in b_{v}(s) metric spaces", "abstract": "Generalizations of a metric space is one of the most important research areas\nin mathematics. In literature ,there are several generalized metric spaces. The\nlatest generalized metric space is b_{v}(s) metric space which is introduced by\nMitrovic and Radenovic in 2017. In this paper, we prove Kannan fixed point\ntheorem and generalize Banach fixed point theorem for weakly contractive\nmappings in b_{v}(s) metric spaces. Our results extend and generalize some\ncorresponding result.", "category": "math.GM"}, {"title": "One categorization of microtonal scales", "abstract": "This study considers rational approximations of musical constant\n$\\beta=\\log_2(3/2)$, which defines perfect fifth. This constant has been the\nsubject of the numerous studies, and this paper determines quality of rational\napproximations in regards to absolute error. We analysed convergents and\nsecondary convergents (some of these are the best Huygens approximations).\nEspecially, we determined quality of the secondary convergents which are not\nthe best Huygens approximations - in this paper we called them non-convergents\napproximations. Some of the microtonal scales have been positioned and\ndetermined by using non-convergents approximation of music constant which\ndefines perfect fifth.", "category": "math.GM"}, {"title": "Independence of the grossone-based infinity methodology from non-standard analysis and comments upon logical fallacies in some texts asserting the opposite", "abstract": "This commentary considers non-standard analysis and a recently introduced\ncomputational methodology based on the notion of \\G1 (this symbol is called\n\\emph{grossone}). The latter approach was developed with the intention to allow\none to work with infinities and infinitesimals numerically in a unique\ncomputational framework and in all the situations requiring these notions.\nNon-standard analysis is a classical purely symbolic technique that works with\nultrafilters, external and internal sets, standard and non-standard numbers,\netc. In its turn, the \\G1-based methodology does not use any of these notions\nand proposes a more physical treatment of mathematical objects separating the\nobjects from tools used to study them. It both offers a possibility to create\nnew numerical methods using infinities and infinitesimals in floating-point\ncomputations and allows one to study certain mathematical objects dealing with\ninfinity more accurately than it is done traditionally. In these notes, we\nexplain that even though both methodologies deal with infinities and\ninfinitesimals, they are independent and represent two different philosophies\nof Mathematics that are not in a conflict. It is proved that texts\n\\cite{Flunks, Gutman_Kutateladze_2008, Kutateladze_2011} asserting that the\n\\G1-based methodology is a part of non-standard analysis unfortunately contain\nseveral logical fallacies. Their attempt to prove that the \\G1-based\nmethodology is a part of non-standard analysis is similar to trying to show\nthat constructivism can be reduced to the traditional mathematics.", "category": "math.GM"}, {"title": "An elementary conjecture which implies the Goldbach conjecture", "abstract": "Let $p_{1}$, ..., $p_{k}$ be the first $k$ odd primes in succession. Let $n$\nbe an even integer such that $n > p_{k}$. We conjecture that if none of $n -\np_{1}$, ..., $n - p_{k}$ are prime, then at least one of them has a prime\nfactor which is greater than or equal to $p_{k}$. In this brief note, we\nobserve that Goldbach's conjecture follows from this conjecture.", "category": "math.GM"}, {"title": "Some Properties of Fibonacci-Sum Set-Graphs", "abstract": "In this paper we study some properties of Fibonacci-sum set-graphs. The\naforesaid graphs are an extension of the notion of Fibonacci-sum graphs to the\nnotion of set-graphs. The colouring of Fibonacci-sum graphs is also discussed.\nA number of challenging research problems are posed in the conclusion.", "category": "math.GM"}, {"title": "Calculus without Limit Theory", "abstract": "This paper establishes calculus upon two physical facts: (1) any average\nvelocity is always between two instantaneous velocities, and (2) the motion of\nan object is determined once its velocity has been determined. It directly\ndefines derivative and definite integral on an ordered field, proves the\nfundamental theorem of calculus with no auxiliary conditions, easily reveals\nthe common properties of derivatives, and obtains differentiation formulas for\nelementary functions. Further discussion shows that the new definitions are in\naccord with the traditional concepts for continuously differentiable functions.\nThis is a result of the authors' research in the field of educational\nmathematics, which hopes to provide a more elementary and effective way to\nteach calculus.", "category": "math.GM"}, {"title": "Some remarks on metrics induced by a fuzzy metric", "abstract": "We introduce a crisp metric $d_M$ as the common limit of two different nets\n$(\\Delta_{M,\\lambda})$ and $(\\delta_{M,\\lambda})$ of crisp metrics induced by a\nfuzzy metric $M$ and prove that the existence of each of these limits is\nequivalent to that of the other and it is characterized by another condition on\nthe original fuzzy metric $M$. We also derive some of the properties of these\napproximate metrics $\\Delta_\\lambda$ and $\\delta_\\lambda$. On the other hand,\nfor a given a crisp metric $d$, establish that the fuzzy metric representing\n$M_d$ with values in $\\{0,1\\}$ and $d$ are compatible with the same topology.\nFurther, we prove that if a crisp metric $d$ induces a fuzzy metric $M_d$, then\nall the approximate crisp metrics $\\Delta_{M,\\lambda}$ and $\\delta_{M,\\lambda}$\ninduced by this fuzzy metric are equal to the original metric $d$.", "category": "math.GM"}, {"title": "A Smooth Curve as a Fractal Under the Third Definition", "abstract": "It is commonly believed in the literature that smooth curves, such as\ncircles, are not fractal, and only non-smooth curves, such as coastlines, are\nfractal. However, this paper demonstrates that a smooth curve can be fractal,\nunder the new, relaxed, third definition of fractal - a set or pattern is\nfractal if the scaling of far more small things than large ones recurs at least\ntwice. The scaling can be rephrased as a hierarchy, consisting of numerous\nsmallest, a very few largest, and some in between the smallest and the largest.\nThe logarithmic spiral, as a smooth curve, is apparently fractal because it\nbears the self-similar property, or the scaling of far more small squares than\nlarge ones recurs multiple times, or the scaling of far more small bends than\nlarge ones recurs multiple times. A half-circle or half-ellipse and the UK\ncoastline (before or after smooth processing) are fractal, if the scaling of\nfar more small bends than large ones recurs at least twice.\n  Keywords: Third definition of fractal, head/tail breaks, bends, ht-index,\nscaling hierarchy", "category": "math.GM"}, {"title": "The BiEntropy of Some Knots on the Simple Cubic Lattice", "abstract": "Binary representations of the trefoil and other knots of up to ten crossings\nin the simple cubic lattice were created. The BiEntropy of each knot was\ncomputed using a variety of binary encodings and compared against controls.\nThis showed that binary encoded knots are highly disordered information\nobjects. The BiEntropy of knots on the simple cubic lattice increases slightly\nas the number of crossings and length of encoding increases. We show that the\nnon-alternating knots of nine and ten crossings are more disordered than the\nalternating knots of nine and ten crossings.", "category": "math.GM"}, {"title": "Arithmetic summable sequence space over non-Newtonian field", "abstract": "Recently Ruckle \\cite{RuckleArithmeticalSummability} introduced the theory of\narithmetical summability suggested by the sum $ \\sum_{k|m}f(k) $ as $ k $\nranges over the divisors of $m$ including $ 1 $ and $ m .$ Following Ruckle\n\\cite{RuckleArithmeticalSummability} we construct the sequence space $ AS(G) $\nand $ AC(G) $ of arithmetic summable and arithmetic convergent sequences in the\nsense of geometric calculus and derive interesting results in the geometric\nfield.", "category": "math.GM"}, {"title": "On a generalized theorem of de Bruijn and Erdös in d-dimensional Fuzzy Linear Spaces", "abstract": "In this study we follow a new framework for the theory that offers us, other\nthan traditional, a new angle to observe and investigate some relations between\nfinite sets, F-lattice L and their elements. The theory is based on the Fuzzy\nLinear Spaces (FLS) S=(N,D). In this case, to operate on these spaces the\nnecessary preliminaries, concepts and operations in lattices relative to FLS\nare introduced. Some definitions, such that k-fuzzy point, k-fuzzy line are\ngiven. Then we correspond these definitions to the definitions in usually\nlinear spaces. We investigate some combinatorics properties of FLS. In some\nexamples in the case where ILI=3*. We see some differences. In general, taking\nan ordered lattice Ln={0,a1,a2,...,an,1} we observe how some combinatorics\nformulas and properties are changed. In FLS the dimension concept is a set. We\nproduce some general formulas by using some trivial examples. Furthermore, we\ngeneralize de Bruijn-Erd\\\"os Theorem in [2].", "category": "math.GM"}, {"title": "Frechet bounds of the 1-st kind for sets of half-rare events", "abstract": "Frechet bounds of the 1-st kind for sets of events and its main properties\nare considered. The lemma on not more than two nonzero values of lower\nFrechet-bounds of the 1-st kind for a set of half-rare events is proved with\nthe corollary on the analogous assertion for sets of events with arbitrary\nevent-probability distributions.", "category": "math.GM"}, {"title": "Complete sets", "abstract": "In this paper we introduce the concept of completeness of sets. We study this\nproperty on the set of integers. We examine how this property is preserved as\nwe carry out various operations compatible with sets. We also introduce the\nproblem of counting the number of complete subsets of any given set. That is,\ngiven any interval of integers $\\mathcal{H}:=[1,N]$ and letting\n$\\mathcal{C}(N)$ denotes the complete set counting function, we establish the\nlower bound $\\mathcal{C}(N)\\gg N\\log N$.", "category": "math.GM"}, {"title": "On involution $le$-semigroups", "abstract": "We deal with involution ordered semigroups possessing a greatest element, we\nintroduce the concepts of $*$-regularity, $*$-intra-regularity, $*$-bi-ideal\nelement and $*$-quasi-ideal element in this type of semigroups and, using the\nright and left ideal elements, we give relations between the regularity and\n$*$-regularity, between intra-regularity and $*$-intra-regularity. Finally, we\nprove that in an involution $*$-regular $\\vee e$-semigroup every $*$-bi-ideal\nelement can be considered as a product of a right and a left ideal element, we\ndescribe the form of the filter generated by an element of an involution\n$*$-intra-regular $poe$-semigroup $S$, showing that every $\\cal N$-class of $S$\nhas a greatest element.", "category": "math.GM"}, {"title": "On a certain identity involving the Gamma function", "abstract": "The goal of this paper is to prove the identity \\begin{align}\\sum\n\\limits_{j=0}^{\\lfloor\ns\\rfloor}\\frac{(-1)^j}{s^j}\\eta_s(j)+\\frac{1}{e^{s-1}s^s}\\sum\n\\limits_{j=0}^{\\lfloor\ns\\rfloor}(-1)^{j+1}\\alpha_s(j)+\\bigg(\\frac{1-((-1)^{s-\\lfloor s\\rfloor\n+2})^{1/(s-\\lfloor s\\rfloor +2)}}{2}\\bigg)\\nonumber \\\\ \\bigg(\\sum\n\\limits_{j=\\lfloor s\\rfloor\n+1}^{\\infty}\\frac{(-1)^j}{s^j}\\eta_s(j)+\\frac{1}{e^{s-1}s^s}\\sum\n\\limits_{j=\\lfloor s\\rfloor\n+1}^{\\infty}(-1)^{j+1}\\alpha_s(j)\\bigg)=\\frac{1}{\\Gamma(s+1)},\\nonumber\n\\end{align}where \\begin{align}\\eta_s(j):=\\bigg(e^{\\gamma (s-j)}\\prod\n\\limits_{m=1}^{\\infty}\\bigg(1+\\frac{s-j}{m}\\bigg)\\nonumber\n\\\\e^{-(s-j)/m}\\bigg)\\bigg(2+\\log s-\\frac{j}{s}+\\sum\n\\limits_{m=1}^{\\infty}\\frac{s}{m(s+m)}-\\sum\n\\limits_{m=1}^{\\infty}\\frac{s-j}{m(s-j+m)}\\bigg), \\nonumber \\end{align}and\n\\begin{align}\\alpha_s(j):=\\bigg(e^{\\gamma (s-j)}\\prod\n\\limits_{m=1}^{\\infty}\\bigg(1+\\frac{s-j}{m}\\bigg)e^{-(s-j)/m}\\bigg)\\bigg(\\sum\n\\limits_{m=1}^{\\infty}\\frac{s}{m(s+m)}-\\sum\n\\limits_{m=1}^{\\infty}\\frac{s-j}{m(s-j+m)}\\bigg),\\nonumber \\end{align}where\n$\\Gamma(s+1)$ is the Gamma function defined by $\\Gamma(s):=\\int\n\\limits_{0}^{\\infty}e^{-t}t^{s-1}dt$ and $\\gamma =\\lim\n\\limits_{n\\longrightarrow \\infty}\\bigg(\\sum \\limits_{k=1}^{n}\\frac{1}{k}-\\log\nn\\bigg)=0.577215664\\cdots $ is the Euler-Mascheroni constant.", "category": "math.GM"}, {"title": "Analytic Continuation of $ζ(s)$ Violates the Law of Non-Contradiction (LNC)", "abstract": "The Dirichlet series of $\\zeta(s)$ was long ago proven to be divergent\nthroughout half-plane $\\text{Re}(s)\\le1$. If also Riemann's proposition is\ntrue, that there exists an \"expression\" of $\\zeta(s)$ that is convergent at all\n$s$ (except at $s=1$), then $\\zeta(s)$ is both divergent and convergent\nthroughout half-plane $\\text{Re}(s)\\le1$ (except at $s=1$). This result\nviolates all three of Aristotle's \"Laws of Thought\": the Law of Identity (LOI),\nthe Law of the Excluded Middle (LEM), and the Law of Non-Contradition (LNC). In\nclassical and intuitionistic logics, the violation of LNC also triggers the\n\"Principle of Explosion\" / \\textit{Ex Contradictione Quodlibet} (ECQ). In\naddition, the Hankel contour used in Riemann's analytic continuation of\n$\\zeta(s)$ violates Cauchy's integral theorem, providing another proof of the\ninvalidity of Riemann's $\\zeta(s)$. Riemann's $\\zeta(s)$ is one of the\n$L$-functions, which are all invalid due to analytic continuation. This result\nrenders unsound all theorems (e.g. Modularity, Fermat's last) and conjectures\n(e.g. BSD, Tate, Hodge, Yang-Mills) that assume that an $L$-function (e.g.\nRiemann's $\\zeta(s)$) is valid. We also show that the Riemann Hypothesis (RH)\nis not \"non-trivially true\" in classical logic, intuitionistic logic, or\nthree-valued logics (3VLs) that assign a third truth-value to paradoxes\n(Bochvar's 3VL, Priest's $LP$).", "category": "math.GM"}, {"title": "From Vectors to Geometric Algebra", "abstract": "Geometric algebra is the natural outgrowth of the concept of a vector and the\naddition of vectors. After reviewing the properties of the addition of vectors,\na multiplication of vectors is introduced in such a way that it encodes the\nfamous Pythagorean theorem. Synthetic proofs of theorems in Euclidean geometry\ncan then be replaced by powerful algebraic proofs. Whereas we largely limit our\nattention to 2 and 3 dimensions, geometric algebra is applicable in any number\nof dimensions, and in both Euclidean and non-Euclidean geometries.", "category": "math.GM"}, {"title": "Studies in Tours of Knight on Rectangular Boards", "abstract": "The author has constructed and enumerated tours of knight having various\nmagic properties on 4 x n and 6 x n boards. 16 magic tours of knight have been\ndiscovered on 4 x 18 board, 88 on 4 x 20 board, 464 on 4 x 22 board, 2076 on 4\nx 24 board, 9904 on 4 x 26 board and 47456 on 4 x 28 board. Magic tours exist\non all boards of size 4 x 2k for k > 8. Quasi-magic tour exists on 6 x 11\nboard. 8 magic tours of knight have been discovered on 6 x 12 board and magic\ntours exist on all boards of size 6 x 4k for k > 2.", "category": "math.GM"}, {"title": "Differential Operator Method of Finding A Particular Solution to An Ordinary Nonhomogeneous Linear Differential Equation with Constant Coefficients", "abstract": "We systematically introduce the idea of applying differential operator method\nto find a particular solution of an ordinary nonhomogeneous linear differential\nequation with constant coefficients when the nonhomogeneous term is a\npolynomial function, exponential function, sine function, cosine function or\nany possible product of these functions. In particular, different from the\ndifferential operator method introduced in literature, we propose and highlight\nutilizing the definition of the inverse of differential operator to determine a\nparticular solution. We suggest that this method should be introduced in\ntextbooks and widely used for determining a particular solution of an ordinary\nnonhomogeneous linear differential equation with constant coefficients in\nparallel to the method of undetermined coefficients.", "category": "math.GM"}, {"title": "Optimal Solution of Nonlinear Fuzzy Optimization Problem under Linear Order Relation", "abstract": "Multi-variable nonlinear fuzzy optimization problem is considered under\nlinear order relation on fuzzy numbers. Using gH-differentiability of a\nfuzzy-valued function $\\tilde{f}$, new necessary and sufficient optimality\nconditions are proposed. The optimality conditions are obtained without putting\nadditional conditions on fuzzy-valued functions like, convexity,\nquasi-convexity, pseudo-convexity. Optimum solution of the fuzzy optimization\nproblem is obtained based on the optimality conditions. Illustrations and a\ncase study are given to explain the numerical applications of the proposed\nresults. Comparison of optimality conditions from existing literature is given.", "category": "math.GM"}, {"title": "Oriented Convex Containers of Polygons", "abstract": "We consider the optimal containment of polygonal regions within convex\ncontainers with the special property of 'orientedness' - an oriented region\nenables us to choose a preferred direction on the plane (this direction is not\nnecessarily an axis of symmetry) - and derive preliminary results.", "category": "math.GM"}, {"title": "Fixed points for $G$-cyclic $(φ-ψ)$-Kannan and $G$-cyclic $(φ -ψ)$-Chatterjea contractions in $G$-metric spaces", "abstract": "Definitions of what are called $G$-cyclic $\\left( \\phi -\\psi \\right)$-Kannan\ncontraction and $G$-cyclic $\\left( \\phi -\\psi\\right)$-Chatterjea contraction\nare introduced in this paper. We use these new concepts to establish new fixed\npoint results in the context of complete generalized metric spaces. These\nresults are new generalizations and extensions of the Kannan and Chatterjea\nfixed point theorems and are generalized versions of some fixed point results\nproved in the literature. The analysis and theory are illustrated by some\nexamples.", "category": "math.GM"}, {"title": "Evaluation of weighted Fibonacci sums of a certain type", "abstract": "We derive a formula for the evaluation of weighted generalized Fibonacci sums\nof the type $S_k^n (w,r) = \\sum_{j = 0}^k {w^j j^r G_j{}^n }$. Several explicit\nevaluations are presented as examples.", "category": "math.GM"}, {"title": "New Proofs of Triangle Inequalities", "abstract": "We give three new proofs of the triangle inequality in Euclidean Geometry.\nThere seems to be only one known proof at the moment. It is due to properties\nof triangles, but our proofs are due to circles or ellipses. We aim to prove\nthe triangle inequality as simple as possible without using properties of\ntriangles.", "category": "math.GM"}, {"title": "On Chromatic Core Subgraph of Simple Graphs", "abstract": "If distinct colours represent distinct technology types that are placed at\nthe vertices of a simple graph in accordance to a minimum proper colouring, a\ndisaster recovery strategy could rely on an answer to the question: \"What is\nthe maximum destruction, if any, the graph (a network) can undergo while\nensuring that at least one of each technology type remain, in accordance to a\nminimum proper colouring of the remaining induced subgraph.\" In this paper, we\nintroduce the notion of a chromatic core subgraph $H$ of a given simple graph\n$G$ in answer to the stated problem. Since for any subgraph $H$ of $G$ it holds\nthat $\\chi(H) \\leq \\chi(G)$, the problem is well defined.", "category": "math.GM"}, {"title": "A Note on the Classification of Permutation Matrix", "abstract": "This paper is concentrated on the classification of permutation matrix with\nthe permutation similarity relation, mainly about the canonical form of a\npermutational similar equivalence class, the cycle matrix decomposition of a\npermutation matrix and the cycle factorization of a permutation matrix or\nmonomial matrix.", "category": "math.GM"}, {"title": "Qualitative analysis of differential equations", "abstract": "Here I introduce basic methods of qualitative analysis of differential\nequations used in mathematical biology for people with minimal mathematical\nbackground.", "category": "math.GM"}, {"title": "The diagonalization method and Brocard's problem", "abstract": "In this paper we introduce and develop the method of diagonalization of\nfunctions $f:\\mathbb{N}\\longrightarrow \\mathbb{R}$. We apply this method to\nshow that the equations of the form $\\Gamma_r(n)+k=m^2$ has a finite number of\nsolutions $n\\in \\mathbb{N}$ with $n>r$ for any fixed $k,r\\in \\mathbb{N}$, where\n$\\Gamma_r(n)=n(n-1)\\cdots (n-r)$ denotes the $r^{th}$ truncated Gamma function.", "category": "math.GM"}, {"title": "Homological Solution of the Riemann-Lanczos and Weyl-Lanczos Problems in Arbitrary Dimension", "abstract": "When ${\\cal{D}}$ is a linear partial differential operator of any order, a\ndirect problem is to look for an operator ${\\cal{D}}_1$ generating the\ncompatibility conditions (CC) ${\\cal{D}}_1\\eta=0$ of ${\\cal{D}}\\xi=\\eta$. We\nmay thus construct a differential sequence with successive operators\n${\\cal{D}},{\\cal{D}}_1,{\\cal{D}}_2, ...$, where each operator is generating the\nCC of the previous one. Introducing the formal adjoint $ad( )$, we have\n${\\cal{D}}_i\\circ {\\cal{D}}_{i-1}=0 \\Rightarrow ad({\\cal{D}}_{i-1}) \\circ\nad({\\cal{D}}_i)=0$ but $ad({\\cal{D}}_{i-1})$ may not generate all the CC of\n$ad({\\cal{D}}_i)$. When $D=K[d_1,...,d_n]=K[d]$ is the (non-commutative) ring\nof differential operators with coefficients in a differential field $K$, it\ngives rise by residue to a differential module $M$ over $D$. The homological\nextension modules $ext^i(M)=ext^i_D(M,D)$ with $ext^0(M)=hom_D(M,D)$ only\ndepend on $M$ and are measuring the above gaps, independently of the previous\ndifferential sequence.The purpose of this rather technical paper is to compute\nthem for certain Lie operators involved in the formal theory of Lie\npseudogroups in arbitrary dimension $n$. In particular, we prove that the\nextension modules highly depend on the Vessiot structure constants $c$. When\none is dealing with a Lie group of transformations or, equivalently, when\n${\\cal{D}}$ is a Lie operator of finite type, then we shall prove that\n$ext^i(M)=0, \\forall 0\\leq i \\leq n-1$. It will follow that the Riemann-Lanczos\nand Weyl-Lanczos problems just amount to prove such a result for $i=2$ and\narbitrary $n$ when ${\\cal{D}}$ is the Killing or conformal Killing operator. We\nfinally prove that ${ext}^i(M)=0, \\forall i\\geq 1$ for the Lie operator of\ninfinitesimal contact transformations with arbitrary $n=2p+1$. Most of these\nnew results have been checked by means of computer algebra.", "category": "math.GM"}, {"title": "Fuzzy soft seperation axioms with sense of Ganguly and Saha", "abstract": "Tanay and Kandemir <cite>TK</cite> introduced the topological structure of\nfuzzy soft sets. In 2013, Manatha and Das <cite>md</cite> defined seperation\naxioms on fuzzy soft topological spaces. In this paper, we generalized form of\nthe seperation axioms.using fuzzy soft quasi-coincidence with sense of Ganguly\nand Saha <cite>GS</cite>. By using this notions, we also give some basic\ntheorems of seperation axioms in classical topological spaces.", "category": "math.GM"}, {"title": "On the Consistency of the Arithmetic System", "abstract": "In this paper we establish that the well-known Arithmetic System is\nconsistent in the traditional sense. The proof is done within this Arithmetic\nSystem.", "category": "math.GM"}, {"title": "Soft elementary compact in soft elementary topology", "abstract": "In a recent paper, Chiney and Samanta have introduced a new definition of\nsoft topology, using the soft elementary intersection and union. In this paper,\nbasing at this approach, we introduce a definition of soft elementary compact\nset, and space. We introduce also some proprieties of the soft elementary\ncompactness, and we prove the soft elementary version of Baire theorem.", "category": "math.GM"}, {"title": "Pythagoras, Binomial, and de Moivre Revisited Through Differential Equations", "abstract": "The classical Pythagoras theorem, binomial theorem, de Moivre's formula, and\nnumerous other deductions are made using the uniqueness theorem for the initial\nvalue problems in linear ordinary differential equations.", "category": "math.GM"}, {"title": "Primes of the form $p=1+n!\\sum n,$ for some $n\\in\\mathbb{N}^{+}$", "abstract": "The purpose of this note is to report on the discovery of the primes of the\nform $p=1+n!\\sum n$, for some natural numbers $n>0$. The number of digits in\nthe prime p are approximately equal to $\\lfloor log_{10}(1+n!\\sum n)\\rceil+1$.", "category": "math.GM"}, {"title": "Projective Line Revisited", "abstract": "This article provides a new perspective on the geometry of a projective line,\nwhich helps clarify and illuminate some classical results about projective\nplane. As part of the same train of ideas, the article also provides a proof of\nthe nine-point circle theorem valid for any affine plane over any field of\ncharacteristic different from 2.", "category": "math.GM"}, {"title": "On Chromatic Curling Number of Graphs", "abstract": "The curling number of a graph G is defined as the number of times an element\nin the degree sequence of G appears the maximum. Graph colouring is an\nassignment of colours, labels or weights to the vertices or edges of a graph. A\ncolouring $\\mathcal{C}$ of colours $c_1,c_2,\\ldots,c_l$ is said to be a minimum\nparameter colouring if C consists of a minimum number of colours with smallest\nsubscripts. In this paper, we study colouring version of curling number of\ncertain graphs, with respect to their minimum parameter colourings.", "category": "math.GM"}, {"title": "Francis Guthrie's approach to The Four Color Problem", "abstract": "The odd wheel is the only type of 4-critical graph in which one vertex always\ngets a unique color. This supports Frederic Guthrie's approach to the Four\nColor Problem.", "category": "math.GM"}, {"title": "An investigation of the non-trivial zeros of the Riemann zeta function", "abstract": "While many zeros of the Riemann zeta function are located on the critical\nline $\\Re(s)=1/2$, the non-existence of zeros in the remaining part of the\ncritical strip $\\Re(s) \\in \\, ]0, 1[$ is the main scope to be proven for the\nRiemann hypothesis. The Riemann zeta functional leads to a relation between the\nzeros on either sides of the critical line. Given $s$ a complex number and\n$\\bar{s}$ its complex conjugate, if $s$ is a zero of the Riemann zeta function\nin the critical strip $\\Re(s) \\in \\, ]0, 1[$, then $\\zeta(s) =\n\\zeta(1-\\bar{s})$, as a key proposition to prove the Riemann hypothesis.", "category": "math.GM"}, {"title": "Lowen type multi-fuzzy topological spaces", "abstract": "In this paper Lowen type multi-fuzzy topological space has been introduced\nand characterization of topology by its nbd system is studied. Also the product\nmulti-fuzzy topological space has been introduced and it has been investigated\nthat 2nd countability and compactness are finitely productive in multi-fuzzy\ntopological spaces.", "category": "math.GM"}, {"title": "Hyperreal delta functions as a new general tool for modeling physical states with infinitely high densities", "abstract": "This paper introduces the expanded real numbers as an ordered subring of the\nhyperreal number field that does not contain any infinitesimals, and defines\nthe set of all integrable functions from the real numbers to the expanded real\nnumbers. This allows to identify the Dirac delta with a special\nhyperreal-valued function of a real variable: the Dirac delta function thus\ndefined is a general tool, applicable for the mathematical modeling of physical\nsystems in which infinitely high densities occur.", "category": "math.GM"}, {"title": "A hybrid natural transform homotopy perturbation method for solving fractional partial differential equations", "abstract": "A hybrid analytical method for solving linear and nonlinear fractional\npartial differential equations is presented. The proposed analytical method is\nan elegant combination of the Natural Transform Method (NTM) and a well-known\nmethod, Homotopy Perturbation Method (HPM). In this analytical method, the\nfractional derivative is computed in Caputo sense and the nonlinear terms are\ncalculated using He's polynomials. The proposed analytical method reduces the\ncomputational size, avoids round-off errors. Exact solutions of linear and\nnonlinear fractional partial differential equations is successfully obtained\nusing the analytical method.", "category": "math.GM"}, {"title": "General Methods For Solving Ordinary Differential Equations 1", "abstract": "The method of this paper is my original creation. A new method for solving\nlinear differential equations is proposed in this paper. The important\nconclusion of this paper is that arbitrary order linear ordinary differential\nequations with variable coefficients can be solved by the method of recursion\nand reduction of order under some conditions which easily be satisfied in\npractical applications.", "category": "math.GM"}, {"title": "A study of divergence from randomness in the distribution of prime numbers within the arithmetic progressions 1+6n and 5+6n", "abstract": "In this article I present results from a statistical study of prime numbers\nthat shows a behaviour that is not compatible with the thesis that they are\ndistributed randomly. The analysis is based on studying two arithmetical\nprogressions defined by the following polynomials: ($1+6n$, $5+6n$, $n\\in{N}$)\nwhose respective numerical sequences have the characteristic of containing all\nthe prime numbers except $3$ and $2$. If prime numbers were distributed\nrandomly, we would expect the two polynomials to generate the same number of\nprimes. Instead, as the reported findings show, we note that the polynomial\n$5+6n$ tends to generate many more primes, and that this divergence grows\nprogressively as more prime numbers are considered. A possible explanation for\nthis phenomenon can be found by calculating the number of products that\ngenerate composite numbers which are expressible by the two polynomials. This\nanalysis reveals that the number of products that generate composite numbers\nexpressible by the polynomial $1+6n$ is $(n+1)^{ 2}$, while the number of\nproducts that generate composites expressible by the polynomial $5+6n$ is\n$(n+1)n$, con $n\\in{N}$. As a composite number is a non-prime number, this\ndifference incited me to analyse the distribution of prime numbers generated by\nthe two polynomials. The results, based on studying the first (approx.) 500\nmillion prime numbers, confirm the fact that the number of primes that can be\nwritten using the polynomial $1+6n$ is lower than the number of primes that can\nwritten using the polynomial $5+6n$, and that this divergence grows\nprogressively with the number of primes considered.", "category": "math.GM"}, {"title": "Quelques remarques sur les vari{é}t{é}s, fonctions de Green et formule de Stokes", "abstract": "We give some remarks on some manifolds K3 surfaces, Complex projective\nspaces, real projective space and Torus and the classification of two\ndimensional Riemannian surfaces, Green functions and the Stokes formula. We\nalso, talk about traces of Sobolev spaces, the distance function, the notion of\ndegree and a duality theorem, the variational formulation and conformal map in\ndimension 2, the metric on the boundary of a Lipschitz domain and polar\ngeodesic coordinates and the Gauss-Bonnet formula and the positive mass theorem\nin dimension 3 and in the locally conformally flat case. And the Ricci flow.\nAnd fields and their relation to the equations.And obstructions in astronomy.\nAnd on strings, superstrings and D-branes. And topological solutions in the\nnegative case, critical, supercritical and superstrings.", "category": "math.GM"}, {"title": "On homeomorphisms and $C^{1}$ maps", "abstract": "Our purpose in this article is first, following [8], to prove that if $\\alpha\n$, $\\beta $ are any points of the open unit disc $D(0;1)$ in the complex plane\n${\\bf C}$ and $r$, $s$ are any positive real numbers such that ${\\overline{D}}(\n\\alpha ;r) \\subseteq D(0;1)$ and ${\\overline{D}}( \\beta ;s) \\subseteq D(0;1)$,\nthen there exist $t \\in (0,1)$ and a homeomorphism $h : {\\overline{D}}(0;1)\n\\rightarrow {\\overline{D}}(0;1)$ such that ${\\overline{D}}( \\alpha ;r)\n\\subseteq D(0;t)$, ${\\overline{D}}( \\beta ;s) \\subseteq D(0;t)$, $h \\left[\n{\\overline{D}}( \\alpha ;r) \\right] = {\\overline{D}}( \\beta ;s)$ and $h = id$ on\n${\\overline{D}}(0;1) \\setminus D(0;t)$, and second, following [9], to prove\nthat if $q \\in {\\bf N} \\setminus \\{ 0, 1 \\} $ and ${\\bf B}({\\bf 0};1)$ is the\nopen unit ball in ${\\bf R}^{q}$, while for any $t>0$, we set $f^{(t)}( {\\bf x}\n) = \\frac{ t {\\bf x} }{ 1 + (t-1) \\Vert {\\bf x} \\Vert }$, whenever ${\\bf x} \\in\n{\\overline{\\bf B}}({\\bf 0};1)$, then $f^{(t)} \\rightarrow id$ in $C^{1} \\left(\n{\\overline{\\bf B}}({\\bf 0};1) , {\\bf R}^{q} \\right) $ as $t \\rightarrow 1^{+}$.", "category": "math.GM"}, {"title": "Triangle Inscribed-Triangle Picking", "abstract": "Given a triangle ABC, we derive the probability distribution function and the\nmoments of the area of an inscribed triangle RST whose vertices are uniformly\ndistributed on AB, BC, and CA. The theoretical results are confirmed by a Monte\nCarlo simulation.", "category": "math.GM"}, {"title": "Hyperreal Numbers for Infinite Divergent Series", "abstract": "Treating divergent series properly has been an ongoing issue in mathematics.\nHowever, many of the problems in divergent series stem from the fact that\ndivergent series were discovered prior to having a number system which could\nhandle them. The infinities that resulted from divergent series led to\ncontradictions within the real number system, but these contradictions are\nlargely alleviated with the hyperreal number system. Hyperreal numbers provide\na framework for dealing with divergent series in a more comprehensive and\ntractable way.", "category": "math.GM"}, {"title": "Development of the matrix of primes and proof of an infinite number of primes-twins", "abstract": "This paper is devoted to the theory of prime numbers. In this paper we first\nintroduce the notion of a matrix of prime numbers. Then, in order to\ninvestigate the density of prime numbers in separate rows of the matrix under\nconsideration, we propose a number of lemmas and theorems that, together with\nthe Dirichlet and Euler theorems, make it possible to prove the infinity of\nprime twins.", "category": "math.GM"}, {"title": "Derivatives of flat functions", "abstract": "We remark that there is no smooth function $f(x)$ on $[0, 1]$ which is flat\nat $0$ such that the derivative $f^{(n)}$ of any order $n\\geq 0$ is positive on\n$(0,1]$. Moreover, the number of zeros of the $n$-th derivative $f^{(n)}$ grows\nto the infinity and the zeros accumulate to $0$ when $n \\to \\infty$.", "category": "math.GM"}, {"title": "Some New Results on Proper Colouring of Edge-set Graphs", "abstract": "In this paper, we present a foundation study for proper colouring of edge-set\ngraphs. The authors consider that a detailed study of the colouring of edge-set\ngraphs corresponding to the family of paths is best suitable for such\nfoundation study. The main result is deriving the chromatic number of the\nedge-set graph of a path, $P_{n+1}$, $n \\geq 1$. It is also shown that edge-set\ngraphs for paths are perfect graphs.", "category": "math.GM"}, {"title": "A Proof of the Riemann Hypothesis Through the Nicolas Inequality", "abstract": "A work by Nicolas has shown that if it can be proven that a certain\ninequality holds for all $n$, the Riemann hypothesis is true. This inequality\nis associated with the Mertens theorem, and hence the Euler totient at\n$\\prod_{k=1}^n p_k$, where $n$ is any integer and $p_n$ is the $n$-th prime. We\nshall show that indeed the Nicolas inequality holds for all $n$.", "category": "math.GM"}, {"title": "Topology and Higher Concurrencies", "abstract": "We formulate a general approach to higher concurrencies in general and neural\ncodes in particular, and suggest how the higher order aspects may be dealt with\nin using topology.", "category": "math.GM"}, {"title": "Identities for second order recurrence sequences", "abstract": "We derive several identities for arbitrary homogeneous second order\nrecurrence sequences with constant coefficients. The results are then applied\nto present a unified study of six well known integer sequences, namely the\nFibonacci sequence, the sequence of Lucas numbers, the Jacobsthal sequence, the\nJacobsthal-Lucas sequence, the Pell sequence and the Pell-Lucas sequence.", "category": "math.GM"}, {"title": "A few results on the infimum of regular polygons equal-size split line", "abstract": "If an n-side unit regular polygon is divided into m equal sized parts, then\nwhat is the minimum length of the split line ${l_{m,n}}$? This problem has its\npractical application in real world. This paper proved that ${l_{2,3}} = \\sqrt\n{\\frac{{\\sqrt 3 \\pi }}{{12}}} $, ${l_{3,3}} = \\frac{{\\sqrt 3 }}{2}$, and\n$\\frac{1}{2}\\sqrt {n\\pi {\\rm{ctan}}\\frac{\\pi }{n}} \\le \\mathop {\\lim\n}\\limits_{m \\to \\infty } \\frac{{{l_{m,n}}}}{{\\sqrt m }} \\le \\sqrt {\\frac{{\\sqrt\n3 }}{2}n{\\rm{ctan}}\\frac{\\pi }{{\\rm{n}}}} $", "category": "math.GM"}, {"title": "Nonlinear Invariants of Planar Point Clouds Transformed by Matrices", "abstract": "The goal of this paper is to present invariants of planar point clouds, that\nis functions which take the same value before and after a linear transformation\nof a planar point cloud via a $2 \\times 2$ invertible matrix. In the approach\nwe adopt here, these invariants are functions of two variables derived from the\nleast squares straight line of the planar point cloud under consideration. A\nlinear transformation of a point cloud induces a nonlinear transformation of\nthese variables. The said invariants are solutions to certain Partial\nDifferential Equations, which are obtained by employing Lie theory. We find\ncloud invariants in the general case of a four$-$parameter transformation\nmatrix, as well as, cloud invariants of various one$-$parameter sets of\ntransformations which can be practically implemented. Case studies and\nsimulations which verify our findings are also provided.", "category": "math.GM"}, {"title": "100% of the zeros of the Riemann zeta-function are on the critical line", "abstract": "We consider a specific family of analytic functions $g_{\\alpha,T}(s)$,\nsatisfying certain functional equations and approximating to linear\ncombinations of the Riemann zeta-function and its derivatives of the form\n  $c_0\\zeta(s)+c_1\\frac{\\zeta'(s)}{\\log T}+c_2\\frac{\\zeta''(s)}{(\\log\nT)^2}+\\dots+c_{K}\\frac{\\zeta^{(K)}(s)}{(\\log T)^{K}}$.\n  We also consider specific mollifiers of the form $M(s)D(s)$ for these linear\ncombinations, where $M(s)$ is the classical mollifier, that is, a short\nDirichlet polynomial for $1/\\zeta(s)$, and the Dirichlet polynomial $D(s)$ is\nalso short but with large and irregular Dirichlet coefficients, and arises from\nsubstitution for $w$, in Runge's complex approximation polynomial for\n$f(w)=\\frac1{c_0+w}$, of the Selberg approximation for\n  $\\frac{c_1}{\\log T}\\frac{\\zeta'}{\\zeta}(s)+\\frac{c_2}{(\\log\nT)^2}\\frac{\\zeta''}{\\zeta}(s)+\\dots+\\frac{c_{K}}{(\\log\nT)^{K}}\\frac{\\zeta^{(K)}}{\\zeta}(s)$\n  (analogous to Selberg's classical approximation for\n$\\frac{\\zeta'}{\\zeta}(s)$).\n  Exploiting the functional equations previously mentioned (concerning\ntranslation of the variable $s$), together with the mean-square asymptotics of\nthe Levinson-Conrey method and the Selberg approximation theory (with some\nadditional results) we show that almost all of the zeros of the Riemann\nzeta-function are on the critical line.", "category": "math.GM"}, {"title": "On the Frankl's union-closed conjecture", "abstract": "A celebrated unresolved conjecture of Peter Frankl states that every finite\ncollection of sets, with finite universe, admits an abundant element. In this\npaper, we prove Frankl's union-closed conjecture(FC). We provide an induction\nproof based on a key result that every candidate collection, $\\Omega$, admits\nan irreducible form. The concept of irreducible collections is one of the key\ncontributions of this paper.\n  We show that the conjecture is true if it holds for a class of irreducible\nfinite collections. Then we show that the conjecture holds for all irreducible\nfinite collections, with non-empty universe.", "category": "math.GM"}, {"title": "A Fast Algorithm to Calculate Power Sum of Natural Numbers", "abstract": "Permutations can be represented as linear combinations of natural numbers\nwith different powers. In this paper, its coefficient matrix and inverse matrix\nis derived, and the results show the coefficient matrix is a lower triangular\nmatrix while the inverse matrix is upper triangular. Permutations of n-th order\nare used to generate the inverse matrix. The generation function of natural\nnumbers' power sum is derived to calculate the power sum.", "category": "math.GM"}, {"title": "On the Philosophy of Higher Structures", "abstract": "The purpose of this paper is to describe and elaborate the philosophical\nideas behind hyperstructures and structure formation in general and emphasize\nthe key ideas of the Hyperstructure Program.", "category": "math.GM"}, {"title": "On the Mathematics of Higher Structures", "abstract": "In this paper we will relate hyperstructures and the general\n$\\mathscr{H}$-principle to known mathematical structures, and also discuss how\nthey may give rise to new mathematical structures. The main purpose is to point\nout new ideas and directions of investigation.", "category": "math.GM"}, {"title": "Roots of polynomials and the Sendov's conjecture", "abstract": "In this paper we first prove that a simple root of a polynomial satisfies the\nSendov's conjecture. As the multiple roots trivially satisfy the Sendov's\nconjecture we conclude that the Sendov's conjecture holds true.", "category": "math.GM"}, {"title": "On Studying the Phase Behavior of the Riemann Zeta Function Along the Critical Line", "abstract": "The critical line of the Riemann zeta function is studied from a new\nviewpoint. It is found that the ratio between the zeta function at any zero and\nthe corresponding one at a conjugate point has a certain phase and its absolute\nvalue is unity. This fact is valid along the whole critical line and only\nthere. The common functional equation is used with the aid of the function\nratio between any zero and its negative side pair, a complex conjugate. As a\nresult, an equation is obtained for solving the phase along the critical line.", "category": "math.GM"}, {"title": "Primitive Roots In Short Intervals", "abstract": "Let $p\\geq 2$ be a large prime, and let $N\\gg ( \\log p)^{1+\\varepsilon}$.\nThis note proves the existence of primitive roots in the short interval\n$[M,M+N]$, where $M \\geq 2$ is a fixed number, and $ \\varepsilon>0$ is a small\nnumber. In particular, the least primitive root $g(p)= O\\left ((\\log\np)^{1+\\varepsilon} \\right)$, and the least prime primitive root $g^*(p)= O\\left\n((\\log p)^{1+\\varepsilon} \\right)$ unconditionally.", "category": "math.GM"}, {"title": "Encoding discrete quantum algebras in a hierarchy of binary words", "abstract": "It is shown how to endow a hierarchy of sets of binary patterns with the\nstructure of an abstract,normed C*-algebra. In the course we also recover an\nintermediate connection with the words of a Dyck language and Tempereley-Lieb\nalgebras for which we also find that an effective arithmetic code is possible\nalbeit of greater complexity. We also discuss possible applications associated\nwith signal theory and waveform engineering on possible ways to embed discrete\ncomputational structures in an analog continuum substrate.", "category": "math.GM"}, {"title": "Several Conclusions on another site setting problem", "abstract": "Let $S = \\{ {A_1},{A_2}, \\cdots ,{A_n}\\} $ be a finite point set in\nm-dimensional Euclidean space ${E^m}$, and$\\left\\| {{A_i}{A_j}} \\right\\|$ be\nthe distance between $A_i$ and $A_j$. Define $\\sigma (S) = \\sum\\limits_{1 \\le i\n< j \\le n} {\\left\\| {{A_i}{A_j}} \\right\\|} $, $D(S) = \\mathop {\\max }\\limits_{1\n\\le i < j \\le n} \\left\\{ {\\left\\| {{A_i}{A_j}} \\right\\|} \\right\\}$, $\\omega\n(m,n) = \\frac{{\\sigma (S)}}{{D(S)}}$, $\\sup \\omega (m,n) = \\max \\left\\{ {\\left.\n{\\frac{{\\sigma (S)}}{{D(S)}}} \\right|S \\subset {E^m},\\left| S \\right| = n}\n\\right\\}$. This paper proves that, for any point P in an n-dimensional simplex\n${A_1}{A_2} \\cdots {A_{n + 1}}$ in Euclidean space, $\\sum\\limits_{i = 1}^{n +\n1} {\\left\\| {P{A_i}} \\right\\|} $ <= $\\mathop {\\sup }\\limits_{{i_t},{j_t} \\in \\{\n1,2, \\cdots ,n + 1\\} } \\left\\{ {\\sum\\limits_{t = 1}^n {\\left\\|\n{{A_{{i_t}}}{A_{{j_t}}}} \\right\\|} } \\right\\}$ By using this inequality and\nseveral results in differential geometry this paper also proves that $\\sup\n\\omega (2,4) = 4 + 2\\sqrt {2 - \\sqrt 3 } $, $\\sup \\omega (n,n + 2)$ >= $C_{n +\n1}^2 + 1 + n\\sqrt {2\\left( {1 - \\sqrt {{\\textstyle{{n + 1} \\over {2n}}}} }\n\\right)} $.", "category": "math.GM"}, {"title": "Fuzzy $α$-cut and related structures", "abstract": "This paper deals with a new notion called fuzzy $\\alpha$-cut and its\nproperties. A notion called localic frame is also introduced. Algebraic\nstructures arising out of the family of fuzzy $\\alpha$-cuts have been\ninvestigated. It will be seen that this family forms a localic frame. Some\nsignificance and usefulness of fuzzy $\\alpha$-cuts are discussed.", "category": "math.GM"}, {"title": "Extending the Calculus of Moving Surfaces to Higher Orders", "abstract": "In 2010, a book published on the work of Jaques Hadamard, entitled\n\"Introduction to Tensor Analysis and the Calculus of Moving Surfaces\" by Dr.\nPavel Grinfeld, proposed an extension of Hadamard's work to ultimately allow\nprinciples of tensorial invariance on surfaces to be extended to notions of\ntime-dependent and moving surfaces. Coined \"The Calculus of Moving Surfaces\"\n(CMS), notions of Invariant Time Derivatives on Arbitrary Surface/Ambient\nTensors, Surface Velocities, and time derivatives of time-dependent Volume &\nSurface Integrals were introduced. This paper focuses on extending concepts\nfound within CMS to other Surface Objects, to Higher Orders, and to further\nuncover Tensors which are powerful at representing Commutations and Curvature\npresent on Surfaces which are moving in Time.", "category": "math.GM"}, {"title": "On the Factorization of Two Adjacent Numbers in Multiplicatively Closed Sets Generated by Two Elements", "abstract": "For two natural numbers $1<p_1<p_2$, with $\\alpha =\n\\frac{\\log(p_1)}{\\log(p_2)}$ irrational, we describe, in main Theorem $\\Omega$\nand in Note $1.5$, the factorization of two adjacent numbers in the\nmultiplicatively closed subset $S = \\{p_1^ip_2^j\\mid i,j\\in\n\\mathbb{N}\\cup\\{0\\}\\}$ using primary and secondary convergents of $\\alpha$.\nThis suggests general Question $1.2$ for more than two generators which is\nstill open.", "category": "math.GM"}, {"title": "A marriage of category theory and set theory: a finitely axiomatized nonstandard first-order theory implying ZF", "abstract": "It is well known that ZFC, despite its usefulness as a foundational theory\nfor mathematics, has two unwanted features: it cannot be written down\nexplicitly due to its infinitely many axioms, and it has a countable model due\nto the L\\\"{o}wenheim-Skolem theorem. This paper presents the axioms one has to\naccept to get rid of these two features. For that matter, some twenty axioms\nare formulated in a nonstandard first-order language with countable many\nconstants: to this collection of axioms is associated a universe of discourse\nconsisting of a class of objects, each of which is a set, and a class of\narrows, each of which is a function. The axioms of ZF are derived from this\nfinite axiom scheme, and it is shown that it does not have a countable\nmodel--if it has a model at all, that is. Furthermore, the axioms of category\ntheory are proven to hold: the present universe may therefore serve as an\nontological basis for category theory. However, it has not been investigated\nwhether any of the soundness and completeness properties hold for the present\ntheory: the inevitable conclusion is therefore that only further research can\nestablish whether the present results indeed constitute an advancement in the\nfoundations of mathematics.", "category": "math.GM"}, {"title": "A Mathematical Approach to the Hierarchical Structure of Languages", "abstract": "In this paper we suggest how the mathematical concept of hyperstructures may\nbe a useful tool in the study of the higher, hierachical structure of\nlanguages.", "category": "math.GM"}, {"title": "Golden ratios, Lucas Sequences and the Quadratic Family", "abstract": "It is conjectured that there is a converging sequence of some generalized\nFibonacci ratios, given the difference between consecutive ratios, such as the\nGolden Ratio, $\\varphi^1$, and the next golden ratio $\\varphi^2$. Moreover, the\ngraphic depiction of those ratios show some overlap with the quadratic family,\nand some numerical evidence suggest that everyone of those ratios in the finite\nset obtained, belong to at least one quadratic family, and finally a proof is\npresented that the converging sequence of some generalized Fibonacci ratios\nbelong to at least one quadratic family.", "category": "math.GM"}, {"title": "Pythagorean fuzzy graphs: Some results", "abstract": "Graph theory has successfully used to solve a wide range of problems\nencountered in diverse fields such as medical sciences, neural networks,\ncontrol theory, transportation, clustering analysis, expert systems, image\ncapturing, and network security. In past few years, a number of generalizations\nof graph theoretical concepts have developed to model the impreciseness and\nuncertainties in graphical network problems. A Pythagorean fuzzy set is a\npowerful tool for describing the vague concepts more precisely. The Pythagorean\nfuzzy set-based models provide more flexibility in handling the human judgment\ninformation as compared to other fuzzy models. The objective of this paper is\nto apply the concept of Pythagorean fuzzy sets to graph theory. This work\nintroduces the notion of Pythagorean fuzzy graphs (PFGs) and describes a number\nof methods for their construction. We then define some basic operations on PFGs\nand prove some of their important properties. The work also discusses the\nnotion of isomorphism between Pythagorean fuzzy graphs with a numerical\nexample. Further, we introduce the concept of the strong Pythagorean fuzzy\ngraph and the complete Pythagorean fuzzy graph. In addition, the paper also\nproves some results on self-complementary, self-weak complementary with\nPythagorean fuzzy strong graphs and Pythagorean fuzzy complete graphs.", "category": "math.GM"}, {"title": "Riemann Hypothesis: a GGC factorisation", "abstract": "A GGC (Generalized Gamma Convolution) representation of Riemann's Xi-function\nis constructed.", "category": "math.GM"}, {"title": "Existence and Smoothness of Navier-Stokes Equations", "abstract": "In this paper we propose new method for proving of global solutions for 3D\nNavier-Stokes equations. This complies an application to the Clay Institute\nMillennium Prize Navier Stokes Problem. The proposed method can be applied for\ninvestigation of global solutions for other classes of PDEs.", "category": "math.GM"}, {"title": "A Note on $J$-Colouring of Jahangir Graphs", "abstract": "In this paper, we discuss $J$-colouring of the family of Jahangir graphs.\nNote that the family of Jahangir graphs is a wide-ranging family of graphs\nwhich by a generalised definition includes wheel graphs. We characterise the\nsubset of Jahangir graphs which admit a $J$-colouring.", "category": "math.GM"}, {"title": "Chromatic Schultz Polynomial of Certain Graphs", "abstract": "A topological index of a graph $G$ is a real number which is preserved under\nisomorphism. Extensive studies on certain polynomials related to these\ntopological indices have also been done recently. In a similar way, chromatic\nversions of certain topological indices and the related polynomials have also\nbeen discussed in the recent literature. In this paper, the chromatic version\nof the Schultz polynomial is introduced and determined this polynomial for\ncertain fundamental graph classes.", "category": "math.GM"}, {"title": "Definitive General Proof of Goldbach's conjecture", "abstract": "The Goldbach conjecture states that every even integer is the sum of two\nprimes. This conjecture was proposed in 1742 and, despite being obviously true,\nhas remained unproven. To prove this conjecture, I have identified a subset of\nthe even numbers that have relatively few prime pairs compared to the other\neven numbers. This subset is the set of all n such that n=2p where p is prime.\nAn equation was derived that determines the number of prime pairs for n=2p. It\nis then proven that the equation never goes to zero for any n, and as n\nincreases, the number of prime pairs also increases, thus validating Goldbach's\nconjecture.", "category": "math.GM"}, {"title": "On the Riemann-Hardy hypothesis for the Ramanujan zeta function", "abstract": "The Ramanujan zeta function was in $1916$ proposed by an Indian mathematician\nSrinivasa Ramanujan. As an analogue of the Riemann hypothesis, an English\nmathematician Godfrey Harold Hardy proposed in $1940$ that the real part of all\ncomplex zeros of the Ramanujan zeta function is $6$. This is the well-known\nRiemann-Hardy hypothesis for the Ramanujan zeta function. This article is\ndevoted to the proof of this hypothesis derived from the Ramanujan-Rankin\nfunction. Owing to the integral representation of the Ramanujan-De Bruijn\nfunction, we establish its series. We also reduce its product using the\nHadamard's factorization theorem. By a class with its series and product\nrepresentations, we conclude that the real part of all zeros for Ramanujan-De\nBruijn function is zero. we also obtain its products of Conrey and Ghosh and\nHadamard-type for the Ramanujan-Rankin function. Based on the obtained result,\nwe prove that the Riemann-Hardy hypothesis is true.", "category": "math.GM"}, {"title": "On the definition of neutrosophic logic", "abstract": "Smarandache (2003) introduced a new set-valued fuzzy logic called\n(nonstandard) neutrosophic logic by using Robinson's nonstandard analysis.\nHowever, its definition involved many errors including the illegal use of\nnonstandard analysis. In this paper, we provide a rigorous definition of\nneutrosophic logic. All the errors in the original definition are addressed. We\nthen point out some paradoxes of neutrosophic logic. Finally we formulate\nneutrosophic logic with no use of nonstandard analysis.", "category": "math.GM"}, {"title": "An alternative method for solving the Gaussian integral", "abstract": "In this paper, we have proposed a new method for solving the Gaussian\nintegral. Introducing a parameter that depends on a $n$ index, we have found a\ngeneral solution for this type of integral inspired by Taylor series of a\nsimple function. We have demonstrated that this parameter represents the Taylor\nseries coefficients of this function, a result very newsworthy. We have also\nintroduced some Theorems that are proved by mathematical induction. The\nproposed method in this work has shown more practical and accessible than some\nmethods found in the literature. As a test for the method, we have investigated\na non-extensive version for the particle number density in Tsallis framework,\nwhich enabled us to evaluate the functionality of the method. Besides,\nsolutions for a certain class of the gamma and factorial functions are derived.\nMoreover, we have presented a simple application in fractional calculus. In\nconclusion, we believe in the relevance of this work because it presents a new\nform of solving the Gaussian integral having the differential calculus as a\ntool.", "category": "math.GM"}, {"title": "A neutral relation between metallic structure and almost quadratic φ-structure", "abstract": "In this paper, metallic structure and almost quadratic metric phi-structure\nare studied. Based on metallic (polynomial) Riemannian manifold, Kenmotsu\nquadratic metric manifold, cosymplectic quadratic metric manifold are defined\nand gave some examples. Finally, we construct quadratic phi-structure on the\nhypersurface M^n of a locally metallic Riemannian manifold M^n+1.", "category": "math.GM"}, {"title": "Lightlike Submanifolds of Metallic Semi-Riemannian Manifolds", "abstract": "Our aim in this paper is to investigate some types of lightlike submanifolds\nin metallic semi-Riemannian manifolds. We study invariant and screen\nsemi-invariant lightlike submanifolds of metallic semi-Riemannian manifolds and\ngive examples. We obtain the conditions for the induced connection to be a\nmetric connection. Also, we find necessary and sufficient conditions for the\ndistributions involved in the definitions of such submanifolds to be\nintegrable.", "category": "math.GM"}, {"title": "Collatz Theorem", "abstract": "This paper studies the proof of Collatz conjecture for some set of sequence\nof odd numbers with infinite number of elements. These set generalized to the\nset which contains all positive odd integers. This extension assumed to be the\nproof of the full conjecture, using the concept of mathematical induction. In\nsection 9, the Collatz conjecture is proved again using mathematical induction.\nTherefore Collatz conjecture is proved two times. Finally two algorithms with\nGNU Octave code are given to check the validity of the proof for some\nparticular numbers, code of Algorithm 1 is the restatement of Collatz\nconjecture function which is used to check the validity of our newly generated\nCollatz function for some particular terms which is provided by Algorithm 2.\nTherefore go from Algorithm 2 to Algorithm 1 for checking the sequence of\nnumbers and the number of steps needed to reach to 1 according to the\nconjecture.", "category": "math.GM"}, {"title": "A note on Graphical Notation Reveals Topological Stability Criteria for Collective Dynamics in Complex Network", "abstract": "This paper clarifies the main research methods and ideas of the thesis\n[1,2,4]. The special calculation process is also realized by corresponding\ncomputer algorithm. Finally, we introduce zero rows sum case and give the\ncorresponding algorithm, which greatly simplifies the relevant calculation of\npaper [1,4].", "category": "math.GM"}, {"title": "Unpredictable Solutions of Linear Differential Equations", "abstract": "In this study, the existence and uniqueness of the unpredictable solution for\na non-homogeneous linear system of ordinary differential equations is\nconsidered. The hyperbolic case is under discussion. New properties of\nunpredictable functions are discovered. The presence of the solutions confirms\nthe existence of Poincar\\'e chaos. Simulations illustrating the chaos are\nprovided.", "category": "math.GM"}, {"title": "Generalized metallic pseudo-Riemannian structures", "abstract": "We generalize the notion of metallic structure in the pseudo-Riemannian\nsetting, define the metallic Norden structure and study its integrability. We\nconstruct a metallic natural connection recovering as particular case the\nGanchev and Mihova connection, which we extend to a metallic natural connection\non the generalized tangent bundle. Moreover, we construct metallic\npseudo-Riemannian structures on the tangent and cotangent bundles.", "category": "math.GM"}, {"title": "La espiral áurea, su longitud y rectángulos áureos", "abstract": "In this article we calculate the length of the golden spiral, and we study\nthe golden rectangles. We calculate some measures of interest. We also show\nthat the only rectangles that can be subdivided or that generate sub rectangles\nindefinitely are the golden rectangles. We emphasize that when subdividing a\nrectangle into sub rectangles, the Fibonacci sequence naturally appears. In\naddition, we identify the rectangles that resemble the golden rectangles.", "category": "math.GM"}, {"title": "Equivalence of the Initialized Riemann-Liouville Derivatives and the Initialized Caputo Derivatives", "abstract": "Initialization of fractional differential equations remains an ongoing\nproblem. In recent years, the initialization function approach and the infinite\nstate approach provide two effective ways to deal with this problem. The\npurpose of this paper is to prove the equivalence of the initialized\nRiemann-Liouville derivatives and the initialized Caputo derivatives with\narbitrary orders. By synthesizing the above two initialization theories, the\ndiffusive representations of the two initialized derivatives with arbitrary\norders are derived. Laplace transforms of the two initialized derivatives are\nshown to be equal. As a result, the two most commonly used derivatives are\nproved to be equivalent when initial conditions are properly imposed.", "category": "math.GM"}, {"title": "Affine Factorable Surfaces in Pseudo-Galilean Space", "abstract": "An affine factorable surface of the second kind in the three dimensional\npseudo-Galilean space G13 is studied depending on the invariant theory and\ntheory of differential equation. The first and second fundamental forms,\nGaussian curvature and mean curvature of the meant surface are obtained\naccording to the basic principles of differential geometry. Also, some special\ncases are presented by changing the partial differential equation into the\nordinary differential equation to simplify the solving process. The\nclassification theorems of the considered surface with zero and non zero\nGaussian and mean curvatures are given. Some examples of such a study are\nprovided", "category": "math.GM"}, {"title": "Hyperbolic k-Fibonacci Quaternions", "abstract": "In this paper, hyperbolic k-Fibonacci quaternions are defined. Also, some\nalgebraic properties of hyperbolic k-Fibonacci quaternions which are connected\nwith hyperbolic numbers and k-Fibonacci numbers are investigated. Furthermore,\nD'Ocagne's identity, the Honsberger identity, Binet's formula, Cassini's\nidentity and Catalan's identity for these quaternions are given.", "category": "math.GM"}, {"title": "Tensor-generated fractals: Using tensor decompositions for creating self-similar patterns", "abstract": "The term fractal describes a class of complex structures exhibiting\nself-similarity across different scales. Fractal patterns can be created by\nusing various techniques such as finite subdivision rules and iterated function\nsystems. In this paper, we will present a method for the construction of\ngeometric fractals that exploits Kronecker products and tensor decompositions,\nwhich can be regarded as a generalization of matrix factorizations. We will\nshow how to create several well-known examples for one-, two-, and\nthree-dimensional self-similar structures. Additionally, the proposed method\nwill be extended to the construction of fractals in arbitrary dimensions.", "category": "math.GM"}, {"title": "A proof of the fundamental theorem of curves in space and its applications", "abstract": "We give a necessary and suficente condition for the existence of a space\ncurve with curvature $\\kappa$ and torsion $\\tau$ finding a solution of a\nnonlinear differential equation of second order and some applications are given\nfor the general helices and slant helices.", "category": "math.GM"}, {"title": "On the notion of structure species in Bourbaki's sence", "abstract": "The exposition of the theory of structure species in Bourbaki's tractate\ntakes only a few pages but still is quite difficult. However, in the exercises,\nBourbaki outlines another approach that is based on the notion of structure\ntype rather than the notion of echelon construction scheme. Herewith, relying\non the permissible limits common sense, one can proceed without complicating\nconsideration the concept of the balanced string of signs, and then get quite\naffordable and at the same time sufficiently rigorous exposition. That's what\nwe are doing by following the path proposed in this doctoral thesis. To make\nthe presentation as accessible as possible, we have included in it a large\nnumber of examples. The work ends with the definition of kind structure. The\nauthor hopes to continue work, including in her consideration of the three main\nspecies of the general structures combined structures and structures with\nmorphisms.", "category": "math.GM"}, {"title": "Generalized Seikkala Differentiability and its Application to Fuzzy initial value problem", "abstract": "This paper proposes a new generalized Seikkala derivative (gS-derivative) of\na fuzzy-valued function. We see that, there are many elementary fuzzy-valued\nfunctions which occur frequently as solution of fuzzy differential equation,\nare not Seikkala differentiable but they are generalized Seikkala\ndifferentiable. We discuss some of the properties of proposed\ndifferentiability. Using gS-differentiability, we find the solution of fuzzy\ninitial value problem.", "category": "math.GM"}, {"title": "Hamiltonian cubic bipartite graphs", "abstract": "We provide a polynomial time algorithm to determine a cubic bipartite graph\nhas a hamilton cycle or not.", "category": "math.GM"}, {"title": "Bargmann transform and generalized heat Cauchy problems", "abstract": "In this article we solve explicitly some Cauchy problems of the heat type\nattached to the generalized real and complex Dirac, Euler and Harmonic\noscillator operators. Our principal tool is the Bargmann transform.", "category": "math.GM"}, {"title": "Natural mates of non-null Frenet curves in Minkowski 3-space", "abstract": "In this paper, we give the definition of the natural mate of a non-null\nFrenet curve in Minkowski 3-spaces. The main purpose of this paper is to prove\nsome relationships between a non-null Frenet curve and its natural mate. In\nparticular, we obtain some necessary and suffcient conditions for the natural\nmate of a non-null Frenet curve to be a slant helix, a spherical curve, or a\ncurve of constant curvature. Several applications of our main results are also\npresented.", "category": "math.GM"}, {"title": "Structures in P based on Properties of Semigroup and Arithmetical Sequence H = (+-3*2; 1)", "abstract": "This paper presents results on structures in P based on tools developed from\nsubjects of elementary number theory. Key findings are: The arithmetical\nsequence H = (+-3*2; 1) is in Z the smallest superset of P \\ {3, 2}. H is a\nsemigroup. A revised definition of P. Unique Gestalt of p in Z. The prime\nnumber lattice packing H exp n. The geometrical locus in HxH of the family of\nsolutions of: - the set of prime twins, - the set of PRACHAR prime twins, - in\nH exp 2, H exp 3 family of solutions of the GOLDBACH conjunction. Partition of\nH in p exp 2-intervals. Prime numbers in p exp 2-intervals. Infinity of the set\nof prime twins. Verification of the GOLDBACH conjunction.", "category": "math.GM"}, {"title": "The Tensor Theory of Connections", "abstract": "This paper extends the univariate Theory of Connections, introduced in\n(Mortari,2017), to the multivariate case on rectangular domains with detailed\nattention to the bivariate case. In particular, it generalizes the bivariate\nCoons surface, introduced by (Coons,1984), by providing analytical expressions,\ncalled \"constrained expressions,\" representing all possible surfaces with\nassigned boundary constraints in terms of functions and arbitrary-order\nderivatives. In two dimensions, these expressions, which contain a freely\nchosen function, g(x,y), satisfy all constraints no matter what the g(x,y) is.\nThe boundary constraints considered in this article are Dirichlet, Neumann, and\nany combinations of them. Although the focus of this article is on\ntwo-dimensional spaces, the final section introduces the \"Tensor Theory of\nConnections,\" validated by mathematical proof. This represents the multivariate\nextension of the Theory of Connections subject to arbitrary-order derivative\nconstraints in rectangular domains. The main task of this paper is to provide\nan analytical procedure to obtain constrained expressions in any space that can\nbe used to transform constrained problems into unconstrained problems. This\ntheory is proposed mainly to better solve PDEs and stochastic differential\nequations.", "category": "math.GM"}, {"title": "Fibonacci Statistical Convergence on Intuitionistic Fuzzy Normed Spaces", "abstract": "In this paper, we study the concept of Fibonacci statistical convergence on\nintuitionisitic fuzzy normed space. We define the Fibonacci statistically\nCauchy sequences with respect to an intuitionisitic fuzzy normed space and\nintroduce the Fibonacci statistical completenes with respect to an\nintuitionisitic fuzzy normed space.", "category": "math.GM"}, {"title": "$4$-index theory of gravity and its relation with the violation of the energy-momentum conservation law", "abstract": "Recently, a $4$-index generalization of the Einstein theory is proposed by\nMoulin (Eur. Phys. J. C 77, 878 (2017)). Using this method, we find the most\ngeneral $2$-index field equations derivable from the Einstein-Hilbert action.\nThe application of Newtonian limit, the role of gravitational coupling constant\nand the effects of the properties of ordinary energy-momentum tensor in\nobtaining a $4$-index gravity theory have been studied. We also address the\nresults of building Weyl free $4$-index gravity theory. Our study displays that\nboth the Einstein and Rastall theories can be obtained as the subclasses of a\n$4$-index gravity theory which shows the power of $4$-index method in unifying\nvarious gravitational theories. It is also obtained that the violation of the\nenergy-momentum conservation law may be allowed in $4$-index gravity theory,\nand moreover, the contraction of $4$-index theory generally admits a\nnon-minimal coupling between geometry and matter field in the Rastall way. This\nstudy also shows that, unlike the Einstein case, the gravitational coupling\nconstant of $4$-index Rastall theory generally differs from that of the\nordinary $2$-index Rastall theory.", "category": "physics.gen-ph"}, {"title": "Ideal gas with a varying (negative absolute) temperature: An alternative to dark energy?", "abstract": "The present work is an attempt to investigate whether the evolutionary\nhistory of the Universe from the offset of inflation can be described by\nassuming the cosmic fluid to be an ideal gas with a specific gas constant but a\nvarying negative absolute temperature (NAT). The motivation of this work is to\nsearch for an alternative to the \"exotic\" and \"supernatural\" dark energy (DE).\nIn fact, the NAT works as an \"effective quintessence\" and there is need to deal\nneither with exotic matter like DE nor with modified gravity theories. For the\nsake of completeness, we release some clarifications on NATs in Section 3 of\nthe paper.", "category": "physics.gen-ph"}, {"title": "Free Fall in Gravitational Theory", "abstract": "Einstein's explanation of Mercury's perihelion motion has been verified by\nastronomical observations. His formula could also be obtained in Schwarzschild\nmetric and was published already in 1898. Motion along a straight geodesic,\nhowever, namely, free fall into a gravitational center with vanishing angular\nmomentum, is incorrectly described both by Einstein's and by Schwarzschild's\nequation of motion. A physical solution for free fall may be obtained by taking\ninto account the dependence of mass on velocity in Newton's gravitational law\nas adopted in the physics of accelerators.", "category": "physics.gen-ph"}, {"title": "Strong Electric Field in 2D Graphene: The Integer Quantum Hall regime from a different (many-body) perspective", "abstract": "We investigate the emerging consequences of an applied strong in-plane\nelectric field on a macroscopically large graphene sheet subjected to a\nperpendicular magnetic field, by determining in exact analytical form various\nmany-body thermodynamic properties and the Hall coefficient. The results\nsuggest exotic possibilities that necessitate very careful experimental\ninvestigation. In this alternate form of Quantum Hall Effect, non-linear\nphenomena related to the global magnetization, energy and Hall conductivity\n(the latter depending on the strengths of magnetic B- and electric E-fields)\nemerge without using perturbation methods, to all orders of E-field and B-field\nstrengths. Interestingly enough, when the value of the electric field is\nsufficiently strong, fractional quantization also emerges, whose topological\nstability has to be verified.", "category": "physics.gen-ph"}, {"title": "Nonlinear Schrodinger equation and classical-field description of the Lamb-Retherford experiment", "abstract": "I show that Lamb-Retherford experiment can be fully described within the\nframework of classical field theory without using concepts such as the discrete\nstates of the atom and jump-like electron transitions between them. The rate of\nstimulated decay of the metastable state of a hydrogen atom in an external\nperiodic electric field is determined. The dependence of this rate on the\nfrequency and amplitude of the external electric field, as well as on the\nparameters of the atom, has been obtained. It is shown that the maximum value\nof the stimulated decay rate of the metastable state of a hydrogen atom is\nachieved at an external electric field frequency equal to the frequency shift\ncorresponding to either the fine structure of the hydrogen atom or the Lamb\nshift.", "category": "physics.gen-ph"}, {"title": "From Elasticity to Electromagnetism: Beyond the Mirror", "abstract": "The first purpose of this short but striking paper is to revisit Elasticity\n(EL) and Electromagnetism (EM) by comparing the structure of these two theories\nand examining with details their well known couplings, in particular\npiezoelectricity and photoelasticity. Despite the strange Helmholtz and\nMach-Lippmann analogies existing between them, no classical technique may\nprovide a common setting. However, unexpected arguments discovered\nindependently by the brothers E. and F. Cosserat in 1909 for EL and by H. Weyl\nin 1918 for EM are leading to construct a new differential sequence called\nSpencer sequence in the framework of the formal theory of Lie pseudogroups and\nto introduce it for the conformal group of space-time with 15 parameters. Then,\nall the previous explicit couplings can be deduced abstractly and one must just\ngo to a laboratory in order to know about the coupling constants on which they\nare depending, like in the Hooke or Minkowski constitutive relations existing\nrespectively in EL or EM separately. We finally provide a new combined\nexperimental and theoretical proof of the fact that any 1-form with value in\nthe second order jets (elations) of the conformal group of space-time can be\nuniquely decomposed into the direct sum of the Ricci tensor R and the\nelectromagnetic field F. This result questions the mathematical foundations of\nboth General Relativity (GR) and Gauge Theory (GT). In particular, the Einstein\noperator (6 terms) must be thus replaced by the formal adjoint of the Ricci\noperator (4 terms only) in the study of gravitational waves.", "category": "physics.gen-ph"}, {"title": "Group theoretical formulation of free fall and projectile motion", "abstract": "In this work we formulate the group theoretical description of free fall and\nprojectile motion. We show that the kinematic equations for constant\nacceleration form a one parameter group acting on a phase space. We define the\ngroup elements $\\phi_t$ by their action on the points in the phase space. We\nalso generalize this approach to projectile motion. We evaluate the group\norbits regarding their relations to the physical orbits of particles and\nunphysical solutions. We note that the group theoretical formulation does not\napply to more general cases involving a time dependent acceleration. This\nmethod improves our understanding of the constant acceleration problem with its\nglobal approach. It is especially beneficial for students who want to pursue a\ncareer in theoretical physics.", "category": "physics.gen-ph"}, {"title": "Shadow of a noncommutative geometry inspired Ayón Beato García black hole", "abstract": "We introduce the noncommutative geometry inspired Ay\\'on Beato Garc\\'ia black\nhole metric and study various properties of this metric by which we try to\nprobe the allowed values of the noncommutative parameter $\\vartheta$ under\ncertain conditions. We then construct the shadow (apparent shape) cast by this\nblack hole. We derive the corresponding photon orbits and explore the effects\nof noncommutative spacetime on them. We then study the effects of\nnoncommutative parameter $\\vartheta$, smeared mass $m(r)$, smeared charge\n$q(r)$ on the silhouette of the shadow analytically and present the results\ngraphically. We then discuss the deformation which arises in the shape of the\nshadow under various conditions. Finally, we introduce a plasma background and\nobserve how the shadow behaves in this scenario.", "category": "physics.gen-ph"}, {"title": "Mechanism for Resolving Gauge Hierarchy and Large Vacuum Energy", "abstract": "Alternative forms of the solutions to the quantum field equations and their\nimplications for physical theory are considered. Incorporation of these\nalternative solution forms, herein deemed \"supplemental solutions\", into the\ndevelopment of quantum field theory leads to a unique class of particle states,\nwhich may provide simple resolutions of more than one extant problem in high\nenergy physics. The symmetry between the traditional and supplemental solutions\nresults in a direct and natural zero-point energy value of zero, and, as well,\na possible mechanism for cancelling the Higgs condensate energy, thereby\nproviding a potential resolution of the large cosmological constant problem.\nFurther, this symmetry may also resolve the Higgs gauge hierarchy problem.\nResolutions of seeming theoretic impediments to supplemental fields, in\nparticular, non-positive definite Fock space metric and vacuum decay, are\npresented, and concomitant implications for unitarity are considered. As\nsupplemental solutions are already inherent in quantum field theory, little\nchange is required to the fundamental mathematics of the theory.", "category": "physics.gen-ph"}, {"title": "The weak-field-limit solution for Kerr black hole in radiation gauge", "abstract": "In this work we present the solution for a rotating Kerr black hole in the\nweak-field limit under the radiation gauge proposed by Chen and Zhu [Phys. Rev.\nD83, 061501(R) (2011)], with which the two physical components of the\ngravitational wave can be picked out exactly.", "category": "physics.gen-ph"}, {"title": "Exact solution for Schwarzschild black hole in radiation gauge", "abstract": "Recently Chen and Zhu propose a true radiation gauge for gravity [Phys. Rev.\nD 83, 061501(R) (2011)]. This work presents a general solution for the metric\nof Schwarzschild black hole in this radiation gauge.", "category": "physics.gen-ph"}, {"title": "On a nonstatic Painleve-Gullstrand spacetime", "abstract": "A time dependent geometry outside a spherically symmetric mass is proposed.\nThe source has zero energy density but nonzero radial and tangential pressures.\nThe time variable is interpreted as the duration of measurement performed upon\nthe physical system. For very short time intervals, the effect of the mass\nsource is much reduced, going to zero when $t \\rightarrow 0$. All physical\nquantities are finite when $t \\rightarrow 0$ and $r \\rightarrow 0$ and also at\ninfinity. The total energy flux measured on a hypersurface of constant $r$ is\nvanishing.", "category": "physics.gen-ph"}, {"title": "A semi-analytical approach to black body radiation", "abstract": "We describe a semi-analytical method to calculate the total radiance received\nform a black body, between two frequencies. As has been done before, the method\ntakes advantage of the fact that the solution simplifies with the use of\npolylogarithm functions. We then use it to study the amount of radiation from\nthe sun received by bodies at Earths surface.", "category": "physics.gen-ph"}, {"title": "Field theoretic model for the Josephson effect", "abstract": "The Josephson effect is found to stem from the quantum behavior of massive\nphotons existing in a superconducting medium. Accordingly, the Josephson\ncoupling energy is found to be equal to the rest mass energy of these photons.\nThe Josephson effect is described by propagation of massive photon field\nfollowing the universal quantum equation instead of being due to quantum\ntunnelling. The mass of the photon is found to be dependent on the electric\nproperties of the junction. A characteristic (critical) quantized capacitance\nof the junction is found to be inversely related to the critical current. The\nquantum (kinetic) inductance induced in the junction is found to be equal to\n$L_q=\\mu_0\\lambda_J$\\,, where $\\lambda_J$ is the Josephson penetration depth,\nand $\\mu_0$ is the free space permeability.", "category": "physics.gen-ph"}, {"title": "Derivations of the Planck Blackbody Spectrum from Thermodynamic Ideas in Classical Physics with Classical Zero-Point Radiation", "abstract": "Based upon thermodynamic ideas, two new derivations of the Planck blackbody\nspectrum are given within classical physics which includes classical zero-point\nradiation. The first and second laws of thermodynamics, applied to a harmonic\noscillator or a radiation normal mode, require that the canonical potential\n$\\phi(\\omega/T)$ is a function of a single variable corresponding to the ratio\nof the oscillation frequency to the temperature. The second law of\nthermodynamics involves extremum ideas which may be applied to thermal\nradiation. Our first derivation of the Planck spectrum is based upon the idea\nthat the canonical potential $\\phi(\\omega/T)$ is a monotonic function and all\nits derivatives are monotonic when interpolating between zero-point energy at\nlow temperature and energy equipartition at high temperature; the monotonic\nbehavior precludes the canonical potential from giving a preferred value for\nthe ratio $\\omega/T.$ Our second derivation of the Planck spectrum is based\nupon the requirement that the change in the Helmholtz free energy of the\nradiation in a partitioned box held at constant temperature should be a minimum\nat thermal equilibrium. Finally, the change in Casimir energy with change in\npartition position for the radiation in a partitioned box is shown to\ncorrespond at high temperature to the absence of zero-point energy when the\nspectral energy per normal mode is chosen as the traditional Planck spectrum\nwhich omits zero-point energy at low temperature; thus the idea of zero-point\nenergy is embedded in the traditional Planck spectrum. It is emphasized that\nthermal radiation is intimately connected with zero-point radiation and the\nstructure of spacetime in classical physics.", "category": "physics.gen-ph"}, {"title": "Three-Dimensional Nonlinear Stokes - Mueller Polarimetry", "abstract": "The formalism is developed for a tree-dimensional ($3D$) nonlinear\nStokes-Mueller polarimetry. The expressions are derived for the generalized\n$3D$ linear and nonlinear Stokes vectors, and the corresponding nonlinear\nMueller matrix. The coherency-like Hermitian square matrix $X$ of\nsusceptibilities is introduced, which is derived from the nonlinear Mueller\nmatrix. The $X$-matrix is characterized by the index of depolarization. Several\ndecompositions of the $X$-matrix are introduced. The $3D$ nonlinear\nStokes-Mueller polarimetry formalism can be applied for three and higher wave\nmixing processes. The $3D$ polarimetric measurements can be used for structural\ninvestigations of materials, including heterogeneous biological structures. The\n$3D$ polarimetry is applicable for nonlinear microscopy with high numerical\naperture objectives.", "category": "physics.gen-ph"}, {"title": "On the Fundamentality of Meaning", "abstract": "The mainstream view of meaning is that it is emergent, not fundamental, but\nsome have disputed this, asserting that there is a more fundamental level of\nreality than that addressed by current physical theories, and that matter and\nmeaning are in some way entangled. In this regard there are intriguing\nparallels between the quantum and biological domains, suggesting that there may\nbe a more fundamental level underlying both. I argue that the organisation of\nthis fundamental level is already to a considerable extent understood by\nbiosemioticians, who have fruitfully integrated Peirce's sign theory into\nbiology; things will happen there resembling what happens with familiar life,\nbut the agencies involved will differ in ways reflecting their fundamentality,\nin other words they will be less complex, but still have structures complex\nenough for what they have to do. According to one approach involving a\ncollaboration with which I have been involved, a part of what they have to do,\nalong with the need to survive and reproduce, is to stop situations becoming\ntoo chaotic, a concept that accords with familiar 'edge of chaos' ideas. Such\nan extension of sign theory (semiophysics?) needs to be explored by physicists,\npossible tools being computational models, existing insights into complexity,\nand dynamical systems theory. Such a theory will not be mathematical in the\nsame way that conventional physics theories are mathematical: rather than being\nfoundational, mathematics will be 'something that life does', something that\nsufficiently evolved life does because in the appropriate context so doing is\nof value to life.", "category": "physics.gen-ph"}, {"title": "New way of second quantized theory of fermions with either Clifford or Grassmann coordinates and spin-charge-family theory", "abstract": "Fermions with the internal degrees of freedom described in Clifford space\ncarry in any dimension a half integer spin. There are two kinds of spins in\nClifford space. The spin-charge-family theory,assuming even d=13+1, uses one\nkind of spins to describe in d=3+1 spins and charges of quarks and leptons and\nantiquarks and antileptons, while the other kind is used to describe families.\nThe new way of second quantization, suggested by the spin-charge-family theory,\nis presented. It is shown that the creation and annihilation operators of\n1-fermion states, written as products of nilpotents and projectors of an odd\nClifford character, fulfill the anticommutation relations as required in the\nsecond quantization procedure for fermions: 1-fermion states are in Clifford\nspace already second quantized, the creation operators for any n-fermion second\nquantized vectors are products of one fermion creation operators, operating on\nthe empty vacuum state. It is demonstrated that also in Grassmann space there\nexist the creation and annihilation operators of an odd Grassmann character,\ngenerating \"fermions\", which fulfill as well the anticommutation relations for\nfermions, representing correspondingly the second quantized 1-\"fermion\" states,\nin this case with integer spins. Grassmann space offers no families. We discuss\nthe new second quantization procedure of the fields in both spaces. For the\nGrassmann case we present the action, basic states, solutions of the Weyl\nequation for free massless \"fermions\" and discrete symmetry operators. A short\noverview of the achievements of the spin-charge-family theory is done, and open\nproblems of this theory still waiting to be solved are presented. The Grassmann\nand the Clifford case are compared in order to better understand open questions\nin physics of elementary fermion and boson fields and in cosmology.", "category": "physics.gen-ph"}, {"title": "Unified Classical and `Quantum Mechanical' Gravity!", "abstract": "It is shown that a unified description of classical and `quantum mechanical'\ngravity in its linearized form is possible.", "category": "physics.gen-ph"}, {"title": "Non-relativistic Arbitrary l-states of Quarkonium through Asymptotic Iteration Method", "abstract": "The energy eigenvalues with any l-states and mass of heavy quark- antiquark\nsystem (quarkonium) are obtained by using Asymptotic Iteration Method in the\nview of non-relativistic quantum chromodynamics, in which the quarks are\nconsidered as spinless for easiness, and are bounded by Cornell potential. A\nsemi-analytical formula for energy eigenvalues and mass is achieved via the\nmethod in scope of the perturbation theory. The accuracy of this formula is\nchecked by comparing the eigenvalues with the ones numerically obtained in this\nstudy, and with exact ones in literature. Furthermore, semi-analytical formula\nis applied to some meson systems for comparing the masses with the experimental\ndata.", "category": "physics.gen-ph"}, {"title": "The fallacy of Schott energy-momentum", "abstract": "The incompatibility between Larmor's formula for radiation losses (at a rate\nproportional to square of the acceleration of the electric charge) and the\nradiation reaction (the rate of loss of momentum of the accelerated charge\nproportional to its rate of change of acceleration) was recently shown to arise\nbecause a proper distinction is not kept between radiation losses calculated in\nterms of a retarded time and those expressed in terms of a \"real time\".\nHowever, the occurrence of this disparity between two formulations is usually\nreconciled in literature by proposing an acceleration-dependent Schott energy\nlying somewhere in the nearby electromagnetic fields of an accelerated charge.\nBut nobody has yet unambiguously demonstrated where the Schott energy actually\nlies in the fields. By scrutinizing electromagnetic fields of a uniformly\naccelerated charge, a mathematically tractable case, we show that contrary to\nthe ideas prevalent in the literature, there is no evidence of any\nacceleration-dependent Schott energy-momentum in the electromagnetic fields,\nanywhere in the near vicinity of the charge or elsewhere. Accordingly, we\nexpose the fallacy of the Schott energy-momentum term, which should henceforth\nbe abandoned, in the electromagnetic radiation formulation.", "category": "physics.gen-ph"}, {"title": "Precursors of gate oxide degradation in SiC power MOSFETs", "abstract": "Gate oxide degradation is more critical in Silicon-Carbide (SiC) MOSFETs than\nin Silicon (Si) MOSFETs. This is because of the smaller gate oxide thickness\nand the higher electric field that develops across the gate oxide in SiC\nMOSFETs. While multiple precursors have been identified for monitoring the gate\noxide degradation in Si MOSFETs, very few precursors have been identified for\nSiC MOSFETs. The purpose of this paper is to demonstrate that gate oxide\ndegradation precursors used in Si MOSFETs: a) threshold voltage, b) gate\nplateau voltage and c) gate plateau time, can also be used as precursors for\nSiC MOSFETS. Moreover, all three precursors are found to exhibit a simultaneous\nincreasing trend (during the stress time) leading to an increase in on-state\nloss, switching loss and switching time of the SiC MOSFET. The existing studies\nof gate oxide degradation mechanisms in SiC MOSFETs, and their effects on\nthreshold voltage and mobility were extended to correlate a variation of all\nthree precursors using analytical expressions. The increasing trends of\nprecursors were experimentally confirmed by inducing gate oxide degradation in\ncommercial SiC MOSFET samples.", "category": "physics.gen-ph"}, {"title": "Fractional Cassini Coordinates", "abstract": "Introducing a set $\\{\\alpha_i\\} \\in R$ of fractional exponential powers of\nfocal distances an extension of symmetric Cassini-coordinates on the plane to\nthe asymmetric case is proposed which leads to a new set of fractional\ngeneralized Cassini-coordinate systems. Orthogonality and classical limiting\ncases are derived. An extension to cylindrically symmetric systems in $R^3$ is\ninvestigated. The resulting asymmetric coordinate systems are well suited to\nsolve corresponding two- and three center problems in physics.", "category": "physics.gen-ph"}, {"title": "Nanocircuits in loop structures: continuous waves preclude gauge invariant wavelengths", "abstract": "Tunnel junctions for quantum computing require discrete spectra from\ncontinuous waves on a doubly connected coordinate or loop. For an electron on a\nmetal ring discrete spectra follow from discontinuous Bloch waves. Can both\npropositions be true? We find using a gauge function originating in the\nLagrangian that continuity on a ring or loop violates gauge invariance of the\nde Broglie wavelength. This same gauge function shows that Lagrangians for the\nelectron on a ring and the charge on a junction are mutual transforms. Thus\npersistent current on a metal ring and the Coulomb blockade on a tunnel\njunction seem to be the same dynamical theory based on discontinuous Bloch\nwaves on the compact perimeter of a circle", "category": "physics.gen-ph"}, {"title": "A novel connection between scalar field theories and quantum mechanics", "abstract": "This work deals with scalar field theories and supersymmetric quantum\nmechanics. The investigation is inspired by a recent result, which shows how to\nuse the reconstruction mechanism to describe two distinct field theories from\nthe very same quantum mechanics potential, and by an older work, which\ndescribes the deformation procedure that offers an interesting way to generate\nand solve new scalar field theories, starting from a given model of current\ninterest. We use the procedure to unveil a new route, from which one can\ndescribe families of scalar field theories that engender the very same quantum\nmechanics potential. The approach can be applied algorithmically, and\nimplemented to generate models that give rise to distinct quantum mechanics\nsystems as well.", "category": "physics.gen-ph"}, {"title": "Generalized boosts with shell structure of the parameter space", "abstract": "A modification of boost transformation in arbitrary pseudo-Euclidean space is\nsuggested, which in the case of the Minkowski space admits the existence of\ninertial reference frames moving with velocities taking values in a certain\nbounded interval. The velocity space may be partitioned by hypersurfaces\n\\beta^2=\\beta^2_k=const, k=1,2,3,..., into a finite or countable number of\ndomains (shells), each of which has own class of inertial \"reference frames\"\nand the velocity composition law. These shells are in one-to-one\ncorrespondence. A set of mappings of shells to each other forms the group,\nisomorphic to permutation group in the case of finite number of shells, or the\ngroup of integers in the case of countable number of shells in the velocity\nspace", "category": "physics.gen-ph"}, {"title": "Quantum models based on finite groups", "abstract": "We consider a constructive modification of quantum-mechanical formalism.\nReplacement of a general unitary group by unitary representations of finite\ngroups makes it possible to reproduce quantum formalism without loss of its\nempirical content. Since any linear representation of a finite group can be\nimplemented as a subrepresentation of a permutation representation,\nquantum-mechanical problems can be formulated in terms of permutation groups.\nReproducing quantum behavior in the framework of permutation representations of\nfinite groups makes it possible to clarify the meaning of a number of physical\nconcepts.", "category": "physics.gen-ph"}, {"title": "Possible scheme for observing acceleration (Unruh) radiation", "abstract": "In an FEL the electrons traveling through the undulator are surrounded in\ntheir own reference frame by Unruh radiation at a temperature of order 8,000\nKelvin. When these virtual photons scatter from the beam electrons they become\nreal and can be detected. Because of the microbunching of the FEL electron beam\nthis process proceeds coherently for a fraction of the electrons in the\nmicrobunch. This enhances the Unruh radiation which is still dominated by the\ncopious spontaneous radiation in the same energy range. We discuss the\nparticular case of the Stanford LCLS, as well as the case of extreme\nacceleration, when the x-ray beam is brought into collision with the 14 GeV\nelectron beam.", "category": "physics.gen-ph"}, {"title": "Magnetically charged black hole in framework of nonlinear electrodynamics model", "abstract": "A model of nonlinear electrodynamics is proposed and investigated in general\nrelativity. We consider the magnetic black hole and find a regular solution\nwhich gives corrections into the Reissner-Nordstr\\\"{o}m solution. At\n$r\\rightarrow\\infty$ the asymptotic spacetime becomes flat. The magnetic mass\nof the black hole is calculated and the metric function is obtained. At some\nvalues of the model parameter there can be one, two or no horizons.\nThermodynamics of black holes is studied and we calculate the Hawking\ntemperature and heat capacity of black holes. It is demonstrated that there is\na phase transition of second order. At some parameters of the model black holes\nare thermodynamically stable.", "category": "physics.gen-ph"}, {"title": "Thermodynamic approach to holographic dark energy and the Rényi entropy", "abstract": "Using the first law of thermodynamics, we propose a relation between the\nsystem entropy ($S$) and its IR ($L$) and UV ($\\Lambda$) cutoffs. In addition,\napplying this relation to the apparent horizon of flat FRW universe, whose\nentropy meets the R\\'{e}nyi entropy, a new holographic dark energy model is\naddressed. Thereinafter, the evolution of the flat FRW universe, filled by a\npressureless source and the obtained dark energy candidate, is studied. In our\nmodel, there is no mutual interaction between the cosmos sectors. We find out\nthat the obtained model is theoretically powerful to explain the current\naccelerated phase of the universe. This result emphasizes that the generalized\nentropy formalism is suitable for describing systems including the long-range\ninteractions such as gravity.", "category": "physics.gen-ph"}, {"title": "Hubble Expansion as an Einstein Curvature", "abstract": "Extending the spacetime manifold of general relativity (GR) to incorporate\nthe Hubble expansion of space as a specific curvature, generates a modified\nsolution with three additional non-zero Christoffel symbols and a reformulated\nRicci tensor and curvature. The observational consequences of this\nreformulation are compared with the $\\Lambda$CDM model for luminosity distance\nusing the extensive type~Ia supernovae (SNe~1a) data with redshift corrected to\nthe CMB, and for angular diameter distance using the recent baryonic acoustic\noscillation (BAO) data. For the SNe~1a data, the modified GR and $\\Lambda$CDM\nmodels differ by $^{+0.11}_{-0.15}~\\mu_B$~mag. over $z_{cmb}=0.01-1.3$, with\noverall weighted RMS errors of $\\pm0.136$ $\\mu_B$~mag for modified GR and\n$\\pm0.151$ $\\mu_B$~mag for $\\Lambda$CDM respectively. The BAO measures span a\nrange $z=0.106-2.36$, with weighted RMS errors of $\\pm0.034$~Mpc with\n$H_0=67.6\\pm0.25$ for the modified GR model, and $\\pm0.085$~Mpc with\n$H_0=70.0\\pm0.25$ for the $\\Lambda$CDM model. The derived GR metric for this\nnew solution describes both the SNe~1a and the BAO observations with comparable\naccuracy to the $w'\\Lambda$CDM model. By incorporating the Hubble expansion of\nspace within general relativity as a specific curvature term, these\nobservations may be described without requiring additional parameters for\neither dark matter or accelerating dark energy.", "category": "physics.gen-ph"}, {"title": "Braids, normed division algebras, and Standard Model symmetries", "abstract": "This paper represents a first attempt at unifying two promising models that\nattempt to explain the origin of the internal symmetries of leptons and quarks.\nIt is shown that each of the four normed division algebras over the reals\nadmits a representation of a circular braid group. For the complex numbers and\nthe quaternions, the represented circular braid groups are $B_2$ and $B_3^c$,\nprecisely those used to construct leptons and quarks as framed braids in the\nHelon model of Bilson-Thompson. It is then shown that these framed braids\ncoincide with the states that span the minimal left ideals of the complex\n(chained) octonions, shown by Furey to describe one generation of leptons and\nquarks with unbroken $SU(3)_{c}$ and $U(1)_{em}$ symmetry.\n  The identification of basis states of minimal ideals with certain framed\nbraids is possible because the braiding in $B_2$ and $B_3^c$ in the Helon model\nare interchangeable. It is shown that the framed braids in the Helon model can\nbe written as pure braid words in $B_3^c$ with trivial braiding in $B_2$,\nsomething which is not possible for framed braids in general.", "category": "physics.gen-ph"}, {"title": "Massive electrodynamics for London's superconductivity and Josephson effect", "abstract": "Massive electrodynamics for London's superconductivity and Josephson effect\nare derived. The propagation of massive boson inside a medium yields electric\nphenomena that are reflected in the Josephson effect. Critical force, magnetic\nfield and temperature are found to be related to the critical current of the\njunction. The mass of the boson depends only on the critical current of the\njunction. The electromagnetic interaction between the Cooper pairs in the two\nsides of the superconductor in the josephson junction is mediated by a massive\nboson. The propagation of the electromagnetic waves mediated by the massive\nbosons gives rise to the electric properties of the Josephson junction. Of\nthese properties are a quantized resistance of Hall type corresponding to a\nnon-quantized magnetic flux, and a quantized capacitance. A non zero magnetic\nflux encompassing a magnetic charge is found to arise despite the fact that it\nis not a priori assumed.", "category": "physics.gen-ph"}, {"title": "Evolving topologically deformed wormholes supported in the dark matter halo", "abstract": "In this paper, we construct an evolving wormhole in the dark matter halo.\nThis work is relevant since matter has two components: (i) cosmological part\n(only time-dependent) and (ii) wormhole part (only space-dependent). In order\nto implement this, we use the Chaplygin gas as an equation of state for the\ncosmic part and Navarro-Frenk-White dark matter density profile as well as\nThomas-Fermi (TF) profile in order to form a dark wormhole. The flare-out\ncondition of wormhole is also satisfied by violating the null energy condition\n(NEC) for some specific values of quantities. Furthermore, we reveal more\ninteresting results regarding how an topologically deformation parameter\n$\\alpha$ affects the evolving wormhole sourced with some dark matter models\nbased on the physically motivated shape function.", "category": "physics.gen-ph"}, {"title": "Space-Time Quasicrystal Structures and Inflationary and Late Time Evolution Dynamics in Accelerating Cosmology", "abstract": "We construct new classes of cosmological solutions in modified and Einstein\ngravity theories encoding space-time quasicrystal, STQC, configurations\nmodelled by nonlinear self-organized and pattern forming quasi-periodic\nstructures. Such solutions are defined by generic off-diagonal locally\nanisotropic and inhomogeneous metrics depending via generating and integration\nfunctions on all spacetime coordinates. There are defined nonholonomic\nvariables and conditions for the generating/integration functions and sources\nfor effective descriptions, or approximations, as \"quasi\"\nFriedmann-Lama\\^itre-Robertson-Walker (FLRW) metrics. Such (off-) diagonal\nSTQC-FLRW configurations contain memory on nonlinear classical and/or quantum\ninteractions and may describe new acceleration cosmology scenarios. For special\ntime-periodic conditions on nonlinear gravitational and matter field\ninteractions, we can model at cosmological scales certain analogous of time\ncrystal like structures originally postulated by Frank Wilczek in condensed\nmatter physics. We speculate how STQC quasi-FLRW configurations could explain\nmodern cosmology data and provide viable descriptions for the inflation and\nstructure formation in our Universe. Finally, it is discussed systematically\nand critically how a unified description of inflation with dark energy era can\nbe explained by (modified) cosmological STQC-scenarios.", "category": "physics.gen-ph"}, {"title": "Resolution of the 300-Year-Old Vibrating String Controversy", "abstract": "The dispute about the well-known 1D vibrating string model and its solutions,\nknown as The Vibrating String Controversy, spanned the whole of 1700s and\ninvolved a group of the most eminent scientists of the time. After that, the\nmodel stood undisputed for over two centuries. In this study, it is shown that\nnot only this 300-year-old model cannot correspond to reality, but it is\ntheoretically not quite plausible, either. A new 2D model is developed removing\nall the assumptions of the classical model. The result is a pair of non-linear\npartial differential equations modeling 2D motions of a finite 1D string. A\ntheorem that can be used to determine the initial displacement functions from\nthe initial shape of the string is proven. The new model is capable of\nrepresenting initial conditions that cannot be handled in the classical model.\nIt also allows initially non-taut/non-slack strings and self-intersecting\nshapes. The classical model and the non-taut strings emerge as special limit\ncases. It is proven that pure transverse motions of a 1D string are possible\nonly in very rare cases. A theorem that sets the conditions for pure transverse\nmotions is also presented. Numerical studies of interesting cases are presented\nin support of the new model. High-speed camera experiments are also conducted,\nthe results of which also support the new theory.", "category": "physics.gen-ph"}, {"title": "Cosmological models with a hybrid scale factor in an extended gravity theory", "abstract": "A general formalism to investigate Bianchi type $VI_h$ universes is developed\nin an extended theory of gravity. A minimally coupled geometry and matter field\nis considered with a rescaled function of $f(R,T)$ substituted in place of the\nRicci scalar $R$ in the geometrical action. Dynamical aspects of the models are\ndiscussed by using a hybrid scale factor that behaves as power law in an\ninitial epoch and as an exponential form at late epoch. The power law behaviour\nand the exponential behaviour appear as two extreme cases of the present model.", "category": "physics.gen-ph"}, {"title": "Has the density of sources of gamma-ray burts been constant over the last ten billion years ?", "abstract": "A generic tired-light mechanism is examined in which a photon, like any\nparticle moving in a medium, experiences friction, that is, a force resisting\nits motion. If the velocity of light is assumed to be constant, this hypothesis\nyields a Hubble-like law which is also a consequence of the Rh = ct cosmology.\nHerein, it is used for estimating matter density as a function of redshift,\nallowing to show that the density of sources of long gamma-ray bursts appears\nto be nearly constant, up to z $\\approx$ 4. Assuming that the later is a fair\nprobe of the former, this means that matter density has been roughly constant\nover the last ten billion years, implying that, at least over this period,\nmatter has been in an overall state of equilibrium.", "category": "physics.gen-ph"}, {"title": "Detection of Exoplanets Using the Transit Method", "abstract": "I conducted differential photometry on a star GSC 3281-0800, a known host to\nexoplanet HAT-P-32b, using analysis software AstroImageJ. I plotted the\nmeasurements from a series of images taken during the transit, via ADU count\ngiven from an earth-based digital CCD camera. I was able to establish a\ndefinite light curve and learn more about the properties of this exoplanet.", "category": "physics.gen-ph"}, {"title": "Conception of Brownian coil", "abstract": "This article proposes a conception of Brownian coil. Brownian coil is a tiny\ncoil with the same size of pollen. Once immersed into designed magnetic field\nand liquid, the coil will be moved and deformed macroscopically, due to the\nmicroscopic thermodynamic molecular collisions. Such deformation and movement\nwill change the magnetic flux through the coil, by which an ElectroMotive Force\n(EMF) is produced. In this work, Brownian heat exchanger and Brownian generator\nare further designed to transform the internal energy of liquid into other\nform: 1) the internal energy of the resistance; 2) the constant electric\nenergy. The two forms accord with the Clausius' statement and Kelvin's\nstatement respectively. If the ideas can be realized, the second law of\nthermodynamics and the second kind of perpetual-motion machine should be\nunderstood again.", "category": "physics.gen-ph"}, {"title": "Towards differential elimination of spinor field from spinor electrodynamics", "abstract": "A system of PDEs for the electromagnetic field and one real component of the\nspinor field is generally equivalent to spinor electrodynamics. There are\nreasons to believe that the component can be differentially eliminated from the\nsystem. A Lagrangian depending on the electromagnetic field and one real\ncomponent of the spinor field generally describes the same physics as spinor\nelectrodynamics.", "category": "physics.gen-ph"}, {"title": "An Introduction to Influence Theory: Kinematics and Dynamics", "abstract": "Influence theory is a foundational theory of physics that is not based on\ntraditional empirically defined concepts, such as positions in space and time,\nmass, energy, or momentum. Instead, the aim is to derive these concepts, and\ntheir empirically determined relationships, from a more primitive model. It is\npostulated that there exist things, which we call particles, that influence one\nanother in a discrete and directed fashion resulting in a partially ordered set\nof influence events. We consider the problem of consistent quantification of\nthe influence events. Observers are modeled as particle chains (observer\nchains) as if an observer were able to track a particle and quantify the\ninfluence events that the particle experiences. From these quantified influence\nevents, we study consistent quantification of the universe of events based on\nthe observer chains. In this paper, we both review and further develop the\nkinematics and dynamics of particles from the perspective of influence theory.", "category": "physics.gen-ph"}, {"title": "Rotating planets in Newtonian gravity", "abstract": "Variational techniques have been used in applications of hydrodynamics in\nspecial cases but an action that is general enough to deal with both potential\nflows and solid-body flows, such as cylindrical Couette flow and rotating\nplanets, has been proposed only recently. This paper is one of a series that\naims to test and develop the new Action Principle. We study a model of rotating\nplanets, a compressible fluid in a stationary state of motion, under the\ninfluence of a fixed or mutual gravitational field. The main problem is to\naccount for the shape and the velocity fields, given the size of the equatorial\nbulges, the angular velocity at equator and the density profiles. The theory is\napplied to the principal objects in the solar system, from Earth and Mars to\nSaturn with fine details of its hexagonal flow and to Haumea with its odd\nshape. With only 2 parameters the model gives a fair fit to the shapes and the\nangular velocity field near the surface. Planetary rings are an unforeseen, but\na natural and inevitable feature of the dynamics; no cataclysmic event need be\ninvoked to justify them. The simple solutions that have been studied so far are\nmost suitable for the hard planets, and for them the predicted density profiles\nare reasonable. The effect of precession was not taken into account, nor were\nentropic forces, so far. There has not yet been a systematic search for truly\nrealistic solutions. The intention is to test the versatility of the action\nprinciple; the indications are are very encouraging.", "category": "physics.gen-ph"}, {"title": "A classical mistake and what it tells us. How to do better with an action principle for Hydro and Thermodynamics", "abstract": "Rayleigh's stability analysis of cylindrical Couette flow, of 1889 and 1916,\nis in contradiction with observation. The analysis is repeated in many\ntextbooks and reviews up to 2017, and its failure to agree with observation was\nduly noted. More successful approaches have been found, but little was done to\ndiscover the weak point of Rayleigh's argument, what is the reason that it\nfails. This paper identifies the mistake as one that is endemic in the\nliterature. Since the physics of the problem remains poorly understood, a\ndiscussion of this paradox should prove useful. Briefly, the argument depends\non the Navier-Stokes equation and on the assumption that a certain expression\ncalled \"energy density\" or \"kinetic potential\" can be interpreted and used as\nsuch. It is shown here that %no energy density is compatible with the\nNavier-Stokes equation, in the context of Couette flow or in general, and that\nthe use of any expression as a kinetic potential is in conflict with the\nNavier-Stokes equation, in all but a very limited context.\n  An alternative analysis of basic Couette flow, based on an action principle\nfor compressible fluids, provides a Hamiltonian density as well as a kinetic\npotential. The two are not the same, even in the simplest cases. The action\nprinciple provides a kinetic potential; a new criterion for stability\nrecognizes the profound effect of the surface adhesion and the tensile strength\nof water. It is in full agreement with observation.\n  Several new experiments are suggested.", "category": "physics.gen-ph"}, {"title": "Gravitational attraction until relativistic equipartition of internal and translational kinetic energies", "abstract": "Translational ordering of the internal kinematic chaos provides the Special\nRelativity referents for the geodesic motion of warm thermodynamical bodies.\nTaking identical mathematics, relativistic physics of the low speed transport\nof time-varying heat-energies differs from Newton's physics of steady masses\nwithout internal degrees of freedom. General Relativity predicts geodesic\nchanges of the internal heat-energy variable under the free gravitational fall\nand the geodesic turn in the radial field center. Internal heat variations\nenable cyclic dynamics of decelerated falls and accelerated takeoffs of\ninertial matter and its structural self-organization. The coordinate speed of\nthe ordered spatial motion takes maximum under the equipartition of\nrelativistic internal and translational kinetic energies. Observable\npredictions are discussed for verification/falsification of the principle of\nequipartition as a new basic for the ordered motion and self-organization in\nexternal fields, including gravitational, electromagnetic, and thermal ones.", "category": "physics.gen-ph"}, {"title": "Volume and Boundary Face Area of a Regular Tetrahedron in a Constant Curvature Space", "abstract": "An example of the volume and boundary face area of a curved polyhedron for\nthe case of regular spherical and hyperbolic tetrahedron is discussed. An exact\nformula is explicitly derived as a function of the scalar curvature and the\nedge length. This work can be used in loop quantum gravity and Regge calculus\nin the context of a non-vanishing cosmological constant.", "category": "physics.gen-ph"}, {"title": "Holographic Renormalization with Machine learning", "abstract": "At low energies, the microscopic characteristics and changes of physical\nsystems as viewed at different distance scales are described by universal scale\ninvariant properties investigated by the Renormalization Group (RG) apparatus,\nan efficient tool used to deal with scaling problems in effective field\ntheories. We employ an information-theoretic approach in a deep learning setup\nby introducing an artificial neural network algorithm to map and identify new\nphysical degrees of freedom. Using deep learning methods mapped to a genuine\nfield theory, we develop a mechanism capable to identify relevant degrees of\nfreedom and induce scale invariance without prior knowledge about a system. We\nshow that deep learning algorithms that use an RG-like scheme to learn relevant\nfeatures from data could help to understand the nature of the holographic\nentanglement entropy and the holographic principle in context of the AdS/CFT\ncorrespondence.", "category": "physics.gen-ph"}, {"title": "The Structure of Matter in Spacetime from the Substructure of Time", "abstract": "The nature of the change in perspective that accompanies the proposal of a\nunified physical theory deriving from the single dimension of time is\nelaborated. On expressing a temporal interval in a multi-dimensional form, via\na direct arithmetic decomposition, both the geometric structure of\n4-dimensional spacetime and the physical structure of matter in spacetime can\nbe derived from the substructure of time. While reviewing this construction,\nhere we emphasise how the new conceptual picture differs from the more typical\nviewpoint in theoretical physics of accounting for the properties of matter by\nfirst postulating entities on top of a given spacetime background or by\ngeometrically augmenting 4-dimensional spacetime itself. With reference to\nhistorical and philosophical sources we argue that the proposed perspective,\ncentred on the possible arithmetic forms of time, provides an account for how\nthe mathematical structures of the theory can relate directly to the physical\nstructures of the empirical world.", "category": "physics.gen-ph"}, {"title": "Riemannian geometry without the hypotheses of homogeneity and symmetry", "abstract": "A generalisation of Riemannian geometry is considered, based exclusively on\nthe minimal assumptions that the line element $ds$ is a regular function of\nposition and direction and that the distance of every point from itself is\nequal to zero. Besides the Riemannian line element, also Riemann's residual\nhypotheses of homogeneity and symmetry are dropped. Surprisingly, the\ninfinitesimal Pythagorean distance formula reemerges, without the need of being\npostulated, as a first approximation to $almost$ $every$ geometry that is\ninvariant with respect to direction reversal. More in general, the first\napproximation to $almost$ $every$ geometry is a one-parameter family of\nhomogeneous Riemann-Randers line elements, naturally providing the geometrical\nframework for a unified theory of the classical electromagnetic and\ngravitational fileds. Geometry naturally accounts for the hierarchy between\nelectromagnetic and gravitational interactions, their different\nattractive/repulsive nature, electric charge, CPT symmetry, Maxwell and\nEinstein equations. Within this framework higher order terms could describe new\nspacetime degrees of freedom of possible large-scale relevance.", "category": "physics.gen-ph"}, {"title": "Quantum interference without quantum mechanics", "abstract": "A recently proposed model of the Dirac electron, which describes observed\nproperties of the particle correctly, is in the present paper shown to be also\nable to explain quantum interference by classical probabilities. According to\nthis model, the electron is not point-like, but rather an \"entity\" formed by a\nfast periodic motion of a quantum whose energy is equal to the rest energy of\nthe electron. Only after a time span equal to the period of that periodic\nmotion the \"entity\" becomes the electron, with its properties, mass, spin,\ncharge, etc.. When in motion with respect to the observer, the \"dynamic\nsubstructure\" of the electron described in this way, leads to a certain time\nstructure of its detection probability, if the space-time point of detection is\ntaken as the space-time point of the quantum. In the typical \"two slit\"\nexperimental situation, this leads to a periodic detection probability with a\nfrequency of twice the De Broglie frequency. This result is identical to the\nresult obtained by the quantum mechanical description of the moving electron by\nthe free particle wave function. The different interpretations of the\nestablished interference pattern, inherent in the two alternative theoretical\ndescriptions is outlined, and the relation between the two descriptions\ndiscussed. It is concluded that quantum interference is well explained with\nclassical probabilities, without quantum mechanics and without paradoxes. In\nview of the demonstrated merits of the model on the one hand, and the new\naspects regarding the established theories it implies on the other, a more\nthorough investigation of its role in relation to relativistic quantum\nmechanics, and to quantum field theory is suggested. Some of the interesting\naspects are summarized.", "category": "physics.gen-ph"}, {"title": "Generalized Nordström Theory Revisited Part II: Nordström & Maxwell United", "abstract": "In 1945 Einstein concluded that [1]: \"The present theory of relativity is\nbased on a division of physical reality into a metric field (gravitation) on\nthe one hand, and into an electromagnetic field and matter on the other hand.\nIn reality space will probably be of a uniform character and the present theory\nbe valid only as a limiting case. For large densities of field and of matter,\nthe field equations and even the field variables which enter into them will\nhave no real significance.\". The dichotomy is resolved by introducing a complex\nRanders metric with a real valued scalar field and complex valued vector field,\nproviding a unified mathematical framework for gravitation & electromagnetism\nfor which the resulting theory's predictions agree with General Relativity; to\nleading order in the gravitational constant. Hence, the related experimental\nresults validate both theories; and the former theory's metric solutions are\nfree of spurious singularities, because its stress-energy tensor includes the\nenergy & momentum for the gravitational field; like e.g. Maxwell's\nstress-energy tensor contains the electromagnetic field.", "category": "physics.gen-ph"}, {"title": "Metriplectic Structure of a Radiation-Matter Interaction Toy Model", "abstract": "A dynamical system defined by a metriplectic structure is a dissipative model\ncharacterized by a specific pair of tensors, which defines the Leibniz\nbrackets. Generally, these tensors are Poisson brackets tensor and a symmetric\nmetric tensor that models purely dissipative dynamics. In this paper, the\nmetriplectic system describing a simplified two-photon absorption by a\ntwo-level atom is disclosed. The Hamiltonian component describes the free\nelectromagnetic radiation. The metric component encodes the radiation-matter\ncoupling, driving the system to an asymptotically stable state in which the\nexcited level of the atom is populated due to absorption. This work is intended\nas a first result to pave the way to apply the metriplectic formalism to many\nother irreversible processes in nonlinear optics.", "category": "physics.gen-ph"}, {"title": "Acoustically driven x-ray emission and matter collapse in lead", "abstract": "The action of focused underwater weak shock waves on a lead sample is\nrevealed to be not restricted by a mechanical influence only. A strong\nunexpected x-ray emission was registered from the lead foil exposed to shock\nwaves ({\\it sound into x-rays}) which were extremely adiabatic compared to\nprocesses of x-ray generation. The lead foil, exposed to shock waves, lost a\npart of its area having the shape of a polygonal hole of the size of $\\sim\n2mm$. The missing polygon of lead foil looks as a delicately removed part with\nno damage at the hole surroundings as it should be after a mechanical breaking.\nThis points to a non-mechanical mechanism of hole formation. That missing\npolygonal lead matter seems to be \"disappeared\" because the total lead volume\nwas reduced by that amount after exposure to acoustic waves ({\\it matter\ncollapse}). Both paradoxical phenomena cannot be explained by a combination of\nknown effects and a fundamentally new mechanism is required to underlie them.\nThe concept of electron anomalous states, which encouraged the experiments and\nspecified main features of them, is likely that mechanism.", "category": "physics.gen-ph"}, {"title": "Connecting the Cabbibo-Kobayashi-Maskawa matrix to quark masses", "abstract": "We show that the Cabbibo-Kobayashi-Maskawa interaction matrix may be\nconstructed with the quark masses.", "category": "physics.gen-ph"}, {"title": "A cylindrically symmetric, static anisotropic fluid spacetime and the naked singularity", "abstract": "In this article, a cylindrical symmetry and static solution of the Einstein's\nfield equations, was presented. The space-time is conformally flat, regular\neverywhere except on the symmetry axis where it possesses a naked curvature\nsingularity. The matter-energy source anisotropic fluids violates the weak\nenergy condition (WEC), diverge on the symmetry axis. We discuss geodesics\nmotion of free test-particles near to the singularity, and geodesic expansion\nin the metric to understand the nature of singularity which is naked or\ncovered, and finally the C-energy of the space-time.", "category": "physics.gen-ph"}, {"title": "The Viability of Phantom Dark Energy as a Quantum Field in 1st-Order FLRW Space", "abstract": "In the standard cosmological framework of the 0th-order FLRW metric and the\nuse of perfect fluids in the stress-energy tensor, dark energy with an\nequation-of-state parameter $w < -1$ (known as phantom dark energy) implies\nnegative kinetic energy and vacuum instability when modeled as a scalar field.\nHowever, the accepted values for present-day $w$ from Planck and WMAP9 include\na significant range of values less than $-1$. A flip of the sign in front of\nthe kinetic energy term in the Lagrangian remedies the negative kinetic energy\nbut introduces ghostlike instabilities, which perhaps may be rendered\nunobservable, but certainly not without great cost to the theory. Staying\nwithin the confines of observational constraints and general relativity, we\ntreat dark energy as a quantum scalar field in the background of this 1st-order\nFLRW space-time, find an approximation for the Green's function, and calculate\nthe expectation value of the field's kinetic energy for $w<-1$ using adiabatic\nexpansion to renormalize and obtain a finite value. We find that the kinetic\nenergy is positive for values of $w$ less than $-1$ in 0th- or 1st-order FLRW\nspace, thus giving more theoretical credence to observational values of $w<-1$\nand demonstrating that phantom dark energy does not categorically have negative\nkinetic energy. For a nonminimal coupling parameter $\\xi=0$, kinetic energy is\npositive for $w \\gtrsim -1.22$, which includes virtually all values of constant\n$w$ allowed by cosmological data constraints, and more negative values of $w$\ngive positive kinetic energy for non-zero values of $\\xi$. Also, our results\nare generally applicable for a massive free field or a field with a small\npotential in a 0th- or 1st-order FLRW background dominated by a fluid with a\nconstant $w$. [abridged]", "category": "physics.gen-ph"}, {"title": "A dual first-postulate basis for special relativity", "abstract": "An overlooked straightforward application of velocity reciprocity to a\ntriplet of inertial frames in collinear motion identifies the ratio of their\ncyclic relative velocities' sum to the negative product as a cosmic invariant,\nwhose inverse square root corresponds to a universal limit speed. A logical\nindeterminacy of the ratio equation establishes the repeatedly observed\nunchanged speed of stellar light as one instance of this universal limit speed.\nThis formally renders the second postulate redundant. The ratio equation\nfurthermore enables the limit speed to be quantified, in principle,\nindependently of a limit speed signal. Assuming negligible gravitational\nfields, two deep-space vehicles in non-collinear motion could measure with only\na single clock the limit speed against the speed of light, without requiring\nthese speeds to be identical. Moreover, the cosmic invariant (from dynamics,\nequal to the mass-to-energy ratio) emerges explicitly as a function of signal\nresponse time ratios between three collinear vehicles, multiplied by the\ninverse square of the velocity of whatever arbitrary signal might be used.", "category": "physics.gen-ph"}, {"title": "Fermions and bosons in the expanding universe by the spin-charge-family theory", "abstract": "The spin-charge-family theory, which is a kind of the Kaluza-Klein theories\nin $d=(13+1)$ --- but with the two kinds of the spin connection fields, the\ngauge fields of the two Clifford algebra objects, $S^{ab}$ and $\\tilde{S}^{ab}$\n--- explains all the assumptions of the standard model: The origin of the\ncharges of fermions appearing in one family, the origin and properties of the\nvector gauge fields of these charges, the origin and properties of the families\nof fermions, the origin of the scalar fields observed as the Higgs's scalar and\nthe Yukawa couplings. The theory explains several other phenomena like: The\norigin of the dark matter, of the matter-antimatter asymmetry, the \"miraculous\"\ntriangle anomaly cancellation in the standard model and others. Since the\ntheory starts at $d=(13+1)$ the question arises how and at which $d$ had our\nuniverse started and how it came down to $d=(13+1)$ and further to $d=(3+1)$.\nIn this short contribution some answers to these questions are presented.", "category": "physics.gen-ph"}, {"title": "On the Origin and Nature of Dark Matter", "abstract": "It is discussed how the ideas of entropy and the second law of\nthermodynamics, conceived long ago during the nineteenth century, underly why\ncosmological dark matter exists and originated in the first three years of the\nuniverse in the form of primordial black holes, a very large number of which\nhave many solar masses including up to the supermassive black holes at the\ncentres of galaxies. Certain upper bounds on dark astrophysical objects with\nmany solar masses based on analysis of the CMB spectrum and published in the\nliterature are criticised. For completeness we discuss WIMPs and axions which\nare leading particle theory candidates for the constituents of dark matter. The\nPIMBHs (Primordial Intermediate Mass Black Holes) with many solar masses should\nbe readily detectable in microlensing experiments which search the Magallenic\nClouds and measure light curves with durations of from one year up to several\nyears.", "category": "physics.gen-ph"}, {"title": "Analysis of the Hubble diagram of type SNe Ia supernovae and of gamma-ray bursts. A comparison between two models", "abstract": "A paper by Harmut Traunm\\\"uller [1] showed from statistical studies of\nobservational data that the most adequate equation to represent observations on\nmagnitude and redshift from 892 type 1a supernovae is $\\mu =\n5\\,log[(1+z)\\,ln(1+z)] + const.$ Comparing the Hubble diagram calculated from\nthe observed redshift data of 280 supernovae with Hubble diagrams inferred on\nthe basis of two cosmological models in the range of z = 0.0104 to 8.1, Laszlo\nMarosi [2] found in a quite independant study that the best fit function to\nrepresent observations is $\\mu= 44.109769 \\,z^{0.059883}$. Noting that\ndifferences between the different cosmological models become more pronouced in\na photon time-of-fligth $t_s$ vs. $z$ repr\\'esentation, he also noted that the\nbest equation to account for observations may also be written $z =\n-1+e^{2.024\\,\\,10^{-18} \\,\\,ts}$. In the light of these observational data, we\ncompare the theoretical Hubble diagram obtained with the flat $\\Lambda CDM$\nmodel to the ones we have obtained few years ago [3, 4, 5] from a model that we\ncall here the \"light model\" for the sake of clarity. Our conclusions are that\nvalues calculated on the basis of the $\\Lambda CDM$ model exhibit poor\nagreement with the presently available data while the light model agrees\nexactly with observations and conclusions of statistical studies [1] and [2]\n(independently of the values of $\\Omega_k$, $\\Omega_M$ or $\\Omega_{\\Lambda}$).\nOur model giving no accelerating expansion of the universe, we conclude that\nthis latter is not necessary and that models can exist which lead exactly to\nobservations without having to consider any accelerating expansion of the\nuniverse. In an Appendix, we discuss some aspects of the model and we present a\nbrief overview of some of its key results.", "category": "physics.gen-ph"}, {"title": "GW170817 event rules out general relativity in favor of vector gravity", "abstract": "The observation of gravitational waves by the three LIGO-Virgo\ninterferometers allows the examination of the polarization of gravitational\nwaves. Here we analyze the binary neutron star event GW170817, whose source\nlocation and distance are determined precisely by concurrent electromagnetic\nobservations. Applying a signal accumulation procedure to the LIGO-Virgo strain\ndata, we find ratios of the signals detected by the three interferometers. We\nconclude that the signal ratios are inconsistent with the predictions of\ngeneral relativity, but consistent with the recently proposed vector theory of\ngravity [Phys. Scr. 92, 125001 (2017)]. Moreover, we find that vector gravity\nyields a distance to the source in agreement with the astronomical\nobservations. If our analysis is correct, Einstein's general theory of\nrelativity is ruled out in favor of vector gravity at 99% confidence level and\nfuture gravitational wave detections by three or more observatories should\nconfirm this conclusion with higher precision.", "category": "physics.gen-ph"}, {"title": "Contrasting Interactions Between Dipole Oscillators in Classical and Quantum Theories: Illustrations of Unretarded van der Waals Forces", "abstract": "Students encounter harmonic-oscillator models in many aspects of basic\nphysics, within widely-varying theoretical contexts. Here we highlight the\ninterconnections and varying points of view. We start with the classical\nmechanics of masses coupled by springs and trace how the same essential systems\nare reanalyzed in the unretarded van der Waals interactions between dipole\noscillators within classical and quantum theories. We note how classical\nmechanical ideas from kinetic theory lead to energy equipartition which\ndetermines the high-temperature van der Waals forces of atoms and molecules\nmodeled as dipole oscillators. In this case, colliding heat-bath particles can\nbe regarded as providing local hidden variables for the statistical mechanical\nbehavior of the oscillators. Next we note how relativistic classical\nelectrodynamical ideas conflict with the assumptions of nonrelativistic\nclassical statistical mechanics. Classical electrodynamics which includes\nclassical zero-point radiation leads to van der Waals forces between dipole\noscillators, and these classical forces agree at all temperatures with the\nforces derived from quantum theory. However, the classical theory providing\nthis agreement is not a local theory, but rather a non-local hidden-variables\ntheory. The classical theory can be regarded as involving hidden variables in\nthe random phases of the plane waves spreading throughout space which provide\nthe source-free random radiation.", "category": "physics.gen-ph"}, {"title": "Space-time can be neither discrete nor continuous", "abstract": "We show that our recent Bohr-like approach to black hole (BH) quantum physics\nimplies that space-time quantization could be energy-dependent. Thus, in a\ncertain sense, space-time can be neither discrete nor continuous. Our approach\npermits also to show that the \"volume quantum\" of the Schwarzschild space-time\nincreases with increasing energy during BH evaporation and arrives to a maximum\nvalue when the Planck scale is reached and the generalized uncertainty\nprinciple (GUP) prevents the total BH evaporation. Remarkably, this result does\nnot depend on the BH original mass. The interesting consequence is that the\nbehavior of BH evaporation should be the same for all Schwarzschild BHs when\nthe Planck scale is approached.", "category": "physics.gen-ph"}, {"title": "The Averagely Radial Speed of Light for The Rotating And Charged Black Hole", "abstract": "The Kerr-Newman metric is used to discuss the averagely measured speed of\nlight along the radial direction at the black hole from a weak-gravitation\nreference frame such as an observer on Earth. The velocity equation of light at\nthe black hole is represented in the spherical coordinate (r, thita, phi) and\nthe main parameters are the Schwarzschild radius RS, the rotation term a, and\nthe charged term RQ. From the calculations, the averagely radial speed of light\nfrom r=Rs to r= (alpha)Rs with alpha>1 is possibly exceeding the speed of light\nc in free space by an observer in a reference frame far away from the black\nhole like on Earth. The result extends to the large r region when the rotation\nof the black hole is very high or the charge is large enough. This averagely\nradial speed finally goes to c in a large distance away from the black hole. We\nalso propose a new explanation based on our results that the observation of the\nfaster-than-light particle is due to the light bending near the black hole or\nsupermassive star with very strong gravity. Finally, we also give explanation\nthat the propagation speed of gravity shall not be faster than the\ncorresponding speed of light.", "category": "physics.gen-ph"}, {"title": "Impact models of gravitational and electrostatic forces: Potential energies, atomic clocks, gravitational anomalies and redshift", "abstract": "The far-reaching gravitational force is described by a heuristic impact model\nwith hypothetical massless entities propagating at the speed of light in vacuum\nand transferring momentum and energy be- tween massive bodies through\ninteractions on a local basis. In the original publication (Wilhelm et al.\n2013), a spherical symmetric emission of secondary entities had been\npostulated. The potential energy problems in gravitationally and\nelectrostatically bound two-body systems have been studied in the framework of\nthis im- pact model of gravity and of a proposed impact model of the\nelectrostatic force (Wilhelm et al. 2014). These studies have indicated that an\nanti-parallel emission of a secondary entity - now called graviton - with\nrespect to the incoming one is more appropriate. This article is based on the\nlatter choice and presents the modifications resulting from this change. The\nmodel has been applied to multiple interactions of gravitons in large mass\nconglomerations in several publications. They will be summarized here taking\nthe modified interaction process into account. In addition, the speed of\nphotons as a function of the gravitational potential are considered in this\ncontext together with the dependence of atomic clocks and the redshift on the\ngravitational potential.", "category": "physics.gen-ph"}, {"title": "Structural color tuning in 1D photonic crystals with electric field and magnetic field", "abstract": "A tuning of the light transmission properties of 1D photonic structures\nemploying an external stimulus is very attracting and opens the way to the\nfabrication of optical switches for colour manipulation in sensing, lighting,\nand display technology. We present the electric field-induced tuning of the\nlight transmission in a photonic crystal device, made by alternating layers of\nsilver nanoparticles and titanium dioxide nanoparticles. We show a shift of\naround 10 nm for an applied voltage of 10 V. We ascribe the shift to an\naccumulation of charges at the silver/TiO2 interface due to electric field,\nresulting in an increase of the number of charges contributing to the plasma\nfrequency in silver, giving rise to a blue shift of the silver plasmon band,\nwith concomitant blue shift of the photonic band gap. The employment of a\nrelatively low applied voltage gives the possibility to build a compact and\nlow-cost device. We also propose the fabrication of 1D photonic crystal and\nmicrocavities employing a magneto-optical material as TGG (Tb3Ga5O12). With\nthese structures we can observe a shift of 22 nm with a magnetic field of 5 T,\nat low temperature (8 K). The option to tune the colour of a photonic crystal\nwith magnetic field is interesting because of the possibility to realize\ncontactless optical switches. We also discuss the possibility to achieve the\ntuning of the photonic band gap with UV light in photonic crystals made with\nindium tin oxide (ITO).", "category": "physics.gen-ph"}, {"title": "Phase transition of spacetime: particles as black holes in anti-de Sitter space", "abstract": "In this work, we re-examined the ancient complex metric in the recent quantum\npicture of black holes as Bose-Einstein condensates of gravitons. Both black\nholes and particles can be described by the complex Kerr-Newman metric in a 6-D\ncomplex space, which appears as a 4-D spacetime for a real or imaginary\nobserver because of the barrier of the horizon. As two kind of complex black\nholes, particle and black hole are complex conjugated and can convert into each\nother through a phase transition. From the view of an observer in 3-D real\nspace, an elementary particle with spin appears as an imaginary black hole in\nan anti-de Sitter space. The self-gravitational interaction of a particle as an\nimaginary black hole makes it obtain its wave-like nature in 4-D spacetime.", "category": "physics.gen-ph"}, {"title": "Existence of Compact Structures in $f(R,T)$ Gravity", "abstract": "The present paper is devoted to investigate the possible emergence of\nrelativistic compact stellar objects through modified $f(R,T)$ gravity. For\nanisotropic matter distribution, we used Krori and Barura solutions and two\nnotable and viable $f(R,T)$ gravity formulations. By choosing particular\nobservational data, we determine the values of constant in solutions for three\nrelativistic compact star candidates. We have presented some physical behavior\nof these relativistic compact stellar objects and some aspects like energy\ndensity, radial as well as transverse pressure, their evolution, stability,\nmeasure of anisotropy and energy conditions.", "category": "physics.gen-ph"}, {"title": "Dimensionally regularized Boltzmann-Gibbs Statistical Mechanics and two-body Newton's gravitation", "abstract": "It is believed that the canonical gravitational partition function $Z$\nassociated to the classical Boltzmann-Gibbs (BG) distribution $\\frac {e^{-\\beta\nH}} {{\\cal Z}}$ cannot be constructed because the integral needed for building\nup $Z$ includes an exponential and thus diverges at the origin.\n  We show here that, by recourse to 1) the analytical extension treatment\nobtained for the first time ever, by Gradshteyn and Rizhik, via an appropriate\nformula for such case and 2) the dimensional regularization approach of Bollini\nand Giambiagi's (DR), one can indeed obtain finite gravitational results\nemploying the BG distribution. The BG treatment is considerably more involved\nthan its Tsallis counterpart. The latter needs only dimensional regularization,\nthe former requires, in addition, analytical extension.", "category": "physics.gen-ph"}, {"title": "\"Quantum\" key distribution using weak classical light waves", "abstract": "The detection of very weak classical electromagnetic (light) waves by\nclassical macroscopic device is discussed. It is shown that the results of such\ndetection can be interpreted as a manifestation of the quantum properties of\nradiation, although in reality they are related to the peculiarities of the\ninteraction of weak classical electromagnetic waves with discrete atoms. We\nshow that the \"quantum\" key distribution protocol can be realized using very\nweak classical light waves and avalanche detectors, and it possesses all the\nproperties of the quantum cryptographic protocol E91 which based on entangled\nphotons.", "category": "physics.gen-ph"}, {"title": "Investigation of the Quantum Vacuum as an Energy Sink for Subcritical and Supercritical Vaporization Lasers", "abstract": "In this paper, it is shown that the quantum electrodynamic vacuum particle\nproduction rate by a vaporization laser is negligible and is not a significant\nenergy sink at electric field strengths beyond the Schwinger Limit.", "category": "physics.gen-ph"}, {"title": "Geometry and Physics of Sp(3)/Sp(1)^3", "abstract": "The action of $Sp(3)$ on a vector space $V_3\\in \\mathbb H^3$ is analyzed. The\ntransitive action of the group is conveyed by the flag manifold (coset space)\n$Sp(3)/Sp(1)^3\\sim G/H$, a Wallach space. The curvature two-forms are shown to\nmediate pair-wise interactions between the components of the $\\mathbb H^3$\nvector space. The root space of the flag manifold is shown to be isomorphic to\nthat of $SU(3)$, suggesting similarities between the representations of the\nflag manifold and those of $SU(3)$. The passage from $SU(3)$ to $Sp(3)$ and the\ninterpretation given here encompasses the spin of the fermionic components of\n$V_3$. Composite fermions are representable as linear combinations of product\nstates of the eigenvectors of $G/H$.", "category": "physics.gen-ph"}, {"title": "The Chern-Simons Current in Time Series of Knots and Links in Proteins", "abstract": "A superspace model of knots and links for DNA time series data is proposed to\ntake into account the feedback loop from docking to undocking state of\nprotein-protein interactions. In particular, the direction of interactions\nbetween the 8 hidden states of DNA is considered. It is a $E_{8}\\times E_{8}$\nunified spin model where the genotype, from active and inactive side of DNA\ntime data series, can be considered for any living organism. The mathematical\nmodel is borrowed from loop-quantum gravity and adapted to biology. It is used\nto derive equations for gene expression describing transitions from ground to\nexcited states, and for the 8 coupling states between geneon and anti-geneon\ntransposon and retrotransposon in trash DNA. Specifically, we adopt a modified\nGrothendieck cohomology and a modified Khovanov cohomology for biology. The\nresult is a Chern-Simons current in $(8+3)$ extradimensions of a given\nunoriented super manifold with ghost fields of protein structures. The $8$\ndimensions come from the 8 hidden states of spinor field of genetic code. The\nextradimensions come from the 3 types of principle fiber bundle in the\nsecondary protein.", "category": "physics.gen-ph"}, {"title": "An exact solution to the partition function of the finite-size Ising Model", "abstract": "There is no an exact solution to three-dimensional (3D) finite-size Ising\nmodel (referred to as the Ising model hereafter for simplicity) and even\ntwo-dimensional (2D) Ising model with non-zero external field to our knowledge.\nHere by using an elementary but rigorous method, we obtain an exact solution to\nthe partition function of the Ising model with $N$ lattice sites. It is a sum\nof $2^N$ exponential functions and holds for $D$-dimensional ($D=1,2,3,...$)\nIsing model with or without the external field. This solution provides a new\ninsight into the problem of the Ising model and the related difficulties, and\nnew understanding of the classic exact solutions for one-dimensional (1D)\n(Kramers and Wannier, 1941) or 2D Ising model (Onsager, 1944). With this\nsolution, the specific heat and magnetisation of a simple 3D Ising model are\ncalculated, which are consistent with the results from experiments and/or\nnumerical simulations. Furthermore, the solution here and the related\napproaches, can also be available to other models like the percolation and/or\nthe Potts model.", "category": "physics.gen-ph"}, {"title": "Supersymmetric Preons and the Standard Model", "abstract": "The experimental fact that standard model superpartners have not been\nobserved compels one to consider an alternative implementation for\nsupersymmetry. The basic supermultiplet proposed here consists of a photon and\na charged spin 1/2 preon field, and their superpartners. These fields are shown\nto yield the standard model fermions, Higgs fields and gauge symmetries.\nSupersymmetry is defined for unbound preons only. Quantum group SLq(2)\nrepresentations are introduced to classify topologically scalars, preons,\nquarks and leptons.", "category": "physics.gen-ph"}, {"title": "Analysis with observational constraints in $ Λ$-cosmology in $f(R,T)$ gravity", "abstract": "An exact cosmological solution of Einstein field equations (EFEs) is derived\nfor a dynamical vacuum energy in $f(R,T)$ gravity for\nFriedmann-Lemaitre-Robertson-Walker (FLRW) space-time. A parametrization of the\nHubble parameter is used to find a deterministic solution of EFE. The\ncosmological dynamics of our model is discussed in detail. We have analyzed the\ntime evolution of physical parameters and obtained their bounds analytically.\nMoreover, the behavior of these parameters are shown graphically in terms of\nredshift $`z'$. Our model is consistent with the formation of structure in the\nUniverse. The role of the $f(R,T)$ coupling constant $\\lambda$ is discussed in\nthe evolution of the equation of state parameter. The statefinder and Om\ndiagnostic analysis is used to distinguish our model with other dark energy\nmodels. The maximum likelihood analysis has been reviewed to obtain the\nconstraints on the Hubble parameter $H_0$ and the model parameter $n$ by taking\ninto account the observational Hubble data set $H(z)$, the Union 2.1\ncompilation data set $SNeIa$, the Baryon Acoustic Oscillation data $BAO$, and\nthe joint data set $H(z)$ + $ SNeIa$ and $H(z)$ + $SNeIa$ + $BAO $. It is\ndemonstrated that the model is in good agreement with various observations.", "category": "physics.gen-ph"}, {"title": "Axial momentum for the relativistic Majorana particle", "abstract": "The Hilbert space of states of the relativistic Majorana particle consists of\nnormalizable bispinors with real components, and the usual momentum operator $-\ni \\nabla$ can not be defined in this space. For this reason, we introduce the\naxial momentum operator, $ - i \\gamma_5 \\nabla$ as a new observable for this\nparticle. In the Heisenberg picture, the axial momentum contains a component\nwhich oscillates with the amplitude proportional to $m/E$, where $E$ is the\nenergy and $m$ the mass of the particle. The presence of the oscillations\ndiscriminates between the massive and massless Majorana particle. We show how\nthe eigenvectors of the axial momentum, called the axial plane waves, can be\nused as a basis for obtaining the general solution of the evolution equation,\nalso in the case of free Majorana field. Here a novel feature is a coupling of\nmodes with the opposite momenta, again present only in the case of massive\nparticle or field.", "category": "physics.gen-ph"}, {"title": "The cosmological constant problem or how the quantum vacuum drives the slow accelerating expansion of the Universe", "abstract": "I argue that a solution to the cosmological constant problem is to assume\nthat the expectation value of the quantum vacuum stress-energy tensor is\nproportional to the metric tensor with a negative energy density and positive\npressure. This assumption is confirmed by an explicit calculation of the vacuum\nexpectation for the free electromagnetic and Dirac fields of quantum\nelectrodynamics. As a consequence the metric of the universe might correspond\nto a FLRW with accelerating expansion only after averaging over large scales,\nbut at small scales it gives rise to an extremely rapid fluctuation between\nexpansion and contraction in every small region, with different phases in\ndifferent points. The vacuum stress-energy tensor has fluctuations that lead to\nshort periods of expansion. A calculation with plausible approximations leads\nto an estimate of the accelerating expansion that fits in the observed value.", "category": "physics.gen-ph"}, {"title": "Solutions of the fractional Schrödinger equation via diagonalization - A plea for the harmonic oscillator basis part 1: the one dimensional case", "abstract": "A covariant non-local extention if the stationary Schr\\\"odinger equation is\npresented and it's solution in terms of Heisenbergs's matrix quantum mechanics\nis proposed. For the special case of the Riesz fractional derivative, the\ncalculation of corresponding matrix elements for the non-local kinetic energy\nterm is performed fully analytically in the harmonic oscillator basis and leads\nto a new interpretation of non local operators in terms of generalized Glauber\nstates.\n  As a first application, for the fractional harmonic oscillator the potential\nenergy matrix elements are calculated and the and the corresponding\nSchr\\\"odinger equation is diagonalized. For the special case of invariance of\nthe non-local wave equation under Fourier-transforms a new symmetry is deduced,\nwhich may be interpreted as an extension of the standard parity-symmetry.", "category": "physics.gen-ph"}, {"title": "A Time-Dependent Model of Dark Energy Based on Four-Dimensional Continuous Deformation Theory", "abstract": "In this article, we investigate the mechanism of cosmological expansion and\ninflation by modeling dark energy as a four-dimensional continuous medium, with\nits elastic deformation described by a four-dimensional vector field. We\ndemonstrate that when the bulk modulus of this cosmological medium is $K = 1.64\n\\times 10^{109} \\text{ N}\\cdot\\text{m}^{-2}$, the dark energy density,\ncorresponding to the stress-energy associated with the deformation of the\nmedium, decreases by a factor of $\\sim 10^{122}$ while the scaling factor\nexpands from $\\sim 10^{-60}$ to $\\sim 10^{-32}$ over approximately $10^{-42}$\nseconds during cosmological inflation in the early universe. Our analysis\nsuggests three potential new physical phenomena for future investigation:\ndetecting longitudinal modes of elastic waves, examining discrepancies in the\nredshift of light from the early universe, and fitting supernova curves using\nthe parameters introduced in our model.", "category": "physics.gen-ph"}, {"title": "On perturbation theory for the Sturm-Liouville problem, Part II", "abstract": "I study some possibilities of analytically solving a particular\nSturm-Liouville problem with step-wise (piece-constant) coefficients with help\nof an iterative procedure mentioned in my previous paper (Green's function sum\nrules). I construct short, simple, but very accurate analytical formulae for\ncalculating the ground state eigenvalue and eigenfunction as well as for\ncalculating the first eigenfunction. I study numerical precision of the\nobtained approximations together with the perturbation theory results.", "category": "physics.gen-ph"}, {"title": "Can the apparent expansion of the Universe be attributed to an increasing vacuum refractive index ?", "abstract": "H.A. Wilson, then R.H. Dicke, proposed to describe gravitation by a spatial\nchange of the refractive index of the vacuum around a gravitational mass. Dicke\nextended this formalism in order to describe the apparent expansion of the\nUniverse by a cosmological time dependence of the global vacuum index. In this\npaper, we develop Dicke's formalism. The metric expansion in standard cosmology\n(the time-dependent scale factor of the Friedmann-Lema\\^itre curved spacetime\nmetric) is replaced by a flat and static Euclidean metric with a change with\ntime of the vacuum index. We show that a vacuum index increasing with time\nproduces both the cosmological redshift and time dilation, and that the\npredicted evolution of the energy density of the cosmological microwave\nbackground is consistent with the standard cosmology. We then show that the\ntype Ia supernovae data, from the joint SDSS-II and SNLS SNe-Ia samples, are\nwell modeled by a vacuum index varying exponentially as n(t)=exp(t/tau0), where\ntau0=8.0+0.2-0.8 Gyr. The main consequence of this formalism is that the\ncosmological redshift should affect any atom, with a relative decrease of the\nenergy levels of about -2 10^{-18} per second. Possibilities for an\nexperimental investigation of this prediction are discussed.", "category": "physics.gen-ph"}, {"title": "Gravitational Field of a Spherical Perfect Fluid", "abstract": "Analyzing the spacetime for a static spherically distributed perfect fluid we\nshow that the smooth matching of the interior and exterior metrics for a\nrealistic source is possible only for the distances from the origin that\nexceeds the photon sphere radius for this object.", "category": "physics.gen-ph"}, {"title": "Space-Time Geodesics and the Derivation of Schrödinger's equation", "abstract": "Using the essence of Feynman's path integral and the space-time geodesics, an\ninfinity of differentiable paths that follow the geometry of a continuous\ngeodesic are constructed, and a wave function is associated to each path as a\nprobability amplitude identical to the Feynman's probability amplitude for each\npath. We prove that each probability amplitude obeys to the Schr\\\"odinger's\nequation for a non relativistic physical system moving in a time independent\npotential, starting from the Jacobi-Hamilton equation.", "category": "physics.gen-ph"}, {"title": "$f(T)$ Corrected Instability of Cylindrical Collapsing Object with Harrison-Wheeler Equation of State", "abstract": "In this paper, we study the dynamical instability of a collapsing object in\nthe framework of generalized teleparallel gravity. We assume a cylindrical\nobject with a specific matter distribution. This distribution contains energy\ndensity, isotropic pressure component with heat conduction. We take oscillating\nstates scheme up to first order to check the instable behavior of the object.\nWe construct a general collapse equation for underlying case with non-diagonal\ntetrad depending on the matter, metric functions, heat conducting term and\ntorsional terms. The Harrison-Wheeler equation of state which contains\nadiabatic index is used to explore the dynamical instability ranges for\nNewtonian and post-Newtonian constraints. These ranges depend on perturbed part\nof metric coefficients, matter parts and torsion.", "category": "physics.gen-ph"}, {"title": "New about the wave function,\"Einstein's boxes'' and scattering a particle on a one-dimensional $δ$-potential", "abstract": "The connection between the problem of scattering a particle on a\none-dimensional $\\delta$-potential with the \"Einstein's boxes\" thought\nexperiment is shown. In both cases, the validity of the superposition principle\nis limited by Einstein's 'separation principle'. It is also shown that the\ngenerally accepted point of view, according to which \"To know the quantum\nmechanical state of a system implies, in general, only statistical restrictions\non the results of measurements\", is fundamentally wrong. First, even the square\nof the modulus of the wave function imposes more than just statistical\nrestrictions. Second, the phase of the wave function also has a physical\nmeaning -- it sets the field of pulses of the ensemble. That is, quantum\nmechanics not only does not prohibit the simultaneous measurement of the\ncoordinate and momentum of a particle, but also predicts the value of the\nmomentum at that spatial point where the particle will (accidentally) be\ndetected.", "category": "physics.gen-ph"}, {"title": "Cosmic evolution in the background of non-minimal coupling in $f(R,T,R_{μν}T^{μν})$ Gravity", "abstract": "An accelerated expansion phase is being experienced by the universe due to\nthe presence of an unknown energy component known as dark energy (DE). To find\nout the cosmic evolution scientists ever tried to modify Einstein's\ngravitational theory and its unexplored parts. We also look forward to address\nthe same problem with a different approach based on interaction between matter\nand geometry. For this purpose we consider $f(R,T,Q)$ modified theory (where\n$R$ is the Ricci Scalar, $T$ is the trace of energy-momentum tensor (EMT)\n$T_{uv}$ and $Q=R_{uv}T^{uv}$ is interaction of EMT $T_{\\mu\\nu}$ and Ricci\nTensor $R_{uv}$). We formulate modified field equations in the background of\nFriedmann-Lema$\\hat{i}$tre-Robertson-Walker (FLRW) model which is defined as\n$ds^2=dt^2-a(t)^2(dx^2+dy^2+dz^2 )$, where $a(t)$ represents the scale factor.\nIn this formalism energy density is found using covariant divergence of\nmodified field equations. $\\rho$ involves a contribution from non-minimal\nmatter geometry coupling which helps to study different cosmic eras based on\nequation of state (EOS). Furthermore, we apply the energy bounds to constrain\nthe model parameters establishing a pathway to discuss the cosmic evolution for\nbest suitable parameters in accordance with recent observations.", "category": "physics.gen-ph"}, {"title": "Interacting Models of Generalised Chaplygin Gas and Modified Chaplygin Gas with Barotropic Fluid", "abstract": "In this letter we consider two different models of our present universe. We\nchoose the models which are consisting different sets of two seperate fluids.\nThe first one of each set tries to justify the late time acceleration and the\nsecond one is barotropic fluid. The former model considers our present time\nuniverse to be homogeneously filled up by Generalized Chaplygin Gas which is\ninteracting with barotropic fluid. On the other hand, the latter model\nconsiders that the cosmic acceleration is generated by Modified Chaplygin Gas\nwhich is interacting with matter depicted by barotropic equation of state. For\nboth the models, we consider the interaction term to vary proportionally with\nHubble's parameter as well as with the exotic matter/dark energy's energy\ndensity. We find an explicit function form of the energy density of the cosmos\nwhich is found to depend on different cosmological parameters like scale\nfactor, dark energy and barotropic fluid's EoS parameters and other constants\nlike interacting constants etc. We draw curves of effective EoS-s, different\ncosmological parameters like deceleration parameter $q$, statefinder parameters\n$r$ and $s$ with repect to the redshift $z$ (for different values of dark\nenergy and barotopic fluid parameters) and study them thoroughly. We compare\ntwo models as well as the nature of dependencies on these models' interaction\ncoefficients. We point out the particular redshift for which the universe may\ntransit from a deceleration to acceleration phase. We tally all these values\nwith different observational data. Here we also analyse how this value of\nparticular redshift does change for different values of interaction\ncoefficients and different dark energy models.", "category": "physics.gen-ph"}, {"title": "Higgs dark energy in inert doublet model", "abstract": "Scalar fields are among the possible candidates for dark energy. This paper\nis devoted to the scalar fields from the inert doublet model, where instead of\none as in the standard model, two SU(2) Higgs doublets are used. The component\nfields of one SU(2) doublet ($\\phi_1$) act in an identical way to the standard\nmodel Higgs while the component fields of the second SU(2) doublet ($\\phi_2$)\nare taken to be the dark energy candidate (which is done by assuming that the\nphase transition in the field has not yet occurred). It is found that one can\narrange for late time acceleration (dark energy) by using an SU(2) Higgs\ndoublet in the inert Higgs doublet model, whose vacuum expectation value is\nzero, in the quintessential regime.", "category": "physics.gen-ph"}, {"title": "Reflection symmetric Erdelyi-Kober type operators - a quasi-particle interpretation", "abstract": "Reflection symmetric Erd$\\acute{\\text{e}}$lyi-Kober type fractional integral\noperators are used to construct fractional quasi-particle generators. The\neigenfunctions and eigenvalues of these operators are given analytically. A set\nof fractional creation- and annihilation-operators is defined and the\nproperties of the corresponding free Hamiltonian are investigated. Analogue to\nthe classical approach for interacting multi-particle systems the results are\ninterpreted as a fractional quantum model for a description of residual\ninteractions of pairing type.", "category": "physics.gen-ph"}, {"title": "A Unified Model of Dark Energy Based on the Mandelstam-Tamm Uncertainty Relation", "abstract": "It is commonly recognized now that Dark Energy (Lambda-term) is of crucial\nimportance both at the early (inflationary) stage of cosmological evolution and\nat the present time. However, little is known about its nature and origin till\nnow. In particular, it is still unclear if Lambda-term is a new fundamental\nconstant or represents just an effective contribution from the underlying field\ntheory. Here, we show that a quite promising and universal approach to this\nproblem might be based on the Mandelstam-Tamm uncertainty relation of quantum\nmechanics. As a result, we get the effective Lambda-term that is important\nthroughout the entire history of the Universe. Besides, such an approach\nrequires a substantial reconsideration of some other cosmological parameters,\ne.g., the age of the Universe.", "category": "physics.gen-ph"}, {"title": "Garrett approximation for asymmetric rectangular potentials and its applications to quantum well infrared photodetectors", "abstract": "Garrett's approximation for the calculation of bound states energy in square\nwells is applied in a consistent way. So, one obtains simple formulas for these\nenergies, with errors of about 1% for moderate, and 0.01% for deep wells. The\napplication in of our results in the physics of quantum well infrared\nphotodetectors is briefly discussed.", "category": "physics.gen-ph"}, {"title": "On the radiative and thermodynamic properties of the cosmic radiations using Cobe Firas instrumental data: Sunyaev-Zeldovich distortion effect", "abstract": "The Sunyaev-Zel'dovich effect is a small spectral distortion of the spectrum\nof the cosmic microwave background (CMB) radiation. This slight distortion is\ndescribed by the Bose-Einstein (mu-type) distribution with non-zero chemical\npotential. It is now interesting to investigate the effect of this distortion\non the integral characteristics of the Bose-Einstein spectrum. The thermal\nradiative and thermodynamic functions of the Bose-Einstein distribution are\nsuch integral characteristics. These functions are as follows: a) the total\nradiation power per unit area; b) total energy density; c) number density of\nphotons; d) grand potential density; e) Helmholtz free energy density; f)\nentropy density; g) heat capacity at constant volume; h) enthalpy density; and\ni) pressure. The exact analytical expressions are obtained for the temperature\ndependences of these functions. Using experimental data measured by the COBE\nFIRAS instrument, the thermal radiative and thermodynamic functions are\ncalculated at the monopole temperature T = 2.72548 K and at z = 0. A\ncomparative analysis of the results obtained with the results for the same\nfunctions of the CMB spectrum is carried out. The thermal radiative and\nthermodynamic functions of the Bose-Einstein distribution are calculated in the\nredshift range from 10(5) to 3x10(6). The expressions are obtained for new\nastrophysical parameters, such as the entropy density/Boltzmann constant and\nnumber density, created by the mu- distortion of the CMB spectrum.", "category": "physics.gen-ph"}, {"title": "Finite Information Numbers through the Inductive Combinatorial Hierarchy", "abstract": "We report on a recent conjecture by Gisin on a restriction of physical\nprocesses in sets of finite information numbers (FIN) and further analyze the\nentropic constraint associated with the proposed algorithm. In the course, we\nprovide a decomposition of binary entropies in a pair of fractal sequences as\nfunctional composites of binary digit-sum functions and we construct a unique\nformula and an abstract partition function for these. We also prove, based on a\npreviously introduced tool of the inductive combinatorial hierarchies that the\nnaturally inherited self-similarity of the resulting hierarchy of entropic sets\ncontains equivalence classes providing unlimited symbolic series for satisfying\nthe demand posed by the FIN conjecture.", "category": "physics.gen-ph"}, {"title": "Does a standalone, \"cold\" (low-thermal-noise), linear resistor exist without cooling?", "abstract": "Classical ways of cooling require some of these elements: phase transition,\ncompressor, non-linearity, valve, and/or switch. A recent example is the 2018\npatent of Linear Technology Corporation; they utilize the shot noise of a diode\nto produce a standalone nonlinear resistor that has T/2 noise temperature\n(about 150 Kelvin). While such \"resistor\" can cool its environment when it is\nAC coupled to a resistor, the thermally cooling effect is only academically\ninteresting. The importance of the invention is of another nature: In low-noise\nelectronics, it is essential to have resistors with low noise temperature to\nimprove the signal-to-noise ratio. A natural question is raised: can we use a\nlinear system with feedback to cool and, most importantly, to show reduced\nnoise temperature? Exploring this problem, were able to produce standalone\nlinear resistors showing strongly reduced thermal noise. Our must successful\ntest shows T/100 (about 3 Kelvin) noise temperature, as if the resistor would\nhave been immersed in liquid helium. We also found that there is an old\nsolution offering similar results utilizing the virtual ground of an inverting\namplifier at negative feedback. There the \"cold\" resistor is generated at the\ninput of an amplifier. On the other hand, our system generates the \"cold\"\nresistance at the output, which can have practical advantages.", "category": "physics.gen-ph"}, {"title": "Emission of cosmic rays from Jupiter. Magnetospheres as Sources of Cosmic Rays", "abstract": "Measurements made recently with the PAMELA satellite have shown with good\nevidence that a fraction of the cosmic rays detected on Earth comes from\nJupiter. This result draws attention to the idea that magnetospheres of\nastrophysical objects could contribute to the sources of cosmic rays. We\ndiscuss this conjecture on the basis of Earth installed instrumentation and of\nthe measurements made with PAMELA. The experiments strongly favor the validity\nof the conjecture. In particular the PAMELA data show that the proton fluxes\nare larger when the Earth orbit intersects the lines of the interplanetary\nmagnetic field connecting Jupiter with Earth. This effect shows up with more\nthan ten standard deviations, difficult to explain without the idea that part\nof the cosmic ray protons comes directly from the Jupiter magnetosphere.", "category": "physics.gen-ph"}, {"title": "FLRW cosmological models with quark and strange quark matters in f(R,T) gravity", "abstract": "In this paper, we have studied the magnetized quark matter (QM) and strange\nquark matter (SQM) distributions in the presence of $ f(R,T)$ gravity in the\nbackground of Friedmann--Lema\\^itre--Robertson--Walker (FLRW) metric. To get\nexact solutions of modified field equations we have used $f(R,T) = R + 2 f(T)$\nmodel given by Harko et al. with two different parametrization of geometrical\nparameters \\textit{i.e.} the parametrization of the deceleration parameter $ q\n$, and the scale factor $ a $ in hybrid expansion form. Also, we have obtained\nEinstein Static Universe (ESU) solutions for QM and SQM distributions in\n$f(R,T)$ gravity and General Relativity (GR). All models in $f(R,T)$ gravity\nand GR for FRW and ESU Universes with QM also SQM distributions, we get zero\nmagnetic field. These results agree with the solutions of Akta{\\c{s} and\nAyg\\\"un in $f(R,T)$ gravity. However, we have also discussed the physical\nconsequences of our obtained models.", "category": "physics.gen-ph"}, {"title": "Arago Optics: Maximal Confinement of Traveling Waves", "abstract": "Optics is limited in the 'ray-approximation'-inclusion of wave properties\nresult in additional phenomena and applications; interferometers and\ndiffraction gratings are two manifestations of such non-geometric, physical\noptics. Incidentally, the most precise measurement ever, at one part per 10^21\nin the (2017) Nobel winning discovery of gravitational waves was achieved with\nan interferometer. Amendments to the properties of the medium promise negative\nrefractive index meta-materials, perfect imaging, light cloaking, and other\nultra-natural marvels. Attention to photon phase, correlations, statistics and\nwavelength independent phase shifts result in singular optics, quantum optics\nand anholonomy. Here we present another possibility, namely 'Arago-optics' to\nmaximize the efficacy of a device by strategically deploying the key qualities\nalong its perimeter. For instance, in conventional sources, waves are generated\nwith maximum intensity at the core; whereas in an Arago-source, intensity is\nminimal or zero at the center, but highest on villus stretches at the margins.\nWe reason that for a given size and energy output, this radiation profile,\nproduces the highest concentration of energy at the focus, with the maximal\nconfinement of the wave packet. Likewise, the utmost detector resolution is\nattained when sensitivity is highest on the perimeter and less at the center.\nThis concept holds beyond ultra-focus and Gaussian beams, but generally applies\nto beams of 'waves' that show constructive and destructive interference. The\nidea is particularly well suited for a fresh integration of geometry and\ntopology with electronics and materials into real-time wave engineering.", "category": "physics.gen-ph"}, {"title": "Some consequences of theories with maximal acceleration in laser-plasma acceleration", "abstract": "In this paper we consider classical electrodynamic theories with maximal\nacceleration and some of their phenomenological consequences for laser-plasma\nacceleration. It is shown that in a recently proposed higher order jet theory\nof electrodynamics, the maximal effective acceleration reachable by a\nconsistent bunch of point charged particles being accelerated by the wakefield\nis damped for bunches containing large number of charged particles. We argue\nthat such prediction of the theory is falsifiable. In the case of Born-Infeld\nkinematics, laser-plasma acceleration phenomenology provides an upper bound for\nthe Born-Infeld parameter $b$. Improvements in the beam qualities will imply\nstronger constraints on $b$.", "category": "physics.gen-ph"}, {"title": "Hyperunified field theory and Taiji program in space for GWD", "abstract": "In this talk, I present the recently established hyperunified field theory\n(HUFT) \\cite{YLWU1,YLWU2} for all basic forces and elementary particles within\nthe framework of gravitational quantum field theory (GQFT)\\cite{YLWU3,YLWU4} in\nhyper-spacetime. GQFT treats gravity as a gauge theory in the framework of\nquantum field theory to avoid the long term obstacle between the general\nrelativity and quantum mechanics. HUFT is built based on the guiding principle:\nthe dimension of hyper-spacetime correlates to intrinsic quantum numbers of\nbasic building blocks of nature, and the action describing the laws of nature\nobeys the gauge invariance and coordinate independence, which is more\nfundamental than that proposed by Einstein for general relativity. The basic\ngravitational field is defined in biframe hyper-spacetime as a bicovariant\nvector field, it is a gauge-type hyper-gravifield rather than a metric field.\nHUFT is characterized by a bimaximal Poincar\\'e and hyper-spin gauge symmetry\nPO(1,$D_h$-1)$\\Join$SP(1,$D_h$-1) with a global and local conformal scaling\ninvariance in biframe hyper-spacetime. The gravitational origin of gauge\nsymmetry is revealed through the hyper-gravifield that plays an essential role\nas a Goldstone-like field, which enables us to demonstrate the gauge-gravity\nand gravity-geometry correspondences and to corroborate the gravitational\ngauge-geometry duality with an emergent hidden general linear group symmetry\nGL($D_h$,R). The Taiji Program in Space for the gravitational wave detection in\nChina\\cite{Nature,Taiji,HUWU} is briefly outlined.", "category": "physics.gen-ph"}, {"title": "Structural analysis with mixed-frequency data: A MIDAS-SVAR model of US capital flows", "abstract": "We develop a new VAR model for structural analysis with mixed-frequency data.\nThe MIDAS-SVAR model allows to identify structural dynamic links exploiting the\ninformation contained in variables sampled at different frequencies. It also\nprovides a general framework to test homogeneous frequency-based\nrepresentations versus mixed-frequency data models. A set of Monte Carlo\nexperiments suggests that the test performs well both in terms of size and\npower. The MIDAS-SVAR is then used to study how monetary policy and financial\nmarket volatility impact on the dynamics of gross capital inflows to the US.\nWhile no relation is found when using standard quarterly data, exploiting the\nvariability present in the series within the quarter shows that the effect of\nan interest rate shock is greater the longer the time lag between the month of\nthe shock and the end of the quarter", "category": "econ.EM"}, {"title": "An Experimental Investigation of Preference Misrepresentation in the Residency Match", "abstract": "The development and deployment of matching procedures that incentivize\ntruthful preference reporting is considered one of the major successes of\nmarket design research. In this study, we test the degree to which these\nprocedures succeed in eliminating preference misrepresentation. We administered\nan online experiment to 1,714 medical students immediately after their\nparticipation in the medical residency match--a leading field application of\nstrategy-proof market design. When placed in an analogous, incentivized\nmatching task, we find that 23% of participants misrepresent their preferences.\nWe explore the factors that predict preference misrepresentation, including\ncognitive ability, strategic positioning, overconfidence, expectations, advice,\nand trust. We discuss the implications of this behavior for the design of\nallocation mechanisms and the social welfare in markets that use them.", "category": "econ.EM"}, {"title": "Prediction of Shared Bicycle Demand with Wavelet Thresholding", "abstract": "Consumers are creatures of habit, often periodic, tied to work, shopping and\nother schedules. We analyzed one month of data from the world's largest\nbike-sharing company to elicit demand behavioral cycles, initially using models\nfrom animal tracking that showed large customers fit an Ornstein-Uhlenbeck\nmodel with demand peaks at periodicities of 7, 12, 24 hour and 7-days. Lorenz\ncurves of bicycle demand showed that the majority of customer usage was\ninfrequent, and demand cycles from time-series models would strongly overfit\nthe data yielding unreliable models. Analysis of thresholded wavelets for the\nspace-time tensor of bike-sharing contracts was able to compress the data into\na 56-coefficient model with little loss of information, suggesting that\nbike-sharing demand behavior is exceptionally strong and regular. Improvements\nto predicted demand could be made by adjusting for 'noise' filtered by our\nmodel from air quality and weather information and demand from infrequent\nriders.", "category": "econ.EM"}, {"title": "A General Method for Demand Inversion", "abstract": "This paper describes a numerical method to solve for mean product qualities\nwhich equates the real market share to the market share predicted by a discrete\nchoice model. The method covers a general class of discrete choice model,\nincluding the pure characteristics model in Berry and Pakes(2007) and the\nrandom coefficient logit model in Berry et al.(1995) (hereafter BLP). The\nmethod transforms the original market share inversion problem to an\nunconstrained convex minimization problem, so that any convex programming\nalgorithm can be used to solve the inversion. Moreover, such results also imply\nthat the computational complexity of inverting a demand model should be no more\nthan that of a convex programming problem. In simulation examples, I show the\nmethod outperforms the contraction mapping algorithm in BLP. I also find the\nmethod remains robust in pure characteristics models with near-zero market\nshares.", "category": "econ.EM"}, {"title": "Knowledge and Unanimous Acceptance of Core Payoffs: An Epistemic Foundation for Cooperative Game Theory", "abstract": "We provide an epistemic foundation for cooperative games by proof theory via\nstudying the knowledge for players unanimously accepting only core payoffs. We\nfirst transform each cooperative game into a decision problem where a player\ncan accept or reject any payoff vector offered to her based on her knowledge\nabout available cooperation. Then we use a modified KD-system in epistemic\nlogic, which can be regarded as a counterpart of the model for non-cooperative\ngames in Bonanno (2008), (2015), to describe a player's knowledge,\ndecision-making criterion, and reasoning process; especially, a formula called\nC-acceptability is defined to capture the criterion for accepting a core payoff\nvector. Within this syntactical framework, we characterize the core of a\ncooperative game in terms of players' knowledge. Based on that result, we\ndiscuss an epistemic inconsistency behind Debreu-Scarf Theorem, that is, the\nincrease of the number of replicas has invariant requirement on each\nparticipant's knowledge from the aspect of competitive market, while requires\nunbounded epistemic ability players from the aspect of cooperative game.", "category": "econ.EM"}, {"title": "The dynamic impact of monetary policy on regional housing prices in the US: Evidence based on factor-augmented vector autoregressions", "abstract": "In this study interest centers on regional differences in the response of\nhousing prices to monetary policy shocks in the US. We address this issue by\nanalyzing monthly home price data for metropolitan regions using a\nfactor-augmented vector autoregression (FAVAR) model. Bayesian model estimation\nis based on Gibbs sampling with Normal-Gamma shrinkage priors for the\nautoregressive coefficients and factor loadings, while monetary policy shocks\nare identified using high-frequency surprises around policy announcements as\nexternal instruments. The empirical results indicate that monetary policy\nactions typically have sizeable and significant positive effects on regional\nhousing prices, revealing differences in magnitude and duration. The largest\neffects are observed in regions located in states on both the East and West\nCoasts, notably California, Arizona and Florida.", "category": "econ.EM"}, {"title": "On the iterated estimation of dynamic discrete choice games", "abstract": "We study the asymptotic properties of a class of estimators of the structural\nparameters in dynamic discrete choice games. We consider K-stage policy\niteration (PI) estimators, where K denotes the number of policy iterations\nemployed in the estimation. This class nests several estimators proposed in the\nliterature such as those in Aguirregabiria and Mira (2002, 2007), Pesendorfer\nand Schmidt-Dengler (2008), and Pakes et al. (2007). First, we establish that\nthe K-PML estimator is consistent and asymptotically normal for all K. This\ncomplements findings in Aguirregabiria and Mira (2007), who focus on K=1 and K\nlarge enough to induce convergence of the estimator. Furthermore, we show under\ncertain conditions that the asymptotic variance of the K-PML estimator can\nexhibit arbitrary patterns as a function of K. Second, we establish that the\nK-MD estimator is consistent and asymptotically normal for all K. For a\nspecific weight matrix, the K-MD estimator has the same asymptotic distribution\nas the K-PML estimator. Our main result provides an optimal sequence of weight\nmatrices for the K-MD estimator and shows that the optimally weighted K-MD\nestimator has an asymptotic distribution that is invariant to K. The invariance\nresult is especially unexpected given the findings in Aguirregabiria and Mira\n(2007) for K-PML estimators. Our main result implies two new corollaries about\nthe optimal 1-MD estimator (derived by Pesendorfer and Schmidt-Dengler (2008)).\nFirst, the optimal 1-MD estimator is optimal in the class of K-MD estimators.\nIn other words, additional policy iterations do not provide asymptotic\nefficiency gains relative to the optimal 1-MD estimator. Second, the optimal\n1-MD estimator is more or equally asymptotically efficient than any K-PML\nestimator for all K. Finally, the appendix provides appropriate conditions\nunder which the optimal 1-MD estimator is asymptotically efficient.", "category": "econ.EM"}, {"title": "Kernel Estimation for Panel Data with Heterogeneous Dynamics", "abstract": "This paper proposes nonparametric kernel-smoothing estimation for panel data\nto examine the degree of heterogeneity across cross-sectional units. We first\nestimate the sample mean, autocovariances, and autocorrelations for each unit\nand then apply kernel smoothing to compute their density functions. The\ndependence of the kernel estimator on bandwidth makes asymptotic bias of very\nhigh order affect the required condition on the relative magnitudes of the\ncross-sectional sample size (N) and the time-series length (T). In particular,\nit makes the condition on N and T stronger and more complicated than those\ntypically observed in the long-panel literature without kernel smoothing. We\nalso consider a split-panel jackknife method to correct bias and construction\nof confidence intervals. An empirical application and Monte Carlo simulations\nillustrate our procedure in finite samples.", "category": "econ.EM"}, {"title": "Identifying the occurrence or non occurrence of cognitive bias in situations resembling the Monty Hall problem", "abstract": "People reason heuristically in situations resembling inferential puzzles such\nas Bertrand's box paradox and the Monty Hall problem. The practical\nsignificance of that fact for economic decision making is uncertain because a\ndeparture from sound reasoning may, but does not necessarily, result in a\n\"cognitively biased\" outcome different from what sound reasoning would have\nproduced. Criteria are derived here, applicable to both experimental and\nnon-experimental situations, for heuristic reasoning in an inferential-puzzle\nsituations to result, or not to result, in cognitively bias. In some\nsituations, neither of these criteria is satisfied, and whether or not agents'\nposterior probability assessments or choices are cognitively biased cannot be\ndetermined.", "category": "econ.EM"}, {"title": "On the solution of the variational optimisation in the rational inattention framework", "abstract": "I analyse the solution method for the variational optimisation problem in the\nrational inattention framework proposed by Christopher A. Sims. The solution,\nin general, does not exist, although it may exist in exceptional cases. I show\nthat the solution does not exist for the quadratic and the logarithmic\nobjective functions analysed by Sims (2003, 2006). For a linear-quadratic\nobjective function a solution can be constructed under restrictions on all but\none of its parameters. This approach is, therefore, unlikely to be applicable\nto a wider set of economic models.", "category": "econ.EM"}, {"title": "Synthetic Control Methods and Big Data", "abstract": "Many macroeconomic policy questions may be assessed in a case study\nframework, where the time series of a treated unit is compared to a\ncounterfactual constructed from a large pool of control units. I provide a\ngeneral framework for this setting, tailored to predict the counterfactual by\nminimizing a tradeoff between underfitting (bias) and overfitting (variance).\nThe framework nests recently proposed structural and reduced form machine\nlearning approaches as special cases. Furthermore, difference-in-differences\nwith matching and the original synthetic control are restrictive cases of the\nframework, in general not minimizing the bias-variance objective. Using\nsimulation studies I find that machine learning methods outperform traditional\nmethods when the number of potential controls is large or the treated unit is\nsubstantially different from the controls. Equipped with a toolbox of\napproaches, I revisit a study on the effect of economic liberalisation on\neconomic growth. I find effects for several countries where no effect was found\nin the original study. Furthermore, I inspect how a systematically important\nbank respond to increasing capital requirements by using a large pool of banks\nto estimate the counterfactual. Finally, I assess the effect of a changing\nproduct price on product sales using a novel scanner dataset.", "category": "econ.EM"}, {"title": "An Note on Why Geographically Weighted Regression Overcomes Multidimensional-Kernel-Based Varying-Coefficient Model", "abstract": "It is widely known that geographically weighted regression(GWR) is\nessentially same as varying-coefficient model. In the former research about\nvarying-coefficient model, scholars tend to use multidimensional-kernel-based\nlocally weighted estimation(MLWE) so that information of both distance and\ndirection is considered. However, when we construct the local weight matrix of\ngeographically weighted estimation, distance among the locations in the\nneighbor is the only factor controlling the value of entries of weight matrix.\nIn other word, estimation of GWR is distance-kernel-based. Thus, in this paper,\nunder stationary and limited dependent data with multidimensional subscripts,\nwe analyze the local mean squared properties of without any assumption of the\nform of coefficient functions and compare it with MLWE. According to the\ntheoretical and simulation results, geographically-weighted locally linear\nestimation(GWLE) is asymptotically more efficient than MLWE. Furthermore, a\nrelationship between optimal bandwith selection and design of scale parameters\nis also obtained.", "category": "econ.EM"}, {"title": "Pricing Mechanism in Information Goods", "abstract": "We study three pricing mechanisms' performance and their effects on the\nparticipants in the data industry from the data supply chain perspective. A\nwin-win pricing strategy for the players in the data supply chain is proposed.\nWe obtain analytical solutions in each pricing mechanism, including the\ndecentralized and centralized pricing, Nash Bargaining pricing, and revenue\nsharing mechanism.", "category": "econ.EM"}, {"title": "A Nonparametric Approach to Measure the Heterogeneous Spatial Association: Under Spatial Temporal Data", "abstract": "Spatial association and heterogeneity are two critical areas in the research\nabout spatial analysis, geography, statistics and so on. Though large amounts\nof outstanding methods has been proposed and studied, there are few of them\ntend to study spatial association under heterogeneous environment.\nAdditionally, most of the traditional methods are based on distance statistic\nand spatial weighted matrix. However, in some abstract spatial situations,\ndistance statistic can not be applied since we can not even observe the\ngeographical locations directly. Meanwhile, under these circumstances, due to\ninvisibility of spatial positions, designing of weight matrix can not\nabsolutely avoid subjectivity. In this paper, a new entropy-based method, which\nis data-driven and distribution-free, has been proposed to help us investigate\nspatial association while fully taking the fact that heterogeneity widely\nexist. Specifically, this method is not bounded with distance statistic or\nweight matrix. Asymmetrical dependence is adopted to reflect the heterogeneity\nin spatial association for each individual and the whole discussion in this\npaper is performed on spatio-temporal data with only assuming stationary\nm-dependent over time.", "category": "econ.EM"}, {"title": "A study of strategy to the remove and ease TBT for increasing export in GCC6 countries", "abstract": "The last technical barriers to trade(TBT) between countries are Non-Tariff\nBarriers(NTBs), meaning all trade barriers are possible other than Tariff\nBarriers. And the most typical examples are (TBT), which refer to measure\nTechnical Regulation, Standards, Procedure for Conformity Assessment, Test &\nCertification etc. Therefore, in order to eliminate TBT, WTO has made all\nmembership countries automatically enter into an agreement on TBT", "category": "econ.EM"}, {"title": "How Smart Are `Water Smart Landscapes'?", "abstract": "Understanding the effectiveness of alternative approaches to water\nconservation is crucially important for ensuring the security and reliability\nof water services for urban residents. We analyze data from one of the\nlongest-running \"cash for grass\" policies - the Southern Nevada Water\nAuthority's Water Smart Landscapes program, where homeowners are paid to\nreplace grass with xeric landscaping. We use a twelve year long panel dataset\nof monthly water consumption records for 300,000 households in Las Vegas,\nNevada. Utilizing a panel difference-in-differences approach, we estimate the\naverage water savings per square meter of turf removed. We find that\nparticipation in this program reduced the average treated household's\nconsumption by 18 percent. We find no evidence that water savings degrade as\nthe landscape ages, or that water savings per unit area are influenced by the\nvalue of the rebate. Depending on the assumed time horizon of benefits from\nturf removal, we find that the WSL program cost the water authority about $1.62\nper thousand gallons of water saved, which compares favorably to alternative\nmeans of water conservation or supply augmentation.", "category": "econ.EM"}, {"title": "Business Cycles in Economics", "abstract": "The business cycles are generated by the oscillating macro-/micro-/nano-\neconomic output variables in the economy of the scale and the scope in the\namplitude/frequency/phase/time domains in the economics. The accurate forward\nlooking assumptions on the business cycles oscillation dynamics can optimize\nthe financial capital investing and/or borrowing by the economic agents in the\ncapital markets. The book's main objective is to study the business cycles in\nthe economy of the scale and the scope, formulating the Ledenyov unified\nbusiness cycles theory in the Ledenyov classic and quantum econodynamics.", "category": "econ.EM"}, {"title": "Testing for Unobserved Heterogeneous Treatment Effects with Observational Data", "abstract": "Unobserved heterogeneous treatment effects have been emphasized in the recent\npolicy evaluation literature (see e.g., Heckman and Vytlacil, 2005). This paper\nproposes a nonparametric test for unobserved heterogeneous treatment effects in\na treatment effect model with a binary treatment assignment, allowing for\nindividuals' self-selection to the treatment. Under the standard local average\ntreatment effects assumptions, i.e., the no defiers condition, we derive\ntestable model restrictions for the hypothesis of unobserved heterogeneous\ntreatment effects. Also, we show that if the treatment outcomes satisfy a\nmonotonicity assumption, these model restrictions are also sufficient. Then, we\npropose a modified Kolmogorov-Smirnov-type test which is consistent and simple\nto implement. Monte Carlo simulations show that our test performs well in\nfinite samples. For illustration, we apply our test to study heterogeneous\ntreatment effects of the Job Training Partnership Act on earnings and the\nimpacts of fertility on family income, where the null hypothesis of homogeneous\ntreatment effects gets rejected in the second case but fails to be rejected in\nthe first application.", "category": "econ.EM"}, {"title": "Testing Continuity of a Density via g-order statistics in the Regression Discontinuity Design", "abstract": "In the regression discontinuity design (RDD), it is common practice to assess\nthe credibility of the design by testing the continuity of the density of the\nrunning variable at the cut-off, e.g., McCrary (2008). In this paper we propose\nan approximate sign test for continuity of a density at a point based on the\nso-called g-order statistics, and study its properties under two complementary\nasymptotic frameworks. In the first asymptotic framework, the number q of\nobservations local to the cut-off is fixed as the sample size n diverges to\ninfinity, while in the second framework q diverges to infinity slowly as n\ndiverges to infinity. Under both of these frameworks, we show that the test we\npropose is asymptotically valid in the sense that it has limiting rejection\nprobability under the null hypothesis not exceeding the nominal level. More\nimportantly, the test is easy to implement, asymptotically valid under weaker\nconditions than those used by competing methods, and exhibits finite sample\nvalidity under stronger conditions than those needed for its asymptotic\nvalidity. In a simulation study, we find that the approximate sign test\nprovides good control of the rejection probability under the null hypothesis\nwhile remaining competitive under the alternative hypothesis. We finally apply\nour test to the design in Lee (2008), a well-known application of the RDD to\nstudy incumbency advantage.", "category": "econ.EM"}, {"title": "Causal Inference for Survival Analysis", "abstract": "In this paper, we propose the use of causal inference techniques for survival\nfunction estimation and prediction for subgroups of the data, upto individual\nunits. Tree ensemble methods, specifically random forests were modified for\nthis purpose. A real world healthcare dataset was used with about 1800 patients\nwith breast cancer, which has multiple patient covariates as well as disease\nfree survival days (DFS) and a death event binary indicator (y). We use the\ntype of cancer curative intervention as the treatment variable (T=0 or 1,\nbinary treatment case in our example). The algorithm is a 2 step approach. In\nstep 1, we estimate heterogeneous treatment effects using a causalTree with the\nDFS as the dependent variable. Next, in step 2, for each selected leaf of the\ncausalTree with distinctly different average treatment effect (with respect to\nsurvival), we fit a survival forest to all the patients in that leaf, one\nforest each for treatment T=0 as well as T=1 to get estimated patient level\nsurvival curves for each treatment (more generally, any model can be used at\nthis step). Then, we subtract the patient level survival curves to get the\ndifferential survival curve for a given patient, to compare the survival\nfunction as a result of the 2 treatments. The path to a selected leaf also\ngives us the combination of patient features and their values which are\ncausally important for the treatment effect difference at the leaf.", "category": "econ.EM"}, {"title": "Two-way fixed effects estimators with heterogeneous treatment effects", "abstract": "Linear regressions with period and group fixed effects are widely used to\nestimate treatment effects. We show that they estimate weighted sums of the\naverage treatment effects (ATE) in each group and period, with weights that may\nbe negative. Due to the negative weights, the linear regression coefficient may\nfor instance be negative while all the ATEs are positive. We propose another\nestimator that solves this issue. In the two applications we revisit, it is\nsignificantly different from the linear regression estimator.", "category": "econ.EM"}, {"title": "How does monetary policy affect income inequality in Japan? Evidence from grouped data", "abstract": "We examine the effects of monetary policy on income inequality in Japan using\na novel econometric approach that jointly estimates the Gini coefficient based\non micro-level grouped data of households and the dynamics of macroeconomic\nquantities. Our results indicate different effects on income inequality for\ndifferent types of households: A monetary tightening increases inequality when\nincome data is based on households whose head is employed (workers'\nhouseholds), while the effect reverses over the medium term when considering a\nbroader definition of households. Differences in the relative strength of the\ntransmission channels can account for this finding. Finally we demonstrate that\nthe proposed joint estimation strategy leads to more informative inference\nwhile results based on the frequently used two-step estimation approach yields\ninconclusive results.", "category": "econ.EM"}, {"title": "Schooling Choice, Labour Market Matching, and Wages", "abstract": "We develop inference for a two-sided matching model where the characteristics\nof agents on one side of the market are endogenous due to pre-matching\ninvestments. The model can be used to measure the impact of frictions in labour\nmarkets using a single cross-section of matched employer-employee data. The\nobserved matching of workers to firms is the outcome of a discrete, two-sided\nmatching process where firms with heterogeneous preferences over education\nsequentially choose workers according to an index correlated with worker\npreferences over firms. The distribution of education arises in equilibrium\nfrom a Bayesian game: workers, knowing the distribution of worker and firm\ntypes, invest in education prior to the matching process. Although the observed\nmatching exhibits strong cross-sectional dependence due to the matching\nprocess, we propose an asymptotically valid inference procedure that combines\ndiscrete choice methods with simulation.", "category": "econ.EM"}, {"title": "Panel Data Analysis with Heterogeneous Dynamics", "abstract": "This paper proposes a model-free approach to analyze panel data with\nheterogeneous dynamic structures across observational units. We first compute\nthe sample mean, autocovariances, and autocorrelations for each unit, and then\nestimate the parameters of interest based on their empirical distributions. We\nthen investigate the asymptotic properties of our estimators using double\nasymptotics and propose split-panel jackknife bias correction and inference\nbased on the cross-sectional bootstrap. We illustrate the usefulness of our\nprocedures by studying the deviation dynamics of the law of one price. Monte\nCarlo simulations confirm that the proposed bias correction is effective and\nyields valid inference in small samples.", "category": "econ.EM"}, {"title": "A Bayesian panel VAR model to analyze the impact of climate change on high-income economies", "abstract": "In this paper, we assess the impact of climate shocks on futures markets for\nagricultural commodities and a set of macroeconomic quantities for multiple\nhigh-income economies. To capture relations among countries, markets, and\nclimate shocks, this paper proposes parsimonious methods to estimate\nhigh-dimensional panel VARs. We assume that coefficients associated with\ndomestic lagged endogenous variables arise from a Gaussian mixture model while\nfurther parsimony is achieved using suitable global-local shrinkage priors on\nseveral regions of the parameter space. Our results point towards pronounced\nglobal reactions of key macroeconomic quantities to climate shocks. Moreover,\nthe empirical findings highlight substantial linkages between regionally\nlocated climate shifts and global commodity markets.", "category": "econ.EM"}, {"title": "Varying Random Coefficient Models", "abstract": "This paper provides a new methodology to analyze unobserved heterogeneity\nwhen observed characteristics are modeled nonlinearly. The proposed model\nbuilds on varying random coefficients (VRC) that are determined by nonlinear\nfunctions of observed regressors and additively separable unobservables. This\npaper proposes a novel estimator of the VRC density based on weighted sieve\nminimum distance. The main example of sieve bases are Hermite functions which\nyield a numerically stable estimation procedure. This paper shows inference\nresults that go beyond what has been shown in ordinary RC models. We provide in\neach case rates of convergence and also establish pointwise limit theory of\nlinear functionals, where a prominent example is the density of potential\noutcomes. In addition, a multiplier bootstrap procedure is proposed to\nconstruct uniform confidence bands. A Monte Carlo study examines finite sample\nproperties of the estimator and shows that it performs well even when the\nregressors associated to RC are far from being heavy tailed. Finally, the\nmethodology is applied to analyze heterogeneity in income elasticity of demand\nfor housing.", "category": "econ.EM"}, {"title": "Inference on Local Average Treatment Effects for Misclassified Treatment", "abstract": "We develop point-identification for the local average treatment effect when\nthe binary treatment contains a measurement error. The standard instrumental\nvariable estimator is inconsistent for the parameter since the measurement\nerror is non-classical by construction. We correct the problem by identifying\nthe distribution of the measurement error based on the use of an exogenous\nvariable that can even be a binary covariate. The moment conditions derived\nfrom the identification lead to generalized method of moments estimation with\nasymptotically valid inferences. Monte Carlo simulations and an empirical\nillustration demonstrate the usefulness of the proposed procedure.", "category": "econ.EM"}, {"title": "Shapley Value Methods for Attribution Modeling in Online Advertising", "abstract": "This paper re-examines the Shapley value methods for attribution analysis in\nthe area of online advertising. As a credit allocation solution in cooperative\ngame theory, Shapley value method directly quantifies the contribution of\nonline advertising inputs to the advertising key performance indicator (KPI)\nacross multiple channels. We simplify its calculation by developing an\nalternative mathematical formulation. The new formula significantly improves\nthe computational efficiency and therefore extends the scope of applicability.\nBased on the simplified formula, we further develop the ordered Shapley value\nmethod. The proposed method is able to take into account the order of channels\nvisited by users. We claim that it provides a more comprehensive insight by\nevaluating the attribution of channels at different stages of user conversion\njourneys. The proposed approaches are illustrated using a real-world online\nadvertising campaign dataset.", "category": "econ.EM"}, {"title": "Estimating Dynamic Treatment Effects in Event Studies with Heterogeneous Treatment Effects", "abstract": "To estimate the dynamic effects of an absorbing treatment, researchers often\nuse two-way fixed effects regressions that include leads and lags of the\ntreatment. We show that in settings with variation in treatment timing across\nunits, the coefficient on a given lead or lag can be contaminated by effects\nfrom other periods, and apparent pretrends can arise solely from treatment\neffects heterogeneity. We propose an alternative estimator that is free of\ncontamination, and illustrate the relative shortcomings of two-way fixed\neffects regressions with leads and lags through an empirical application.", "category": "econ.EM"}, {"title": "Revisiting the thermal and superthermal two-class distribution of incomes: A critical perspective", "abstract": "This paper offers a two-pronged critique of the empirical investigation of\nthe income distribution performed by physicists over the past decade. Their\nfinding rely on the graphical analysis of the observed distribution of\nnormalized incomes. Two central observations lead to the conclusion that the\nmajority of incomes are exponentially distributed, but neither each individual\npiece of evidence nor their concurrent observation robustly proves that the\nthermal and superthermal mixture fits the observed distribution of incomes\nbetter than reasonable alternatives. A formal analysis using popular measures\nof fit shows that while an exponential distribution with a power-law tail\nprovides a better fit of the IRS income data than the log-normal distribution\n(often assumed by economists), the thermal and superthermal mixture's fit can\nbe improved upon further by adding a log-normal component. The economic\nimplications of the thermal and superthermal distribution of incomes, and the\nexpanded mixture are explored in the paper.", "category": "econ.EM"}, {"title": "Estimating Treatment Effects in Mover Designs", "abstract": "Researchers increasingly leverage movement across multiple treatments to\nestimate causal effects. While these \"mover regressions\" are often motivated by\na linear constant-effects model, it is not clear what they capture under weaker\nquasi-experimental assumptions. I show that binary treatment mover regressions\nrecover a convex average of four difference-in-difference comparisons and are\nthus causally interpretable under a standard parallel trends assumption.\nEstimates from multiple-treatment models, however, need not be causal without\nstronger restrictions on the heterogeneity of treatment effects and\ntime-varying shocks. I propose a class of two-step estimators to isolate and\ncombine the large set of difference-in-difference quasi-experiments generated\nby a mover design, identifying mover average treatment effects under\nconditional-on-covariate parallel trends and effect homogeneity restrictions. I\ncharacterize the efficient estimators in this class and derive specification\ntests based on the model's overidentifying restrictions. Future drafts will\napply the theory to the Finkelstein et al. (2016) movers design, analyzing the\ncausal effects of geography on healthcare utilization.", "category": "econ.EM"}, {"title": "Transaction Costs in Collective Waste Recovery Systems in the EU", "abstract": "The study aims to identify the institutional flaws of the current EU waste\nmanagement model by analysing the economic model of extended producer\nresponsibility and collective waste management systems and to create a model\nfor measuring the transaction costs borne by waste recovery organizations. The\nmodel was approbated by analysing the Bulgarian collective waste management\nsystems that have been complying with the EU legislation for the last 10 years.\nThe analysis focuses on waste oils because of their economic importance and the\nlimited number of studies and analyses in this field as the predominant body of\nresearch to date has mainly addressed packaging waste, mixed household waste or\ndiscarded electrical and electronic equipment. The study aims to support the\nprocess of establishing a circular economy in the EU, which was initiated in\n2015.", "category": "econ.EM"}, {"title": "Empirical Equilibrium", "abstract": "We study the foundations of empirical equilibrium, a refinement of Nash\nequilibrium that is based on a non-parametric characterization of empirical\ndistributions of behavior in games (Velez and Brown,2020b arXiv:1907.12408).\nThe refinement can be alternatively defined as those Nash equilibria that do\nnot refute the regular QRE theory of Goeree, Holt, and Palfrey (2005). By\ncontrast, some empirical equilibria may refute monotone additive randomly\ndisturbed payoff models. As a by product, we show that empirical equilibrium\ndoes not coincide with refinements based on approximation by monotone additive\nrandomly disturbed payoff models, and further our understanding of the\nempirical content of these models.", "category": "econ.EM"}, {"title": "Price Competition with Geometric Brownian motion in Exchange Rate Uncertainty", "abstract": "We analyze an operational policy for a multinational manufacturer to hedge\nagainst exchange rate uncertainties and competition. We consider a single\nproduct and single period. Because of long-lead times, the capacity investment\nmust done before the selling season begins when the exchange rate between the\ntwo countries is uncertain. we consider a duopoly competition in the foreign\ncountry. We model the exchange rate as a random variable. We investigate the\nimpact of competition and exchange rate on optimal capacities and optimal\nprices. We show how competition can impact the decision of the home\nmanufacturer to enter the foreign market.", "category": "econ.EM"}, {"title": "Statistical and Economic Evaluation of Time Series Models for Forecasting Arrivals at Call Centers", "abstract": "Call centers' managers are interested in obtaining accurate point and\ndistributional forecasts of call arrivals in order to achieve an optimal\nbalance between service quality and operating costs. We present a strategy for\nselecting forecast models of call arrivals which is based on three pillars: (i)\nflexibility of the loss function; (ii) statistical evaluation of forecast\naccuracy; (iii) economic evaluation of forecast performance using money\nmetrics. We implement fourteen time series models and seven forecast\ncombination schemes on three series of daily call arrivals. Although we focus\nmainly on point forecasts, we also analyze density forecast evaluation. We show\nthat second moments modeling is important both for point and density\nforecasting and that the simple Seasonal Random Walk model is always\noutperformed by more general specifications. Our results suggest that call\ncenter managers should invest in the use of forecast models which describe both\nfirst and second moments of call arrivals.", "category": "econ.EM"}, {"title": "Economic inequality and Islamic Charity: An exploratory agent-based modeling approach", "abstract": "Economic inequality is one of the pivotal issues for most of economic and\nsocial policy makers across the world to insure the sustainable economic growth\nand justice. In the mainstream school of economics, namely neoclassical\ntheories, economic issues are dealt with in a mechanistic manner. Such a\nmainstream framework is majorly focused on investigating a socio-economic\nsystem based on an axiomatic scheme where reductionism approach plays a vital\nrole. The major limitations of such theories include unbounded rationality of\neconomic agents, reducing the economic aggregates to a set of predictable\nfactors and lack of attention to adaptability and the evolutionary nature of\neconomic agents. In tackling deficiencies of conventional economic models, in\nthe past two decades, some new approaches have been recruited. One of those\nnovel approaches is the Complex adaptive systems (CAS) framework which has\nshown a very promising performance in action. In contrast to mainstream school,\nunder this framework, the economic phenomena are studied in an organic manner\nwhere the economic agents are supposed to be both boundedly rational and\nadaptive. According to it, the economic aggregates emerge out of the ways\nagents of a system decide and interact. As a powerful way of modeling CASs,\nAgent-based models (ABMs) has found a growing application among academicians\nand practitioners. ABMs show that how simple behavioral rules of agents and\nlocal interactions among them at micro-scale can generate surprisingly complex\npatterns at macro-scale. In this paper, ABMs have been used to show (1) how an\neconomic inequality emerges in a system and to explain (2) how sadaqah as an\nIslamic charity rule can majorly help alleviating the inequality and how\nresource allocation strategies taken by charity entities can accelerate this\nalleviation.", "category": "econ.EM"}, {"title": "Aide et Croissance dans les pays de l'Union Economique et Mon{é}taire Ouest Africaine (UEMOA) : retour sur une relation controvers{é}e", "abstract": "The main purpose of this paper is to analyze threshold effects of official\ndevelopment assistance (ODA) on economic growth in WAEMU zone countries. To\nachieve this, the study is based on OECD and WDI data covering the period\n1980-2015 and used Hansen's Panel Threshold Regression (PTR) model to\n\"bootstrap\" aid threshold above which its effectiveness is effective. The\nevidence strongly supports the view that the relationship between aid and\neconomic growth is non-linear with a unique threshold which is 12.74% GDP.\nAbove this value, the marginal effect of aid is 0.69 points, \"all things being\nequal to otherwise\". One of the main contribution of this paper is to show that\nWAEMU countries need investments that could be covered by the foreign aid. This\nlater one should be considered just as a complementary resource. Thus, WEAMU\ncountries should continue to strengthen their efforts in internal resource\nmobilization in order to fulfil this need.", "category": "econ.EM"}, {"title": "Endogenous growth - A dynamic technology augmentation of the Solow model", "abstract": "In this paper, I endeavour to construct a new model, by extending the classic\nexogenous economic growth model by including a measurement which tries to\nexplain and quantify the size of technological innovation ( A ) endogenously. I\ndo not agree technology is a \"constant\" exogenous variable, because it is\nhumans who create all technological innovations, and it depends on how much\nhuman and physical capital is allocated for its research. I inspect several\npossible approaches to do this, and then I test my model both against sample\nand real world evidence data. I call this method \"dynamic\" because it tries to\nmodel the details in resource allocations between research, labor and capital,\nby affecting each other interactively. In the end, I point out which is the new\nresidual and the parts of the economic growth model which can be further\nimproved.", "category": "econ.EM"}, {"title": "Optimal Linear Instrumental Variables Approximations", "abstract": "This paper studies the identification and estimation of the optimal linear\napproximation of a structural regression function. The parameter in the linear\napproximation is called the Optimal Linear Instrumental Variables Approximation\n(OLIVA). This paper shows that a necessary condition for standard inference on\nthe OLIVA is also sufficient for the existence of an IV estimand in a linear\nmodel. The instrument in the IV estimand is unknown and may not be identified.\nA Two-Step IV (TSIV) estimator based on Tikhonov regularization is proposed,\nwhich can be implemented by standard regression routines. We establish the\nasymptotic normality of the TSIV estimator assuming neither completeness nor\nidentification of the instrument. As an important application of our analysis,\nwe robustify the classical Hausman test for exogeneity against misspecification\nof the linear structural model. We also discuss extensions to weighted least\nsquares criteria. Monte Carlo simulations suggest an excellent finite sample\nperformance for the proposed inferences. Finally, in an empirical application\nestimating the elasticity of intertemporal substitution (EIS) with US data, we\nobtain TSIV estimates that are much larger than their standard IV counterparts,\nwith our robust Hausman test failing to reject the null hypothesis of\nexogeneity of real interest rates.", "category": "econ.EM"}, {"title": "Sufficient Statistics for Unobserved Heterogeneity in Structural Dynamic Logit Models", "abstract": "We study the identification and estimation of structural parameters in\ndynamic panel data logit models where decisions are forward-looking and the\njoint distribution of unobserved heterogeneity and observable state variables\nis nonparametric, i.e., fixed-effects model. We consider models with two\nendogenous state variables: the lagged decision variable, and the time duration\nin the last choice. This class of models includes as particular cases important\neconomic applications such as models of market entry-exit, occupational choice,\nmachine replacement, inventory and investment decisions, or dynamic demand of\ndifferentiated products. The identification of structural parameters requires a\nsufficient statistic that controls for unobserved heterogeneity not only in\ncurrent utility but also in the continuation value of the forward-looking\ndecision problem. We obtain the minimal sufficient statistic and prove\nidentification of some structural parameters using a conditional likelihood\napproach. We apply this estimator to a machine replacement model.", "category": "econ.EM"}, {"title": "Density Forecasts in Panel Data Models: A Semiparametric Bayesian Perspective", "abstract": "This paper constructs individual-specific density forecasts for a panel of\nfirms or households using a dynamic linear model with common and heterogeneous\ncoefficients as well as cross-sectional heteroskedasticity. The panel\nconsidered in this paper features a large cross-sectional dimension N but short\ntime series T. Due to the short T, traditional methods have difficulty in\ndisentangling the heterogeneous parameters from the shocks, which contaminates\nthe estimates of the heterogeneous parameters. To tackle this problem, I assume\nthat there is an underlying distribution of heterogeneous parameters, model\nthis distribution nonparametrically allowing for correlation between\nheterogeneous parameters and initial conditions as well as individual-specific\nregressors, and then estimate this distribution by combining information from\nthe whole panel. Theoretically, I prove that in cross-sectional homoskedastic\ncases, both the estimated common parameters and the estimated distribution of\nthe heterogeneous parameters achieve posterior consistency, and that the\ndensity forecasts asymptotically converge to the oracle forecast.\nMethodologically, I develop a simulation-based posterior sampling algorithm\nspecifically addressing the nonparametric density estimation of unobserved\nheterogeneous parameters. Monte Carlo simulations and an empirical application\nto young firm dynamics demonstrate improvements in density forecasts relative\nto alternative approaches.", "category": "econ.EM"}, {"title": "Efficiency in Micro-Behaviors and FL Bias", "abstract": "In this paper, we propose a model which simulates odds distributions of\npari-mutuel betting system under two hypotheses on the behavior of bettors: 1.\nThe amount of bets increases very rapidly as the deadline for betting comes\nnear. 2. Each bettor bets on a horse which gives the largest expectation value\nof the benefit. The results can be interpreted as such efficient behaviors do\nnot serve to extinguish the FL bias but even produce stronger FL bias.", "category": "econ.EM"}, {"title": "The Finite Sample Performance of Treatment Effects Estimators based on the Lasso", "abstract": "This paper contributes to the literature on treatment effects estimation with\nmachine learning inspired methods by studying the performance of different\nestimators based on the Lasso. Building on recent work in the field of\nhigh-dimensional statistics, we use the semiparametric efficient score\nestimation structure to compare different estimators. Alternative weighting\nschemes are considered and their suitability for the incorporation of machine\nlearning estimators is assessed using theoretical arguments and various Monte\nCarlo experiments. Additionally we propose an own estimator based on doubly\nrobust Kernel matching that is argued to be more robust to nuisance parameter\nmisspecification. In the simulation study we verify theory based intuition and\nfind good finite sample properties of alternative weighting scheme estimators\nlike the one we propose.", "category": "econ.EM"}, {"title": "Data-Driven Investment Decision-Making: Applying Moore's Law and S-Curves to Business Strategies", "abstract": "This paper introduces a method for linking technological improvement rates\n(i.e. Moore's Law) and technology adoption curves (i.e. S-Curves). There has\nbeen considerable research surrounding Moore's Law and the generalized versions\napplied to the time dependence of performance for other technologies. The prior\nwork has culminated with methodology for quantitative estimation of\ntechnological improvement rates for nearly any technology. This paper examines\nthe implications of such regular time dependence for performance upon the\ntiming of key events in the technological adoption process. We propose a simple\ncrossover point in performance which is based upon the technological\nimprovement rates and current level differences for target and replacement\ntechnologies. The timing for the cross-over is hypothesized as corresponding to\nthe first 'knee'? in the technology adoption \"S-curve\" and signals when the\nmarket for a given technology will start to be rewarding for innovators. This\nis also when potential entrants are likely to intensely experiment with\nproduct-market fit and when the competition to achieve a dominant design\nbegins. This conceptual framework is then back-tested by examining two\ntechnological changes brought about by the internet, namely music and video\ntransmission. The uncertainty analysis around the cases highlight opportunities\nfor organizations to reduce future technological uncertainty. Overall, the\nresults from the case studies support the reliability and utility of the\nconceptual framework in strategic business decision-making with the caveat that\nwhile technical uncertainty is reduced, it is not eliminated.", "category": "econ.EM"}, {"title": "Happy family of stable marriages", "abstract": "Some aspects of the problem of stable marriage are discussed. There are two\ndistinguished marriage plans: the fully transferable case, where money can be\ntransferred between the participants, and the fully non transferable case where\neach participant has its own rigid preference list regarding the other gender.\nWe continue to discuss intermediate partial transferable cases. Partial\ntransferable plans can be approached as either special cases of cooperative\ngames using the notion of a core, or as a generalization of the cyclical\nmonotonicity property of the fully transferable case (fake promises). We shall\nintroduced these two approaches, and prove the existence of stable marriage for\nthe fully transferable and non-transferable plans.", "category": "econ.EM"}, {"title": "Bitcoin price and its marginal cost of production: support for a fundamental value", "abstract": "This study back-tests a marginal cost of production model proposed to value\nthe digital currency bitcoin. Results from both conventional regression and\nvector autoregression (VAR) models show that the marginal cost of production\nplays an important role in explaining bitcoin prices, challenging recent\nallegations that bitcoins are essentially worthless. Even with markets pricing\nbitcoin in the thousands of dollars each, the valuation model seems robust. The\ndata show that a price bubble that began in the Fall of 2017 resolved itself in\nearly 2018, converging with the marginal cost model. This suggests that while\nbubbles may appear in the bitcoin market, prices will tend to this bound and\nnot collapse to zero.", "category": "econ.EM"}, {"title": "Model Selection in Time Series Analysis: Using Information Criteria as an Alternative to Hypothesis Testing", "abstract": "The issue of model selection in applied research is of vital importance.\nSince the true model in such research is not known, which model should be used\nfrom among various potential ones is an empirical question. There might exist\nseveral competitive models. A typical approach to dealing with this is classic\nhypothesis testing using an arbitrarily chosen significance level based on the\nunderlying assumption that a true null hypothesis exists. In this paper we\ninvestigate how successful this approach is in determining the correct model\nfor different data generating processes using time series data. An alternative\napproach based on more formal model selection techniques using an information\ncriterion or cross-validation is suggested and evaluated in the time series\nenvironment via Monte Carlo experiments. This paper also explores the\neffectiveness of deciding what type of general relation exists between two\nvariables (e.g. relation in levels or relation in first differences) using\nvarious strategies based on hypothesis testing and on information criteria with\nthe presence or absence of unit roots.", "category": "econ.EM"}, {"title": "A Double Machine Learning Approach to Estimate the Effects of Musical Practice on Student's Skills", "abstract": "This study investigates the dose-response effects of making music on youth\ndevelopment. Identification is based on the conditional independence assumption\nand estimation is implemented using a recent double machine learning estimator.\nThe study proposes solutions to two highly practically relevant questions that\narise for these new methods: (i) How to investigate sensitivity of estimates to\ntuning parameter choices in the machine learning part? (ii) How to assess\ncovariate balancing in high-dimensional settings? The results show that\nimprovements in objectively measured cognitive skills require at least medium\nintensity, while improvements in school grades are already observed for low\nintensity of practice.", "category": "econ.EM"}, {"title": "Flexible shrinkage in high-dimensional Bayesian spatial autoregressive models", "abstract": "This article introduces two absolutely continuous global-local shrinkage\npriors to enable stochastic variable selection in the context of\nhigh-dimensional matrix exponential spatial specifications. Existing approaches\nas a means to dealing with overparameterization problems in spatial\nautoregressive specifications typically rely on computationally demanding\nBayesian model-averaging techniques. The proposed shrinkage priors can be\nimplemented using Markov chain Monte Carlo methods in a flexible and efficient\nway. A simulation study is conducted to evaluate the performance of each of the\nshrinkage priors. Results suggest that they perform particularly well in\nhigh-dimensional environments, especially when the number of parameters to\nestimate exceeds the number of observations. For an empirical illustration we\nuse pan-European regional economic growth data.", "category": "econ.EM"}, {"title": "Tilting Approximate Models", "abstract": "Model approximations are common practice when estimating structural or\nquasi-structural models. The paper considers the econometric properties of\nestimators that utilize projections to reimpose information about the exact\nmodel in the form of conditional moments. The resulting estimator efficiently\ncombines the information provided by the approximate law of motion and the\nmoment conditions. The paper develops the corresponding asymptotic theory and\nprovides simulation evidence that tilting substantially reduces the mean\nsquared error for parameter estimates. It applies the methodology to pricing\nlong-run risks in aggregate consumption in the US, whereas the model is solved\nusing the Campbell and Shiller (1988) approximation. Tilting improves empirical\nfit and results suggest that approximation error is a source of upward bias in\nestimates of risk aversion and downward bias in the elasticity of intertemporal\nsubstitution.", "category": "econ.EM"}, {"title": "Modeling the residential electricity consumption within a restructured power market", "abstract": "The United States' power market is featured by the lack of judicial power at\nthe federal level. The market thus provides a unique testing environment for\nthe market organization structure. At the same time, the econometric modeling\nand forecasting of electricity market consumption become more challenging.\nImport and export, which generally follow simple rules in European countries,\ncan be a result of direct market behaviors. This paper seeks to build a general\nmodel for power consumption and using the model to test several hypotheses.", "category": "econ.EM"}, {"title": "Estimation and Inference for Policy Relevant Treatment Effects", "abstract": "The policy relevant treatment effect (PRTE) measures the average effect of\nswitching from a status-quo policy to a counterfactual policy. Estimation of\nthe PRTE involves estimation of multiple preliminary parameters, including\npropensity scores, conditional expectation functions of the outcome and\ncovariates given the propensity score, and marginal treatment effects. These\npreliminary estimators can affect the asymptotic distribution of the PRTE\nestimator in complicated and intractable manners. In this light, we propose an\northogonal score for double debiased estimation of the PRTE, whereby the\nasymptotic distribution of the PRTE estimator is obtained without any influence\nof preliminary parameter estimators as far as they satisfy mild requirements of\nconvergence rates. To our knowledge, this paper is the first to develop limit\ndistribution theories for inference about the PRTE.", "category": "econ.EM"}, {"title": "Ill-posed Estimation in High-Dimensional Models with Instrumental Variables", "abstract": "This paper is concerned with inference about low-dimensional components of a\nhigh-dimensional parameter vector $\\beta^0$ which is identified through\ninstrumental variables. We allow for eigenvalues of the expected outer product\nof included and excluded covariates, denoted by $M$, to shrink to zero as the\nsample size increases. We propose a novel estimator based on desparsification\nof an instrumental variable Lasso estimator, which is a regularized version of\n2SLS with an additional correction term. This estimator converges to $\\beta^0$\nat a rate depending on the mapping properties of $M$ captured by a sparse link\ncondition. Linear combinations of our estimator of $\\beta^0$ are shown to be\nasymptotically normally distributed. Based on consistent covariance estimation,\nour method allows for constructing confidence intervals and statistical tests\nfor single or low-dimensional components of $\\beta^0$. In Monte-Carlo\nsimulations we analyze the finite sample behavior of our estimator.", "category": "econ.EM"}, {"title": "Asymptotic Refinements of a Misspecification-Robust Bootstrap for Generalized Empirical Likelihood Estimators", "abstract": "I propose a nonparametric iid bootstrap procedure for the empirical\nlikelihood, the exponential tilting, and the exponentially tilted empirical\nlikelihood estimators that achieves asymptotic refinements for t tests and\nconfidence intervals, and Wald tests and confidence regions based on such\nestimators. Furthermore, the proposed bootstrap is robust to model\nmisspecification, i.e., it achieves asymptotic refinements regardless of\nwhether the assumed moment condition model is correctly specified or not. This\nresult is new, because asymptotic refinements of the bootstrap based on these\nestimators have not been established in the literature even under correct model\nspecification. Monte Carlo experiments are conducted in dynamic panel data\nsetting to support the theoretical finding. As an application, bootstrap\nconfidence intervals for the returns to schooling of Hellerstein and Imbens\n(1999) are calculated. The result suggests that the returns to schooling may be\nhigher.", "category": "econ.EM"}, {"title": "Quasi-Experimental Shift-Share Research Designs", "abstract": "Many studies use shift-share (or ``Bartik'') instruments, which average a set\nof shocks with exposure share weights. We provide a new econometric framework\nfor shift-share instrumental variable (SSIV) regressions in which\nidentification follows from the quasi-random assignment of shocks, while\nexposure shares are allowed to be endogenous. The framework is motivated by an\nequivalence result: the orthogonality between a shift-share instrument and an\nunobserved residual can be represented as the orthogonality between the\nunderlying shocks and a shock-level unobservable. SSIV regression coefficients\ncan similarly be obtained from an equivalent shock-level regression, motivating\nshock-level conditions for their consistency. We discuss and illustrate several\npractical insights of this framework in the setting of Autor et al. (2013),\nestimating the effect of Chinese import competition on manufacturing employment\nacross U.S. commuting zones.", "category": "econ.EM"}, {"title": "The Impact of Supervision and Incentive Process in Explaining Wage Profile and Variance", "abstract": "The implementation of a supervision and incentive process for identical\nworkers may lead to wage variance that stems from employer and employee\noptimization. The harder it is to assess the nature of the labor output, the\nmore important such a process becomes, and the influence of such a process on\nwage development growth. The dynamic model presented in this paper shows that\nan employer will choose to pay a worker a starting wage that is less than what\nhe deserves, resulting in a wage profile that fits the classic profile in the\nhuman-capital literature. The wage profile and wage variance rise at times of\ntechnological advancements, which leads to increased turnover as older workers\nare replaced by younger workers due to a rise in the relative marginal cost of\nthe former.", "category": "econ.EM"}, {"title": "Asymptotic Refinements of a Misspecification-Robust Bootstrap for Generalized Method of Moments Estimators", "abstract": "I propose a nonparametric iid bootstrap that achieves asymptotic refinements\nfor t tests and confidence intervals based on GMM estimators even when the\nmodel is misspecified. In addition, my bootstrap does not require recentering\nthe moment function, which has been considered as critical for GMM. Regardless\nof model misspecification, the proposed bootstrap achieves the same sharp\nmagnitude of refinements as the conventional bootstrap methods which establish\nasymptotic refinements by recentering in the absence of misspecification. The\nkey idea is to link the misspecified bootstrap moment condition to the large\nsample theory of GMM under misspecification of Hall and Inoue (2003). Two\nexamples are provided: Combining data sets and invalid instrumental variables.", "category": "econ.EM"}, {"title": "A Consistent Variance Estimator for 2SLS When Instruments Identify Different LATEs", "abstract": "Under treatment effect heterogeneity, an instrument identifies the\ninstrument-specific local average treatment effect (LATE). With multiple\ninstruments, two-stage least squares (2SLS) estimand is a weighted average of\ndifferent LATEs. What is often overlooked in the literature is that the\npostulated moment condition evaluated at the 2SLS estimand does not hold unless\nthose LATEs are the same. If so, the conventional heteroskedasticity-robust\nvariance estimator would be inconsistent, and 2SLS standard errors based on\nsuch estimators would be incorrect. I derive the correct asymptotic\ndistribution, and propose a consistent asymptotic variance estimator by using\nthe result of Hall and Inoue (2003, Journal of Econometrics) on misspecified\nmoment condition models. This can be used to correctly calculate the standard\nerrors regardless of whether there is more than one LATE or not.", "category": "econ.EM"}, {"title": "Leave-out estimation of variance components", "abstract": "We propose leave-out estimators of quadratic forms designed for the study of\nlinear models with unrestricted heteroscedasticity. Applications include\nanalysis of variance and tests of linear restrictions in models with many\nregressors. An approximation algorithm is provided that enables accurate\ncomputation of the estimator in very large datasets. We study the large sample\nproperties of our estimator allowing the number of regressors to grow in\nproportion to the number of observations. Consistency is established in a\nvariety of settings where plug-in methods and estimators predicated on\nhomoscedasticity exhibit first-order biases. For quadratic forms of increasing\nrank, the limiting distribution can be represented by a linear combination of\nnormal and non-central $\\chi^2$ random variables, with normality ensuing under\nstrong identification. Standard error estimators are proposed that enable tests\nof linear restrictions and the construction of uniformly valid confidence\nintervals for quadratic forms of interest. We find in Italian social security\nrecords that leave-out estimates of a variance decomposition in a two-way fixed\neffects model of wage determination yield substantially different conclusions\nregarding the relative contribution of workers, firms, and worker-firm sorting\nto wage inequality than conventional methods. Monte Carlo exercises corroborate\nthe accuracy of our asymptotic approximations, with clear evidence of\nnon-normality emerging when worker mobility between blocks of firms is limited.", "category": "econ.EM"}, {"title": "A Quantitative Analysis of Possible Futures of Autonomous Transport", "abstract": "Autonomous ships (AS) used for cargo transport have gained a considerable\namount of attention in recent years. They promise benefits such as reduced crew\ncosts, increased safety and increased flexibility. This paper explores the\neffects of a faster increase in technological performance in maritime shipping\nachieved by leveraging fast-improving technological domains such as computer\nprocessors, and advanced energy storage. Based on historical improvement rates\nof several modes of transport (Cargo Ships, Air, Rail, Trucking) a simplified\nMarkov-chain Monte-Carlo (MCMC) simulation of an intermodal transport model\n(IMTM) is used to explore the effects of differing technological improvement\nrates for AS. The results show that the annual improvement rates of traditional\nshipping (Ocean Cargo Ships = 2.6%, Air Cargo = 5.5%, Trucking = 0.6%, Rail =\n1.9%, Inland Water Transport = 0.4%) improve at lower rates than technologies\nassociated with automation such as Computer Processors (35.6%), Fuel Cells\n(14.7%) and Automotive Autonomous Hardware (27.9%). The IMTM simulations up to\nthe year 2050 show that the introduction of any mode of autonomous transport\nwill increase competition in lower cost shipping options, but is unlikely to\nsignificantly alter the overall distribution of transport mode costs. Secondly,\nif all forms of transport end up converting to autonomous systems, then the\nuncertainty surrounding the improvement rates yields a complex intermodal\ntransport solution involving several options, all at a much lower cost over\ntime. Ultimately, the research shows a need for more accurate measurement of\ncurrent autonomous transport costs and how they are changing over time.", "category": "econ.EM"}, {"title": "A Growth Model with Unemployment", "abstract": "A standard growth model is modified in a straightforward way to incorporate\nwhat Keynes (1936) suggests in the \"essence\" of his general theory. The\ntheoretical essence is the idea that exogenous changes in investment cause\nchanges in employment and unemployment. We implement this idea by assuming the\npath for capital growth rate is exogenous in the growth model. The result is a\ngrowth model that can explain both long term trends and fluctuations around the\ntrend. The modified growth model was tested using the U.S. economic data from\n1947 to 2014. The hypothesized inverse relationship between the capital growth\nand changes in unemployment was confirmed, and the structurally estimated model\nfits fluctuations in unemployment reasonably well.", "category": "econ.EM"}, {"title": "The Role of Agricultural Sector Productivity in Economic Growth: The Case of Iran's Economic Development Plan", "abstract": "This study provides the theoretical framework and empirical model for\nproductivity growth evaluations in agricultural sector as one of the most\nimportant sectors in Iran's economic development plan. We use the Solow\nresidual model to measure the productivity growth share in the value-added\ngrowth of the agricultural sector. Our time series data includes value-added\nper worker, employment, and capital in this sector. The results show that the\naverage total factor productivity growth rate in the agricultural sector is\n-0.72% during 1991-2010. Also, during this period, the share of total factor\nproductivity growth in the value-added growth is -19.6%, while it has been\nforecasted to be 33.8% in the fourth development plan. Considering the\neffective role of capital in the agricultural low productivity, we suggest\napplying productivity management plans (especially in regards of capital\nproductivity) to achieve future growth goals.", "category": "econ.EM"}, {"title": "Estimating Trade-Related Adjustment Costs in the Agricultural Sector in Iran", "abstract": "Tariff liberalization and its impact on tax revenue is an important\nconsideration for developing countries, because they are increasingly facing\nthe difficult task of implementing and harmonizing regional and international\ntrade commitments. The tariff reform and its costs for Iranian government is\none of the issues that are examined in this study. Another goal of this paper\nis, estimating the cost of trade liberalization. On this regard, imports value\nof agricultural sector in Iran in 2010 was analyzed according to two scenarios.\nFor reforming nuisance tariff, a VAT policy is used in both scenarios. In this\nstudy, TRIST method is used. In the first scenario, imports' value decreased to\na level equal to the second scenario and higher tariff revenue will be created.\nThe results show that reducing the average tariff rate does not always result\nin the loss of tariff revenue. This paper is a witness that different forms of\ntariff can generate different amount of income when they have same level of\nliberalization and equal effect on producers. Therefore, using a good tariff\nregime can help a government to generate income when increases social welfare\nby liberalization.", "category": "econ.EM"}, {"title": "On the relation between Sion's minimax theorem and existence of Nash equilibrium in asymmetric multi-players zero-sum game with only one alien", "abstract": "We consider the relation between Sion's minimax theorem for a continuous\nfunction and a Nash equilibrium in an asymmetric multi-players zero-sum game in\nwhich only one player is different from other players, and the game is\nsymmetric for the other players. Then,\n  1. The existence of a Nash equilibrium, which is symmetric for players other\nthan one player, implies Sion's minimax theorem for pairs of this player and\none of other players with symmetry for the other players.\n  2. Sion's minimax theorem for pairs of one player and one of other players\nwith symmetry for the other players implies the existence of a Nash equilibrium\nwhich is symmetric for the other players.\n  Thus, they are equivalent.", "category": "econ.EM"}, {"title": "Cluster-Robust Standard Errors for Linear Regression Models with Many Controls", "abstract": "It is common practice in empirical work to employ cluster-robust standard\nerrors when using the linear regression model to estimate some\nstructural/causal effect of interest. Researchers also often include a large\nset of regressors in their model specification in order to control for observed\nand unobserved confounders. In this paper we develop inference methods for\nlinear regression models with many controls and clustering. We show that\ninference based on the usual cluster-robust standard errors by Liang and Zeger\n(1986) is invalid in general when the number of controls is a non-vanishing\nfraction of the sample size. We then propose a new clustered standard errors\nformula that is robust to the inclusion of many controls and allows to carry\nout valid inference in a variety of high-dimensional linear regression models,\nincluding fixed effects panel data models and the semiparametric partially\nlinear model. Monte Carlo evidence supports our theoretical results and shows\nthat our proposed variance estimator performs well in finite samples. The\nproposed method is also illustrated with an empirical application that\nre-visits Donohue III and Levitt's (2001) study of the impact of abortion on\ncrime.", "category": "econ.EM"}, {"title": "Shift-Share Designs: Theory and Inference", "abstract": "We study inference in shift-share regression designs, such as when a regional\noutcome is regressed on a weighted average of sectoral shocks, using regional\nsector shares as weights. We conduct a placebo exercise in which we estimate\nthe effect of a shift-share regressor constructed with randomly generated\nsectoral shocks on actual labor market outcomes across U.S. Commuting Zones.\nTests based on commonly used standard errors with 5\\% nominal significance\nlevel reject the null of no effect in up to 55\\% of the placebo samples. We use\na stylized economic model to show that this overrejection problem arises\nbecause regression residuals are correlated across regions with similar\nsectoral shares, independently of their geographic location. We derive novel\ninference methods that are valid under arbitrary cross-regional correlation in\nthe regression residuals. We show using popular applications of shift-share\ndesigns that our methods may lead to substantially wider confidence intervals\nin practice.", "category": "econ.EM"}, {"title": "The transmission of uncertainty shocks on income inequality: State-level evidence from the United States", "abstract": "In this paper, we explore the relationship between state-level household\nincome inequality and macroeconomic uncertainty in the United States. Using a\nnovel large-scale macroeconometric model, we shed light on regional disparities\nof inequality responses to a national uncertainty shock. The results suggest\nthat income inequality decreases in most states, with a pronounced degree of\nheterogeneity in terms of shapes and magnitudes of the dynamic responses. By\ncontrast, some few states, mostly located in the West and South census region,\ndisplay increasing levels of income inequality over time. We find that this\ndirectional pattern in responses is mainly driven by the income composition and\nlabor market fundamentals. In addition, forecast error variance decompositions\nallow for a quantitative assessment of the importance of uncertainty shocks in\nexplaining income inequality. The findings highlight that volatility shocks\naccount for a considerable fraction of forecast error variance for most states\nconsidered. Finally, a regression-based analysis sheds light on the driving\nforces behind differences in state-specific inequality responses.", "category": "econ.EM"}, {"title": "Semiparametrically Point-Optimal Hybrid Rank Tests for Unit Roots", "abstract": "We propose a new class of unit root tests that exploits invariance properties\nin the Locally Asymptotically Brownian Functional limit experiment associated\nto the unit root model. The invariance structures naturally suggest tests that\nare based on the ranks of the increments of the observations, their average,\nand an assumed reference density for the innovations. The tests are\nsemiparametric in the sense that they are valid, i.e., have the correct\n(asymptotic) size, irrespective of the true innovation density. For a correctly\nspecified reference density, our test is point-optimal and nearly efficient.\nFor arbitrary reference densities, we establish a Chernoff-Savage type result,\ni.e., our test performs as well as commonly used tests under Gaussian\ninnovations but has improved power under other, e.g., fat-tailed or skewed,\ninnovation distributions. To avoid nonparametric estimation, we propose a\nsimplified version of our test that exhibits the same asymptotic properties,\nexcept for the Chernoff-Savage result that we are only able to demonstrate by\nmeans of simulations.", "category": "econ.EM"}, {"title": "Point-identification in multivariate nonseparable triangular models", "abstract": "In this article we introduce a general nonparametric point-identification\nresult for nonseparable triangular models with a multivariate first- and second\nstage. Based on this we prove point-identification of Hedonic models with\nmultivariate heterogeneity and endogenous observable characteristics, extending\nand complementing identification results from the literature which all require\nexogeneity. As an additional application of our theoretical result, we show\nthat the BLP model (Berry et al. 1995) can also be identified without index\nrestrictions.", "category": "econ.EM"}, {"title": "Partial Mean Processes with Generated Regressors: Continuous Treatment Effects and Nonseparable Models", "abstract": "Partial mean with generated regressors arises in several econometric\nproblems, such as the distribution of potential outcomes with continuous\ntreatments and the quantile structural function in a nonseparable triangular\nmodel. This paper proposes a nonparametric estimator for the partial mean\nprocess, where the second step consists of a kernel regression on regressors\nthat are estimated in the first step. The main contribution is a uniform\nexpansion that characterizes in detail how the estimation error associated with\nthe generated regressor affects the limiting distribution of the marginal\nintegration estimator. The general results are illustrated with two examples:\nthe generalized propensity score for a continuous treatment (Hirano and Imbens,\n2004) and control variables in triangular models (Newey, Powell, and Vella,\n1999; Imbens and Newey, 2009). An empirical application to the Job Corps\nprogram evaluation demonstrates the usefulness of the method.", "category": "econ.EM"}, {"title": "Treatment Effect Estimation with Noisy Conditioning Variables", "abstract": "I develop a new identification strategy for treatment effects when noisy\nmeasurements of unobserved confounding factors are available. I use proxy\nvariables to construct a random variable conditional on which treatment\nvariables become exogenous. The key idea is that, under appropriate conditions,\nthere exists a one-to-one mapping between the distribution of unobserved\nconfounding factors and the distribution of proxies. To ensure sufficient\nvariation in the constructed control variable, I use an additional variable,\ntermed excluded variable, which satisfies certain exclusion restrictions and\nrelevance conditions. I establish asymptotic distributional results for\nsemiparametric and flexible parametric estimators of causal parameters. I\nillustrate empirical relevance and usefulness of my results by estimating\ncausal effects of attending selective college on earnings.", "category": "econ.EM"}, {"title": "Randomization Tests for Equality in Dependence Structure", "abstract": "We develop a new statistical procedure to test whether the dependence\nstructure is identical between two groups. Rather than relying on a single\nindex such as Pearson's correlation coefficient or Kendall's Tau, we consider\nthe entire dependence structure by investigating the dependence functions\n(copulas). The critical values are obtained by a modified randomization\nprocedure designed to exploit asymptotic group invariance conditions.\nImplementation of the test is intuitive and simple, and does not require any\nspecification of a tuning parameter or weight function. At the same time, the\ntest exhibits excellent finite sample performance, with the null rejection\nrates almost equal to the nominal level even when the sample size is extremely\nsmall. Two empirical applications concerning the dependence between income and\nconsumption, and the Brexit effect on European financial market integration are\nprovided.", "category": "econ.EM"}, {"title": "Nonparametric Analysis of Finite Mixtures", "abstract": "Finite mixture models are useful in applied econometrics. They can be used to\nmodel unobserved heterogeneity, which plays major roles in labor economics,\nindustrial organization and other fields. Mixtures are also convenient in\ndealing with contaminated sampling models and models with multiple equilibria.\nThis paper shows that finite mixture models are nonparametrically identified\nunder weak assumptions that are plausible in economic applications. The key is\nto utilize the identification power implied by information in covariates\nvariation. First, three identification approaches are presented, under distinct\nand non-nested sets of sufficient conditions. Observable features of data\ninform us which of the three approaches is valid. These results apply to\ngeneral nonparametric switching regressions, as well as to structural\neconometric models, such as auction models with unobserved heterogeneity.\nSecond, some extensions of the identification results are developed. In\nparticular, a mixture regression where the mixing weights depend on the value\nof the regressors in a fully unrestricted manner is shown to be\nnonparametrically identifiable. This means a finite mixture model with\nfunction-valued unobserved heterogeneity can be identified in a cross-section\nsetting, without restricting the dependence pattern between the regressor and\nthe unobserved heterogeneity. In this aspect it is akin to fixed effects panel\ndata models which permit unrestricted correlation between unobserved\nheterogeneity and covariates. Third, the paper shows that fully nonparametric\nestimation of the entire mixture model is possible, by forming a sample\nanalogue of one of the new identification strategies. The estimator is shown to\npossess a desirable polynomial rate of convergence as in a standard\nnonparametric estimation problem, despite nonregular features of the model.", "category": "econ.EM"}, {"title": "Nonparametric maximum likelihood methods for binary response models with random coefficients", "abstract": "Single index linear models for binary response with random coefficients have\nbeen extensively employed in many econometric settings under various parametric\nspecifications of the distribution of the random coefficients. Nonparametric\nmaximum likelihood estimation (NPMLE) as proposed by Cosslett (1983) and\nIchimura and Thompson (1998), in contrast, has received less attention in\napplied work due primarily to computational difficulties. We propose a new\napproach to computation of NPMLEs for binary response models that significantly\nincrease their computational tractability thereby facilitating greater\nflexibility in applications. Our approach, which relies on recent developments\ninvolving the geometry of hyperplane arrangements, is contrasted with the\nrecently proposed deconvolution method of Gautier and Kitamura (2013). An\napplication to modal choice for the journey to work in the Washington DC area\nillustrates the methods.", "category": "econ.EM"}, {"title": "Estimation of a Structural Break Point in Linear Regression Models", "abstract": "This study proposes a point estimator of the break location for a one-time\nstructural break in linear regression models. If the break magnitude is small,\nthe least-squares estimator of the break date has two modes at the ends of the\nfinite sample period, regardless of the true break location. To solve this\nproblem, I suggest an alternative estimator based on a modification of the\nleast-squares objective function. The modified objective function incorporates\nestimation uncertainty that varies across potential break dates. The new break\npoint estimator is consistent and has a unimodal finite sample distribution\nunder small break magnitudes. A limit distribution is provided under an in-fill\nasymptotic framework. Monte Carlo simulation results suggest that the new\nestimator outperforms the least-squares estimator. I apply the method to\nestimate the break date in U.S. real GDP growth and U.S. and UK stock return\nprediction models.", "category": "econ.EM"}, {"title": "Bootstrapping Structural Change Tests", "abstract": "This paper analyses the use of bootstrap methods to test for parameter change\nin linear models estimated via Two Stage Least Squares (2SLS). Two types of\ntest are considered: one where the null hypothesis is of no change and the\nalternative hypothesis involves discrete change at k unknown break-points in\nthe sample; and a second test where the null hypothesis is that there is\ndiscrete parameter change at l break-points in the sample against an\nalternative in which the parameters change at l + 1 break-points. In both\ncases, we consider inferences based on a sup-Wald-type statistic using either\nthe wild recursive bootstrap or the wild fixed bootstrap. We establish the\nasymptotic validity of these bootstrap tests under a set of general conditions\nthat allow the errors to exhibit conditional and/or unconditional\nheteroskedasticity, and report results from a simulation study that indicate\nthe tests yield reliable inferences in the sample sizes often encountered in\nmacroeconomics. The analysis covers the cases where the first-stage estimation\nof 2SLS involves a model whose parameters are either constant or themselves\nsubject to discrete parameter change. If the errors exhibit unconditional\nheteroskedasticity and/or the reduced form is unstable then the bootstrap\nmethods are particularly attractive because the limiting distributions of the\ntest statistics are not pivotal.", "category": "econ.EM"}, {"title": "Identification and estimation of multinomial choice models with latent special covariates", "abstract": "Identification of multinomial choice models is often established by using\nspecial covariates that have full support. This paper shows how these\nidentification results can be extended to a large class of multinomial choice\nmodels when all covariates are bounded. I also provide a new\n$\\sqrt{n}$-consistent asymptotically normal estimator of the finite-dimensional\nparameters of the model.", "category": "econ.EM"}, {"title": "Estimation of High-Dimensional Seemingly Unrelated Regression Models", "abstract": "In this paper, we investigate seemingly unrelated regression (SUR) models\nthat allow the number of equations (N) to be large, and to be comparable to the\nnumber of the observations in each equation (T). It is well known in the\nliterature that the conventional SUR estimator, for example, the generalized\nleast squares (GLS) estimator of Zellner (1962) does not perform well. As the\nmain contribution of the paper, we propose a new feasible GLS estimator called\nthe feasible graphical lasso (FGLasso) estimator. For a feasible implementation\nof the GLS estimator, we use the graphical lasso estimation of the precision\nmatrix (the inverse of the covariance matrix of the equation system errors)\nassuming that the underlying unknown precision matrix is sparse. We derive\nasymptotic theories of the new estimator and investigate its finite sample\nproperties via Monte-Carlo simulations.", "category": "econ.EM"}, {"title": "Bayesian Inference for Structural Vector Autoregressions Identified by Markov-Switching Heteroskedasticity", "abstract": "In this study, Bayesian inference is developed for structural vector\nautoregressive models in which the structural parameters are identified via\nMarkov-switching heteroskedasticity. In such a model, restrictions that are\njust-identifying in the homoskedastic case, become over-identifying and can be\ntested. A set of parametric restrictions is derived under which the structural\nmatrix is globally or partially identified and a Savage-Dickey density ratio is\nused to assess the validity of the identification conditions. The latter is\nfacilitated by analytical derivations that make the computations fast and\nnumerical standard errors small. As an empirical example, monetary models are\ncompared using heteroskedasticity as an additional device for identification.\nThe empirical results support models with money in the interest rate reaction\nfunction.", "category": "econ.EM"}, {"title": "Model instability in predictive exchange rate regressions", "abstract": "In this paper we aim to improve existing empirical exchange rate models by\naccounting for uncertainty with respect to the underlying structural\nrepresentation. Within a flexible Bayesian non-linear time series framework,\nour modeling approach assumes that different regimes are characterized by\ncommonly used structural exchange rate models, with their evolution being\ndriven by a Markov process. We assume a time-varying transition probability\nmatrix with transition probabilities depending on a measure of the monetary\npolicy stance of the central bank at the home and foreign country. We apply\nthis model to a set of eight exchange rates against the US dollar. In a\nforecasting exercise, we show that model evidence varies over time and a model\napproach that takes this empirical evidence seriously yields improvements in\naccuracy of density forecasts for most currency pairs considered.", "category": "econ.EM"}, {"title": "Generalized Dynamic Factor Models and Volatilities: Consistency, rates, and prediction intervals", "abstract": "Volatilities, in high-dimensional panels of economic time series with a\ndynamic factor structure on the levels or returns, typically also admit a\ndynamic factor decomposition. We consider a two-stage dynamic factor model\nmethod recovering the common and idiosyncratic components of both levels and\nlog-volatilities. Specifically, in a first estimation step, we extract the\ncommon and idiosyncratic shocks for the levels, from which a log-volatility\nproxy is computed. In a second step, we estimate a dynamic factor model, which\nis equivalent to a multiplicative factor structure for volatilities, for the\nlog-volatility panel. By exploiting this two-stage factor approach, we build\none-step-ahead conditional prediction intervals for large $n \\times T$ panels\nof returns. Those intervals are based on empirical quantiles, not on\nconditional variances; they can be either equal- or unequal- tailed. We provide\nuniform consistency and consistency rates results for the proposed estimators\nas both $n$ and $T$ tend to infinity. We study the finite-sample properties of\nour estimators by means of Monte Carlo simulations. Finally, we apply our\nmethodology to a panel of asset returns belonging to the S&P100 index in order\nto compute one-step-ahead conditional prediction intervals for the period\n2006-2013. A comparison with the componentwise GARCH benchmark (which does not\ntake advantage of cross-sectional information) demonstrates the superiority of\nour approach, which is genuinely multivariate (and high-dimensional),\nnonparametric, and model-free.", "category": "econ.EM"}, {"title": "LM-BIC Model Selection in Semiparametric Models", "abstract": "This paper studies model selection in semiparametric econometric models. It\ndevelops a consistent series-based model selection procedure based on a\nBayesian Information Criterion (BIC) type criterion to select between several\nclasses of models. The procedure selects a model by minimizing the\nsemiparametric Lagrange Multiplier (LM) type test statistic from Korolev (2018)\nbut additionally rewards simpler models. The paper also develops consistent\nupward testing (UT) and downward testing (DT) procedures based on the\nsemiparametric LM type specification test. The proposed semiparametric LM-BIC\nand UT procedures demonstrate good performance in simulations. To illustrate\nthe use of these semiparametric model selection procedures, I apply them to the\nparametric and semiparametric gasoline demand specifications from Yatchew and\nNo (2001). The LM-BIC procedure selects the semiparametric specification that\nis nonparametric in age but parametric in all other variables, which is in line\nwith the conclusions in Yatchew and No (2001). The results of the UT and DT\nprocedures heavily depend on the choice of tuning parameters and assumptions\nabout the model errors.", "category": "econ.EM"}, {"title": "A Residual Bootstrap for Conditional Expected Shortfall", "abstract": "This paper studies a fixed-design residual bootstrap method for the two-step\nestimator of Francq and Zako\\\"ian (2015) associated with the conditional\nExpected Shortfall. For a general class of volatility models the bootstrap is\nshown to be asymptotically valid under the conditions imposed by Beutner et al.\n(2018). A simulation study is conducted revealing that the average coverage\nrates are satisfactory for most settings considered. There is no clear evidence\nto have a preference for any of the three proposed bootstrap intervals. This\ncontrasts results in Beutner et al. (2018) for the VaR, for which the\nreversed-tails interval has a superior performance.", "category": "econ.EM"}, {"title": "Column Generation Algorithms for Nonparametric Analysis of Random Utility Models", "abstract": "Kitamura and Stoye (2014) develop a nonparametric test for linear inequality\nconstraints, when these are are represented as vertices of a polyhedron instead\nof its faces. They implement this test for an application to nonparametric\ntests of Random Utility Models. As they note in their paper, testing such\nmodels is computationally challenging. In this paper, we develop and implement\nmore efficient algorithms, based on column generation, to carry out the test.\nThese improved algorithms allow us to tackle larger datasets.", "category": "econ.EM"}, {"title": "Doubly Robust Difference-in-Differences Estimators", "abstract": "This article proposes doubly robust estimators for the average treatment\neffect on the treated (ATT) in difference-in-differences (DID) research\ndesigns. In contrast to alternative DID estimators, the proposed estimators are\nconsistent if either (but not necessarily both) a propensity score or outcome\nregression working models are correctly specified. We also derive the\nsemiparametric efficiency bound for the ATT in DID designs when either panel or\nrepeated cross-section data are available, and show that our proposed\nestimators attain the semiparametric efficiency bound when the working models\nare correctly specified. Furthermore, we quantify the potential efficiency\ngains of having access to panel data instead of repeated cross-section data.\nFinally, by paying articular attention to the estimation method used to\nestimate the nuisance parameters, we show that one can sometimes construct\ndoubly robust DID estimators for the ATT that are also doubly robust for\ninference. Simulation studies and an empirical application illustrate the\ndesirable finite-sample performance of the proposed estimators. Open-source\nsoftware for implementing the proposed policy evaluation tools is available.", "category": "econ.EM"}, {"title": "Identifying the Effect of Persuasion", "abstract": "This paper examines a commonly used measure of persuasion whose precise\ninterpretation has been obscure in the literature. By using the potential\noutcome framework, we define the causal persuasion rate by a proper conditional\nprobability of taking the action of interest with a persuasive message\nconditional on not taking the action without the message. We then formally\nstudy identification under empirically relevant data scenarios and show that\nthe commonly adopted measure generally does not estimate, but often overstates,\nthe causal rate of persuasion. We discuss several new parameters of interest\nand provide practical methods for causal inference.", "category": "econ.EM"}, {"title": "A supreme test for periodic explosive GARCH", "abstract": "We develop a uniform test for detecting and dating explosive behavior of a\nstrictly stationary GARCH$(r,s)$ (generalized autoregressive conditional\nheteroskedasticity) process. Namely, we test the null hypothesis of a globally\nstable GARCH process with constant parameters against an alternative where\nthere is an 'abnormal' period with changed parameter values. During this\nperiod, the change may lead to an explosive behavior of the volatility process.\nIt is assumed that both the magnitude and the timing of the breaks are unknown.\nWe develop a double supreme test for the existence of a break, and then provide\nan algorithm to identify the period of change. Our theoretical results hold\nunder mild moment assumptions on the innovations of the GARCH process.\nTechnically, the existing properties for the QMLE in the GARCH model need to be\nreinvestigated to hold uniformly over all possible periods of change. The key\nresults involve a uniform weak Bahadur representation for the estimated\nparameters, which leads to weak convergence of the test statistic to the\nsupreme of a Gaussian Process. In simulations we show that the test has good\nsize and power for reasonably large time series lengths. We apply the test to\nApple asset returns and Bitcoin returns.", "category": "econ.EM"}, {"title": "What Is the Value Added by Using Causal Machine Learning Methods in a Welfare Experiment Evaluation?", "abstract": "Recent studies have proposed causal machine learning (CML) methods to\nestimate conditional average treatment effects (CATEs). In this study, I\ninvestigate whether CML methods add value compared to conventional CATE\nestimators by re-evaluating Connecticut's Jobs First welfare experiment. This\nexperiment entails a mix of positive and negative work incentives. Previous\nstudies show that it is hard to tackle the effect heterogeneity of Jobs First\nby means of CATEs. I report evidence that CML methods can provide support for\nthe theoretical labor supply predictions. Furthermore, I document reasons why\nsome conventional CATE estimators fail and discuss the limitations of CML\nmethods.", "category": "econ.EM"}, {"title": "Fuzzy Difference-in-Discontinuities: Identification Theory and Application to the Affordable Care Act", "abstract": "This paper explores the use of a fuzzy regression discontinuity design where\nmultiple treatments are applied at the threshold. The identification results\nshow that, under the very strong assumption that the change in the probability\nof treatment at the cutoff is equal across treatments, a\ndifference-in-discontinuities estimator identifies the treatment effect of\ninterest. The point estimates of the treatment effect using a simple fuzzy\ndifference-in-discontinuities design are biased if the change in the\nprobability of a treatment applying at the cutoff differs across treatments.\nModifications of the fuzzy difference-in-discontinuities approach that rely on\nmilder assumptions are also proposed. Our results suggest caution is needed\nwhen applying before-and-after methods in the presence of fuzzy\ndiscontinuities. Using data from the National Health Interview Survey, we apply\nthis new identification strategy to evaluate the causal effect of the\nAffordable Care Act (ACA) on older Americans' health care access and\nutilization.", "category": "econ.EM"}, {"title": "Approximate State Space Modelling of Unobserved Fractional Components", "abstract": "We propose convenient inferential methods for potentially nonstationary\nmultivariate unobserved components models with fractional integration and\ncointegration. Based on finite-order ARMA approximations in the state space\nrepresentation, maximum likelihood estimation can make use of the EM algorithm\nand related techniques. The approximation outperforms the frequently used\nautoregressive or moving average truncation, both in terms of computational\ncosts and with respect to approximation quality. Monte Carlo simulations reveal\ngood estimation properties of the proposed methods for processes of different\ncomplexity and dimension.", "category": "econ.EM"}, {"title": "Multivariate Fractional Components Analysis", "abstract": "We propose a setup for fractionally cointegrated time series which is\nformulated in terms of latent integrated and short-memory components. It\naccommodates nonstationary processes with different fractional orders and\ncointegration of different strengths and is applicable in high-dimensional\nsettings. In an application to realized covariance matrices, we find that\northogonal short- and long-memory components provide a reasonable fit and\ncompetitive out-of-sample performance compared to several competing methods.", "category": "econ.EM"}, {"title": "Many Average Partial Effects: with An Application to Text Regression", "abstract": "We study estimation, pointwise and simultaneous inference, and confidence\nintervals for many average partial effects of lasso Logit. Focusing on\nhigh-dimensional, cluster-sampling environments, we propose a new average\npartial effect estimator and explore its asymptotic properties. Practical\npenalty choices compatible with our asymptotic theory are also provided. The\nproposed estimator allow for valid inference without requiring oracle property.\nWe provide easy-to-implement algorithms for cluster-robust high-dimensional\nhypothesis testing and construction of simultaneously valid confidence\nintervals using a multiplier cluster bootstrap. We apply the proposed\nalgorithms to the text regression model of Wu (2018) to examine the presence of\ngendered language on the internet.", "category": "econ.EM"}, {"title": "Functional Sequential Treatment Allocation", "abstract": "Consider a setting in which a policy maker assigns subjects to treatments,\nobserving each outcome before the next subject arrives. Initially, it is\nunknown which treatment is best, but the sequential nature of the problem\npermits learning about the effectiveness of the treatments. While the\nmulti-armed-bandit literature has shed much light on the situation when the\npolicy maker compares the effectiveness of the treatments through their mean,\nmuch less is known about other targets. This is restrictive, because a cautious\ndecision maker may prefer to target a robust location measure such as a\nquantile or a trimmed mean. Furthermore, socio-economic decision making often\nrequires targeting purpose specific characteristics of the outcome\ndistribution, such as its inherent degree of inequality, welfare or poverty. In\nthe present paper we introduce and study sequential learning algorithms when\nthe distributional characteristic of interest is a general functional of the\noutcome distribution. Minimax expected regret optimality results are obtained\nwithin the subclass of explore-then-commit policies, and for the unrestricted\nclass of all policies.", "category": "econ.EM"}, {"title": "Robust Tests for Convergence Clubs", "abstract": "In many applications common in testing for convergence the number of\ncross-sectional units is large and the number of time periods are few. In these\nsituations asymptotic tests based on an omnibus null hypothesis are\ncharacterised by a number of problems. In this paper we propose a multiple\npairwise comparisons method based on an a recursive bootstrap to test for\nconvergence with no prior information on the composition of convergence clubs.\nMonte Carlo simulations suggest that our bootstrap-based test performs well to\ncorrectly identify convergence clubs when compared with other similar tests\nthat rely on asymptotic arguments. Across a potentially large number of\nregions, using both cross-country and regional data for the European Union, we\nfind that the size distortion which afflicts standard tests and results in a\nbias towards finding less convergence, is ameliorated when we utilise our\nbootstrap test.", "category": "econ.EM"}, {"title": "A $t$-test for synthetic controls", "abstract": "We propose a practical and robust method for making inferences on average\ntreatment effects estimated by synthetic controls. We develop a $K$-fold\ncross-fitting procedure for bias correction. To avoid the difficult estimation\nof the long-run variance, inference is based on a self-normalized\n$t$-statistic, which has an asymptotically pivotal $t$-distribution. Our\n$t$-test is easy to implement, provably robust against misspecification, and\nvalid with stationary and non-stationary data. It demonstrates an excellent\nsmall sample performance in application-based simulations and performs well\nrelative to alternative methods. We illustrate the usefulness of the $t$-test\nby revisiting the effect of carbon taxes on emissions.", "category": "econ.EM"}, {"title": "Decentralization Estimators for Instrumental Variable Quantile Regression Models", "abstract": "The instrumental variable quantile regression (IVQR) model (Chernozhukov and\nHansen, 2005) is a popular tool for estimating causal quantile effects with\nendogenous covariates. However, estimation is complicated by the non-smoothness\nand non-convexity of the IVQR GMM objective function. This paper shows that the\nIVQR estimation problem can be decomposed into a set of conventional quantile\nregression sub-problems which are convex and can be solved efficiently. This\nreformulation leads to new identification results and to fast, easy to\nimplement, and tuning-free estimators that do not require the availability of\nhigh-level \"black box\" optimization routines.", "category": "econ.EM"}, {"title": "Predicting \"Design Gaps\" in the Market: Deep Consumer Choice Models under Probabilistic Design Constraints", "abstract": "Predicting future successful designs and corresponding market opportunity is\na fundamental goal of product design firms. There is accordingly a long history\nof quantitative approaches that aim to capture diverse consumer preferences,\nand then translate those preferences to corresponding \"design gaps\" in the\nmarket. We extend this work by developing a deep learning approach to predict\ndesign gaps in the market. These design gaps represent clusters of designs that\ndo not yet exist, but are predicted to be both (1) highly preferred by\nconsumers, and (2) feasible to build under engineering and manufacturing\nconstraints. This approach is tested on the entire U.S. automotive market using\nof millions of real purchase data. We retroactively predict design gaps in the\nmarket, and compare predicted design gaps with actual known successful designs.\nOur preliminary results give evidence it may be possible to predict design\ngaps, suggesting this approach has promise for early identification of market\nopportunity.", "category": "econ.EM"}, {"title": "Dynamic Models with Robust Decision Makers: Identification and Estimation", "abstract": "This paper studies identification and estimation of a class of dynamic models\nin which the decision maker (DM) is uncertain about the data-generating\nprocess. The DM surrounds a benchmark model that he or she fears is\nmisspecified by a set of models. Decisions are evaluated under a worst-case\nmodel delivering the lowest utility among all models in this set. The DM's\nbenchmark model and preference parameters are jointly underidentified. With the\nbenchmark model held fixed, primitive conditions are established for\nidentification of the DM's worst-case model and preference parameters. The key\nstep in the identification analysis is to establish existence and uniqueness of\nthe DM's continuation value function allowing for unbounded statespace and\nunbounded utilities. To do so, fixed-point results are derived for monotone,\nconvex operators that act on a Banach space of thin-tailed functions arising\nnaturally from the structure of the continuation value recursion. The\nfixed-point results are quite general; applications to models with learning and\nRust-type dynamic discrete choice models are also discussed. For estimation, a\nperturbation result is derived which provides a necessary and sufficient\ncondition for consistent estimation of continuation values and the worst-case\nmodel. The result also allows convergence rates of estimators to be\ncharacterized. An empirical application studies an endowment economy where the\nDM's benchmark model may be interpreted as an aggregate of experts' forecasting\nmodels. The application reveals time-variation in the way the DM\npessimistically distorts benchmark probabilities. Consequences for asset\npricing are explored and connections are drawn with the literature on\nmacroeconomic uncertainty.", "category": "econ.EM"}, {"title": "Nonparametric Instrumental Variables Estimation Under Misspecification", "abstract": "Nonparametric Instrumental Variables (NPIV) analysis is based on a\nconditional moment restriction. We show that if this moment condition is even\nslightly misspecified, say because instruments are not quite valid, then NPIV\nestimates can be subject to substantial asymptotic error and the identified set\nunder a relaxed moment condition may be large. Imposing strong a priori\nsmoothness restrictions mitigates the problem but induces bias if the\nrestrictions are too strong. In order to manage this trade-off we develop a\nmethods for empirical sensitivity analysis and apply them to the consumer\ndemand data previously analyzed in Blundell (2007) and Horowitz (2011).", "category": "econ.EM"}, {"title": "Shrinkage for Categorical Regressors", "abstract": "This paper introduces a flexible regularization approach that reduces point\nestimation risk of group means stemming from e.g. categorical regressors,\n(quasi-)experimental data or panel data models. The loss function is penalized\nby adding weighted squared l2-norm differences between group location\nparameters and informative first-stage estimates. Under quadratic loss, the\npenalized estimation problem has a simple interpretable closed-form solution\nthat nests methods established in the literature on ridge regression,\ndiscretized support smoothing kernels and model averaging methods. We derive\nrisk-optimal penalty parameters and propose a plug-in approach for estimation.\nThe large sample properties are analyzed in an asymptotic local to zero\nframework by introducing a class of sequences for close and distant systems of\nlocations that is sufficient for describing a large range of data generating\nprocesses. We provide the asymptotic distributions of the shrinkage estimators\nunder different penalization schemes. The proposed plug-in estimator uniformly\ndominates the ordinary least squares in terms of asymptotic risk if the number\nof groups is larger than three. Monte Carlo simulations reveal robust\nimprovements over standard methods in finite samples. Real data examples of\nestimating time trends in a panel and a difference-in-differences study\nillustrate potential applications.", "category": "econ.EM"}, {"title": "Eight-cluster structure of chloroplast genomes differs from similar one observed for bacteria", "abstract": "Previously, a seven-cluster pattern claiming to be a universal one in\nbacterial genomes has been reported. Keeping in mind the most popular theory of\nchloroplast origin, we checked whether a similar pattern is observed in\nchloroplast genomes. Surprisingly, eight cluster structure has been found, for\nchloroplasts. The pattern observed for chloroplasts differs rather\nsignificantly, from bacterial one, and from that latter observed for\ncyanobacteria. The structure is provided by clustering of the fragments of\nequal length isolated within a genome so that each fragment is converted in\ntriplet frequency dictionary with non-overlapping triplets with no gaps in\nframe tiling. The points in 63-dimensional space were clustered due to elastic\nmap technique. The eight cluster found in chloroplasts comprises the fragments\nof a genome bearing tRNA genes and exhibiting excessively high\n$\\mathsf{GC}$-content, in comparison to the entire genome.", "category": "q-bio.GN"}, {"title": "Predicting the spectrum of TCR repertoire sharing with a data-driven model of recombination", "abstract": "Despite the extreme diversity of T cell repertoires, many identical T-cell\nreceptor (TCR) sequences are found in a large number of individual mice and\nhumans. These widely-shared sequences, often referred to as `public', have been\nsuggested to be over-represented due to their potential immune functionality or\ntheir ease of generation by V(D)J recombination. Here we show that even for\nlarge cohorts the observed degree of sharing of TCR sequences between\nindividuals is well predicted by a model accounting for by the known\nquantitative statistical biases in the generation process, together with a\nsimple model of thymic selection. Whether a sequence is shared by many\nindividuals is predicted to depend on the number of queried individuals and the\nsampling depth, as well as on the sequence itself, in agreement with the data.\nWe introduce the degree of publicness conditional on the queried cohort size\nand the size of the sampled repertoires. Based on these observations we propose\na public/private sequence classifier, `PUBLIC' (Public Universal Binary\nLikelihood Inference Classifier), based on the generation probability, which\nperforms very well even for small cohort sizes.", "category": "q-bio.GN"}, {"title": "Single nucleotide polymorphisms that modulate microRNA regulation of gene expression in tumors", "abstract": "Genome-wide association studies (GWAS) have identified single nucleotide\npolymorphisms (SNPs) associated with trait diversity and disease\nsusceptibility, yet the functional properties of many genetic variants and\ntheir molecular interactions remains unclear. It has been hypothesized that\nSNPs in microRNA binding sites may disrupt gene regulation by microRNAs\n(miRNAs), short non-coding RNAs that bind to mRNA and downregulate the target\ngene. While a number of studies have been conducted to predict the location of\nSNPs in miRNA binding sites, to date there has been no comprehensive analysis\nof how SNP variants may impact miRNA regulation of genes. Here we investigate\nthe functional properties of genetic variants and their effects on miRNA\nregulation of gene expression in cancer. Our analysis is motivated by the\nhypothesis that distinct alleles may cause differential binding (from miRNAs to\nmRNAs or from transcription factors to DNA) and change the expression of genes.\nWe previously identified pathways--systems of genes conferring specific cell\nfunctions--that are dysregulated by miRNAs in cancer, by comparing\nmiRNA-pathway associations between healthy and tumor tissue. We draw on these\nresults as a starting point to assess whether SNPs in genes on dysregulated\npathways are responsible for miRNA dysregulation of individual genes in tumors.\nUsing an integrative analysis that incorporates miRNA expression, mRNA\nexpression, and SNP genotype data, we identify SNPs that appear to influence\nthe association between miRNAs and genes, which we term \"regulatory QTLs\n(regQTLs)\": loci whose alleles impact the regulation of genes by miRNAs. We\ndescribe the method, apply it to analyze four cancer types (breast, liver,\nlung, prostate) using data from The Cancer Genome Atlas (TCGA), and provide a\ntool to explore the findings.", "category": "q-bio.GN"}, {"title": "Minimum error correction-based haplotype assembly: considerations for long read data", "abstract": "The single nucleotide polymorphism (SNP) is the most widely studied type of\ngenetic variation. A haplotype is defined as the sequence of alleles at SNP\nsites on each haploid chromosome. Haplotype information is essential in\nunravelling the genome-phenotype association. Haplotype assembly is a\nwell-known approach for reconstructing haplotypes, exploiting reads generated\nby DNA sequencing devices. The Minimum Error Correction (MEC) metric is often\nused for reconstruction of haplotypes from reads. However, problems with the\nMEC metric have been reported. Here, we investigate the MEC approach to\ndemonstrate that it may result in incorrectly reconstructed haplotypes for\ndevices that produce error-prone long reads. Specifically, we evaluate this\napproach for devices developed by Illumina, Pacific BioSciences and Oxford\nNanopore Technologies. We show that imprecise haplotypes may be reconstructed\nwith a lower MEC than that of the exact haplotype. The performance of MEC is\nexplored for different coverage levels and error rates of data. Our simulation\nresults reveal that in order to avoid incorrect MEC-based haplotypes, a\ncoverage of 25 is needed for reads generated by Pacific BioSciences RS systems.", "category": "q-bio.GN"}, {"title": "The bromodomain-containing protein Ibd1 links multiple chromatin related protein complexes to highly expressed genes in Tetrahymena thermophila", "abstract": "Background: The chromatin remodelers of the SWI/SNF family are critical\ntranscriptional regulators. Recognition of lysine acetylation through a\nbromodomain (BRD) component is key to SWI/SNF function; in most eukaryotes,\nthis function is attributed to SNF2/Brg1.\n  Results: Using affinity purification coupled to mass spectrometry (AP-MS) we\nidentified members of a SWI/SNF complex (SWI/SNFTt) in Tetrahymena thermophila.\nSWI/SNFTt is composed of 11 proteins, Snf5Tt, Swi1Tt, Swi3Tt, Snf12Tt, Brg1Tt,\ntwo proteins with potential chromatin interacting domains and four proteins\nwithout orthologs to SWI/SNF proteins in yeast or mammals. SWI/SNFTt subunits\nlocalize exclusively to the transcriptionally active macronucleus (MAC) during\ngrowth and development, consistent with a role in transcription. While\nTetrahymena Brg1 does not contain a BRD, our AP-MS results identified a\nBRD-containing SWI/SNFTt component, Ibd1 that associates with SWI/SNFTt during\ngrowth but not development. AP-MS analysis of epitope-tagged Ibd1 revealed it\nto be a subunit of several additional protein complexes, including putative\nSWRTt, and SAGATt complexes as well as a putative H3K4-specific histone methyl\ntransferase complex. Recombinant Ibd1 recognizes acetyl-lysine marks on\nhistones correlated with active transcription. Consistent with our AP-MS and\nhistone array data suggesting a role in regulation of gene expression, ChIP-Seq\nanalysis of Ibd1 indicated that it primarily binds near promoters and within\ngene bodies of highly expressed genes during growth.\n  Conclusions: Our results suggest that through recognizing specific histones\nmarks, Ibd1 targets active chromatin regions of highly expressed genes in\nTetrahymena where it subsequently might coordinate the recruitment of several\nchromatin remodeling complexes to regulate the transcriptional landscape of\nvegetatively growing Tetrahymena cells.", "category": "q-bio.GN"}, {"title": "Modeling and analysis of RNA-seq data: a review from a statistical perspective", "abstract": "Background: Since the invention of next-generation RNA sequencing (RNA-seq)\ntechnologies, they have become a powerful tool to study the presence and\nquantity of RNA molecules in biological samples and have revolutionized\ntranscriptomic studies. The analysis of RNA-seq data at four different levels\n(samples, genes, transcripts, and exons) involve multiple statistical and\ncomputational questions, some of which remain challenging up to date.\n  Results: We review RNA-seq analysis tools at the sample, gene, transcript,\nand exon levels from a statistical perspective. We also highlight the\nbiological and statistical questions of most practical considerations.\n  Conclusion: The development of statistical and computational methods for\nanalyzing RNA- seq data has made significant advances in the past decade.\nHowever, methods developed to answer the same biological question often rely on\ndiverse statical models and exhibit different performance under different\nscenarios. This review discusses and compares multiple commonly used\nstatistical models regarding their assumptions, in the hope of helping users\nselect appropriate methods as needed, as well as assisting developers for\nfuture method development.", "category": "q-bio.GN"}, {"title": "Identification of a complete YPT1 Rab GTPase sequence from the fungal pathogen Colletotrichum incanum", "abstract": "Colletotrichum represent a genus of fungal species primarily known as plant\npathogens with severe economic impacts in temperate, subtropical and tropical\nclimates Consensus taxonomy and classification systems for Colletotrichum\nspecies have been undergoing revision as high resolution genomic data becomes\navailable. Here we propose an alternative annotation that provides a complete\nsequence for a Colletotrichum YPT1 gene homolog using the whole genome shotgun\nsequence of Colletotrichum incanum isolated from soybean crops in Illinois,\nUSA.", "category": "q-bio.GN"}, {"title": "The Qatar Genome: A Population-Specific Tool for Precision Medicine in the Middle East", "abstract": "Reaching the full potential of precision medicine depends on the quality of\npersonalized genome interpretation. In order to facilitate precision medicine\nin regions of the Middle East and North Africa (MENA), a population-specific\nreference genome for the indigenous Arab popula-tion of Qatar (QTRG) was\nconstructed by incorporating allele frequency data from sequencing of 1,161\nQataris, representing 0.4% of the population. A total of 20.9 million SNP and\n3.1 million indels were observed in Qatar, including an average of 1.79% novel\nvariants per individual ge-nome. Replacement of the GRCh37 standard reference\nwith QTRG in a best practices genome analysis workflow resulted in an average\nof 7* deeper coverage depth (an improvement of 23%), and 756,671 fewer variants\non average, a reduction of 16% that is attributed to common Qatari alleles\nbeing present in the QTRG reference. The benefit for using QTRG varies across\nances-tries, a factor that should be taken into consideration when selecting an\nappropriate reference for analysis.", "category": "q-bio.GN"}, {"title": "A quick guide for student-driven community genome annotation", "abstract": "High quality gene models are necessary to expand the molecular and genetic\ntools available for a target organism, but these are available for only a\nhandful of model organisms that have undergone extensive curation and\nexperimental validation over the course of many years. The majority of gene\nmodels present in biological databases today have been identified in draft\ngenome assemblies using automated annotation pipelines that are frequently\nbased on orthologs from distantly related model organisms. Manual curation is\ntime consuming and often requires substantial expertise, but is instrumental in\nimproving gene model structure and identification. Manual annotation may seem\nto be a daunting and cost-prohibitive task for small research communities but\ninvolving undergraduates in community genome annotation consortiums can be\nmutually beneficial for both education and improved genomic resources. We\noutline a workflow for efficient manual annotation driven by a team of\nprimarily undergraduate annotators. This model can be scaled to large teams and\nincludes quality control processes through incremental evaluation. Moreover, it\ngives students an opportunity to increase their understanding of genome biology\nand to participate in scientific research in collaboration with peers and\nsenior researchers at multiple institutions.", "category": "q-bio.GN"}, {"title": "Transcription Factor-DNA Binding Via Machine Learning Ensembles", "abstract": "We present ensemble methods in a machine learning (ML) framework combining\npredictions from five known motif/binding site exploration algorithms. For a\ngiven TF the ensemble starts with position weight matrices (PWM's) for the\nmotif, collected from the component algorithms. Using dimension reduction, we\nidentify significant PWM-based subspaces for analysis. Within each subspace a\nmachine classifier is built for identifying the TF's gene (promoter) targets\n(Problem 1). These PWM-based subspaces form an ML-based sequence analysis tool.\nProblem 2 (finding binding motifs) is solved by agglomerating k-mer (string)\nfeature PWM-based subspaces that stand out in identifying gene targets. We\napproach Problem 3 (binding sites) with a novel machine learning approach that\nuses promoter string features and ML importance scores in a classification\nalgorithm locating binding sites across the genome. For target gene\nidentification this method improves performance (measured by the F1 score) by\nabout 10 percentage points over the (a) motif scanning method and (b) the\ncoexpression-based association method. Top motif outperformed 5 component\nalgorithms as well as two other common algorithms (BEST and DEME). For\nidentifying individual binding sites on a benchmark cross species database\n(Tompa et al., 2005) we match the best performer without much human\nintervention. It also improved the performance on mammalian TFs.\n  The ensemble can integrate orthogonal information from different weak\nlearners (potentially using entirely different types of features) into a\nmachine learner that can perform consistently better for more TFs. The TF gene\ntarget identification component (problem 1 above) is useful in constructing a\ntranscriptional regulatory network from known TF-target associations. The\nensemble is easily extendable to include more tools as well as future PWM-based\ninformation.", "category": "q-bio.GN"}, {"title": "The sequencing and interpretation of the genome obtained from a Serbian individual", "abstract": "Recent genetic studies and whole-genome sequencing projects have greatly\nimproved our understanding of human variation and clinically actionable genetic\ninformation. Smaller ethnic populations, however, remain underrepresented in\nboth individual and large-scale sequencing efforts and hence present an\nopportunity to discover new variants of biomedical and demographic\nsignificance. This report describes the sequencing and analysis of a genome\nobtained from an individual of Serbian origin, introducing tens of thousands of\npreviously unknown variants to the currently available pool. Ancestry analysis\nplaces this individual in close proximity of the Central and Eastern European\npopulations; i.e., closest to Croatian, Bulgarian and Hungarian individuals\nand, in terms of other Europeans, furthest from Ashkenazi Jewish, Spanish,\nSicilian, and Baltic individuals. Our analysis confirmed gene flow between\nNeanderthal and ancestral pan-European populations, with similar contributions\nto the Serbian genome as those observed in other European groups. Finally, to\nassess the burden of potentially disease-causing/clinically relevant variation\nin the sequenced genome, we utilized manually curated genotype-phenotype\nassociation databases and variant-effect predictors. We identified several\nvariants that have previously been associated with severe early-onset disease\nthat is not evident in the proband, as well as variants that could yet prove to\nbe clinically relevant to the proband over the next decades. The presence of\nnumerous private and low-frequency variants along with the observed and\npredicted disease-causing mutations in this genome exemplify some of the global\nchallenges of genome interpretation, especially in the context of understudied\nethnic groups.", "category": "q-bio.GN"}, {"title": "Quantifying Local Randomness in Human DNA and RNA Sequences Using Erdos Motifs", "abstract": "In 1932, Paul Erdos asked whether a random walk constructed from a binary\nsequence can achieve the lowest possible deviation (lowest discrepancy), for\nthe sequence itself and for all its subsequences formed by homogeneous\narithmetic progressions. Although avoiding low discrepancy is impossible for\ninfinite sequences, as recently proven by Terence Tao, attempts were made to\nconstruct such sequences with finite lengths. We recognize that such\nconstructed sequences (we call these \"Erdos sequences\") exhibit certain\nhallmarks of randomness at the local level: they show roughly equal frequencies\nof subsequences, and at the same time exclude the trivial periodic patterns.\nFor the human DNA we examine the frequency of a set of Erdos motifs of\nlength-10 using three nucleotides-to-binary mappings. The particular length-10\nErdos sequence is derived by the length-11 Mathias sequence and is identical\nwith the first 10 digits of the Thue-Morse sequence, underscoring the fact that\nboth are deficient in periodicities. Our calculations indicate that: (1) the\npurine (A and G)/pyridimine (C and T) based Erdos motifs are greatly\nunderrepresented in the human genome, (2) the strong(G and C)/weak(A and T)\nbased Erdos motifs are slightly overrepresented, (3) the densities of the two\nare negatively correlated, (4) the Erdos motifs based on all three mappings\nbeing combined are slightly underrepresented, and (5) the strong/weak based\nErdos motifs are greatly overrepresented in the human messenger RNA sequences.", "category": "q-bio.GN"}, {"title": "Identifying viruses from metagenomic data by deep learning", "abstract": "The recent development of metagenomic sequencing makes it possible to\nsequence microbial genomes including viruses in an environmental sample.\nIdentifying viral sequences from metagenomic data is critical for downstream\nvirus analyses. The existing reference-based and gene homology-based methods\nare not efficient in identifying unknown viruses or short viral sequences. Here\nwe have developed a reference-free and alignment-free machine learning method,\nDeepVirFinder, for predicting viral sequences in metagenomic data using deep\nlearning techniques. DeepVirFinder was trained based on a large number of viral\nsequences discovered before May 2015. Evaluated on the sequences after that\ndate, DeepVirFinder outperformed the state-of-the-art method VirFinder at all\ncontig lengths. Enlarging the training data by adding millions of purified\nviral sequences from environmental metavirome samples significantly improves\nthe accuracy for predicting under-represented viruses. Applying DeepVirFinder\nto real human gut metagenomic samples from patients with colorectal carcinoma\n(CRC) identified 51,138 viral sequences belonging to 175 bins. Ten bins were\nassociated with the cancer status, indicating their potential use for\nnon-invasive diagnosis of CRC. In summary, DeepVirFinder greatly improved the\nprecision and recall rates of viral identification, and it will significantly\naccelerate the discovery rate of viruses.", "category": "q-bio.GN"}, {"title": "Innovative method for reducing uninformative calls in non-invasive prenatal testing", "abstract": "Non-invasive prenatal testing or NIPT is currently among the top researched\ntopic in obstetric care. While the performance of the current state-of-the-art\nNIPT solutions achieve high sensitivity and specificity, they still struggle\nwith a considerable number of samples that cannot be concluded with certainty.\nSuch uninformative results are often subject to repeated blood sampling and\nre-analysis, usually after two weeks, and this period may cause a stress to the\nfuture mothers as well as increase the overall cost of the test. We propose a\nsupplementary method to traditional z-scores to reduce the number of such\nuninformative calls. The method is based on a novel analysis of the length\nprofile of circulating cell free DNA which compares the change in such profiles\nwhen random-based and length-based elimination of some fragments is performed.\nThe proposed method is not as accurate as the standard z-score; however, our\nresults suggest that combination of these two independent methods correctly\nresolves a substantial portion of healthy samples with an uninformative result.\nAdditionally, we discuss how the proposed method can be used to identify\nmaternal aberrations, thus reducing the risk of false positive and false\nnegative calls.\n  Keywords: Next-generation sequencing, Cell-free DNA, Uninformative result,\nMethod, Trisomy, Prenatal testing", "category": "q-bio.GN"}, {"title": "Genesis of the alpha beta T-cell receptor", "abstract": "The T-cell (TCR) repertoire relies on the diversity of receptors composed of\ntwo chains, called $\\alpha$ and $\\beta$, to recognize pathogens. Using results\nof high throughput sequencing and computational chain-pairing experiments of\nhuman TCR repertoires, we quantitively characterize the $\\alpha\\beta$\ngeneration process. We estimate the probabilities of a rescue recombination of\nthe $\\beta$ chain on the second chromosome upon failure or success on the first\nchromosome. Unlike $\\beta$ chains, $\\alpha$ chains recombine simultaneously on\nboth chromosomes, resulting in correlated statistics of the two genes which we\npredict using a mechanistic model. We find that $\\sim 28 \\%$ of cells express\nboth $\\alpha$ chains. We report that clones sharing the same $\\beta$ chain but\ndifferent $\\alpha$ chains are overrepresented, suggesting that they respond to\ncommon immune challenges. Altogether, our statistical analysis gives a complete\nquantitative mechanistic picture that results in the observed correlations in\nthe generative process. We learn that the probability to generate any\nTCR$\\alpha\\beta$ is lower than $10^{-12}$ and estimate the generation diversity\nand sharing properties of the $\\alpha\\beta$ TCR repertoire.", "category": "q-bio.GN"}, {"title": "Searching by index for similar sequences: the SEQR algorithm", "abstract": "This paper describes a method to efficiently retrieve protein database\nsequences similar to a query sequence, while allowing for significant numbers\nof mutations. We call this method SEQR for SEQuence Retrieval. This approach\nincreases the speed of sequence similarity searches by an order of magnitude\ncompared to conventional algorithms at the expense of sensitivity. Furthermore,\nretrieval time increases less than linearly with the number of sequences, a\ndesirable property during an era when next generation sequencing technologies\nhave yielded greater than exponential increases in sequence records. The lower\nsensitivity of the algorithm for distantly related sequences compared to\nbenchmarks is not intrinsic to the method itself, but rather due to the\nprocedure used to construct the indexing terms, and may be improved. The\nindexing terms themselves can be added to standard information retrieval\nengines, enabling complex queries that include sequence similarity and other\ndescriptors such as taxonomy and text descriptions.", "category": "q-bio.GN"}, {"title": "Linking de novo assembly results with long DNA reads by dnaasm-link application", "abstract": "Currently, third-generation sequencing techniques, which allow to obtain much\nlonger DNA reads compared to the next-generation sequencing technologies, are\nbecoming more and more popular. There are many possibilities to combine data\nfrom next-generation and third-generation sequencing.\n  Herein, we present a new application called dnaasm-link for linking contigs,\na result of \\textit{de novo} assembly of second-generation sequencing data,\nwith long DNA reads. Our tool includes an integrated module to fill gaps with a\nsuitable fragment of appropriate long DNA read, which improves the consistency\nof the resulting DNA sequences. This feature is very important, in particular\nfor complex DNA regions, as presented in the paper. Finally, our implementation\noutperforms other state-of-the-art tools in terms of speed and memory\nrequirements, which may enable the usage of the presented application for\norganisms with a large genome, which is not possible in~existing applications.\n  The presented application has many advantages as (i) significant memory\noptimization and reduction of computation time (ii) filling the gaps through\nthe appropriate fragment of a specified long DNA read (iii) reducing number of\nspanned and unspanned gaps in the existing genome drafts.\n  The application is freely available to all users under GNU Library or Lesser\nGeneral Public License version 3.0 (LGPLv3). The demo application, docker image\nand source code are available at http://dnaasm.sourceforge.net.", "category": "q-bio.GN"}, {"title": "DNA methylation markers to assess biological age", "abstract": "Among the different biomarkers of aging based on omics and clinical data, DNA\nmethylation clocks stand apart providing unmatched accuracy in assessing the\nbiological age of both humans and animal models of aging. Here, we discuss\nrobustness of DNA methylation clocks and bounds on their out-of-sample\nperformance and review computational strategies for development of the clocks.", "category": "q-bio.GN"}, {"title": "JS-MA: A Jensen-Shannon Divergence Based Method for Mapping Genome-wide Associations on Multiple Diseases", "abstract": "Taking advantages of high-throughput genotyping technology of single\nnucleotide polymorphism (SNP), large genome-wide association studies (GWASs)\nhave been considered as the promise to unravel the complex relationships\nbetween genotypes and phenotypes, in particularly common diseases. However,\ncurrent multi-locus-based methods are insufficient, in terms of computational\ncost and discrimination power, to detect statistically significant interactions\nand they are lacking in the ability of finding diverse genetic effects on\nmultifarious diseases. Especially, multiple statistic tests for high-order\nepistasis ($ \\geq $ 2 SNPs) will raise huge analytical challenges because the\ncomputational cost increases exponentially as the growth of the cardinality of\nSNPs in an epistatic module. In this paper, we develop a simple, fast and\npowerful method, named JS-MA, using the Jensen-Shannon divergence and a\nhigh-dimensional $ k $-mean clustering algorithm for mapping the genome-wide\nmulti-locus epistatic interactions on multiple diseases. Compared with some\nstate-of-the-art association mapping tools, our method is demonstrated to be\nmore powerful and efficient from the experimental results on the systematical\nsimulations. We also applied JS-MA to the GWAS datasets from WTCCC for two\ncommon diseases, i.e. Rheumatoid Arthritis and Type 1 Diabetes. JS-MA not only\nconfirms some recently reported biologically meaningful associations but also\nidentifies some novel findings. Therefore, we believe that our method is\nsuitable and efficient for the full-scale analysis of multi-disease-related\ninteractions in the large GWASs.", "category": "q-bio.GN"}, {"title": "A Multi-Trait Approach Identified Genetic Variants Including a Rare Mutation in RGS3 with Impact on Abnormalities of Cardiac Structure/Function", "abstract": "Heart failure is a major cause for premature death. Given heterogeneity of\nthe heart failure syndrome, identifying genetic determinants of cardiac\nfunction and structure may provide greater insights into heart failure. Despite\nprogress in understanding the genetic basis of heart failure through genome\nwide association studies, heritability of heart failure is not well understood.\nGaining further insights into mechanisms that contribute to heart failure\nrequires systematic approaches that go beyond single trait analysis. We\nintegrated Bayesian multi-trait approach and Bayesian networks for the analysis\nof 10 correlated traits of cardiac structure and function measured for 3387\nindividuals with whole exome sequence data. While using single-trait based\napproaches did not find any significant genetic variant, applying the\nintegrative Bayesian multi-trait approach, we identified 3 novel variants\nlocated in genes, RGS3, CHD3, and MRPL38 with significant impact on the cardiac\ntraits such as left ventricular volume index, parasternal long axis\ninterventricular septum thickness, and mean left ventricular wall thickness.\nAmong these, the rare variant NC_000009.11:g.116346115C>A (rs144636307) in RGS3\nshowed pleiotropic effect on left ventricular mass index, left ventricular\nvolume index and Maximum left atrial anterior-posterior diameter while RGS3 can\ninhibit TGF-beta signaling associated with left ventricle dilation and systolic\ndysfunction.", "category": "q-bio.GN"}, {"title": "Private Shotgun DNA Sequencing", "abstract": "Current techniques in sequencing a genome allow a service provider (e.g. a\nsequencing company) to have full access to the genome information, and thus the\nprivacy of individuals regarding their lifetime secret is violated. In this\npaper, we introduce the problem of private DNA sequencing, where the goal is to\nkeep the DNA sequence private to the sequencer. We propose an architecture,\nwhere the task of reading fragments of DNA and the task of DNA assembly are\nseparated, the former is done at the sequencer(s), and the later is completed\nat a local trusted data collector. To satisfy the privacy constraint at the\nsequencer and reconstruction condition at the data collector, we create an\ninformation gap between these two relying on two techniques: (i) we use more\nthan one non-colluding sequencer, all reporting the read fragments to the\nsingle data collector, (ii) adding the fragments of some known DNA molecules,\nwhich are still unknown to the sequencers, to the pool. We prove that these two\ntechniques provide enough freedom to satisfy both conditions at the same time.", "category": "q-bio.GN"}, {"title": "GenHap: A Novel Computational Method Based on Genetic Algorithms for Haplotype Assembly", "abstract": "The computational problem of inferring the full haplotype of a cell starting\nfrom read sequencing data is known as haplotype assembly, and consists in\nassigning all heterozygous Single Nucleotide Polymorphisms (SNPs) to exactly\none of the two chromosomes. Indeed, the knowledge of complete haplotypes is\ngenerally more informative than analyzing single SNPs and plays a fundamental\nrole in many medical applications. To reconstruct the two haplotypes, we\naddressed the weighted Minimum Error Correction (wMEC) problem, which is a\nsuccessful approach for haplotype assembly. This NP-hard problem consists in\ncomputing the two haplotypes that partition the sequencing reads into two\ndisjoint sub-sets, with the least number of corrections to the SNP values. To\nthis aim, we propose here GenHap, a novel computational method for haplotype\nassembly based on Genetic Algorithms, yielding optimal solutions by means of a\nglobal search process. In order to evaluate the effectiveness of our approach,\nwe run GenHap on two synthetic (yet realistic) datasets, based on the Roche/454\nand PacBio RS II sequencing technologies. We compared the performance of GenHap\nagainst HapCol, an efficient state-of-the-art algorithm for haplotype phasing.\nOur results show that GenHap always obtains high accuracy solutions (in terms\nof haplotype error rate), and is up to 4x faster than HapCol in the case of\nRoche/454 instances and up to 20x faster when compared on the PacBio RS II\ndataset. Finally, we assessed the performance of GenHap on two different real\ndatasets. Future-generation sequencing technologies, producing longer reads\nwith higher coverage, can highly benefit from GenHap, thanks to its capability\nof efficiently solving large instances of the haplotype assembly problem.", "category": "q-bio.GN"}, {"title": "De novo inference of diversity genes and analysis of non-canonical V(DD)J recombination in immunoglobulins", "abstract": "The V(D)J recombination forms the immunoglobulin genes by joining the\nvariable (V), diversity (D), and joining (J) germline genes. Since variations\nin germline genes have been linked to various diseases, personalized\nimmunogenomics aims at finding alleles of germline genes across various\npatients. Although recent studies described algorithms for de novo inference of\nV and J genes from immunosequencing data, they stopped short of solving a more\ndifficult problem of reconstructing D genes that form the highly divergent CDR3\nregions and provide the most important contribution to the antigen binding. We\npresent the IgScout algorithm for de novo D gene reconstruction and apply it to\nreveal new alleles of human D genes and previously unknown D genes in camel, an\nimportant model organism in immunology. We further analyze non-canonical V(DD)J\nrecombination that results in unusually long tandem CDR3s and thus expands the\ndiversity of the antibody repertoires. We demonstrate that tandem CDR3s\nrepresent a consistent and functional feature of all analyzed immunosequencing\ndatasets, reveal ultra-long tandem CDR3s, and shed light on the mechanism\nresponsible for their formation.", "category": "q-bio.GN"}, {"title": "A Hybrid HMM Approach for the Dynamics of DNA Methylation", "abstract": "The understanding of mechanisms that control epigenetic changes is an\nimportant research area in modern functional biology. Epigenetic modifications\nsuch as DNA methylation are in general very stable over many cell divisions.\nDNA methylation can however be subject to specific and fast changes over a\nshort time scale even in non-dividing (i.e. not-replicating) cells. Such\ndynamic DNA methylation changes are caused by a combination of active\ndemethylation and de novo methylation processes which have not been\ninvestigated in integrated models. Here we present a hybrid (hidden) Markov\nmodel to describe the cycle of methylation and demethylation over (short) time\nscales. Our hybrid model decribes several molecular events either happening at\ndeterministic points (i.e. describing mechanisms that occur only during cell\ndivision) and other events occurring at random time points. We test our model\non mouse embryonic stem cells using time-resolved data. We predict methylation\nchanges and estimate the efficiencies of the different modification steps\nrelated to DNA methylation and demethylation.", "category": "q-bio.GN"}, {"title": "Identifying centromeric satellites with dna-brnn", "abstract": "Summary: Human alpha satellite and satellite 2/3 contribute to several\npercent of the human genome. However, identifying these sequences with\ntraditional algorithms is computationally intensive. Here we develop dna-brnn,\na recurrent neural network to learn the sequences of the two classes of\ncentromeric repeats. It achieves high similarity to RepeatMasker and is times\nfaster. Dna-brnn explores a novel application of deep learning and may\naccelerate the study of the evolution of the two repeat classes.\n  Availability and implementation: https://github.com/lh3/dna-nn\n  Contact: hli@jimmy.harvard.edu", "category": "q-bio.GN"}, {"title": "Proteomic and metagenomic insights into prehistoric Spanish Levantine Rock Art", "abstract": "The Iberian Mediterranean Basin is home to one of the largest groups of\nprehistoric rock art sites in Europe. Despite the cultural relevance of\nprehistoric Spanish Levantine rock art, pigment composition remains partially\nunknown, and the nature of the binders used for painting has yet to be\ndisclosed. In this work, we present the first omic analysis applied to one of\nthe flagship Levantine rock art sites: the Valltorta ravine (Castell{\\'o}n,\nSpain). We used high-throughput sequencing to provide the first description of\nthe bacterial communities colonizing the rock art patina, which proved to be\ndominated by Firmicutes species and might have a protective effect on the\npaintings. Proteomic analysis was also performed on rock art microsamples in\norder to determine the organic binders present in Levantine prehistoric rock\nart pigments. This information could shed light on the controversial dating of\nthis UNESCO Cultural Heritage, and contribute to defining the chrono-cultural\nframework of the societies responsible for these paintings.", "category": "q-bio.GN"}, {"title": "HIV-1 virus cycle replication: a review of RNA polymerase II transcription, alternative splicing and protein synthesis", "abstract": "HIV virus replication is a time-related process that includes several stages.\nFocusing on the core steps, RNA polymerase II transcripts in an early stage\npre-mRNA containing regulator proteins (i.e nef,tat,rev,vif,vpr,vpu), which are\ncompletely spliced by the spliceosome complex (0.9kb and 1.8kb) and exported to\nthe ribosome for protein synthesis. These splicing and export processes are\nregulated by tat protein, which binds on Trans-activation response (TAR)\nelement, and by rev protein, which binds to the Rev-responsive Element (RRE).\nAs long as these regulators are synthesized, splicing is progressively\ninhibited (from 4.0kb to 9.0kb) and mRNAs are translated into structural and\nenzymatic proteins (env, gag-pol). During this RNAPII scanning and splicing,\naround 40 different multi-cystronic mRNA have been produced. Long-read\nsequencing has been applied to the HIV-1 virus genome (type HXB2CG) with the\nHIV.pro software, a fortran 90 code for simulating the virus replication cycle,\nspecially RNAPII transcription, exon/intron splicing and ribosome protein\nsynthesis, including the frameshift at gag/pol gene and the ribosome pause at\nenv gene. All HIV-1 virus proteins have been identified as far as other ORFs.\nAs observed, tat/rev protein regulators have different length depending on the\nsplicing cleavage site: tat protein varies from 224aa to a final state of 72aa,\nwhereas rev protein from 25aa to 27aa, with a maximum of 119aa. Furthermore,\nseveral ORFs coding for small polypeptides sPEP (less than 10 amino acids) and\nfor other unidentified proteins have been localised with unknown functionality.\nThe detailed analysis of the HIV virus replication and the virus proteomics are\nimportant for identifying which antigens are presented by macrophages to CD4\ncells, for localizing reactive epitopes or for creating transfer vectors to\ndevelop new HIV vaccines and effective therapies.", "category": "q-bio.GN"}, {"title": "pdbmine: A Node.js API for the RCSB Protein Data Bank (PDB)", "abstract": "Summary: The advent of Web-based tools that assist in the analysis and\nvisualization of macromolecules require application programming interfaces\n(APIs) designed for modern web frameworks. To this end, we have developed a\nNode.js module pdbmine that allows any user to generate faster data-request\nqueries to the RCSB Protein Data Bank (PDB). This JavaScript API acts as a\nlayer over the XML-based RCSB PDB RESTful API. The relatively simple nature of\nthe function calls within this module allows the user to easily implement and\nintegrate pdbmine into larger Node.js web applications.\n  Availability: This module can be installed via the Node Package Manager (NPM)\nat https://www.npmjs.com/package/pdbmine/, and is hosted on GitHub under the\nopen-source MIT license at https://github.com/nnj1/pdbmine/. Relevant\ndocumentation is detailed at https://nnj1.github.io/pdbmine/", "category": "q-bio.GN"}, {"title": "Statistical methods for the quantitative genetic analysis of high-throughput phenotyping data", "abstract": "The advent of plant phenomics, coupled with the wealth of genotypic data\ngenerated by next-generation sequencing technologies, provides exciting new\nresources for investigations into and improvement of complex traits. However,\nthese new technologies also bring new challenges in quantitative genetics,\nnamely, a need for the development of robust frameworks that can accommodate\nthese high-dimensional data. In this chapter, we describe methods for the\nstatistical analysis of high-throughput phenotyping (HTP) data with the goal of\nenhancing the prediction accuracy of genomic selection (GS). Following the\nIntroduction in Section 1, Section 2 discusses field-based HTP, including the\nuse of unmanned aerial vehicles and light detection and ranging, as well as how\nwe can achieve increased genetic gain by utilizing image data derived from HTP.\nSection 3 considers extending commonly used GS models to integrate HTP data as\ncovariates associated with the principal trait response, such as yield.\nParticular focus is placed on single-trait, multi-trait, and genotype by\nenvironment interaction models. One unique aspect of HTP data is that phenomics\nplatforms often produce large-scale data with high spatial and temporal\nresolution for capturing dynamic growth, development, and stress responses.\nSection 4 discusses the utility of a random regression model for performing\nlongitudinal GS. The chapter concludes with a discussion of some standing\nissues.", "category": "q-bio.GN"}, {"title": "A bioinformatics pipeline for the identification of CHO cell differential gene expression from RNA-Seq data", "abstract": "In recent years the publication of genome sequences for the Chinese hamster\nand Chinese hamster ovary (CHO) cell lines have facilitated study of these\nbiopharmaceutical cell factories with unprecedented resolution. Our\nunderstanding of the CHO cell transcriptome, in particular, has rapidly\nadvanced through the application of next-generation sequencing (NGS) technology\nto characterise RNA expression (RNA-Seq). In this chapter we present a\ncomputational pipeline for the analysis of CHO cell RNA-Seq data from the\nIllumina platform to identify differentially expressed genes. The example data\nand bioinformatics workflow required to run this analysis are freely available\nat www.cgcdb.org/rnaseq_analysis_protocol.html.", "category": "q-bio.GN"}, {"title": "RACS: Rapid Analysis of ChIP-Seq data for contig based genomes", "abstract": "Background: Chromatin immunoprecipitation coupled to next generation\nsequencing (ChIP-Seq) is a widely used technique to investigate the function of\nchromatin-related proteins in a genome-wide manner. ChIP-Seq generates large\nquantities of data which can be difficult to process and analyse, particularly\nfor organisms with contig based genomes. Contig-based genomes often have poor\nannotations for cis-elements, for example enhancers, that are important for\ngene expression. Poorly annotated genomes make a comprehensive analysis of\nChIP-Seq data difficult and as such standardized analysis pipelines are\nlacking. Methods: We report a computational pipeline that utilizes traditional\nHigh-Performance Computing techniques and open source tools for processing and\nanalysing data obtained from ChIP-Seq. We applied our computational pipeline\n\"Rapid Analysis of ChIP-Seq data\" (RACS) to ChIP-Seq data that was generated in\nthe model organism Tetrahymena thermophila, an example of an organism with a\ngenome that is available in contigs. Results: To test the performance and\nefficiency of RACs, we performed control ChIP-Seq experiments allowing us to\nrapidly eliminate false positives when analyzing our previously published data\nset. Our pipeline segregates the found read accumulations between genic and\nintergenic regions and is highly efficient for rapid downstream analyses.\nConclusions: Altogether, the computational pipeline presented in this report is\nan efficient and highly reliable tool to analyze genome-wide ChIP-Seq data\ngenerated in model organisms with contig-based genomes.\n  RACS is an open source computational pipeline available to download from:\nhttps://bitbucket.org/mjponce/racs --or--\nhttps://gitrepos.scinet.utoronto.ca/public/?a=summary&p=RACS", "category": "q-bio.GN"}, {"title": "RNASeqR: an R package for automated two-group RNA-Seq analysis workflow", "abstract": "RNA-Seq analysis has revolutionized researchers' understanding of the\ntranscriptome in biological research. Assessing the differences in\ntranscriptomic profiles between tissue samples or patient groups enables\nresearchers to explore the underlying biological impact of transcription.\nRNA-Seq analysis requires multiple processing steps and huge computational\ncapabilities. There are many well-developed R packages for individual steps;\nhowever, there are few R/Bioconductor packages that integrate existing software\ntools into a comprehensive RNA-Seq analysis and provide fundamental end-to-end\nresults in pure R environment so that researchers can quickly and easily get\nfundamental information in big sequencing data. To address this need, we have\ndeveloped the open source R/Bioconductor package, RNASeqR. It allows users to\nrun an automated RNA-Seq analysis with only six steps, producing essential\ntabular and graphical results for further biological interpretation. The\nfeatures of RNASeqR include: six-step analysis, comprehensive visualization,\nbackground execution version, and the integration of both R and command-line\nsoftware. RNASeqR provides fast, light-weight, and easy-to-run RNA-Seq analysis\npipeline in pure R environment. It allows users to efficiently utilize popular\nsoftware tools, including both R/Bioconductor and command-line tools, without\npredefining the resources or environments. RNASeqR is freely available for\nLinux and macOS operating systems from Bioconductor\n(https://bioconductor.org/packages/release/bioc/html/RNASeqR.html).", "category": "q-bio.GN"}, {"title": "Tumor Microenvironment-based Gene Signatures Divides Novel Immune and Stromal Subgroup Classification of Lung Adenocarcinoma", "abstract": "Tumor microenvironment has complex effects on tumorigenesis and metastasis.\nHowever, there is still a lack of comprehensive understanding of the\nrelationship among molecular and cellular characteristics in tumor\nmicroenvironment, clinical prognosis and immunotherpy response. In this study,\nthe immune and stromal (non-immune) signatures of tumor microenvironment were\nintegrated to identify novel subgroups of lung adenocarcinoma by\neigendecomposition and extraction algorithms of bioinformatics and machine\nlearning, such as non-negative matrix factorization and multitask learning.\nTumors were classified into 4 groups according to the activation of immunity\nand stroma by novel signatures. The 4 groups had different mutation landscape,\nmolecular, cellular characteristics and prognosis, which have been validation\nin 6 independent data sets containing 1551 patients. High-immune and\nlow-stromal activation group links to high immunocyte infiltration, high\nimmunocompetence, low fibroblasts, endothelial cells, collagen, laminin, tumor\nmutation burden, and better overall survival. We developed a novel model based\non tumor microenvironment by integrating immune and stromal activation, namely\nPMBT (prognostic model based on tumor microenvironment). The PMBT showed the\nvalue to predict overall survival and immunotherapy responses.", "category": "q-bio.GN"}, {"title": "ReadsMap: a new tool for high precision mapping of DNAseq and RNAseq read sequences", "abstract": "There are currently plenty of programs available for mapping short sequences\n(reads) to a genome. Most of them, however, including such popular and actively\ndeveloped programs as Bowtie, BWA, TopHat and many others, are based on\nBurrows-Wheeler Transform (BWT) algorithm. This approach is very effective for\nmapping high-homology reads, but runs into problems when mapping reads with\nhigh level of errors or SNP. Also it has problems with mapping RNASeq spliced\nreads (such as reads that aligning with gaps corresponding intron sequences),\nthe kind that is essential for finding introns and alternative splicing gene\nisoforms. Meanwhile, finding intron positions is the most important task for\ndetermining the gene structure, and especially alternatively spliced variants\nof genes. In this paper, we propose a new algorithm that involves hashing\nreference genome. ReadsMap program, implementing such algorithm, demonstrate\nvery high-accuracy mapping of large number of short reads to one or more\ngenomic contigs. It is achieved mostly by better alignment of very short parts\nof reads separated by long introns with accounting information from mapping\nother reads containing the same intron inserted between bigger blocks.\nAvailability and implementation: ReadsMap is implemented in C. It is\nincorporated in Fgenesh++ gene identification pipeline and is freely available\nto academic users at Softberry web server www.softberry.com.", "category": "q-bio.GN"}, {"title": "Transcriptomic Causal Networks identified patterns of differential gene regulation in human brain from Schizophrenia cases versus controls", "abstract": "Common and complex traits are the consequence of the interaction and\nregulation of multiple genes simultaneously, which work in a coordinated way.\nHowever, the vast majority of studies focus on the differential expression of\none individual gene at a time. Here, we aim to provide insight into the\nunderlying relationships of the genes expressed in the human brain in cases\nwith schizophrenia (SCZ) and controls. We introduced a novel approach to\nidentify differential gene regulatory patterns and identify a set of essential\ngenes in the brain tissue. Our method integrates genetic, transcriptomic, and\nHi-C data and generates a transcriptomic-causal network. Employing this\napproach for analysis of RNA-seq data from CommonMind Consortium, we identified\ndifferential regulatory patterns for SCZ cases and control groups to unveil the\nmechanisms that control the transcription of the genes in the human brain. Our\nanalysis identified modules with a high number of SCZ-associated genes as well\nas assessing the relationship of the hubs with their down-stream genes in both,\ncases and controls. In addition, the results identified essential genes for\nbrain function and suggested new genes putatively related to SCZ.", "category": "q-bio.GN"}, {"title": "A multi-modal neural network for learning cis and trans regulation of stress response in yeast", "abstract": "Deciphering gene regulatory networks is a central problem in computational\nbiology. Here, we explore the use of multi-modal neural networks to learn\npredictive models of gene expression that include cis and trans regulatory\ncomponents. We learn models of stress response in the budding yeast\nSaccharomyces cerevisiae. Our models achieve high performance and substantially\noutperform other state-of-the-art methods such as boosting algorithms that use\npre-defined cis-regulatory features. Our model learns several cis and trans\nregulators including well-known master stress response regulators. We use our\nmodels to perform in-silico TF knock-out experiments and demonstrate that\nin-silico predictions of target gene changes correlate with the results of the\ncorresponding TF knockout microarray experiment.", "category": "q-bio.GN"}, {"title": "Reading tea leaves? Polygenic scores and differences in traits among groups", "abstract": "In the past decade, Genome-Wide Association Studies (GWAS) have delivered an\nincreasingly broad view of the genetic basis of human phenotypic variation. One\nof the major developments from GWAS is polygenic scores, a genetic predictor of\nan individual's genetic predisposition towards a trait constructed from GWAS.\nThe success of GWAS and polygenic scores seems to suggest that we will soon be\nable to settle debates about whether phenotypic differences among groups are\ndriven in part by genetics. However, answering these questions is more\ncomplicated than it seems at first glance and touches on many old issues about\nthe interpretation of human genetic variation. In this perspective piece, I\noutline the ways in which issues of causality, stratification,\ngene-by-environment interactions, and divergence among groups all complicate\nthe interpretation of among-population polygenic score differences.", "category": "q-bio.GN"}, {"title": "Organizing genome engineering for the gigabase scale", "abstract": "Engineering the entire genome of an organism enables large-scale changes in\norganization, function, and external interactions, with significant\nimplications for industry, medicine, and the environment. Improvements to DNA\nsynthesis and organism engineering are already enabling substantial changes to\norganisms with megabase genomes, such as Escherichia coli and Saccharomyces\ncerevisiae. Simultaneously, recent advances in genome-scale modeling are\nincreasingly informing the design of metabolic networks. However, major\nchallenges remain for integrating these and other relevant technologies into\nworkflows that can scale to the engineering of gigabase genomes.\n  In particular, we find that a major under-recognized challenge is\ncoordinating the flow of models, designs, constructs, and measurements across\nthe large teams and complex technological systems that will likely be required\nfor gigabase genome engineering. We recommend that the community address these\nchallenges by 1) adopting and extending existing standards and technologies for\nrepresenting and exchanging information at the gigabase genomic scale, 2)\ndeveloping new technologies to address major open questions around data\ncuration and quality control, 3) conducting fundamental research on the\nintegration of modeling and design at the genomic scale, and 4) developing new\nlegal and contractual infrastructure to better enable collaboration across\nmultiple institutions.", "category": "q-bio.GN"}, {"title": "Autism spectrum disorder: a neuro-immunometabolic hypothesis of the developmental origins", "abstract": "Fetal neuroinflammation and prenatal stress (PS) may contribute to lifelong\nneurological disabilities. Astrocytes and microglia, among the brain's\nnon-neuronal glia cell populations, play a pivotal role in neurodevelopment,\npredisposition to and initiation of disease throughout lifespan. One of the\nmost common neurodevelopmental disorders manifesting between 1-4 years of age\nis autism spectrum disorder (ASD). A pathological glial-neuronal interplay is\nthought to increase the risk for clinical manifestation of ASD in at-risk\nchildren, but the mechanisms remain poorly understood and integrative,\nmulti-scale models are needed. We propose a model that integrates the data\nacross the scales of physiological organization, from genome to phenotype, and\nprovides a foundation to explain the disparate findings on the genomic level.\nWe hypothesize that via gene-environment interactions, fetal neuroinflammation\nand PS may reprogram glial immunometabolic phenotypes that impact\nneurodevelopment and neurobehavior. Drawing on genomic data from the recently\npublished series of ovine and rodent glial transcriptome analyses with fetuses\nexposed to neuroinflammation or PS, we conduct an analysis on the Simons\nFoundation Autism Research Initiative (SFARI) Gene database. We confirm 21 gene\nhits. Using unsupervised statistical network analysis, we then identify six\nclusters of probable protein-protein interactions mapping onto the\nimmunometabolic and stress response networks and epigenetic memory. These\nfindings support our hypothesis. We discuss the implications for ASD etiology,\nearly detection, and novel therapeutic approaches. We conclude with delineation\nof the next steps to verify our model on the individual gene level in an\nassumption-free manner.", "category": "q-bio.GN"}, {"title": "Whole genome sequencing identifies putative associations between genomic polymorphisms and clinical response to the antiepileptic drug levetiracetam", "abstract": "In the context of pharmacogenomics, whole genome sequencing provides a\npowerful approach for identifying correlations between response variability to\nspecific drugs and genomic polymorphisms in a population, in an unbiased\nmanner. In this study, we employed whole genome sequencing of DNA samples from\npatients showing extreme response (n=72) and non-response (n=27) to the\nantiepileptic drug levetiracetam, in order to identify genomic variants that\nunderlie response to the drug. Although no common SNP (MAF>5%) crossed the\nconventional genome-wide significance threshold of 5e-8, we found common\npolymorphisms in genes SPNS3, HDC, MDGA2, NSG1 and RASGEF1C, which collectively\npredict clinical response to levetiracetam in our cohort with ~91% predictive\naccuracy. Among these genes, HDC, NSG1, MDGA2 and RASGEF1C are potentially\nimplicated in synaptic neurotransmission, while SPNS3 is an atypical solute\ncarrier transporter homologous to SV2A, the known molecular target of\nlevetiracetam. Furthermore, we performed gene- and pathway-based statistical\nanalysis on sets of rare and low-frequency variants (MAF<5%) and we identified\nassociations between the following genes or pathways and response to\nlevetiracetam: a) genes PRKCB and DLG2, which are involved in glutamatergic\nneurotransmission, a known target of anticonvulsants, including levetiracetam;\nb) genes FILIP1 and SEMA6D, which are involved in axon guidance and modelling\nof neural connections; and c) pathways with a role in synaptic\nneurotransmission, such as WNT5A-dependent internalization of FZD4 and\ndisinhibition of SNARE formation. In summary, our approach to utilise whole\ngenome sequencing on subjects with extreme response phenotypes is a feasible\nroute to generate plausible hypotheses for investigating the genetic factors\nunderlying drug response variability in cases of pharmaco-resistant epilepsy.", "category": "q-bio.GN"}, {"title": "Identification of Biomarkers Driving Blood Cell Development", "abstract": "A blood cell lineage consists of several consecutive developmental stages\nfrom the pluripotent or multipotent stem cell to a particular stage of\nterminally differentiated cells. There is considerable interest in identifying\nthe key regulatory genes that govern blood cell development from the gene\nexpression data without considering the underlying network between\ntranscription factors (TFs) and their target genes. In this study, we introduce\na novel expression pattern that key regulators expose along the differentiation\npath. We deploy this pattern to identify the cell-specific key regulators\nresponsible for the development. As proof of concept, we consider this approach\nto data on six developmental stages from mouse embryonic stem cells to\nterminally differentiated macrophages.", "category": "q-bio.GN"}, {"title": "A Common Gene Expression Signature Analysis Method for Multiple Types of Cancer", "abstract": "Mining gene expression profiles has proven valuable for identifying\nsignatures serving as surrogates of cancer phenotypes. However, the\nsimilarities of such signatures across different cancer types have not been\nstrong enough to conclude that they represent a universal biological mechanism\nshared among multiple cancer types. Here we describe a network-based approach\nthat explores gene-to-gene connections in multiple cancer datasets while\nmaximizing the overall association of the subnetwork with clinical outcomes.\nWith the dataset of The Cancer Genome Atlas (TCGA), we studied the\ncharacteristics of common gene expression of three types of cancers: Rectum\nadenocarcinoma (READ), Breast invasive carcinoma (BRCA) and Colon\nadenocarcinoma (COAD). By analyzing several pairs of highly correlated genes\nafter filtering and clustering work, we found that the co-expressed genes\nacross multiple types of cancers point to particular biological mechanisms\nrelated to cancer cell progression , suggesting that they represent important\nattributes of cancer in need of being elucidated for potential applications in\ndiagnostic, prognostic and therapeutic products applicable to multiple cancer\ntypes.", "category": "q-bio.GN"}, {"title": "DNA methylation heterogeneity induced by collaborations between enhancers", "abstract": "During mammalian embryo development, reprogramming of DNA methylation plays\nimportant roles in the erasure of parental epigenetic memory and the\nestablishment of na\\\"{i}ve pluripogent cells. Multiple enzymes that regulate\nthe processes of methylation and demethylation work together to shape the\npattern of genome-scale DNA methylation and guid the process of cell\ndifferentiation. Recent availability of methylome information from single-cell\nwhole genome bisulfite sequencing (scBS-seq) provides an opportunity to study\nDNA methylation dynamics in the whole genome in individual cells, which reveal\nthe heterogeneous methylation distributions of enhancers in embryo stem cells\n(ESCs). In this study, we developed a computational model of enhancer\nmethylation inheritance to study the dynamics of genome-scale DNA methylation\nreprogramming during exit from pluripotency. The model enables us to track\ngenome-scale DNA methylation reprogramming at single-cell level during the\nembryo development process, and reproduce the DNA methylation heterogeneity\nreported by scBS-seq. Model simulations show that DNA methylation heterogeneity\nis an intrinsic property driven by cell division along the development process,\nand the collaboration between neighboring enhancers is required for\nheterogeneous methylation. Our study suggest that the mechanism of genome-scale\noscillation proposed by Rulands et al. (2018) might not necessary to the DNA\nmethylation during exit from pluripotency.", "category": "q-bio.GN"}, {"title": "Phylogenetic analyses of the severe acute respiratory syndrome coronavirus 2 reflected the several routes of introduction to Taiwan, the United States, and Japan", "abstract": "Worldwide Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)\ninfection is disrupting in the economy and anxiety of people. The public\nanxiety has increased the psychological burden on government and healthcare\nprofessionals, resulting in a government worker suicide in Japan. The terrified\npeople are asking the government for border measures. However, are border\nmeasures possible for this virus? By analyzing 48 almost complete virus genome\nsequences, we found out that the viruses that invaded Taiwan, the United\nStates, and Japan were introduced independently. We identified thirteen\nparsimony-informative sites and three groups (CTC, TCC, and TCT). Viruses found\noutside China did not form a monophyletic clade, opposite to previous study.\nThese results suggest the difficulty of implementing effective border measures\nagainst this virus.", "category": "q-bio.GN"}, {"title": "Phylogenetic Study of 2019-nCoV by Using Alignment Free Method (Evolutionary Bifurcation of Novel Coronavirus Mutants)", "abstract": "The phylogenetic tree of SARS-CoV-2 (nCov-19) viruses is reconstructed\naccording to the similarity of genome sequences. The tree topology of\nBetacoronavirus is remarkably consistent with biologist's systematics. Because\nthe tree construction contains enough information about virus mutants, it is\nsuitable to study the evolutionary relationship between novel coronavirus\nmutants transmitted among humans. The emergences of 14 kinds of main mutants\nare studied and these strains can be classified as eight bifurcations of the\nphylogenetic tree. It is found that there exist three types of virus mutations,\nnamely, the mutation among sub-branches of the same branch, the off-root\nmutation and the root-oriented mutation between large branches of the tree.\nFrom the point of the relation between viral mutation and host selection we\nfound that individuals with low immunity provide a special environment for the\npositive natural selection of virus evolution. It gives a mechanism to explain\nwhy large mutations between two distant branches generally occur in the nCov-19\nphylogenetic tree. The finding is helpful to formulate strategies to control\nthe spread of COVID-19.", "category": "q-bio.GN"}, {"title": "The design and construction of reference pangenome graphs", "abstract": "The recent advances in sequencing technologies enables the assembly of\nindividual genomes to the reference quality. How to integrate multiple genomes\nfrom the same species and to make the integrated representation accessible to\nbiologists remain an open challenge. Here we propose a graph-based data model\nand associated formats to represent multiple genomes while preserving the\ncoordinate of the linear reference genome. We implemented our ideas in the\nminigraph toolkit and demonstrate that we can efficiently construct a pangenome\ngraph and compactly encode tens of thousands of structural variants missing\nfrom the current reference genome.", "category": "q-bio.GN"}, {"title": "Analysis of genetic differences between psychiatric disorders: Exploring pathways and cell-types/tissues involved and ability to differentiate the disorders by polygenic scores", "abstract": "Although displaying genetic correlations, psychiatric disorders are\nclinically defined as categorical entities as they each have distinguishing\nclinical features and may involve different treatments. Identifying\ndifferential genetic variations between these disorders may reveal how the\ndisorders differ biologically and help to guide more personalized treatment.\n  Here we presented a comprehensive analysis to identify genetic markers\ndifferentially associated with various psychiatric disorders/traits based on\nGWAS summary statistics, covering 18 psychiatric traits/disorders and 26\ncomparisons. We also conducted comprehensive analysis to unravel the genes,\npathways and SNP functional categories involved, and the cell types and tissues\nimplicated. We also assessed how well one could distinguish between psychiatric\ndisorders by polygenic risk scores (PRS).\n  SNP-based heritabilities (h2SNP) were significantly larger than zero for most\ncomparisons. Based on current GWAS data, PRS have mostly modest power to\ndistinguish between psychiatric disorders. For example, we estimated that AUC\nfor distinguishing schizophrenia from major depressive disorder (MDD), bipolar\ndisorder (BPD) from MDD and schizophrenia from BPD were 0.694, 0.602 and 0.618\nrespectively, while the maximum AUC (based on h2SNP) were 0.763, 0.749 and\n0.726 respectively. We also uncovered differences in each pair of studied\ntraits in terms of their differences in genetic correlation with comorbid\ntraits. For example, clinically-defined MDD appeared to more strongly\ngenetically correlated with other psychiatric disorders and heart disease, when\ncompared to non-clinically-defined depression in UK Biobank.\n  Our findings highlight genetic differences between psychiatric disorders and\nthe mechanisms involved. PRS may aid differential diagnosis of selected\npsychiatric disorders in the future with larger GWAS samples.", "category": "q-bio.GN"}, {"title": "Genome Variant Calling with a Deep Averaging Network", "abstract": "Variant calling, the problem of estimating whether a position in a DNA\nsequence differs from a reference sequence, given noisy, redundant, overlapping\nshort sequences that cover that position, is fundamental to genomics. We\npropose a deep averaging network designed specifically for variant calling. Our\nmodel takes into account the independence of each short input read sequence by\ntransforming individual reads through a series of convolutional layers,\nlimiting the communication between individual reads to averaging and\nconcatenating operations. Training and testing on the precisionFDA Truth\nChallenge (pFDA), we match state of the art overall 99.89 F1 score. Genome\ndatasets exhibit extreme skew between easy examples and those on the decision\nboundary. We take advantage of this property to converge models at 5x the speed\nof standard epoch-based training by skipping easy examples during training. To\nfacilitate future work, we release our code, trained models and pre-processed\npublic domain datasets.", "category": "q-bio.GN"}, {"title": "A framework to decipher the genetic architecture of combinations of complex diseases: applications in cardiovascular medicine", "abstract": "Genome-wide association studies(GWAS) have proven to be highly useful in\nrevealing the genetic basis of complex diseases. At present, most GWAS are\nstudies of a particular single disease diagnosis against controls. However, in\npractice, an individual is often affected by more than one condition/disorder.\nFor example, patients with coronary artery disease(CAD) are often comorbid with\ndiabetes mellitus(DM). Along a similar line, it is often clinically meaningful\nto study patients with one disease but without a comorbidity. For example,\nobese DM may have different pathophysiology from non-obese DM.\n  Here we developed a statistical framework to uncover susceptibility variants\nfor comorbid disorders (or a disorder without comorbidity), using GWAS summary\nstatistics only. In essence, we mimicked a case-control GWAS in which the cases\nare affected with comorbidities or a disease without a relevant comorbid\ncondition (in either case, we may consider the cases as those affected by a\nspecific subtype of disease, as characterized by the presence or absence of\ncomorbid conditions). We extended our methodology to deal with continuous\ntraits with clinically meaningful categories (e.g. lipids). In addition, we\nillustrated how the analytic framework may be extended to more than two traits.\nWe verified the feasibility and validity of our method by applying it to\nsimulated scenarios and four cardiometabolic (CM) traits. We also analyzed the\ngenes, pathways, cell-types/tissues involved in CM disease subtypes. LD-score\nregression analysis revealed some subtypes may indeed be biologically distinct\nwith low genetic correlations. Further Mendelian randomization analysis found\ndifferential causal effects of different subtypes to relevant complications. We\nbelieve the findings are of both scientific and clinical value, and the\nproposed method may open a new avenue to analyzing GWAS data.", "category": "q-bio.GN"}, {"title": "Estimation of genome size using k-mer frequencies from corrected long reads", "abstract": "The third-generation long reads sequencing technologies, such as PacBio and\nNanopore, have great advantages over second-generation Illumina sequencing in\nde novo assembly studies. However, due to the inherent low base accuracy,\nthird-generation sequencing data cannot be used for k-mer counting and\nestimating genomic profile based on k-mer frequencies. Thus, in current genome\nprojects, second-generation data is also necessary for accurately determining\ngenome size and other genomic characteristics. We show that corrected\nthird-generation data can be used to count k-mer frequencies and estimate\ngenome size reliably, in replacement of using second-generation data.\nTherefore, future genome projects can depend on only one sequencing technology\nto finish both assembly and k-mer analysis, which will largely decrease\nsequencing cost in both time and money. Moreover, we present a fast\nlight-weight tool kmerfreq and use it to perform all the k-mer counting tasks\nin this work. We have demonstrated that corrected third-generation sequencing\ndata can be used to estimate genome size and developed a new open-source C/C++\nk-mer counting tool, kmerfreq, which is freely available at\nhttps://github.com/fanagislab/kmerfreq.", "category": "q-bio.GN"}, {"title": "SOS: Online probability estimation and generation of T and B cell receptors", "abstract": "Recent advances in modelling VDJ recombination and subsequent selection of T\nand B cell receptors provide useful tools to analyze and compare immune\nrepertoires across time, individuals, and tissues. A suite of tools--IGoR [1],\nOLGA [2] and SONIA [3]--have been publicly released to the community that allow\nfor the inference of generative and selection models from high-throughput\nsequencing data. However using these tools requires some scripting or\ncommand-line skills and familiarity with complex datasets. As a result the\napplication of the above models has not been available to a broad audience. In\nthis application note we fill this gap by presenting Simple OLGA & SONIA (SOS),\na web-based interface where users with no coding skills can compute the\ngeneration and post-selection probabilities of their sequences, as well as\ngenerate batches of synthetic sequences. The application also functions on\nmobile phones.", "category": "q-bio.GN"}, {"title": "Coronavirus SARS-CoV-2: Analysis of subgenomic mRNA transcription, 3CLpro and PL2pro protease cleavage sites and protein synthesis", "abstract": "Coronaviruses have recently caused world-wide severe outbreaks: SARS (Severe\nAcute Respiratory Syndrome) in 2002 and MERS (Middle-East Respiratory Syndrome)\nin 2012. At the end of 2019, a new coronavirus outbreak appeared in Wuhan\n(China) seafood market as first focus of infection, becoming a pandemics in\n2020, spreading mainly into Europe and Asia. Although the virus family is\nwell-known, this specific virus presents considerable differences, as higher\ntransmission rates, being a challenge for diagnostic methods, treatments and\nvaccines. Coronavirus(C++).pro is a C++ application which simulates Coronavirus\nreplication cycle. This software has identified virus type in short times and\nprovided FASTA files of virus proteins, a list of mRNA sequences and secondary\nstructures. Furthermore, the software has identified a list of structural,\nnon-structural and accessory proteins in 2019-nCoV virus genome more similar to\nSARS than to MERS, as several fusion proteins characteristics of this virus\ntype. These results are useful as a first step in order to develop diagnostic\nmethods, new vaccines or antiviral drugs, which could avoid virus replication\nin any stage: fusion inhibitors, RdRp inhibitors and PL2pro/3CLpro protease\ninhibitors.", "category": "q-bio.GN"}, {"title": "HLA predictions from the bronchoalveolar lavage fluid samples of five patients at the early stage of the Wuhan seafood market COVID-19 outbreak", "abstract": "We are in the midst of a global viral pandemic, one with no cure and a high\nmortality rate. The Human Leukocyte Antigen (HLA) gene complex plays a critical\nrole in host immunity. We predicted HLA class I and II alleles from the\ntranscriptome sequencing data prepared from the bronchoalveolar lavage fluid\nsamples of five patients at the early stage of the COVID-19 outbreak. We\nidentified the HLA-I allele A*24:02 in four out of five patients, which is\nhigher than the expected frequency (17.2%) in the South Han Chinese population.\nThe difference is statistically significant with a p-value less than $10^{-4}$.\nOur analysis results may help provide future insights on disease\nsusceptibility.", "category": "q-bio.GN"}, {"title": "LAI-Net: Local-Ancestry Inference with Neural Networks", "abstract": "Local-ancestry inference (LAI), also referred to as ancestry deconvolution,\nprovides high-resolution ancestry estimation along the human genome. In both\nresearch and industry, LAI is emerging as a critical step in DNA sequence\nanalysis with applications extending from polygenic risk scores (used to\npredict traits in embryos and disease risk in adults) to genome-wide\nassociation studies, and from pharmacogenomics to inference of human population\nhistory. While many LAI methods have been developed, advances in computing\nhardware (GPUs) combined with machine learning techniques, such as neural\nnetworks, are enabling the development of new methods that are fast, robust and\neasily shared and stored. In this paper we develop the first neural network\nbased LAI method, named LAI-Net, providing competitive accuracy with\nstate-of-the-art methods and robustness to missing or noisy data, while having\na small number of layers.", "category": "q-bio.GN"}, {"title": "High fidelity epigenetic inheritance: Information theoretic model predicts $k$-threshold filling of histone modifications post replication", "abstract": "Beyond the genetic code, there is another layer of information encoded as\nchemical modifications on histone proteins positioned along the DNA.\nMaintaining these modifications is crucial for survival and identity of cells.\nHow the information encoded in the histone marks gets inherited, given that\nonly half the parental nucleosomes are transferred to each daughter chromatin,\nis a puzzle. We address this problem using ideas from Information theory and\nunderstanding from recent biological experiments. Mapping the replication and\nreconstruction of modifications to equivalent problems in communication, we ask\nhow well an enzyme-machinery can recover information, if they were ideal\ncomputing machines. Studying a parameter regime where realistic enzymes can\nfunction, our analysis predicts that, pragmatically, enzymes may implement a\nthreshold$-k$ filling algorithm which derives from maximum \\`a posteriori\nprobability decoding. Simulations using our method produce modification\npatterns similar to what is observed in recent experiments.", "category": "q-bio.GN"}, {"title": "Identification of Repurposable Drugs and Adverse Drug Reactions for Various Courses of COVID-19 Based on Single-Cell RNA Sequencing Data", "abstract": "Coronavirus disease 2019 (COVID-19) has impacted almost every part of human\nlife worldwide, posing a massive threat to human health. There is no specific\ndrug for COVID-19, highlighting the urgent need for the development of\neffective therapeutics. To identify potentially repurposable drugs, we employed\na systematic approach to mine candidates from U.S. FDA-approved drugs and\npreclinical small-molecule compounds by integrating the gene expression\nperturbation data for chemicals from the Library of Integrated Network-Based\nCellular Signatures project with a publicly available single-cell RNA\nsequencing dataset from mild and severe COVID-19 patients. We identified 281\nFDA-approved drugs that have the potential to be effective against SARS-CoV-2\ninfection, 16 of which are currently undergoing clinical trials to evaluate\ntheir efficacy against COVID-19. We experimentally tested the inhibitory\neffects of tyrphostin-AG-1478 and brefeldin-a on the replication of the\nsingle-stranded ribonucleic acid (ssRNA) virus influenza A virus. In\nconclusion, we have identified a list of repurposable anti-SARS-CoV-2 drugs\nusing a systems biology approach.", "category": "q-bio.GN"}, {"title": "Longitudinal high-throughput TCR repertoire profiling reveals the dynamics of T cell memory formation after mild COVID-19 infection", "abstract": "COVID-19 is a global pandemic caused by the SARS-CoV-2 coronavirus. T cells\nplay a key role in the adaptive antiviral immune response by killing infected\ncells and facilitating the selection of virus-specific antibodies. However\nneither the dynamics and cross-reactivity of the SARS-CoV-2-specific T cell\nresponse nor the diversity of resulting immune memory are well understood. In\nthis study we use longitudinal high-throughput T cell receptor (TCR) sequencing\nto track changes in the T cell repertoire following two mild cases of COVID-19.\nIn both donors we identified CD4+ and CD8+ T cell clones with transient clonal\nexpansion after infection. The antigen specificity of CD8+ TCR sequences to\nSARS-CoV-2 epitopes was confirmed by both MHC tetramer binding and presence in\nlarge database of SARS-CoV-2 epitope-specific TCRs. We describe characteristic\nmotifs in TCR sequences of COVID-19-reactive clones and show preferential\noccurence of these motifs in publicly available large dataset of repertoires\nfrom COVID-19 patients. We show that in both donors the majority of\ninfection-reactive clonotypes acquire memory phenotypes. Certain T cell clones\nwere detected in the memory fraction at the pre-infection timepoint, suggesting\nparticipation of pre-existing cross-reactive memory T cells in the immune\nresponse to SARS-CoV-2.", "category": "q-bio.GN"}, {"title": "Comprehensive assessment of error correction methods for high-throughput sequencing data", "abstract": "The advent of DNA and RNA sequencing has revolutionized the study of genomics\nand molecular biology. Next generation sequencing (NGS) technologies like\nIllumina, Ion Torrent, SOLiD sequencing etc. have brought about a quick and\ncheap way to sequence genomes. Recently, third generation sequencing (TGS)\ntechnologies like PacBio and Oxford Nanopore Technology (ONT) have also been\ndeveloped. Different technologies use different underlying methods for\nsequencing and are prone to different error rates. Though many tools exist for\nerror correction of sequencing data from NGS and TGS methods, no standard\nmethod is available yet to evaluate the accuracy and effectiveness of these\nerror-correction tools. In this study, we present a Software Package for Error\nCorrection Tool Assessment on nuCLEic acid sequences (SPECTACLE) providing\ncomprehensive algorithms to evaluate error-correction methods for DNA and RNA\nsequencing, for NGS and TGS platforms. We also present a compilation of\nsequencing datasets for Illumina, PacBio and ONT platforms that present\nchallenging scenarios for error-correction tools. Using these datasets and\nSPECTACLE, we evaluate the performance of 23 different error-correction tools\nand present unique and helpful insights into their strengths and weaknesses. We\nhope that our methodology will standardize the evaluation of DNA and RNA\nerror-correction tools in the future.", "category": "q-bio.GN"}, {"title": "Dynamics of B-cell repertoires and emergence of cross-reactive responses in COVID-19 patients with different disease severity", "abstract": "COVID-19 patients show varying severity of the disease ranging from\nasymptomatic to requiring intensive care. Although a number of SARS-CoV-2\nspecific monoclonal antibodies have been identified, we still lack an\nunderstanding of the overall landscape of B-cell receptor (BCR) repertoires in\nCOVID-19 patients. Here, we used high-throughput sequencing of bulk and plasma\nB-cells collected over multiple time points during infection to characterize\nsignatures of B-cell response to SARS-CoV-2 in 19 patients. Using principled\nstatistical approaches, we determined differential features of BCRs associated\nwith different disease severity. We identified 38 significantly expanded clonal\nlineages shared among patients as candidates for specific responses to\nSARS-CoV-2. Using single-cell sequencing, we verified reactivity of BCRs shared\namong individuals to SARS-CoV-2 epitopes. Moreover, we identified natural\nemergence of a BCR with cross-reactivity to SARS-CoV-1 and SARS-CoV-2 in a\nnumber of patients. Our results provide important insights for development of\nrational therapies and vaccines against COVID-19.", "category": "q-bio.GN"}, {"title": "Learning the heterogeneous hypermutation landscape of immunoglobulins from high-throughput repertoire data", "abstract": "Somatic hypermutations of immunoglobulin (Ig) genes occuring during affinity\nmaturation drive B-cell receptors' ability to evolve strong binding to their\nantigenic targets. The landscape of these mutations is highly heterogeneous,\nwith certain regions of the Ig gene being preferentially targeted. However, a\nrigorous quantification of this bias has been difficult because of phylogenetic\ncorrelations between sequences and the interference of selective forces. Here,\nwe present an approach that corrects for these issues, and use it to learn a\nmodel of hypermutation preferences from a recently published large IgH\nrepertoire dataset. The obtained model predicts mutation profiles accurately\nand in a reproducible way, including in the previously uncharacterized\nComplementarity Determining Region 3, revealing that both the sequence context\nof the mutation and its absolute position along the gene are important. In\naddition, we show that hypermutations occurring concomittantly along B-cell\nlineages tend to co-localize, suggesting a possible mechanism for accelerating\naffinity maturation.", "category": "q-bio.GN"}, {"title": "On the Transcriptomic Signature and General Stress State Associated with Aneuploidy", "abstract": "Whether aneuploid cells with diverse karyotypes have any properties in common\nhas a been a subject of intense interest. A recent study by Terhorst et al. (1)\nreinvestigated the common aneuploidy gene expression (CAGE), disputing the\nconclusion of our recent work (2). In this short article, which has been\nsubmitted to PNAS as a Letter to the Editor, we explain our major concerns\nabout Terhorst et al. and why we believe that our previous conclusion stands\nvalid.", "category": "q-bio.GN"}, {"title": "Structural representations of DNA regulatory substrates can enhance sequence-based algorithms by associating functional sequence variants", "abstract": "The nucleotide sequence representation of DNA can be inadequate for resolving\nprotein-DNA binding sites and regulatory substrates, such as those involved in\ngene expression and horizontal gene transfer. Considering that sequence-like\nrepresentations are algorithmically very useful, here we fused over 60\ncurrently available DNA physicochemical and conformational variables into\ncompact structural representations that can encode single DNA binding sites to\nwhole regulatory regions. We find that the main structural components reflect\nkey properties of protein-DNA interactions and can be condensed to the amount\nof information found in a single nucleotide position. The most accurate\nstructural representations compress functional DNA sequence variants by 30% to\n50%, as each instance encodes from tens to thousands of sequences. We show that\na structural distance function discriminates among groups of DNA substrates\nmore accurately than nucleotide sequence-based metrics. As this opens up a\nvariety of implementation possibilities, we develop and test a distance-based\nalignment algorithm, demonstrating the potential of using the structural\nrepresentations to enhance sequence-based algorithms. Due to the bias of most\ncurrent bioinformatic methods to nucleotide sequence representations, it is\npossible that considerable performance increases might still be achievable with\nsuch solutions.", "category": "q-bio.GN"}, {"title": "MOSGA: Modular Open-Source Genome Annotator", "abstract": "The generation of high-quality assemblies, even for large eukaryotic genomes,\nhas become a routine task for many biologists thanks to recent advances in\nsequencing technologies. However, the annotation of these assemblies - a\ncrucial step towards unlocking the biology of the organism of interest - has\nremained a complex challenge that often requires advanced bioinformatics\nexpertise. Here we present MOSGA, a genome annotation framework for eukaryotic\ngenomes with a user-friendly web-interface that generates and integrates\nannotations from various tools. The aggregated results can be analyzed with a\nfully integrated genome browser and are provided in a format ready for\nsubmission to NCBI. MOSGA is built on a portable, customizable, and easily\nextendible Snakemake backend, and thus, can be tailored to a wide range of\nusers and projects. We provide MOSGA as a publicly free available web service\nat https://mosga.mathematik.uni-marburg.de and as a docker container at\nregistry.gitlab.com/mosga/mosga:latest. Source code can be found at\nhttps://gitlab.com/mosga/mosga", "category": "q-bio.GN"}, {"title": "Genome-wide association and transcriptome analysis reveals serum ghrelin to be linked with GFRAL", "abstract": "Objective: Ghrelin is an orexigenic peptide hormone involved in the\nregulation of energy homeostasis, food intake and glucose metabolism. Serum\nlevels increase anticipating a meal and fall afterwards. Underlying genetic\nmechanisms of the ghrelin secretion are unknown. Methods: Total serum ghrelin\nwas measured in 1501 subjects selected from the population-based\nLIFE-ADULT-sample after an overnight fast. A genome-wide association study\n(GWAS) was performed. Gene-based expression association analyses\n(transcriptome-wide association study (TWAS)) were done using MetaXcan.\nResults: In the GWAS, three loci reached genome-wide significance: the\nWW-domain containing the oxidoreductase-gene (WWOX; p=1.80E-10) on chromosome\n16q23.3-24.1 (SNP: rs76823993); the Contactin-Associated Protein-Like 2 gene\n(CNTNAP2; p=9.0E-9) on chromosome 7q35-q36 (SNP: rs192092592) and the Ghrelin\nAnd Obestatin Prepropeptide gene (GHRL; p=2.72E-8) on chromosome 3p25.3 (SNP:\nrs143729751). In the TWAS, serum ghrelin was negatively associated with RNA\nexpression of the GDNF Family Receptor Alpha Like (GFRAL), receptor of the\nanorexigenic Growth Differentiation Factor-15 (GDF15), (z-score=-4.288,\np=1.81E-05). Furthermore, ghrelin was positively associated with Ribosomal\nProtein L36 (RPL36; z-score=4.848, p=1.25E-06). Conclusions: Our findings\nprovide evidence of a functional link between two major players of weight\nregulation, the ghrelin system and the GDF15/GFRAL-pathway.", "category": "q-bio.GN"}, {"title": "Whole-Genome Sequence of the Trypoxylus dichotomus Japanese rhinoceros beetle", "abstract": "The draft whole-genome sequence of the Japanese rhinoceros beetle, Trypoxylus\ndichotomus was obtained using long-read PacBio sequence technology. The final\nassembled genome consisted of 739 Mbp in 2,347 contigs, with 24.5x mean\ncoverage and a G+C content of 35.99%.", "category": "q-bio.GN"}, {"title": "Expanding the phenotype of SCA19/22: Parkinsonism, cognitive impairment and epilepsy", "abstract": "BACKGROUND: Spinocerebellar ataxia types 19 and 22 (SCA19/22) are rare\nconditions in which relatively isolated cerebellar involvement is frequently\nassociated with cognitive impairment. Here, we report on new clinical features\nand provide details of the cognitive profile in two SCA19/22 families.METHODS:\nTwo families displaying an autosomal-dominant form of cerebellar ataxia\nunderwent clinical examinations and genetic testing.RESULTS: In addition to the\nclassical clinical features of SCA, a wide spectrum of cognitive disorders\n(including visuospatial impairments) was observed. Eight patients had mild\nParkinsonism, and five had epilepsy. Genetic testing showed that the KCND3\nmutation (c.679_681delTTC, p.F227del) was present in both families.CONCLUSIONS:\nOur findings broaden the phenotypic spectrum of SCA19/22, and suggest that\nKCND3 should be included in the list of candidate genes for epilepsy,\nParkinsonism and cognitive impairment.", "category": "q-bio.GN"}, {"title": "TMEM240 mutations cause spinocerebellar ataxia 21 with mental retardation and severe cognitive impairment", "abstract": "Autosomal dominant cerebellar ataxia corresponds to a clinically and\ngenetically heterogeneous group of neurodegenerative disorders that primarily\naffect the cerebellum. Here, we report the identification of the causative gene\nin spinocerebellar ataxia 21, an autosomal-dominant disorder previously mapped\nto chromosome 7p21.3-p15.1. This ataxia was firstly characterized in a large\nFrench family with slowly progressive cerebellar ataxia, accompanied by severe\ncognitive impairment and mental retardation in two young children. Following\nthe recruitment of 12 additional young family members, linkage analysis enabled\nus to definitively map the disease locus to chromosome 1p36.33-p36.32. The\ncausative mutation, (c.509C4T/p.P170L) in the transmembrane protein gene\nTMEM240, was identified by whole exome sequencing and then was confirmed by\nSanger sequencing and co-segregation analyses. Index cases from 368 French\nfamilies with autosomal-dominant cerebellar ataxia were also screened for\nmutations. In seven cases, we identified a range of missense mutations\n(c.509C4T/p.P170L, c.239C4T/p.T80M, c.346C4T/p.R116C, c.445G4A/p.E149K,\nc.511C4T/p.R171W), and a stop mutation (c.489C4G/p.Y163*) in the same gene.\nTMEM240 is a small, strongly conserved transmembrane protein of unknown\nfunction present in cerebellum and brain. Spinocerebellar ataxia 21 may be a\nparticular early-onset disease associated with severe cognitive impairment.", "category": "q-bio.GN"}, {"title": "NoisET: Noise learning and Expansion detection of T-cell receptors", "abstract": "High-throughput sequencing of T- and B-cell receptors makes it possible to\ntrack immune repertoires across time, in different tissues, in acute and\nchronic diseases and in healthy individuals. However quantitative comparison\nbetween repertoires is confounded by variability in the read count of each\nreceptor clonotype due to sampling, library preparation, and expression noise.\nWe review methods for accounting for both biological and experimental noise and\npresent an easy-to-use python package NoisET that implements and generalizes a\npreviously developed Bayesian method. It can be used to learn experimental\nnoise models for repertoire sequencing from replicates, and to detect\nresponding clones following a stimulus. We test the package on different\nrepertoire sequencing technologies and datasets. We review how such approaches\nhave been used to identify responding clonotypes in vaccination and disease\ndata. Availability: NoisET is freely available to use with source code at\ngithub.com/statbiophys/NoisET.", "category": "q-bio.GN"}, {"title": "Performance Evaluation of Transcriptomics Data Normalization for Survival Risk Prediction", "abstract": "One pivotal feature of transcriptomics data is the unwanted variations caused\nby disparate experimental handling, known as handling effects. Various data\nnormalization methods were developed to alleviate the adverse impact of\nhandling effects in the setting of differential expression analysis. However,\nlittle research has been done to evaluate their performance in the setting of\nsurvival outcome prediction, an important analysis goal for transcriptomics\ndata in biomedical research. Leveraging a unique pair of datasets for the same\nset of tumor samples-one with handling effects and the other without, we\ndeveloped a benchmarking tool for conducting such an evaluation in microRNA\nmicroarrays. We applied this tool to evaluate the performance of three popular\nnormalization methods-quantile normalization, median normalization, and\nvariance stabilizing normalization-in survival prediction using various\napproaches for model building and designs for sample assignment. We showed that\nhandling effects can have a strong impact on survival prediction, and that\nquantile normalization, a most popular method in current practice, tends to\nunderperform median normalization and variance stabilizing normalization. We\ndemonstrated with a small example the reason for quantile normalization's poor\nperformance in this setting. Our finding highlights the importance of putting\nnormalization evaluation in the context of the downstream analysis setting and\nthe potential of improving the development of survival predictors by applying\nmedian normalization. We make available our benchmarking tool for performing\nsuch evaluation on additional normalization methods in connection with\nprediction modeling approaches.", "category": "q-bio.GN"}, {"title": "Modern tools for annotation of small genomes of non-model eukaryotes", "abstract": "Nowadays, due to the increasing amount of experimental data obtained by\nsequencing, the most interest is focused on determining the functions and\ncharacteristics of its individual parts of the genome instead of determining\nthe nucleotide sequence of the genome. The genome annotation includes the\nidentification of coding and non-coding sequences, determining the structure of\nthe gene and determining the functions of these sequences. Despite the\nsignificant achievements in computational technologies working with sequencing\ndata, there is no general approach to the functional annotation of the genome\nin the reason of the large number of unresolved molecular determination of the\nfunction of some genomes parts. Nevertheless, the scientific community is\ntrying to solve this problem. This review analyzed existing approaches to\neukaryotic genome annotation. This work includes 3 main parts: introduction,\nmain body and discussion. The introduction reflects the development of\nindependent tools and automatic pipelines for annotation of eukaryotic genomes,\nwhich are associated with existing achievements in annotating prokaryotic ones.\nThe main body consists of two distinguished parts, the first one is devoted to\ninstructions for annotating genomes of non-model eukaryotes, and the second\nblock is about recent versions of automatic pipelines that require minimal\nuser's curation. The question of assessing the quality and completeness of the\nannotated genome is noted briefly, and the tools to conduct this analysis are\ndiscussed. Currently, there is no universal automatic software for eukaryotic\ngenome annotation, covering the whole list of tasks, without manual curation or\nusing additional external tools and resources. Thus it leads to the task of\ndeveloping a wider functional and universal protocol for automatic annotation\nof small eukaryotic genomes.", "category": "q-bio.GN"}, {"title": "Polygenic Risk Score in Africa Population: Progress and challenges", "abstract": "Polygenic risk score (PRS) analysis is a powerful method been used to\nestimate an individual's genetic risk towards targeted traits. PRS analysis\ncould be used to obtain evidence of a genetic effect beyond Genome-Wide\nAssociation Studies (GWAS) results i.e. when there are no significant markers.\nPRS analysis has been widely applied to investigate the genetic basis of\nseveral traits including rare diseases. However, the accuracy of PRS analysis\ndepends on the genomic data of the underlying population. For instance, several\nstudies showed that obtaining higher prediction power of PRS analysis is\nchallenging for non-Europeans. In this manuscript, we reviewed the conventional\nPRS methods and their application to sub-saharan Africa communities. We\nconcluded that the limiting factor of applying PRS analysis to sub-saharan\npopulations is the lack of sufficient GWAS data. Also, we recommended\ndeveloping African-specific PRS tools", "category": "q-bio.GN"}, {"title": "Unexpected novel Merbecovirus discoveries in agricultural sequencing datasets from Wuhan, China", "abstract": "In this study we document the unexpected discovery of multiple coronaviruses\nand a BSL-3 pathogen in agricultural cotton and rice sequencing datasets. In\nparticular, we have identified a novel HKU5-related Merbecovirus in a cotton\ndataset sequenced by the Huazhong Agricultural University in 2017. We have also\nfound an infectious clone sequence containing a novel HKU4-related Merbecovirus\nrelated to MERS coronavirus in a rice dataset sequenced by the Huazhong\nAgricultural University in early 2020. Another HKU5-related Merbecovirus, as\nwell as Japanese encephalitis virus, were identified in a cotton dataset\nsequenced by the Huazhong Agricultural University in 2018. An HKU3-related\nBetacoronavirus was found in a Mus musculus sequencing dataset from the Wuhan\nInstitute of Virology in 2017. Finally, a SARS-WIV1-like Betacoronavirus was\nfound in a rice dataset sequenced by the Fujian Agriculture and Forestry\nUniversity in 2017. Using the contaminating reads we have extracted from the\nabove datasets, we were able to assemble complete genomes of two novel\ncoronaviruses which we disclose herein. In light of our findings, we raise\nconcerns about biosafety protocol breaches, as indicated by our discovery of\nmultiple dangerous human pathogens in agricultural sequencing laboratories in\nWuhan and Fouzou City, China.", "category": "q-bio.GN"}, {"title": "Functional annotation of creeping bentgrass protein sequences based on convolutional neural network", "abstract": "Background: Creeping bentgrass (Agrostis soionifera) is a perennial grass of\nGramineae, belonging to cold season turfgrass, but has poor disease resistance.\nUp to now, little is known about the induced systemic resistance (ISR)\nmechanism, especially the relevant functional proteins, which is important to\ndisease resistance of turfgrass. Achieving more information of proteins of\ninfected creeping bentgrass is helpful to understand the ISR mechanism.\nResults: With BDO treatment, creeping bentgrass seedlings were grown, and the\nISR response was induced by infecting Rhizoctonia solani. High-quality protein\nsequences of creeping bentgrass seedlings were obtained. Some of protein\nsequences were functionally annotated according to the database alignment while\na large part of the obtained protein sequences was left non-annotated. To treat\nthe non-annotated sequences, a prediction model based on convolutional neural\nnetwork was established with the dataset from Uniport database in three domains\nto acquire good performance, especially the higher false positive control rate.\nWith established model, the non-annotated protein sequences of creeping\nbentgrass were analyzed to annotate proteins relevant to disease-resistance\nresponse and signal transduction. Conclusions: The prediction model based on\nconvolutional neural network was successfully applied to select good candidates\nof the proteins with functions relevant to the ISR mechanism from the protein\nsequences which cannot be annotated by database alignment. The waste of\nsequence data can be avoided, and research time and labor will be saved in\nfurther research of protein of creeping bentgrass by molecular biology\ntechnology. It also provides reference for other sequence analysis of turfgrass\ndisease-resistance research.", "category": "q-bio.GN"}, {"title": "Integration of Unpaired Single-cell Chromatin Accessibility and Gene Expression Data via Adversarial Learning", "abstract": "Deep learning has empowered analysis for single-cell sequencing data in many\nways and has generated deep understanding about a range of complex cellular\nsystems. As the booming single-cell sequencing technologies brings the surge of\nhigh dimensional data that come from different sources and represent cellular\nsystems with different features, there is an equivalent rise and challenge of\nintegrating single-cell sequence across modalities. Here, we present a novel\nadversarial approach to integrate single-cell chromatin accessibility and gene\nexpression data in a semi-supervised manner. We demonstrate that our method\nsubstantially improves data integration from a simple adversarial domain\nadaption approach, and it also outperforms two state-of-the-art (SOTA) methods.", "category": "q-bio.GN"}, {"title": "New strategies to improve minimap2 alignment accuracy", "abstract": "Summary: We present several recent improvements to minimap2, a versatile\npairwise aligner for nucleotide sequences. Now minimap2 v2.22 can more\naccurately map long reads to highly repetitive regions and align through\ninsertions or deletions up to 100kb by default, addressing major weakness in\nminimap2 v2.18 or earlier.\n  Availability and implementation: https://github.com/lh3/minimap2", "category": "q-bio.GN"}, {"title": "SquiggleFilter: An Accelerator for Portable Virus Detection", "abstract": "The MinION is a recent-to-market handheld nanopore sequencer. It can be used\nto determine the whole genome of a target virus in a biological sample. Its\nRead Until feature allows us to skip sequencing a majority of non-target reads\n(DNA/RNA fragments), which constitutes more than 99% of all reads in a typical\nsample. However, it does not have any on-board computing, which significantly\nlimits its portability.\n  We analyze the performance of a Read Until metagenomic pipeline for detecting\ntarget viruses and identifying strain-specific mutations. We find new sources\nof performance bottlenecks (basecaller in classification of a read) that are\nnot addressed by past genomics accelerators.\n  We present SquiggleFilter, a novel hardware accelerated dynamic time warping\n(DTW) based filter that directly analyzes MinION's raw squiggles and filters\neverything except target viral reads, thereby avoiding the expensive\nbasecalling step. We show that our 14.3W 13.25mm2 accelerator has 274X greater\nthroughput and 3481X lower latency than existing GPU-based solutions while\nconsuming half the power, enabling Read Until for the next generation of\nnanopore sequencers.", "category": "q-bio.GN"}, {"title": "Analysis of pangolin metagenomic datasets reveals significant contamination, raising concerns for pangolin CoV host attribution", "abstract": "Metagenomic datasets from pangolin tissue specimens have previously yielded\nSARS-related coronaviruses which show high homology in their receptor binding\ndomain to SARS-CoV-2, suggesting a potential zoonotic source for this feature\nof the human virus, possibly via recombination (Liu et al. 2019, Lam et al.\n2020, Xiao et al. 2020, Liu et al. 2020). Here we re-examine these published\ndatasets. We report that only a few pangolin samples were found to contain\ncoronavirus reads, and even then in low abundance, while other non-pangolin\nhosted viruses were present in higher abundance. We also discovered extensive\ncontamination with human, rodent, and other mammalian gene sequences, which was\na surprising finding. Furthermore, we uncovered a number of pangolin CoV\nsequences embedded in standard laboratory cloning vectors, which suggests the\npangolin specimens could have been contaminated with sequences derived from\nsynthetic biology experiments. Finally, we discover a third pangolin dataset\n(He et al. 2022) with low levels of SARSr-CoV sequences and unambiguous\nextensive contamination of several pangolin samples. For these reasons, we find\nit unlikely that the pangolins in question had a coronavirus infection while\nalive, and all current versions of the cited papers claiming a zoonotic\ninfection of pangolins with a SARS-r CoV require substantial corrections and\nshould be retracted until such corrections are made.", "category": "q-bio.GN"}, {"title": "Transcriptome Complexities Across Eukaryotes", "abstract": "Genomic complexity is a growing field of evolution, with case studies for\ncomparative evolutionary analyses in model and emerging non-model systems.\nUnderstanding complexity and the functional components of the genome is an\nuntapped wealth of knowledge ripe for exploration. With the \"remarkable lack of\ncorrespondence\" between genome size and complexity, there needs to be a way to\nquantify complexity across organisms. In this study we use a set of complexity\nmetrics that allow for evaluation of changes in complexity using TranD. We\nascertain if complexity is increasing or decreasing across transcriptomes and\nat what structural level, as complexity is varied. We define three metrics --\nTpG, EpT, and EpG in this study to quantify the complexity of the transcriptome\nthat encapsulate the dynamics of alternative splicing. Here we compare\ncomplexity metrics across 1) whole genome annotations, 2) a filtered subset of\northologs, and 3) novel genes to elucidate the impacts of ortholog and novel\ngenes in transcriptome analysis. We also derive a metric from Hong et al.,\n2006, Effective Exon Number (EEN), to compare the distribution of exon sizes\nwithin transcripts against random expectations of uniform exon placement. EEN\naccounts for differences in exon size, which is important because novel genes\ndifferences in complexity for orthologs and whole transcriptome analyses are\nbiased towards low complexity genes with few exons and few alternative\ntranscripts. With our metric analyses, we are able to implement changes in\ncomplexity across diverse lineages with greater precision and accuracy than\nprevious cross-species comparisons under ortholog conditioning. These analyses\nrepresent a step forward toward whole transcriptome analysis in the emerging\nfield of non-model evolutionary genomics, with key insights for evolutionary\ninference of complexity changes on deep timescales across the tree of life. We\nsuggest a means to quantify biases generated in ortholog calling and correct\ncomplexity analysis for lineage-specific effects. With these metrics, we\ndirectly assay the quantitative properties of newly formed lineage-specific\ngenes as they lower complexity in transcriptomes.", "category": "q-bio.GN"}, {"title": "Predicting Gene Expression Between Species with Neural Networks", "abstract": "We train a neural network to predict human gene expression levels based on\nexperimental data for rat cells. The network is trained with paired human/rat\nsamples from the Open TG-GATES database, where paired samples were treated with\nthe same compound at the same dose. When evaluated on a test set of held out\ncompounds, the network successfully predicts human expression levels. On the\nmajority of the test compounds, the list of differentially expressed genes\ndetermined from predicted expression levels agrees well with the list of\ndifferentially expressed genes determined from actual human experimental data.", "category": "q-bio.GN"}, {"title": "SpliceCombo: A Hybrid Technique efficiently use for Principal Component Analysis of Splice Site Prediction", "abstract": "The primary step in search of the gene prediction is an identification of the\ncoding region from genomic DNA sequence. Gene structure in the case of a\neukaryotic organism is composed of promoter, intron, start codon, exons, stop\ncodon, etc. Splice site prediction, which separates the junction between exon\nand intron, though the sequence beside. The splice sites have huge\npreservation, however, the precision of the tool exhibits less than 90%. The\nmain objective of this work to exhibits a hybrid technique that efficiently\nimproves the existing gene recognition technique. Therefore to enhance the\nidentification of splice sites, the respective algorithm needs to be improved.\nOver the last decade, the researcher paid more attention to improve the\naccuracy of a predicted model in this domain. Our proposed method, SpliceCombo\ninvolves three stages. At initial stage, which considers the principal\nComponent Analysis, based on the feature extracted. In the intermediate stage,\ni.e.,, the second stage Case- Based Reasoning is done, i.e., feature selection.\nThe third stage uses support vector machine based along with polynomial kernel\nfunction for final classification. In comparison with other methods, the\nproposed SpliceCombo model outperforms other prediction models with respect to\nprediction accuracies. Particularly for donor splice site the methodology\nexhibits sensitivity is 97.25% accurate and specificity is 97.46% accurate. For\nacceptor Splice Site the sensitivity is 96.51% and Specificity is 94.48%\ncorrect.", "category": "q-bio.GN"}, {"title": "ReadsClean: a new approach to error correction of sequencing reads based on alignments clustering", "abstract": "Motivation: Next generation methods of DNA sequencing produce relatively high\nrate of reading errors, which interfere with de novo genome assembly of newly\nsequenced organisms and particularly affect the quality of SNP detection\nimportant for diagnostics of many hereditary diseases. There exists a number of\nprograms developed for correcting errors in NGS reads. Such programs utilize\nvarious approaches and are optimized for different specific tasks, but all of\nthem are far from being able to correct all errors, especially in sequencing\nreads that crossing by repeats and DNA from di/polyploid eukaryotic genomes.\nResults: This paper describes a novel method of error correction based on\nclustering of alignments of similar reads. This method is implemented in\nReadsClean program, which is designed for cleaning Illumina HiSeq sequencing\nreads. We compared ReadsClean to other reads cleaning programs recognized to be\nthe best by several publications. Our sequence assembly tests using actual and\nsimulated sequencing reads show superior results achieved by ReadsClean.\nAvailability and implementation: ReadsClean is implemented as a standalone C\ncode. It is incorporated in an error correction pipeline and is freely\navailable to academic users at Softberry web server www.softberry.com.", "category": "q-bio.GN"}, {"title": "Generalized Method of Moments Estimation for Stochastic Models of DNA Methylation Patterns", "abstract": "With recent advances in sequencing technologies, large amounts of epigenomic\ndata have become available and computational methods are contributing\nsignificantly to the progress of epigenetic research. As an orthogonal approach\nto methods based on machine learning, mechanistic modeling aims at a\ndescription of the mechanisms underlying epigenetic changes. Here, we propose\nan efficient method for parameter estimation for stochastic models that\ndescribe the dynamics of DNA methylation patterns over time. Our method is\nbased on the Generalized Method of Moments (GMM) and gives results with an\naccuracy similar to that of maximum likelihood-based estimation approaches.\nHowever, in contrast to the latter, the GMM still allows an efficient and\naccurate calibration of parameters even if the complexity of the model is\nincreased by considering longer methylation patterns. We show the usefulness of\nour method by applying it to hairpin bisulfite sequencing data from mouse ESCs\nfor varying pattern lengths.", "category": "q-bio.GN"}, {"title": "Turning genome-wide association study findings into opportunities for drug repositioning", "abstract": "Drug development is a very costly and lengthy process, while repositioned or\nrepurposed drugs could be brought into clinical practice within a shorter\ntime-frame and at a much reduced cost. The past decade has observed a massive\ngrowth in the amount of data from genome-wide association studies (GWAS). The\nrich information contained in GWAS data has great potential to guide drug\ndiscovery or repositioning. Here we provide an overview of different\ncomputational approaches which employ GWAS data to guide drug repositioning.\nThese methods include selection of top candidate genes from GWAS as drug\ntargets, deducing drug candidates based on drug-drug and disease-disease\nsimilarity, searching for reversed expression profiles between drugs and\ndiseases, pathway-based methods as well as repositioning based on analysis of\nbiological networks. Each method is illustrated with examples, and their\nrespective strengths and limitations are discussed. Finally we discussed\nseveral areas for future research.", "category": "q-bio.GN"}, {"title": "Identification of key genes related to the mechanism and prognosis of lung squamous cell carcinoma using bioinformatics analysis", "abstract": "Objectives Lung squamous cell carcinoma (LUSC) often diagnosed as advanced\nwith poor prognosis. The mechanisms of its pathogenesis and prognosis require\nurgent elucidation. This study was performed to screen potential biomarkers\nrelated to the occurrence, development and prognosis of LUSC to reveal unknown\nphysiological and pathological processes. Materials and Methods Using\nbioinformatics analysis, the lung squamous cell carcinoma microarray datasets\nfrom the GEO and TCGA databases were analyzed to identify differentially\nexpressed genes(DEGs). Furthermore, PPI and WGCNA network analysis were\nintegrated to identify the key genes closely related to the process of LUSC\ndevelopment. In addition, survival analysis was performed to achieve a\nprognostic model that accomplished a high level of prediction accuracy. Results\nand Conclusion Eighty-five up-regulated and 39 down-regulated genes were\nidentified, on which functional and pathway enrichment analysis was conducted.\nGO analysis demonstrated that up-regulated genes were principally enriched in\nepidermal development and DNA unwinding in DNA replication. Down-regulated\ngenes were mainly involved in cell adhesion, signal transduction and positive\nregulation of inflammatory response. After PPI and WGCNA network analysis,\neight genes, including AURKA, RAD51, TTK, AURKB, CCNA2, TPX2, KPNA2 and KIF23,\nhave been found to play a vital role in LUSC development. The prognostic model\ncontained 20 genes, 18 of which were detrimental to prognosis. The AUC of the\nestablished prognostic model for predicting the survival of patients at 1, 3,\nand 5 years was 0.828, 0.826 and 0.824, respectively. To conclude, this study\nidentified a number of biomarkers of significant interest for additional\ninvestigation of the therapies and methods of prognosis of lung squamous cell\ncarcinoma.", "category": "q-bio.GN"}, {"title": "Indoor microbiome, environmental characteristics and asthma among junior high school students in Johor Bahru, Malaysia", "abstract": "Indoor microbial diversity and composition are suggested to affect the\nprevalence and severity of asthma. In this study, we collected floor dust and\nenvironmental characteristics from 21 classrooms, and health data related to\nasthma symptoms from 309 students, in junior high schools in Johor Bahru,\nMalaysia. Bacterial and fungal composition was characterized by sequencing 16s\nrRNA gene and internal transcribed spacer (ITS) region, and the absolute\nmicrobial concentration was quantified by qPCR. In total, 326 bacterial and 255\nfungal genera were characterized. Five bacterial (Sphingobium, Rhodomicrobium,\nShimwellia, Solirubrobacter, Pleurocapsa) and two fungal (Torulaspora and\nLeptosphaeriaceae) taxa were protective for asthma severity. Two bacterial\ntaxa, Izhakiella and Robinsoniella, were positively associated with asthma\nseverity. Several protective bacterial taxa including Rhodomicrobium,\nShimwellia and Sphingobium has been reported as protective microbes in previous\nstudies, whereas other taxa were first time reported. Environmental\ncharacteristics, such as age of building, size of textile curtain per room\nvolume, occurrence of cockroaches, concentration of house dust mite allergens\ntransferred from homes by the occupants, were involved in shaping the overall\nmicrobial community but not asthma-associated taxa; whereas visible dampness\nand mold, which did not change the overall microbial community for floor dust,\ndecreased the concentration of protective bacteria Rhodomicrobium\n(\\b{eta}=-2.86, p=0.021) of asthma, indicating complex interactions between\nmicrobes, environmental characteristics and asthma symptoms. Overall, this is\nthe first indoor microbiome study to characterize the asthma-associated\nmicrobes and their environmental determinant in tropical area, promoting the\nunderstanding of microbial exposure and respiratory health in this region.", "category": "q-bio.GN"}, {"title": "A genomic dominion with regulatory dependencies on human-specific single-nucleotide changes in Modern Humans", "abstract": "Gene set enrichment analyses of 8,405 genes linked with 35,074 human-specific\n(hs) regulatory single-nucleotide changes (SNCs) revealed the staggering\nbreadth of significant associations with morphological structures,\nphysiological processes, and pathological conditions of Modern Humans.\nSignificant enrichment traits include more than 1,000 anatomically-distinct\nregions of the adult human brain, many different types of human cells and\ntissues, more than 200 common human disorders and more than 1,000 records of\nrare diseases. Thousands of genes connected with regulatory hsSNCs have been\nidentified in this contribution, which represent essential genetic elements of\nthe autosomal inheritance and survival of species phenotypes: a total of 1,494\ngenes linked with either autosomal dominant or recessive inheritance as well as\n2,273 genes associated with premature death, embryonic lethality, as well as\npre-, peri-, neo-, and post-natal lethality of both complete and incomplete\npenetrance. Therefore, thousands of heritable traits and critical genes\nimpacting the offspring survival appear under the human-specific regulatory\ncontrol in genomes of Modern Humans. These observations highlight the\nremarkable translational opportunities afforded by the discovery of genetic\nregulatory loci harboring hsSNCs that are fixed in humans, distinct from other\nprimates, and located in differentially-accessible (DA) chromatin regions\nduring human brain development.", "category": "q-bio.GN"}, {"title": "DomainScope: A disease network based on protein domain connections", "abstract": "Protein domains are highly conserved functional units of proteins. Because\nthey carry functionally significant information, the majority of the coding\ndisease variants are located on domains. Additionally, domains are specific\nunits of the proteins that can be targeted for drug delivery purposes. Here,\nusing information about variants sites associated with diseases, a disease\nnetwork was built, based on their sharing the same domain and domain variation\nsite. The result was 49,990 disease pairs linked by domain variant site and\n533,687 disease pairs that share the same mutated domain. These pairs were\ncompared to disease pairs made using previous methods such as gene identity and\ngene variant site identity, which revealed that over 8,000 of these pairs were\nnot only missing from the gene pairings but also not found commonly together in\nliterature. The disease network was analyzed from their disease subject\ncategories, which when compared to the gene-based disease network revealed that\nthe domain method results in higher number of connections across disease\ncategories versus within a disease category. Further, a study into the drug\nrepurposing possibilities of the disease network created using domain revealed\nthat 16,902 of the disease pairs had a drug reported for one disease but not\nthe other, highlighting the drug repurposing potential of this new methodology.", "category": "q-bio.GN"}, {"title": "Can artificial neural networks supplant the polygene risk score for risk prediction of complex disorders given very large sample sizes?", "abstract": "Genome-wide association studies (GWAS) provide a means of examining the\ncommon genetic variation underlying a range of traits and disorders. In\naddition, it is hoped that GWAS may provide a means of differentiating affected\nfrom unaffected individuals. This has potential applications in the area of\nrisk prediction. Current attempts to address this problem focus on using the\npolygene risk score (PRS) to predict case-control status on the basis of GWAS\ndata. However this approach has so far had limited success for complex traits\nsuch as schizophrenia (SZ). This is essentially a classification problem.\nArtificial neural networks (ANNs) have been shown in recent years to be highly\neffective in such applications. Here we apply an ANN to the problem of\ndistinguishing SZ patients from unaffected controls. We compare the\neffectiveness of the ANN with the PRS in classifying individuals by\ncase-control status based only on genetic data from a GWAS. We use the\nschizophrenia dataset from the Psychiatric Genomics Consortium (PGC) for this\nstudy. Our analysis indicates that the ANN is more sensitive to sample size\nthan the PRS. As larger and larger sample sizes become available, we suggest\nthat ANNs are a promising alternative to the PRS for classification and risk\nprediction for complex genetic disorders.", "category": "q-bio.GN"}, {"title": "LRez: C++ API and toolkit for analyzing and managing Linked-Reads data", "abstract": "Linked-Reads technologies, such as 10x Genomics, combine both the\nhigh-quality and low cost of short-reads sequencing and a long-range\ninformation, through the use of barcodes able to tag reads which originate from\na common long DNA fragment. This technology has been employed in a broad range\nof applications including assembly or phasing of genomes, and structural\nvariant calling. However, to date, no tool or API dedicated to the manipulation\nof Linked-Reads data exist. We introduce LRez, a C++ API and toolkit which\nallows easy management of Linked-Reads data. LRez includes various\nfunctionalities, for computing number of common barcodes between genomic\nregions, extracting barcodes from BAM files, as well as indexing and querying\nboth BAM and FASTQ files to quickly fetch reads or alignments sharing one or\nmultiple barcodes. LRez can thus be used in a broad range of applications\nrequiring barcode processing, in order to improve their performances. LRez is\nimplemented in C++, supported on Linux platforms, and available under AGPL-3.0\nLicense at https://github.com/morispi/LRez.", "category": "q-bio.GN"}, {"title": "COSINE: A Web Server for Clonal and Subclonal Structure Inference and Evolution in Cancer Genomics", "abstract": "Cancers evolve from mutation of a single cell with sequential clonal and\nsubclonal expansion of somatic mutation acquisition. Inferring clonal and\nsubclonal structures from bulk or single cell tumor genomic sequencing data has\na huge impact on cancer evolution studies. Clonal state and mutational order\ncan provide detailed insight into tumor origin and its future development. In\nthe past decade, a variety of methods have been developed for subclonal\nreconstruction using bulk tumor sequencing data. As these methods have been\ndeveloped in different programming languages and using different input data\nformats, their use and comparison can be problematic. Therefore, we established\na web server for clonal and subclonal structure inference and evolution of\ncancer genomic data (COSINE), which included 12 popular subclonal\nreconstruction methods. We decomposed each method via a detailed workflow of\nsingle processing steps with a user-friendly interface. To the best of our\nknowledge, this is the first web server providing online subclonal inference,\nincluding the most popular subclonal reconstruction methods. COSINE is freely\naccessible at www.clab-cosine.net or http://bio.rj.run:48996/cun-web.", "category": "q-bio.GN"}, {"title": "grenepipe: A flexible, scalable, and reproducible pipeline to automate variant and frequency calling from sequence reads", "abstract": "Processing high-throughput DNA sequencing data of individuals or populations\nrequires stringing together independent software tools with many parameters,\noften leading to non-reproducible pipelines and datasets. We developed\ngrenepipe to streamline this data processing, an all-in-one Snakemake workflow\nfrom raw sequencing data to the end product of a table of individuals'\ngenotypes or population frequencies. Our pipeline allows users to select among\na range of popular software tools within a single configuration file,\nautomatically downloads and installs software and dependencies, and runs with\ntwo command calls: to prepare and to run. It is highly optimized for\nscalability in cluster environments and parallel computing, splitting data\ntasks into manageable genomic sections and automatically consolidating the\noutputs. grenepipe is published under the GPL-3 license, and freely available\nat https://github.com/moiexpositoalonsolab/grenepipe.", "category": "q-bio.GN"}, {"title": "LAPIS is a fast web API for massive open virus sequencing databases", "abstract": "Background: Recent epidemic outbreaks such as the SARS-CoV-2 pandemic and the\nmpox outbreak in 2022 have demonstrated the value of genomic sequencing data\nfor tracking the origin and spread of pathogens. Laboratories around the globe\ngenerated new sequences at unprecedented speed and volume and bioinformaticians\ndeveloped new tools and dashboards to analyze this wealth of data. However, a\nmajor challenge that remains is the lack of simple and efficient approaches for\naccessing and processing sequencing data.\n  Results: The Lightweight API for Sequences (LAPIS) facilitates rapid\nretrieval and analysis of genomic sequencing data through a REST API. It\nsupports complex mutation- and metadata-based queries and can perform\naggregation operations on massive datasets. LAPIS is optimized for typical\nquestions relevant to genomic epidemiology. Using a newly-developed in-memory\ndatabase engine, it has a high speed and throughput: between 25 January and 4\nFebruary 2023, the SARS-CoV-2 instance of LAPIS, which contains 14.5 million\nsequences, processed over 20 million requests with a mean response time of 411\nms and a median response time of 1 ms. LAPIS is the core engine behind our\ndashboards on genspectrum.org and we currently maintain public LAPIS instances\nfor SARS-CoV-2 and mpox.\n  Conclusions: Powered by an optimized database engine and available through a\nweb API, LAPIS enhances the accessibility of genomic sequencing data. It is\ndesigned to serve as a common backend for dashboards and analyses with the\npotential to be integrated into common database platforms such as GenBank.", "category": "q-bio.GN"}, {"title": "PhaTYP: Predicting the lifestyle for bacteriophages using BERT", "abstract": "Bacteriophages (or phages), which infect bacteria, have two distinct\nlifestyles: virulent and temperate. Predicting the lifestyle of phages helps\ndecipher their interactions with their bacterial hosts, aiding phages'\napplications in fields such as phage therapy. Because experimental methods for\nannotating the lifestyle of phages cannot keep pace with the fast accumulation\nof sequenced phages, computational method for predicting phages' lifestyles has\nbecome an attractive alternative. Despite some promising results, computational\nlifestyle prediction remains difficult because of the limited known annotations\nand the sheer amount of sequenced phage contigs assembled from metagenomic\ndata. In particular, most of the existing tools cannot precisely predict\nphages' lifestyles for short contigs. In this work, we develop PhaTYP (Phage\nTYPe prediction tool) to improve the accuracy of lifestyle prediction on short\ncontigs. We design two different training tasks, self-supervised and\nfine-tuning tasks, to overcome lifestyle prediction difficulties. We rigorously\ntested and compared PhaTYP with four state-of-the-art methods: DeePhage,\nPHACTS, PhagePred, and BACPHLIP. The experimental results show that PhaTYP\noutperforms all these methods and achieves more stable performance on short\ncontigs. In addition, we demonstrated the utility of PhaTYP for analyzing the\nphage lifestyle on human neonates' gut data. This application shows that PhaTYP\nis a useful means for studying phages in metagenomic data and helps extend our\nunderstanding of microbial communities.", "category": "q-bio.GN"}, {"title": "Universal and idiosyncratic characteristic lengths in bacterial genomes", "abstract": "In condensed matter physics, simplified descriptions are obtained by\ncoarse-graining the features of a system at a certain characteristic length,\ndefined as the typical length beyond which some properties are no longer\ncorrelated. From a physics standpoint, in vitro DNA has thus a characteristic\nlength of 300 base pairs (bp), the Kuhn length of the molecule beyond which\ncorrelations in its orientations are typically lost. From a biology standpoint,\nin vivo DNA has a characteristic length of 1000 bp, the typical length of\ngenes. Since bacteria live in very different physico-chemical conditions and\nsince their genomes lack translational invariance, whether larger, universal\ncharacteristic lengths exist is a non-trivial question. Here, we examine this\nproblem by leveraging the large number of fully sequenced genomes available in\npublic databases. By analyzing GC content correlations and the evolutionary\nconservation of gene contexts (synteny) in hundreds of bacterial chromosomes,\nwe conclude that a fundamental characteristic length around 10-20 kb can be\ndefined. This characteristic length reflects elementary structures involved in\nthe coordination of gene expression, which are present all along the genome of\nnearly all bacteria. Technically, reaching this conclusion required us to\nimplement methods that are insensitive to the presence of large idiosyncratic\ngenomic features, which may co-exist along these fundamental universal\nstructures.", "category": "q-bio.GN"}, {"title": "Differential proteomics highlights macrophage-specific responses to amorphous silica nanoparticles", "abstract": "The technological and economic benefits of engineered nanomaterials may be\noffset by their adverse effects on living organisms. One of the highly produced\nnanomaterials under such scrutiny is amorphous silica nanoparticles, which are\nknown to have an appreciable, although reversible, inflammatory potential. This\nis due to their selective toxicity toward macrophages, and it is thus important\nto study the cellular responses of this cell type to silica nanoparticles to\nbetter understand the direct or indirect adverse effects of nanosilica. We have\nhere studied the responses of the RAW264.7 murine macrophage cells and of the\ncontrol MPC11 plasma cells to subtoxic concentrations of nanosilica, using a\ncombination of pro-teomic and targeted approaches. This allowed us to document\nalterations in the cellular cytoskeleton, in the phagocytic capacity of the\ncells as well as their ability to respond to bacterial stimuli. More\nsurprisingly, silica nanoparticles also induce a greater sensitivity of\nmacrophages to DNA alkylating agents, such as styrene oxide, even at doses\nwhich do not induce any appreciable cell death.", "category": "q-bio.GN"}, {"title": "Zinc oxide induces the stringent response and major reorientations in the central metabolism of Bacillus subtilis", "abstract": "Microorganisms, such as bacteria, are one of the first targets of\nnanoparticles in the environment. In this study, we tested the effect of two\nnanoparticles, ZnO and TiO2, with the salt ZnSO4 as the control, on the\nGram-positive bacterium Bacillus subtilis by 2D gel electrophoresis-based\nproteomics. Despite a significant effect on viability (LD50), TiO2 NPs had no\ndetectable effect on the proteomic pattern, while ZnO NPs and ZnSO4\nsignificantly modified B. subtilis metabolism. These results allowed us to\nconclude that the effects of ZnO observed in this work were mainly attributable\nto Zn dissolution in the culture media. Proteomic analysis highlighted twelve\nmodulated proteins related to central metabolism: MetE and MccB (cysteine\nmetabolism), OdhA, AspB, IolD, AnsB, PdhB and YtsJ (Krebs cycle) and XylA,\nYqjI, Drm and Tal (pentose phosphate pathway). Biochemical assays, such as free\nsulfhydryl, CoA-SH and malate dehydrogenase assays corroborated the observed\ncentral metabolism reorientation and showed that Zn stress induced oxidative\nstress, probably as a consequence of thiol chelation stress by Zn ions. The\nother patterns affected by ZnO and ZnSO4 were the stringent response and the\ngeneral stress response. Nine proteins involved in or controlled by the\nstringent response showed a modified expression profile in the presence of ZnO\nNPs or ZnSO4: YwaC, SigH, YtxH, YtzB, TufA, RplJ, RpsB, PdhB and Mbl. An\nincrease in the ppGpp concentration confirmed the involvement of the stringent\nresponse during a Zn stress. All these metabolic reorientations in response to\nZn stress were probably the result of complex regulatory mechanisms including\nat least the stringent response via YwaC.", "category": "q-bio.GN"}, {"title": "NGS Based Haplotype Assembly Using Matrix Completion", "abstract": "We apply matrix completion methods for haplotype assembly from NGS reads to\ndevelop the new HapSVT, HapNuc, and HapOPT algorithms. This is performed by\napplying a mathematical model to convert the reads to an incomplete matrix and\nestimating unknown components. This process is followed by quantizing and\ndecoding the completed matrix in order to estimate haplotypes. These algorithms\nare compared to the state-of-the-art algorithms using simulated data as well as\nthe real fosmid data. It is shown that the SNP missing rate and the haplotype\nblock length of the proposed HapOPT are better than those of HapCUT2 with\ncomparable accuracy in terms of reconstruction rate and switch error rate. A\nprogram implementing the proposed algorithms in MATLAB is freely available at\nhttps://github.com/smajidian/HapMC.", "category": "q-bio.GN"}, {"title": "The exon junction complex undergoes a compositional switch that alters mRNP structure and nonsense-mediated mRNA decay activity", "abstract": "The exon junction complex (EJC) deposited upstream of mRNA exon junctions\nshapes structure, composition and fate of spliced mRNA ribonucleoprotein\nparticles (mRNPs). To achieve this, the EJC core nucleates assembly of a\ndynamic shell of peripheral proteins that function in diverse\npost-transcriptional processes. To illuminate consequences of EJC composition\nchange, we purified EJCs from human cells via peripheral proteins RNPS1 and\nCASC3. We show that EJC originates as an SR-rich mega-dalton sized RNP that\ncontains RNPS1 but lacks CASC3. After mRNP export to the cytoplasm and before\ntranslation, the EJC undergoes a remarkable compositional and structural\nremodeling into an SR-devoid monomeric complex that contains CASC3.\nSurprisingly, RNPS1 is important for nonsense-mediated mRNA decay (NMD) in\ngeneral whereas CASC3 is needed for NMD of only select mRNAs. The promotion of\nswitch to CASC3-EJC slows down NMD. Overall, the EJC compositional switch\ndramatically alters mRNP structure and specifies two distinct phases of\nEJC-dependent NMD.", "category": "q-bio.GN"}, {"title": "OLGA: fast computation of generation probabilities of B- and T-cell receptor amino acid sequences and motifs", "abstract": "Motivation: High-throughput sequencing of large immune repertoires has\nenabled the development of methods to predict the probability of generation by\nV(D)J recombination of T- and B-cell receptors of any specific nucleotide\nsequence. These generation probabilities are very non-homogeneous, ranging over\n20 orders of magnitude in real repertoires. Since the function of a receptor\nreally depends on its protein sequence, it is important to be able to predict\nthis probability of generation at the amino acid level. However, brute-force\nsummation over all the nucleotide sequences with the correct amino acid\ntranslation is computationally intractable. The purpose of this paper is to\npresent a solution to this problem.\n  Results: We use dynamic programming to construct an efficient and flexible\nalgorithm, called OLGA (Optimized Likelihood estimate of immunoGlobulin\nAmino-acid sequences), for calculating the probability of generating a given\nCDR3 amino acid sequence or motif, with or without V/J restriction, as a result\nof V(D)J recombination in B or T cells. We apply it to databases of\nepitope-specific T-cell receptors to evaluate the probability that a typical\nhuman subject will possess T cells responsive to specific disease-associated\nepitopes. The model prediction shows an excellent agreement with published\ndata. We suggest that OLGA may be a useful tool to guide vaccine design.\n  Availability: Source code is available at https://github.com/zsethna/OLGA", "category": "q-bio.GN"}, {"title": "Detecting T-cell receptors involved in immune responses from single repertoire snapshots", "abstract": "Hypervariable T-cell receptors (TCR) play a key role in adaptive immunity,\nrecognising a vast diversity of pathogen-derived antigens. High throughput\nsequencing of TCR repertoires (RepSeq) produces huge datasets of T-cell\nreceptor sequences from blood and tissue samples. However, our ability to\nextract clinically relevant information from RepSeq data is limited, mainly\nbecause little is known about TCR-disease associations. Here we present a\nstatistical approach called ALICE (Antigen-specific Lymphocyte Identification\nby Clustering of Expanded sequences) that identifies TCR sequences that are\nactively involved in the current immune response from a single RepSeq sample,\nand apply it to repertoires of patients with a variety of disorders -\nautoimmune disease (ankylosing spondylitis), patients under cancer\nimmunotherapy, or subject to an acute infection (live yellow fever vaccine).\nThe method's robustness is demonstrated by the agreement of its predictions\nwith independent assays, and is supported by its ability to selectively detect\nresponding TCR in the memory but not in the naive subset. ALICE requires no\nlongitudinal data collection nor large cohorts, and is thus directly applicable\nto most RepSeq datasets. Its results facilitate the identification of TCR\nvariants associated with a wide variety of diseases and conditions, which can\nbe used for diagnostics, rational vaccine design and evaluation of the adaptive\nimmune system state.", "category": "q-bio.GN"}, {"title": "Another Look at Statistical Calibration: A Non-Asymptotic Theory and Prediction-Oriented Optimality", "abstract": "We provide another look at the statistical calibration problem in computer\nmodels. This viewpoint is inspired by two overarching practical considerations\nof computer models: (i) many computer models are inadequate for perfectly\nmodeling physical systems, even with the best-tuned calibration parameters;\n(ii) only a finite number of data points are available from the physical\nexperiment associated with a computer model. Following this new line of\nthinking, we provide a non-asymptotic theory and derive a prediction-oriented\ncalibration method. Our calibration method minimizes the predictive mean\nsquared error for a finite sample size with statistical guarantees. We\nintroduce an algorithm to perform the proposed calibration method and connect\nit to existing Bayesian calibration methods. Synthetic and real examples are\nprovided to corroborate the derived theory and illustrate some advantages of\nthe proposed calibration method.", "category": "stat.ME"}, {"title": "Practical Bayesian Modeling and Inference for Massive Spatial Datasets On Modest Computing Environments", "abstract": "With continued advances in Geographic Information Systems and related\ncomputational technologies, statisticians are often required to analyze very\nlarge spatial datasets. This has generated substantial interest over the last\ndecade, already too vast to be summarized here, in scalable methodologies for\nanalyzing large spatial datasets. Scalable spatial process models have been\nfound especially attractive due to their richness and flexibility and,\nparticularly so in the Bayesian paradigm, due to their presence in hierarchical\nmodel settings. However, the vast majority of research articles present in this\ndomain have been geared toward innovative theory or more complex model\ndevelopment. Very limited attention has been accorded to approaches for easily\nimplementable scalable hierarchical models for the practicing scientist or\nspatial analyst. This article is submitted to the Practice section of the\njournal with the aim of developing massively scalable Bayesian approaches that\ncan rapidly deliver Bayesian inference on spatial process that are practically\nindistinguishable from inference obtained using more expensive alternatives. A\nkey emphasis is on implementation within very standard (modest) computing\nenvironments (e.g., a standard desktop or laptop) using easily available\nstatistical software packages without requiring message-parsing interfaces or\nparallel programming paradigms. Key insights are offered regarding assumptions\nand approximations concerning practical efficiency.", "category": "stat.ME"}, {"title": "Predicting outcomes for games of skill by redefining what it means to win", "abstract": "The Elo rating system is a highly successful ranking algorithm for games of\nskill where, by construction, one team wins and the other loses. A primary\nlimitation of the original Elo algorithm is its inability to predict\ninformation beyond a match's win-loss probability. Specifically, the victor is\nawarded the same point bounty if he beats a team by 1 point or 10 points; only\nthe rating difference between the team and its opponent affects the match\nbounty. In this work, we explain that Elo ratings and predictions can be\nnaturally extended to include margin-of-victory information by simply\nredefining \"what it means to win.\" We create ratings for each value of the\nmargin-of-victory and use these ratings to predict the full distribution of\npoint spread outcomes for matches which have not yet been played.", "category": "stat.ME"}, {"title": "A novel approach to estimate the Cox model with temporal covariates and its application to medical cost data", "abstract": "We propose a novel approach to estimate the Cox model with temporal\ncovariates. Our new approach treats the temporal covariates as arising from a\nlongitudinal process which is modeled jointly with the event time. Different\nfrom the literature, the longitudinal process in our model is specified as a\nbounded variational process and determined by a family of Initial Value\nProblems associated with an Ordinary Differential Equation. Our specification\nhas the advantage that only the observation of the temporal covariates at the\ntime to event and the time to event itself are required to fit the model, while\nit is fine but not necessary to have more longitudinal observations. This fact\nmakes our approach very useful for many medical outcome datasets, like the New\nYork State Statewide Planning and Research Cooperative System and the National\nInpatient Sample, where it is important to find the hazard rate of being\ndischarged given the accumulative cost but only the total cost at the discharge\ntime is available due to the protection of patient information. Our estimation\nprocedure is based on maximizing the full information likelihood function. The\nresulting estimators are shown to be consistent and asymptotically normally\ndistributed. Variable selection techniques, like Adaptive LASSO, can be easily\nmodified and incorporated into our estimation procedure. The oracle property is\nverified for the resulting estimator of the regression coefficients.\nSimulations and a real example illustrate the practical utility of the proposed\nmodel. Finally, a couple of potential extensions of our approach are discussed.", "category": "stat.ME"}, {"title": "Stochastic Kriging for Inadequate Simulation Models", "abstract": "Stochastic kriging is a popular metamodeling technique for representing the\nunknown response surface of a simulation model. However, the simulation model\nmay be inadequate in the sense that there may be a non-negligible discrepancy\nbetween it and the real system of interest. Failing to account for the model\ndiscrepancy may conceivably result in erroneous prediction of the real system's\nperformance and mislead the decision-making process. This paper proposes a\nmetamodel that extends stochastic kriging to incorporate the model discrepancy.\nBoth the simulation outputs and the real data are used to characterize the\nmodel discrepancy. The proposed metamodel can provably enhance the prediction\nof the real system's performance. We derive general results for experiment\ndesign and analysis, and demonstrate the advantage of the proposed metamodel\nrelative to competing methods. Finally, we study the effect of Common Random\nNumbers (CRN). The use of CRN is well known to be detrimental to the prediction\naccuracy of stochastic kriging in general. By contrast, we show that the effect\nof CRN in the new context is substantially more complex. The use of CRN can be\neither detrimental or beneficial depending on the interplay between the\nmagnitude of the observation errors and other parameters involved.", "category": "stat.ME"}, {"title": "Bayes Calculations from Quantile Implied Likelihood", "abstract": "In statistical practice, a realistic Bayesian model for a given data set can\nbe defined by a likelihood function that is analytically or computationally\nintractable, due to large data sample size, high parameter dimensionality, or\ncomplex likelihood functional form. This in turn poses challenges to the\ncomputation and inference of the posterior distribution of the model\nparameters. For such a model, a tractable likelihood function is introduced\nwhich approximates the exact likelihood through its quantile function. It is\ndefined by an asymptotic chi-square confidence distribution for a pivotal\nquantity, which is generated by the asymptotic normal distribution of the\nsample quantiles given model parameters. This Quantile Implied Likelihood (QIL)\ngives rise to an approximate posterior distribution which can be estimated by\nusing penalized log-likelihood maximization or any suitable Monte Carlo\nalgorithm. The QIL approach to Bayesian Computation is illustrated through the\nBayesian analysis of simulated and real data sets having sample sizes that\nreach the millions. The analyses involve various models for univariate or\nmultivariate iid or non-iid data, with low or high parameter dimensionality,\nmany of which are defined by intractable likelihoods. The probability models\ninclude the Student's t, g-and-h, and g-and-k distributions; the Bayesian logit\nregression model with many covariates; exponential random graph model, a\ndoubly-intractable model for networks; the multivariate skew normal model, for\nrobust inference of the inverse-covariance matrix when it is large relative to\nthe sample size; and the Wallenius distribution model.", "category": "stat.ME"}, {"title": "Assessing Prediction Error at Interpolation and Extrapolation Points", "abstract": "Common model selection criteria, such as $AIC$ and its variants, are based on\nin-sample prediction error estimators. However, in many applications involving\npredicting at interpolation and extrapolation points, in-sample error cannot be\nused for estimating the prediction error. In this paper new prediction error\nestimators, $tAI$ and $Loss(w_{t})$ are introduced. These estimators generalize\nprevious error estimators, however are also applicable for assessing prediction\nerror in cases involving interpolation and extrapolation. Based on the\nprediction error estimators, two model selection criteria with the same spirit\nas $AIC$ are suggested. The advantages of our suggested methods are\ndemonstrated in simulation and real data analysis of studies involving\ninterpolation and extrapolation in a Linear Mixed Model framework.", "category": "stat.ME"}, {"title": "Randomization Tests that Condition on Non-Categorical Covariate Balance", "abstract": "A benefit of randomized experiments is that covariate distributions of\ntreatment and control groups are balanced on average, resulting in simple\nunbiased estimators for treatment effects. However, it is possible that a\nparticular randomization yields covariate imbalances that researchers want to\naddress in the analysis stage through adjustment or other methods. Here we\npresent a randomization test that conditions on covariate balance by only\nconsidering treatment assignments that are similar to the observed one in terms\nof covariate balance. Previous conditional randomization tests have only\nallowed for categorical covariates, while our randomization test allows for any\ntype of covariate. Through extensive simulation studies, we find that our\nconditional randomization test is more powerful than unconditional\nrandomization tests and other conditional tests. Furthermore, we find that our\nconditional randomization test is valid (1) unconditionally across levels of\ncovariate balance, and (2) conditional on particular levels of covariate\nbalance. Meanwhile, unconditional randomization tests are valid for (1) but not\n(2). Finally, we find that our conditional randomization test is similar to a\nrandomization test that uses a model-adjusted test statistic.", "category": "stat.ME"}, {"title": "INLA goes extreme: Bayesian tail regression for the estimation of high spatio-temporal quantiles", "abstract": "This work has been motivated by the challenge of the 2017 conference on\nExtreme-Value Analysis (EVA2017), with the goal of predicting daily\nprecipitation quantiles at the $99.8\\%$ level for each month at observed and\nunobserved locations. We here develop a Bayesian generalized additive modeling\nframework tailored to estimate complex trends in marginal extremes observed\nover space and time. Our approach is based on a set of regression equations\nlinked to the exceedance probability above a high threshold and to the size of\nthe excess, the latter being modeled using the generalized Pareto (GP)\ndistribution suggested by Extreme-Value Theory. Latent random effects are\nmodeled additively and semi-parametrically using Gaussian process priors, which\nprovides high flexibility and interpretability. Fast and accurate estimation of\nposterior distributions may be performed thanks to the Integrated Nested\nLaplace approximation (INLA), efficiently implemented in the R-INLA software,\nwhich we also use for determining a nonstationary threshold based on a model\nfor the body of the distribution. We show that the GP distribution meets the\ntheoretical requirements of INLA, and we then develop a penalized complexity\nprior specification for the tail index, which is a crucial parameter for\nextrapolating tail event probabilities. This prior concentrates mass close to a\nlight exponential tail while allowing heavier tails by penalizing the distance\nto the exponential distribution. We illustrate this methodology through the\nmodeling of spatial and seasonal trends in daily precipitation data provided by\nthe EVA2017 challenge. Capitalizing on R-INLA's fast computation capacities and\nlarge distributed computing resources, we conduct an extensive cross-validation\nstudy to select model parameters governing the smoothness of trends. Our\nresults outperform simple benchmarks and are comparable to the best-scoring\napproach.", "category": "stat.ME"}, {"title": "Re-thinking non-inferiority: a practical trial design for optimising treatment duration", "abstract": "Background: trials to identify the minimal effective treatment duration are\nneeded in different therapeutic areas, including bacterial infections, TB and\nHepatitis--C. However, standard non-inferiority designs have several\nlimitations, including arbitrariness of non-inferiority margins, choice of\nresearch arms and very large sample sizes.\n  Methods: we recast the problem of finding an appropriate non-inferior\ntreatment duration in terms of modelling the entire duration-response curve\nwithin a pre-specified range. We propose a multi-arm randomised trial design,\nallocating patients to different treatment durations. We use fractional\npolynomials and spline-based methods to flexibly model the duration-response\ncurve. We compare different methods in terms of a scaled version of the area\nbetween true and estimated prediction curves. We evaluate sensitivity to key\ndesign parameters, including sample size, number and position of arms.\n  Results: a total sample size of $\\sim 500$ patients divided into a moderate\nnumber of equidistant arms (5-7) is sufficient to estimate the\nduration-response curve within a $5\\%$ error margin in $95\\%$ of the\nsimulations. Fractional polynomials provide similar or better results than\nspline-based methods in most scenarios.\n  Conclusions: our proposed practical randomised trial design is an alternative\nto standard non-inferiority designs, avoiding many of their limitations, and\nyet being fairly robust to different possible duration-response curves. The\ntrial outcome is the whole duration-response curve, which could be used by\nclinicians and policy makers to make informed decisions, facilitating a move\naway from a forced binary hypothesis testing paradigm.", "category": "stat.ME"}, {"title": "Exceedance-based nonlinear regression of tail dependence", "abstract": "The probability and structure of co-occurrences of extreme values in\nmultivariate data may critically depend on auxiliary information provided by\ncovariates. In this contribution, we develop a flexible generalized additive\nmodeling framework based on high threshold exceedances for estimating\ncovariate-dependent joint tail characteristics for regimes of asymptotic\ndependence and asymptotic independence. The framework is based on suitably\ndefined marginal pretransformations and projections of the random vector along\nthe directions of the unit simplex, which lead to convenient univariate\nrepresentations of multivariate exceedances based on the exponential\ndistribution. Good performance of our estimators of a nonparametrically\ndesigned influence of covariates on extremal coefficients and tail dependence\ncoefficients are shown through a simulation study. We illustrate the usefulness\nof our modeling framework on a large dataset of nitrogen dioxide measurements\nrecorded in France between 1999 and 2012, where we use the generalized additive\nframework for modeling marginal distributions and tail dependence in monthly\nmaxima. Our results imply asymptotic independence of data observed at different\nstations, and we find that the estimated coefficients of tail dependence\ndecrease as a function of spatial distance and show distinct patterns for\ndifferent years and for different types of stations (traffic vs. background).", "category": "stat.ME"}, {"title": "A Wilks' theorem for grouped data", "abstract": "Consider $n$ independent measurements, with the additional information of the\ntimes at which measurements are performed. This paper deals with testing\nstatistical hypotheses when $n$ is large and only a small amount of\nobservations concentrated in short time intervals are relevant to the study. We\ndefine a testing procedure in terms of multiple likelihood ratio (LR)\nstatistics obtained by splitting the observations into groups, and in\naccordance with the following principles: P1) each LR statistic is formed by\ngathering the data included in $G$ consecutive vectors of observations, where\n$G$ is a suitable time window defined a priori with respect to an arbitrary\nchoice of the `origin of time'; P2) the null statistical hypothesis is rejected\nonly if at least $k$ LR statistics are sufficiently small, for a suitable\nchoice of $k$. We show that the application of the classical Wilks' theorem may\nbe affected by the arbitrary choice of the \"origin of time\", in connection with\nP1). We then introduce a Wilks' theorem for grouped data which leads to a\ntesting procedure that overcomes the problem of the arbitrary choice of the\n`origin of time', while fulfilling P1) and P2). Such a procedure is more\npowerful than the corresponding procedure based on Wilks' theorem.", "category": "stat.ME"}, {"title": "The additive hazard estimator is consistent for continuous-time marginal structural models", "abstract": "Marginal structural models (MSMs) allow for causal analysis of longitudinal\ndata. The MSMs were originally developed as discrete time models. Recently,\ncontinuous-time MSMs were presented as a conceptually appealing alternative for\nsurvival analysis. In applied analyses, it is often assumed that the\ntheoretical treatment weights are known, but these weights are usually unknown\nand must be estimated from the data. Here we provide a sufficient condition for\na class of continuous-time MSMs to be consistent even when the weights are\nestimated, and we show how additive hazard models can be used to estimate such\nweights. Our results suggest that the continuous-time weights perform better\nthan IPTW when the underlying treatment process is continuous. Furthermore, we\nmay wish to transform effect estimates of hazards to other scales that are\neasier to interpret causally. We show that a general transformation strategy\ncan be used on weighted cumulative hazard estimates to obtain a range of other\nparameters in survival analysis, and demonstrate how this strategy can be\napplied on data using our R packages ahw and transform.hazards.", "category": "stat.ME"}, {"title": "An Imputation-Consistency Algorithm for High-Dimensional Missing Data Problems and Beyond", "abstract": "Missing data are frequently encountered in high-dimensional problems, but\nthey are usually difficult to deal with using standard algorithms, such as the\nexpectation-maximization (EM) algorithm and its variants. To tackle this\ndifficulty, some problem-specific algorithms have been developed in the\nliterature, but there still lacks a general algorithm. This work is to fill the\ngap: we propose a general algorithm for high-dimensional missing data problems.\nThe proposed algorithm works by iterating between an imputation step and a\nconsistency step. At the imputation step, the missing data are imputed\nconditional on the observed data and the current estimate of parameters; and at\nthe consistency step, a consistent estimate is found for the minimizer of a\nKullback-Leibler divergence defined on the pseudo-complete data. For high\ndimensional problems, the consistent estimate can be found under sparsity\nconstraints. The consistency of the averaged estimate for the true parameter\ncan be established under quite general conditions. The proposed algorithm is\nillustrated using high-dimensional Gaussian graphical models, high-dimensional\nvariable selection, and a random coefficient model.", "category": "stat.ME"}, {"title": "Mixtures of Factor Analyzers with Fundamental Skew Symmetric Distributions", "abstract": "Mixtures of factor analyzers (MFA) provide a powerful tool for modelling\nhigh-dimensional datasets. In recent years, several generalizations of MFA have\nbeen developed where the normality assumption of the factors and/or of the\nerrors was relaxed to allow for skewness in the data. However, due to the form\nof the adopted component densities, the distribution of the factors/errors in\nmost of these models is typically limited to modelling skewness oncentrated in\na single direction. Here, we introduce a more flexible finite mixture of factor\nanalyzers based on the class of scale mixtures of canonical fundamental skew\nnormal (SMCFUSN) distributions. This very general class of skew distributions\ncan capture various types of skewness and asymmetry in the data. In particular,\nthe proposed mixture model of SMCFUSN factor analyzers(SMCFUSNFA) can\nsimultaneously accommodate multiple directions of skewness. As such, it\nencapsulates many commonly used models as special and/or limiting cases, such\nas models of some versions of skew normal and skew t-factor analyzers, and skew\nhyperbolic factor analyzers. For illustration, we focus on the t-distribution\nmember of the class of SMCFUSN distributions, leading to mixtures of canonical\nfundamental skew t-factor analyzers (CFUSTFA). Parameter estimation can be\ncarried out by maximum likelihood via an EM-type algorithm. The usefulness and\npotential of the proposed model are demonstrated using two real datasets.", "category": "stat.ME"}, {"title": "Interpolating Population Distributions using Public-use Data: An Application to Income Segregation using American Community Survey Data", "abstract": "Income segregation measures the extent to which households choose to live\nnear other households with similar incomes. Sociologists theorize that income\nsegregation can exacerbate the impacts of income inequality, and have developed\nindices to measure it at the metro area level, including the information theory\nindex introduced in \\citet{reardon2011income}, and the divergence index\npresented in \\citet{roberto2015divergence}. To study their differences, we\nconstruct both indices using recent American Community Survey (ACS) estimates\nof features of the income distribution. Since the elimination of the decennial\ncensus long form, methods of computing these estimates must be updated to use\nACS estimates and account for survey error. We propose a model-based method to\ninterpolate estimates of features of the income distribution that accounts for\nthis error. This method improves on previous approaches by allowing for the use\nof more types of estimates, and by providing uncertainty quantification. We\napply this method to estimate U.S. census tract-level income distributions\nusing ACS tabulations, and in turn use these to construct both income\nsegregation indices. We find major differences between the two indices in the\nrelative ranking of metro areas, as well as differences in how both indices\ncorrelate with the Gini index.", "category": "stat.ME"}, {"title": "Correlation Estimation System Minimization Compared to Least Squares Minimization in Simple Linear Regression", "abstract": "A general method of minimization using correlation coefficients and order\nstatistics is evaluated relative to least squares procedures in the estimation\nof parameters for normal data in simple linear regression.", "category": "stat.ME"}, {"title": "A Bayesian Approach to Multi-State Hidden Markov Models: Application to Dementia Progression", "abstract": "People are living longer than ever before, and with this arises new\ncomplications and challenges for humanity. Among the most pressing of these\nchallenges is of understanding the role of aging in the development of\ndementia. This paper is motivated by the Mayo Clinic Study of Aging data for\n4742 subjects since 2004, and how it can be used to draw inference on the role\nof aging in the development of dementia. We construct a hidden Markov model\n(HMM) to represent progression of dementia from states associated with the\nbuildup of amyloid plaque in the brain, and the loss of cortical thickness. A\nhierarchical Bayesian approach is taken to estimate the parameters of the HMM\nwith a truly time-inhomogeneous infinitesimal generator matrix, and response\nfunctions of the continuous-valued biomarker measurements are cut-point\nagnostic. A Bayesian approach with these features could be useful in many\ndisease progression models. Additionally, an approach is illustrated for\ncorrecting a common bias in delayed enrollment studies, in which some or all\nsubjects are not observed at baseline. Standard software is incapable of\naccounting for this critical feature, so code to perform the estimation of the\nmodel described below is made available online.", "category": "stat.ME"}, {"title": "More Efficient Estimation for Logistic Regression with Optimal Subsample", "abstract": "In this paper, we propose improved estimation method for logistic regression\nbased on subsamples taken according the optimal subsampling probabilities\ndeveloped in Wang et al. 2018 Both asymptotic results and numerical results\nshow that the new estimator has a higher estimation efficiency. We also develop\na new algorithm based on Poisson subsampling, which does not require to\napproximate the optimal subsampling probabilities all at once. This is\ncomputationally advantageous when available random-access memory is not enough\nto hold the full data. Interestingly, asymptotic distributions also show that\nPoisson subsampling produces a more efficient estimator if the sampling rate,\nthe ratio of the subsample size to the full data sample size, does not converge\nto zero. We also obtain the unconditional asymptotic distribution for the\nestimator based on Poisson subsampling. The proposed approach requires to use a\npilot estimator to correct biases of un-weighted estimators. We further show\nthat even if the pilot estimator is inconsistent, the resulting estimators are\nstill consistent and asymptotically normal if the model is correctly specified.", "category": "stat.ME"}, {"title": "Data-adaptive doubly robust instrumental variable methods for treatment effect heterogeneity", "abstract": "We consider the estimation of the average treatment effect in the treated as\na function of baseline covariates, where there is a valid (conditional)\ninstrument.\n  We describe two doubly robust (DR) estimators: a locally efficient\ng-estimator, and a targeted minimum loss-based estimator (TMLE). These two DR\nestimators can be viewed as generalisations of the two-stage least squares\n(TSLS) method to semi-parametric models that make weaker assumptions. We\nexploit recent theoretical results that extend to the g-estimator the use of\ndata-adaptive fits for the nuisance parameters.\n  A simulation study is used to compare standard TSLS with the two DR\nestimators' finite-sample performance, (1) when fitted using parametric\nnuisance models, and (2) using data-adaptive nuisance fits, obtained from the\nSuper Learner, an ensemble machine learning method.\n  Data-adaptive DR estimators have lower bias and improved coverage, when\ncompared to incorrectly specified parametric DR estimators and TSLS. When the\nparametric model for the treatment effect curve is correctly specified, the\ng-estimator outperforms all others, but when this model is misspecified, TMLE\nperforms best, while TSLS can result in large biases and zero coverage.\n  Finally, we illustrate the methods by reanalysing the COPERS (COping with\npersistent Pain, Effectiveness Research in Self-management) trial to make\ninference about the causal effect of treatment actually received, and the\nextent to which this is modified by depression at baseline.", "category": "stat.ME"}, {"title": "Forecasting under model uncertainty:Non-homogeneous hidden Markov models with Polya-Gamma data augmentation", "abstract": "We consider two-state Non-Homogeneous Hidden Markov Models (NHHMMs) for\nforecasting univariate time series. Given a set of predictors, the time series\nare modeled via predictive regressions with state dependent coefficients and\ntime-varying transition probabilities that depend on the predictors via a\nlogistic function. In a hidden Markov setting, inference for logistic\nregression coefficients becomes complicated and in some cases impossible due to\nconvergence issues. In this paper, we aim to address this problem using a new\nlatent variable scheme that utilizes the P\\'{o}lya-Gamma class of\ndistributions. We allow for model uncertainty regarding the predictors that\naffect the series both linearly -- in the mean -- and non-linearly -- in the\ntransition matrix. Predictor selection and inference on the model parameters\nare based on a MCMC scheme with reversible jump steps. Single-step and\nmultiple-steps-ahead predictions are obtained by the most probable model,\nmedian probability model or a Bayesian Model Averaging approach. Using\nsimulation experiments, we illustrate the performance of our algorithm in\nvarious setups, in terms of mixing properties, model selection and predictive\nability. An empirical study on realized volatility data shows that our\nmethodology gives improved forecasts compared to benchmark models.", "category": "stat.ME"}, {"title": "A Minimum Message Length Criterion for Robust Linear Regression", "abstract": "This paper applies the minimum message length principle to inference of\nlinear regression models with Student-t errors. A new criterion for variable\nselection and parameter estimation in Student-t regression is proposed. By\nexploiting properties of the regression model, we derive a suitable\nnon-informative proper uniform prior distribution for the regression\ncoefficients that leads to a simple and easy-to-apply criterion. Our proposed\ncriterion does not require specification of hyperparameters and is invariant\nunder both full rank transformations of the design matrix and linear\ntransformations of the outcomes. We compare the proposed criterion with several\nstandard model selection criteria, such as the Akaike information criterion and\nthe Bayesian information criterion, on simulations and real data with promising\nresults.", "category": "stat.ME"}, {"title": "Bootstrap validation of links of a minimum spanning tree", "abstract": "We describe two different bootstrap methods applied to the detection of a\nminimum spanning tree obtained from a set of multivariate variables. We show\nthat two different bootstrap procedures provide partly distinct information\nthat can be highly informative about the investigated complex system. Our case\nstudy, based on the investigation of daily returns of a portfolio of stocks\ntraded in the US equity markets, shows the degree of robustness and\ncompleteness of the information extracted with popular information filtering\nmethods such as the minimum spanning tree and the planar maximally filtered\ngraph. The first method performs a \"row bootstrap\" whereas the second method\nperforms a \"pair bootstrap\". We show that the parallel use of the two methods\nis suggested especially for complex systems presenting both a nested\nhierarchical organization together with the presence of global feedback\nchannels.", "category": "stat.ME"}, {"title": "A whitening approach to probabilistic canonical correlation analysis for omics data integration", "abstract": "Background: Canonical correlation analysis (CCA) is a classic statistical\ntool for investigating complex multivariate data. Correspondingly, it has found\nmany diverse applications, ranging from molecular biology and medicine to\nsocial science and finance. Intriguingly, despite the importance and\npervasiveness of CCA, only recently a probabilistic understanding of CCA is\ndeveloping, moving from an algorithmic to a model-based perspective and\nenabling its application to large-scale settings.\n  Results: Here, we revisit CCA from the perspective of statistical whitening\nof random variables and propose a simple yet flexible probabilistic model for\nCCA in the form of a two-layer latent variable generative model. The advantages\nof this variant of probabilistic CCA include non-ambiguity of the latent\nvariables, provisions for negative canonical correlations, possibility of\nnon-normal generative variables, as well as ease of interpretation on all\nlevels of the model. In addition, we show that it lends itself to\ncomputationally efficient estimation in high-dimensional settings using\nregularized inference. We test our approach to CCA analysis in simulations and\napply it to two omics data sets illustrating the integration of gene expression\ndata, lipid concentrations and methylation levels.\n  Conclusions: Our whitening approach to CCA provides a unifying perspective on\nCCA, linking together sphering procedures, multivariate regression and\ncorresponding probabilistic generative models. Furthermore, we offer an\nefficient computer implementation in the \"whitening\" R package available at\nhttps://CRAN.R-project.org/package=whitening .", "category": "stat.ME"}, {"title": "A General Framework For Frequentist Model Averaging", "abstract": "Model selection strategies have been routinely employed to determine a model\nfor data analysis in statistics, and further study and inference then often\nproceed as though the selected model were the true model that were known a\npriori. This practice does not account for the uncertainty introduced by the\nselection process and the fact that the selected model can possibly be a wrong\none. Model averaging approaches try to remedy this issue by combining\nestimators for a set of candidate models. Specifically, instead of deciding\nwhich model is the 'right' one, a model averaging approach suggests to fit a\nset of candidate models and average over the estimators using certain data\nadaptive weights. In this paper we establish a general frequentist model\naveraging framework that does not set any restrictions on the set of candidate\nmodels. It greatly broadens the scope of the existing methodologies under the\nfrequentist model averaging development. Assuming the data is from an unknown\nmodel, we derive the model averaging estimator and study its limiting\ndistributions and related predictions while taking possible modeling biases\ninto account. We propose a set of optimal weights to combine the individual\nestimators so that the expected mean squared error of the average estimator is\nminimized. Simulation studies are conducted to compare the performance of the\nestimator with that of the existing methods. The results show the benefits of\nthe proposed approach over traditional model selection approaches as well as\nexisting model averaging methods.", "category": "stat.ME"}, {"title": "Simultaneous Rank Tests in Analysis of Covariance Based on Pairwise Ranking", "abstract": "Nonparametric tests provide robust and powerful alternatives to the\ncorresponding least squares methods. There are two approaches to nonparametric\npairwise comparisons of treatment effects, the method based on pairwise\nrankings and the method based on overall ranking. The former is generally\nrecommended in the literature because of its strong control of familywise error\nrate. However, this method is developed only for one-way layouts and randomized\ncomplete blocks. By combining the method of aligned ranks and pairwise ranking,\nwe extend the Steel-Dwass pairwise comparisons to the analysis of covariance\nand factorial models for both one-sided and two-sided comparisons as well as\ntesting for treatment versus control. Unlike the traditional two-sample\nstandardization of test statistics, we propose a weighted estimate of the scale\nparameter for ranks and show through simulation that it has superior small\nsample performance by controlling the familywise error rate at nominal level.\nThis method provides an improvement for large sample approximation of\nSteel-Dwass method for one-way layouts. The marginal and joint asymptotic\ndistributions are derived and power comparisons are made with the method of\naligned rank transformation and the least squares method.", "category": "stat.ME"}, {"title": "Estimating Diffusion With Compound Poisson Jumps Based On Self-normalized Residuals", "abstract": "We consider parametric estimation of the continuous part of a class of\nergodic diffusions with jumps based on high-frequency samples. Various papers\npreviously proposed threshold based methods, which enable us to distinguish\nwhether observed increments have jumps or not at each small-time interval,\nhence to estimate the unknown parameters separately. However, a data-adapted\nand quantitative choice of the threshold parameter is known to be a subtle and\nsensitive problem. In this paper, we present a simple alternative based on the\nJarque-Bera normality test for the Euler residuals. Different from the\nthreshold based method, the proposed method does not require any sensitive fine\ntuning, hence is of practical value. It is shown that under suitable conditions\nthe proposed estimator is asymptotically equivalent to an estimator constructed\nby the unobserved fluctuation of the continuous part of the solution process,\nhence is asymptotically efficient. Some numerical experiments are conducted to\nobserve finite-sample performance of the proposed method.", "category": "stat.ME"}, {"title": "Exact and efficient inference for Partial Bayes problems", "abstract": "Bayesian methods are useful for statistical inference. However, real-world\nproblems can be challenging using Bayesian methods when the data analyst has\nonly limited prior knowledge. In this paper we consider a class of problems,\ncalled Partial Bayes problems, in which the prior information is only partially\navailable. Taking the recently proposed Inferential Model approach, we develop\na general inference framework for Partial Bayes problems, and derive both exact\nand efficient solutions. In addition to the theoretical investigation,\nnumerical results and real applications are used to demonstrate the superior\nperformance of the proposed method.", "category": "stat.ME"}, {"title": "Detecting weak signals by combining small P-values in genetic association studies", "abstract": "We approach the problem of combining top-ranking association statistics or\nP-value from a new perspective which leads to a remarkably simple and powerful\nmethod. Statistical methods, such as the Rank Truncated Product (RTP), have\nbeen developed for combining top-ranking associations and this general strategy\nproved to be useful in applications for detecting combined effects of multiple\ndisease components. To increase power, these methods aggregate signals across\ntop ranking SNPs, while adjusting for their total number assessed in a study.\nAnalytic expressions for combined top statistics or P-values tend to be\nunwieldy, which complicates interpretation, practical implementation, and\nhinders further developments. Here, we propose the Augmented Rank Truncation\n(ART) method that retains main characteristics of the RTP but is substantially\nsimpler to implement. ART leads to an efficient form of the adaptive algorithm,\nan approach where the number of top ranking SNPs is varied to optimize power.\nWe illustrate our methods by strengthening previously reported associations of\n$\\mu$-opioid receptor variants with sensitivity to pain.", "category": "stat.ME"}, {"title": "Randomized Empirical Processes and Confidence Bands via Virtual Resampling", "abstract": "Let $X,X_1,X_2,\\cdots$ be independent real valued random variables with a\ncommon distribution function $F$, and consider $\\{X_1,\\cdots,X_N \\}$, possibly\na big concrete data set, or an imaginary random sample of size $N\\geq 1$ on\n$X$. In the latter case, or when a concrete data set in hand is too big to be\nentirely processed, then the sample distribution function $F_N$ and the the\npopulation distribution function $F$ are both to be estimated. This, in this\npaper, is achieved via viewing $\\{X_1,\\cdots,X_N \\}$ as above, as a finite\npopulation of real valued random variables with $N$ labeled units, and sampling\nits indices $\\{1,\\cdots,N \\}$ with replacement $m_N:= \\sum_{i=1}^N w_{i}^{(N)}$\ntimes so that for each $1\\leq i \\leq N$, $w_{i}^{(N)}$ is the count of number\nof times the index $i$ of $X_i$ is chosen in this virtual resampling process.\nThis exposition extends the Doob-Donsker classical theory of weak convergence\nof empirical processes to that of the thus created randomly weighted empirical\nprocesses when $N, m_N \\rightarrow \\infty$ so that $m_N=o(N^2)$.", "category": "stat.ME"}, {"title": "When and when not to use optimal model averaging", "abstract": "Traditionally model averaging has been viewed as an alternative to model\nselection with the ultimate goal to incorporate the uncertainty associated with\nthe model selection process in standard errors and confidence intervals by\nusing a weighted combination of candidate models. In recent years, a new class\nof model averaging estimators has emerged in the literature, suggesting to\ncombine models such that the squared risk, or other risk functions, are\nminimized. We argue that, contrary to popular belief, these estimators do not\nnecessarily address the challenges induced by model selection uncertainty, but\nshould be regarded as attractive complements for the machine learning and\nforecasting literature, as well as tools to identify causal parameters. We\nillustrate our point by means of several targeted simulation studies.", "category": "stat.ME"}, {"title": "Distributionally Robust Mean-Variance Portfolio Selection with Wasserstein Distances", "abstract": "We revisit Markowitz's mean-variance portfolio selection model by considering\na distributionally robust version, where the region of distributional\nuncertainty is around the empirical measure and the discrepancy between\nprobability measures is dictated by the so-called Wasserstein distance. We\nreduce this problem into an empirical variance minimization problem with an\nadditional regularization term. Moreover, we extend recent inference\nmethodology in order to select the size of the distributional uncertainty as\nwell as the associated robust target return rate in a data-driven way.", "category": "stat.ME"}, {"title": "Ultrahigh-dimensional Robust and Efficient Sparse Regression using Non-Concave Penalized Density Power Divergence", "abstract": "We propose a sparse regression method based on the non-concave penalized\ndensity power divergence loss function which is robust against infinitesimal\ncontamination in very high dimensionality. Present methods of sparse and robust\nregression are based on $\\ell_1$-penalization, and their theoretical properties\nare not well-investigated. In contrast, we use a general class of folded\nconcave penalties that ensure sparse recovery and consistent estimation of\nregression coefficients. We propose an alternating algorithm based on the\nConcave-Convex procedure to obtain our estimate, and demonstrate its robustness\nproperties using influence function analysis. Under some conditions on the\nfixed design matrix and penalty function, we prove that this estimator\npossesses large-sample oracle properties in an ultrahigh-dimensional regime.\nThe performance and effectiveness of our proposed method for parameter\nestimation and prediction compared to state-of-the-art are demonstrated through\nsimulation studies.", "category": "stat.ME"}, {"title": "Using Longitudinal Targeted Maximum Likelihood Estimation in Complex Settings with Dynamic Interventions", "abstract": "Longitudinal targeted maximum likelihood estimation (LTMLE) has very rarely\nbeen used to estimate dynamic treatment effects in the context of\ntime-dependent confounding affected by prior treatment when faced with long\nfollow-up times, multiple time-varying confounders, and complex associational\nrelationships simultaneously. Reasons for this include the potential\ncomputational burden, technical challenges, restricted modeling options for\nlong follow-up times, and limited practical guidance in the literature.\nHowever, LTMLE has desirable asymptotic properties, i.e. it is doubly robust,\nand can yield valid inference when used in conjunction with machine learning.\nWe use a topical and sophisticated question from HIV treatment research to show\nthat LTMLE can be used successfully in complex realistic settings and compare\nresults to competing estimators. Our example illustrates the following\npractical challenges common to many epidemiological studies 1) long follow-up\ntime (30 months), 2) gradually declining sample size 3) limited support for\nsome intervention rules of interest 4) a high-dimensional set of potential\nadjustment variables, increasing both the need and the challenge of integrating\nappropriate machine learning methods 5) consideration of collider bias. Our\nanalyses, as well as simulations, shed new light on the application of LTMLE in\ncomplex and realistic settings: we show that (i) LTMLE can yield stable and\ngood estimates, even when confronted with small samples and limited modeling\noptions; (ii) machine learning utilized with a small set of simple learners (if\nmore complex ones can't be fitted) can outperform a single, complex model,\nwhich is tailored to incorporate prior clinical knowledge; (iii) performance\ncan vary considerably depending on interventions and their support in the data,\nand therefore critical quality checks should accompany every LTMLE analysis.", "category": "stat.ME"}, {"title": "A Weighted Likelihood Approach Based on Statistical Data Depths", "abstract": "We propose a general approach to construct weighted likelihood estimating\nequations with the aim of obtain robust estimates. The weight, attached to each\nscore contribution, is evaluated by comparing the statistical data depth at the\nmodel with that of the sample in a given point. Observations are considered\nregular when the ratio of these two depths is close to one, whereas, when the\nratio is large the corresponding score contribution may be downweigthed.\nDetails and examples are provided for the robust estimation of the parameters\nin the multivariate normal model. Because of the form of the weights, we expect\nthat, there will be no downweighting under the true model leading to highly\nefficient estimators. Robustness is illustrated using two real data sets.", "category": "stat.ME"}, {"title": "Robust and sparse Gaussian graphical modeling under cell-wise contamination", "abstract": "Graphical modeling explores dependences among a collection of variables by\ninferring a graph that encodes pairwise conditional independences. For jointly\nGaussian variables, this translates into detecting the support of the precision\nmatrix. Many modern applications feature high-dimensional and contaminated data\nthat complicate this task. In particular, traditional robust methods that\ndown-weight entire observation vectors are often inappropriate as\nhigh-dimensional data may feature partial contamination in many observations.\nWe tackle this problem by giving a robust method for sparse precision matrix\nestimation based on the $\\gamma$-divergence under a cell-wise contamination\nmodel. Simulation studies demonstrate that our procedure outperforms existing\nmethods especially for highly contaminated data.", "category": "stat.ME"}, {"title": "Gaussian process modeling of heterogeneity and discontinuities using Voronoi tessellations", "abstract": "Many methods for modelling spatial processes assume global smoothness\nproperties; such assumptions are often violated in practice. We introduce a\nmethod for modelling spatial processes that display heterogeneity or contain\ndiscontinuities. The problem of non-stationarity is dealt with by using a\ncombination of Voronoi tessellation to partition the input space, and a\nseparate Gaussian process to model the data on each region of the partitioned\nspace. Our method is highly flexible because we allow the Voronoi cells to form\nrelationships with each other, which can enable non-convex and disconnected\nregions to be considered. In such problems, identifying the borders between\nregions is often of great importance and we propose an adaptive sampling method\nto gain extra information along such borders. The method is illustrated with\nsimulation studies and application to real data.", "category": "stat.ME"}, {"title": "Direct Estimation of Differences in Causal Graphs", "abstract": "We consider the problem of estimating the differences between two causal\ndirected acyclic graph (DAG) models with a shared topological order given\ni.i.d. samples from each model. This is of interest for example in genomics,\nwhere changes in the structure or edge weights of the underlying causal graphs\nreflect alterations in the gene regulatory networks. We here provide the first\nprovably consistent method for directly estimating the differences in a pair of\ncausal DAGs without separately learning two possibly large and dense DAG models\nand computing their difference. Our two-step algorithm first uses invariance\ntests between regression coefficients of the two data sets to estimate the\nskeleton of the difference graph and then orients some of the edges using\ninvariance tests between regression residual variances. We demonstrate the\nproperties of our method through a simulation study and apply it to the\nanalysis of gene expression data from ovarian cancer and during T-cell\nactivation.", "category": "stat.ME"}, {"title": "Prediction of spatial functional random processes: Comparing functional and spatio-temporal kriging approaches", "abstract": "In this paper, we present and compare functional and spatio-temporal (Sp.T.)\nkriging approaches to predict spatial functional random processes (which can\nalso be viewed as Sp.T. random processes). Comparisons with respect to\ncomputational time and prediction performance via functional cross-validation\nis evaluated, mainly through a simulation study but also on two real data sets.\nWe restrict comparisons to Sp.T. kriging versus ordinary kriging for functional\ndata (OKFD), since the more flexible functional kriging approaches, pointwise\nfunctional kriging (PWFK) and functional kriging total model, coincide with\nOKFD in several situations. We contribute with new knowledge by proving that\nOKFD and PWFK coincide under certain conditions. From the simulation study, it\nis concluded that the prediction performance for the two kriging approaches in\ngeneral is rather equal for stationary Sp.T. processes, with a tendency for\nfunctional kriging to work better for small sample sizes and Sp.T. kriging to\nwork better for large sample sizes. For non-stationary Sp.T. processes, with a\ncommon deterministic time trend and/or time varying variances and dependence\nstructure, OKFD performs better than Sp.T. kriging irrespective of sample size.\nFor all simulated cases, the computational time for OKFD was considerably lower\ncompared to those for the Sp.T. kriging methods.", "category": "stat.ME"}, {"title": "Robust estimation in controlled branching processes: Bayesian estimators via disparities", "abstract": "This paper is concerned with Bayesian inferential methods for data from\ncontrolled branching processes that account for model robustness through the\nuse of disparities. Under regularity conditions, we establish that estimators\nbuilt on disparity-based posterior, such as expectation and maximum a\nposteriori estimates, are consistent and efficient under the posited model.\nAdditionally, we show that the estimates are robust to model misspecification\nand presence of aberrant outliers. To this end, we develop several fundamental\nideas relating minimum disparity estimators to Bayesian estimators built on the\ndisparity-based posterior, for dependent tree-structured data. We illustrate\nthe methodology through a simulated example and apply our methods to a real\ndata set from cell kinetics.", "category": "stat.ME"}, {"title": "High-dimensional covariance matrix estimation using a low-rank and diagonal decomposition", "abstract": "We study high-dimensional covariance/precision matrix estimation under the\nassumption that the covariance/precision matrix can be decomposed into a\nlow-rank component L and a diagonal component D. The rank of L can either be\nchosen to be small or controlled by a penalty function. Under moderate\nconditions on the population covariance/precision matrix itself and on the\npenalty function, we prove some consistency results for our estimators. A\nblockwise coordinate descent algorithm, which iteratively updates L and D, is\nthen proposed to obtain the estimator in practice. Finally, various numerical\nexperiments are presented: using simulated data, we show that our estimator\nperforms quite well in terms of the Kullback-Leibler loss; using stock return\ndata, we show that our method can be applied to obtain enhanced solutions to\nthe Markowitz portfolio selection problem.", "category": "stat.ME"}, {"title": "A Parsimonious Personalized Dose Finding Model via Dimension Reduction", "abstract": "Learning an individualized dose rule in personalized medicine is a\nchallenging statistical problem. Existing methods often suffer from the curse\nof dimensionality, especially when the decision function is estimated\nnonparametrically. To tackle this problem, we propose a dimension reduction\nframework that effectively reduces the estimation to a lower-dimensional\nsubspace of the covariates. We exploit that the individualized dose rule can be\ndefined in a subspace spanned by a few linear combinations of the covariates,\nleading to a more parsimonious model. The proposed framework does not require\nthe inverse probability of the propensity score under observational studies due\nto a direct maximization of the value function. This distinguishes us from the\noutcome weighted learning framework, which also solves decision rules directly.\nUnder the same framework, we further propose a pseudo-direct learning approach\nthat focuses more on estimating the dimensionality-reduced subspace of the\ntreatment outcome. Parameters in both approaches can be estimated efficiently\nusing an orthogonality constrained optimization algorithm on the Stiefel\nmanifold. Under mild regularity assumptions, the results on the asymptotic\nnormality of the proposed estimators are established, respectively. We also\nderive the consistency and convergence rate for the value function under the\nestimated optimal dose rule. We evaluate the performance of the proposed\napproaches through extensive simulation studies and a warfarin pharmacogenetic\ndataset.", "category": "stat.ME"}, {"title": "A rank-based Cramér-von-Mises-type test for two samples", "abstract": "We study a rank based univariate two-sample distribution-free test. The test\nstatistic is the difference between the average of between-group rank distances\nand the average of within-group rank distances. This test statistic is closely\nrelated to the two-sample Cram\\'er-von Mises criterion. They are different\nempirical versions of a same quantity for testing the equality of two\npopulation distributions. Although they may be different for finite samples,\nthey share the same expected value, variance and asymptotic properties. The\nadvantage of the new rank based test over the classical one is its ease to\ngeneralize to the multivariate case. Rather than using the empirical process\napproach, we provide a different easier proof, bringing in a different\nperspective and insight. In particular, we apply the H\\'ajek projection and\northogonal decomposition technique in deriving the asymptotics of the proposed\nrank based statistic. A numerical study compares power performance of the rank\nformulation test with other commonly-used nonparametric tests and\nrecommendations on those tests are provided. Lastly, we propose a multivariate\nextension of the test based on the spatial rank.", "category": "stat.ME"}, {"title": "Graphical Models for Non-Negative Data Using Generalized Score Matching", "abstract": "A common challenge in estimating parameters of probability density functions\nis the intractability of the normalizing constant. While in such cases maximum\nlikelihood estimation may be implemented using numerical integration, the\napproach becomes computationally intensive. In contrast, the score matching\nmethod of Hyv\\\"arinen (2005) avoids direct calculation of the normalizing\nconstant and yields closed-form estimates for exponential families of\ncontinuous distributions over $\\mathbb{R}^m$. Hyv\\\"arinen (2007) extended the\napproach to distributions supported on the non-negative orthant\n$\\mathbb{R}_+^m$. In this paper, we give a generalized form of score matching\nfor non-negative data that improves estimation efficiency. We also generalize\nthe regularized score matching method of Lin et al. (2016) for non-negative\nGaussian graphical models, with improved theoretical guarantees.", "category": "stat.ME"}, {"title": "Geostatistical methods for disease mapping and visualization using data from spatio-temporally referenced prevalence surveys", "abstract": "In this paper we set out general principles and develop geostatistical\nmethods for the analysis of data from spatio-temporally referenced prevalence\nsurveys. Our objective is to provide a tutorial guide that can be used in order\nto identify parsimonious geostatistical models for prevalence mapping. A\ngeneral variogram-based Monte Carlo procedure is proposed to check the validity\nof the modelling assumptions. We describe and contrast likelihood-based and\nBayesian methods of inference, showing how to account for parameter uncertainty\nunder each of the two paradigms. We also describe extensions of the standard\nmodel for disease prevalence that can be used when stationarity of the\nspatio-temporal covariance function is not supported by the data. We discuss\nhow to define predictive targets and argue that exceedance probabilities\nprovide one of the most effective ways to convey uncertainty in prevalence\nestimates. We describe statistical software for the visualization of\nspatio-temporal predictive summaries of prevalence through interactive\nanimations. Finally, we illustrate an application to historical malaria\nprevalence data from 1334 surveys conducted in Senegal between 1905 and 2014.", "category": "stat.ME"}, {"title": "Estimation of the linear fractional stable motion", "abstract": "In this paper we investigate the parametric inference for the linear\nfractional stable motion in high and low frequency setting. The symmetric\nlinear fractional stable motion is a three-parameter family, which constitutes\na natural non-Gaussian analogue of the scaled fractional Brownian motion. It is\nfully characterised by the scaling parameter $\\sigma>0$, the self-similarity\nparameter $H \\in (0,1)$ and the stability index $\\alpha \\in (0,2)$ of the\ndriving stable motion. The parametric estimation of the model is inspired by\nthe limit theory for stationary increments L\\'evy moving average processes that\nhas been recently studied in \\cite{BLP}. More specifically, we combine\n(negative) power variation statistics and empirical characteristic functions to\nobtain consistent estimates of $(\\sigma, \\alpha, H)$. We present the law of\nlarge numbers and some fully feasible weak limit theorems.", "category": "stat.ME"}, {"title": "Maximum value of the standardized log of odds ratio and celestial mechanics", "abstract": "The odds ratio (OR) is a widely used measure of the effect size in\nobservational research. ORs reflect statistical association between a binary\noutcome, such as the presence of a health condition, and a binary predictor,\nsuch as an exposure to a pollutant. Statistical significance and interval\nestimates are often computed for the logarithm of OR, ln(OR), and depend on the\nasymptotic standard error of ln(OR). For a sample of size N, the standard error\ncan be written as a ratio of sigma over square root of N, where sigma is the\npopulation standard deviation of ln(OR). The ratio of ln(OR) over sigma is a\nstandardized effect size. Unlike correlation, that is another familiar\nstandardized statistic, the standardized ln(OR) cannot reach values of minus\none or one. We find that its maximum possible value is given by the Laplace\nLimit Constant, (LLC=0.6627...), that appears as a condition in solutions to\nKepler equation -- one of the central equations in celestial mechanics. The\nrange of the standardized ln(OR) is bounded by minus LLC to LLC, reaching its\nmaximum for ln(OR)~4.7987. This range has implications for analysis of\nepidemiological associations, affecting the behavior of the reasonable prior\ndistribution for the standardized ln(OR).", "category": "stat.ME"}, {"title": "Empirical Bayes Matrix Factorization", "abstract": "Matrix factorization methods - including Factor analysis (FA), and Principal\nComponents Analysis (PCA) - are widely used for inferring and summarizing\nstructure in multivariate data. Many matrix factorization methods exist,\ncorresponding to different assumptions on the elements of the underlying matrix\nfactors. For example, many recent methods use a penalty or prior distribution\nto achieve sparse representations (\"Sparse FA/PCA\"). Here we introduce a\ngeneral Empirical Bayes approach to matrix factorization (EBMF), whose key\nfeature is that it uses the observed data to estimate prior distributions on\nmatrix elements. We derive a correspondingly-general variational fitting\nalgorithm, which reduces fitting EBMF to solving a simpler problem - the\nso-called \"normal means\" problem. We implement this general algorithm, but\nfocus particular attention on the use of sparsity-inducing priors that are\nuni-modal at 0. This yields a sparse EBMF approach - essentially a version of\nsparse FA/PCA - that automatically adapts the amount of sparsity to the data.\nWe demonstrate the benefits of our approach through both numerical comparisons\nwith competing methods and through analysis of data from the GTEx (Genotype\nTissue Expression) project on genetic associations across 44 human tissues. In\nnumerical comparisons EBMF often provides more accurate inferences than other\nmethods. In the GTEx data, EBMF identifies interpretable structure that\nconcords with known relationships among human tissues. Software implementing\nour approach is available at https://github.com/stephenslab/flashr", "category": "stat.ME"}, {"title": "How to analyze data in a factorial design? An extensive simulation study", "abstract": "Factorial designs are frequently used in different fields of science, e.g.\npsychological, medical or biometric studies. Standard approaches, as the ANOVA\n$F$-test, make different assumptions on the distribution of the error terms,\nthe variances or the sample sizes in the different groups. Because of time\nconstraints or a lack of statistical background, many users do not check these\nassumptions; enhancing the risk of potentially inflated type-$I$ error rates or\na substantial loss of power. It is the aim of the present paper, to give an\noverview of different methods without such restrictive assumptions and to\nidentify situations in which one method is superior compared to others. In\nparticular, after summarizing their underlying assumptions, the different\napproaches are compared within extensive simulations. To also address the\ncurrent discussion about redefining the statistical significance level, we also\nincluded simulations for the 0.5\\% level.", "category": "stat.ME"}, {"title": "Discussion on \"Sparse graphs using exchangeable random measures\" by Francois Caron and Emily B. Fox", "abstract": "This is a discussion on \"Sparse graphs using exchangeable random measures\" by\nFrancois Caron and Emily B. Fox, published in Journal of the Royal Statistical\nSociety, Series B, 2017.", "category": "stat.ME"}, {"title": "Mutual Assent or Unilateral Nomination? A Performance Comparison of Intersection and Union Rules for Integrating Self-reports of Social Relationships", "abstract": "Data collection designs for social network studies frequently involve asking\nboth parties to a potential relationship to report on the presence of absence\nof that relationship, resulting in two measurements per potential tie. When\ninferring the underlying network, is it better to estimate the tie as present\nonly when both parties report it as present or do so when either reports it?\nEmploying several data sets in which network structure can be well-determined\nfrom large numbers of informant reports, we examine the performance of these\ntwo simple rules. Our analysis shows better results for mutual assent across\nall data sets examined. A theoretical analysis of estimator performance shows\nthat the best rule depends on both underlying error rates and the sparsity of\nthe underlying network, with sparsity driving the superiority of mutual assent\nin typical social network settings.", "category": "stat.ME"}, {"title": "Two-way sparsity for time-varying networks, with applications in genomics", "abstract": "We propose a novel way of modelling time-varying networks, by inducing\ntwo-way sparsity on local models of node connectivity. This two-way sparsity\nseparately promotes sparsity across time and sparsity across variables (within\ntime). Separation of these two types of sparsity is achieved through a novel\nprior structure, which draws on ideas from the Bayesian lasso and from copula\nmodelling. We provide an efficient implementation of the proposed model via a\nGibbs sampler, and we apply the model to data from neural development. In doing\nso, we demonstrate that the proposed model is able to identify changes in\ngenomic network structure that match current biological knowledge. Such changes\nin genomic network structure can then be used by neuro-biologists to identify\npotential targets for further experimental investigation.", "category": "stat.ME"}, {"title": "Correlation-Adjusted Regression Survival Scores for High-Dimensional Variable Selection", "abstract": "Background: The development of classification methods for personalized\nmedicine is highly dependent on the identification of predictive genetic\nmarkers. In survival analysis it is often necessary to discriminate between\ninfluential and non-influential markers. Usually, the first step is to perform\na univariate screening step that ranks the markers according to their\nassociations with the outcome. It is common to perform screening using Cox\nscores, which quantify the associations between survival and each of the\nmarkers individually. Since Cox scores do not account for dependencies between\nthe markers, their use is suboptimal in the presence highly correlated markers.\nMethods: As an alternative to the Cox score, we propose the\ncorrelation-adjusted regression survival (CARS) score for right-censored\nsurvival outcomes. By removing the correlations between the markers, the CARS\nscore quantifies the associations between the outcome and the set of\n\"de-correlated\" marker values. Estimation of the scores is based on inverse\nprobability weighting, which is applied to log-transformed event times. For\nhigh-dimensional data, estimation is based on shrinkage techniques. Results:\nThe consistency of the CARS score is proven under mild regularity conditions.\nIn simulations, survival models based on CARS score rankings achieved higher\nareas under the precision-recall curve than competing methods. Two example\napplications on prostate and breast cancer confirmed these results. CARS scores\nare implemented in the R package carSurv. Conclusions: In research applications\ninvolving high-dimensional genetic data, the use of CARS scores for marker\nselection is a favorable alternative to Cox scores even when correlations\nbetween covariates are low. Having a straightforward interpretation and low\ncomputational requirements, CARS scores are an easy-to-use screening tool in\npersonalized medicine research.", "category": "stat.ME"}, {"title": "A Better (Bayesian) Interval Estimate for Within-Subject Designs", "abstract": "We develop a Bayesian highest-density interval (HDI) for use in\nwithin-subject designs. This credible interval is based on a standard\nnoninformative prior and a modified posterior distribution that conditions on\nboth the data and point estimates of the subject-specific random effects.\nConditioning on the estimated random effects removes between-subject variance\nand produces intervals that are the Bayesian analogue of the within-subject\nconfidence interval proposed in Loftus and Masson (1994). We show that the\nlatter interval can also be derived as a Bayesian within-subject HDI under a\ncertain improper prior. We argue that the proposed new interval is superior to\nthe original within-subject confidence interval, on the grounds of (a) it being\nbased on a more sensible prior, (b) it having a clear and intuitively appealing\ninterpretation, and (c) because its length is always smaller. A generalization\nof the new interval that can be applied to heteroscedastic data is also\nderived, and we show that the resulting interval is numerically equivalent to\nthe normalization method discussed in Franz and Loftus (2012); however, our\nwork provides a Bayesian formulation for the normalization method, and in doing\nso we identify the associated prior distribution.", "category": "stat.ME"}, {"title": "A Class of Tests for Trend in Time Censored Recurrent Event Data", "abstract": "Statistical tests for trend in recurrent event data not following a Poisson\nprocess are generally constructed for event censored data. However, time\ncensored data are more frequently encountered in practice. In this paper we\ncontribute to filling an important gap in the literature on trend testing by\npresenting a class of statistical tests for trend in time censored recurrent\nevent data, based on the null hypothesis of a renewal process. The class of\ntests is constructed by an adaption of a functional central limit theorem for\nrenewal processes. By this approach a number of tests for time censored\nrecurrent event data can be constructed, including among others a version of\nthe classical Lewis-Robinson trend test and an Anderson-Darling type test. The\nlatter test turns out to have attractive properties for general use by having\ngood power properties against both monotonic and non-monotonic trends.\nExtensions to situations with several processes are considered. Properties of\nthe tests are studied by simulations, and the approach is illustrated in two\ndata examples.", "category": "stat.ME"}, {"title": "Nonparametric Estimation of a distribution function from doubly truncated data under dependence", "abstract": "The NPMLE of a distribution function from doubly truncated data was\nintroduced in the seminal paper of Efron and Petrosian. The consistency of the\nEfron-Petrosian estimator depends however on the assumption of independent\ntruncation. In this work we introduce an extension of the Efron-Petrosian NPMLE\nwhen the variable of interest and the truncation variables may be dependent.\nThe proposed estimator is constructed on the basis of a copula function which\nrepresents the dependence structure between the variable of interest and the\ntruncation variables. Two different iterative algorithms to compute the\nestimator in practice are introduced, and their performance is explored through\nan intensive Monte Carlo simulation study. We illustrate the use of the\nestimators on two real data examples.", "category": "stat.ME"}, {"title": "Accelerate iterated filtering", "abstract": "In simulation-based inferences for partially observed Markov process models\n(POMP), the by-product of the Monte Carlo filtering is an approximation of the\nlog likelihood function. Recently, iterated filtering [14, 13] has originally\nbeen introduced and it has been shown that the gradient of the log likelihood\ncan also be approximated. Consequently, different stochastic optimization\nalgorithm can be applied to estimate the parameters of the underlying models.\nAs accelerated gradient is an efficient approach in the optimization\nliterature, we show that we can accelerate iterated filtering in the same\nmanner and inherit that high convergence rate while relaxing the restricted\nconditions of unbiased gradient approximation. We show that this novel\nalgorithm can be applied to both convex and non-convex log likelihood\nfunctions. In addition, this approach has substantially outperformed most of\nother previous approaches in a toy example and in a challenging scientific\nproblem of modeling infectious diseases.", "category": "stat.ME"}, {"title": "Bayesian Semiparametric Functional Mixed Models for Serially Correlated Functional Data, with Application to Glaucoma Data", "abstract": "Glaucoma, a leading cause of blindness, is characterized by optic nerve\ndamage related to intraocular pressure (IOP), but its full etiology is unknown.\nResearchers at UAB have devised a custom device to measure scleral strain\ncontinuously around the eye under fixed levels of IOP, which here is used to\nassess how strain varies around the posterior pole, with IOP, and across\nglaucoma risk factors such as age. The hypothesis is that scleral strain\ndecreases with age, which could alter biomechanics of the optic nerve head and\ncause damage that could eventually lead to glaucoma. To evaluate this\nhypothesis, we adapted Bayesian Functional Mixed Models to model these complex\ndata consisting of correlated functions on spherical scleral surface, with\nnonparametric age effects allowed to vary in magnitude and smoothness across\nthe scleral surface, multi-level random effect functions to capture\nwithin-subject correlation, and functional growth curve terms to capture serial\ncorrelation across IOPs that can vary around the scleral surface. Our method\nyields fully Bayesian inference on the scleral surface or any aggregation or\ntransformation thereof, and reveals interesting insights into the biomechanical\netiology of glaucoma. The general modeling framework described is very flexible\nand applicable to many complex, high-dimensional functional data.", "category": "stat.ME"}, {"title": "Efficient nonparametric causal inference with missing exposure information", "abstract": "Missing exposure information is a very common feature of many observational\nstudies. Here we study identifiability and efficient estimation of causal\neffects on vector outcomes, in such cases where treatment is unconfounded but\npartially missing. We consider a missing at random setting where missingness in\ntreatment can depend not only on complex covariates, but also on post-treatment\noutcomes. We give a new identifying expression for average treatment effects in\nthis setting, along with the efficient influence function for this parameter in\na nonparametric model, which yields a nonparametric efficiency bound. We use\nthis latter result to construct nonparametric estimators that are less\nsensitive to the curse of dimensionality than usual, e.g., by having faster\nrates of convergence than the complex nuisance estimators they rely on. Further\nwe show that these estimators can be root-n consistent and asymptotically\nnormal under weak nonparametric conditions, even when constructed using\nflexible machine learning. Finally we apply these results to the problem of\ncausal inference with a partially missing instrumental variable.", "category": "stat.ME"}, {"title": "Sparse Network Estimation for Dynamical Spatio-temporal Array Models", "abstract": "Neural field models represent neuronal communication on a population level\nvia synaptic weight functions. Using voltage sensitive dye (VSD) imaging it is\npossible to obtain measurements of neural fields with a relatively high spatial\nand temporal resolution. The synaptic weight functions represent functional\nconnectivity in the brain and give rise to a spatio-temporal dependence\nstructure. We present a stochastic functional differential equation for\nmodeling neural fields, which leads to a vector autoregressive model of the\ndata via basis expansions of the synaptic weight functions and time and space\ndiscretization. Fitting the model to data is a pratical challenge as this\nrepresents a large scale regression problem. By using a 1-norm penalty in\ncombination with localized basis functions it is possible to learn a sparse\nnetwork representation of the functional connectivity of the brain, but still,\nthe explicit construction of a design matrix can be computationally\nprohibitive. We demonstrate that by using tensor product basis expansions, the\ncomputation of the penalized estimator via a proximal gradient algorithm\nbecomes feasible. It is crucial for the computations that the data is organized\nin an array as is the case for the three dimensional VSD imaging data. This\nallows for the use of array arithmetic that is both memory and time\nefficient.The proposed method is implemented and showcased in the R package\ndynamo available from CRAN.", "category": "stat.ME"}, {"title": "Distributions associated with simultaneous multiple hypothesis testing", "abstract": "We develop the distribution of the number of hypotheses found to be\nstatistically significant using the rule from Benjamini and Hochberg (1995) for\ncontrolling the false discovery rate (FDR). This distribution has both a small\nsample form and an asymptotic expression for testing many independent\nhypotheses simultaneously. We propose a parametric distribution\n$\\,\\Psi_I(\\cdot)\\,$ to approximate the marginal distribution of p-values under\na non-uniform alternative hypothesis. This distribution is useful when there\nare many different alternative hypotheses and these are not individually well\nunderstood. We fit $\\,\\Psi_I\\,$ to data from three cancer studies and use it to\nillustrate the distribution of the number of notable hypotheses observed in\nthese examples. We model dependence of sampled p-values using a copula model\nand a latent variable approach. These methods can be combined to illustrate a\npower analysis in planning a large study on the basis of a smaller pilot study.\nWe show the number of statistically significant p-values behaves approximately\nas a mixture of a normal and the Borel-Tanner distribution.", "category": "stat.ME"}, {"title": "Estimation of the Evolutionary Spectra with Application to Stationarity Test", "abstract": "In this work, we propose a new inference procedure for understanding\nnon-stationary processes, under the framework of evolutionary spectra developed\nby Priestley. Among various frameworks of modeling non-stationary processes,\nthe distinguishing feature of the evolutionary spectra is its focus on the\nphysical meaning of frequency. The classical estimate of the evolutionary\nspectral density is based on a double-window technique consisting of a\nshort-time Fourier transform and a smoothing. However, smoothing is known to\nsuffer from the so-called bias leakage problem. By incorporating Thomson's\nmultitaper method that was originally designed for stationary processes, we\npropose an improved estimate of the evolutionary spectral density, and analyze\nits bias/variance/resolution tradeoff. As an application of the new estimate,\nwe further propose a non-parametric rank-based stationarity test, and provide\nvarious experimental studies.", "category": "stat.ME"}, {"title": "First derivatives at the optimum analysis (\\textit{fdao}): An approach to estimate the uncertainty in nonlinear regression involving stochastically independent variables", "abstract": "An important problem of optimization analysis surges when parameters such as\n$ \\{\\theta_j\\}_{j=1,\\, \\dots \\,,k }$, determining a function $\ny=f(x\\given\\{\\theta_j\\}) $, must be estimated from a set of observables $ \\{\nx_i,y_i\\}_{i=1,\\, \\dots \\,,m} $. Where $ \\{x_i\\} $ are independent variables\nassumed to be uncertainty-free. It is known that analytical solutions are\npossible if $ y=f(x\\given\\theta_j) $ is a linear combination of $\n\\{\\theta_{j=1,\\, \\dots \\,,k} \\}.$ Here it is proposed that determining the\nuncertainty of parameters that are not \\textit{linearly independent} may be\nachieved from derivatives $ \\tfrac{\\partial f(x \\given \\{\\theta_j\\})}{\\partial\n\\theta_j} $ at an optimum, if the parameters are \\textit{stochastically\nindependent}.", "category": "stat.ME"}, {"title": "Partial Distance Correlation Screening for High Dimensional Time Series", "abstract": "High dimensional time series datasets are becoming increasingly common in\nvarious fields such as economics, finance, meteorology, and neuroscience. Given\nthis ubiquity of time series data, it is surprising that very few works on\nvariable screening discuss the time series setting, and even fewer works have\ndeveloped methods which utilize the unique features of time series data. This\npaper introduces several model free screening methods based on the partial\ndistance correlation and developed specifically to deal with time dependent\ndata. Methods are developed both for univariate models, such as nonlinear\nautoregressive models with exogenous predictors (NARX), and multivariate models\nsuch as linear or nonlinear VAR models. Sure screening properties are proved\nfor our methods, which depend on the moment conditions, and the strength of\ndependence in the response and covariate processes, amongst other factors.\nDependence is quantified by functional dependence measures (Wu [Proc. Natl.\nAcad. Sci. USA 102 (2005) 14150-14154]) and $\\beta$-mixing coefficients, and\nthe results rely on the use of Nagaev and Rosenthal type inequalities for\ndependent random variables. Finite sample performance of our methods is shown\nthrough extensive simulation studies, and we include an application to\nmacroeconomic forecasting.", "category": "stat.ME"}, {"title": "Estimating Precipitation Extremes using Log-Histospline", "abstract": "One of the commonly used approaches to modeling extremes is the\npeaks-over-threshold (POT) method. The POT method models exceedances over a\nthreshold that is sufficiently high or low so that the exceedance has\napproximately a generalized Pareto distribution (GPD). This method requires the\nselection of a threshold that might affect the estimates. Here we propose an\nalternative method, the Log-Histospline (LHSpline), to explore modeling the\ntail behavior and the remainder of the density in one step using the full range\nof the data. LHSpline applies a smoothing spline model to a finely binned\nhistogram of the log transformed data to estimate its log density. By\nconstruction, a LHSpline estimation is constrained to have polynomial tail\nbehavior, a feature commonly observed in daily rainfall observations. We\nillustrate the LHSpline method by analyzing precipitation data collected in\nHouston, Texas.", "category": "stat.ME"}, {"title": "Bayesian Sample Size Determination for Planning Hierarchical Bayes Small Area Estimates", "abstract": "This paper devises a fully Bayesian sample size determination method for\nhierarchical model-based small area estimation with a decision risk approach. A\nnew loss function specified around a desired maximum posterior variance target\nimplements conventional official statistics criteria of estimator reliability\n(coefficient of variation of up to 20 per cent). This approach comes with an\nefficient binary search algorithm identifying the minimum effective sample size\nneeded to produce small area estimates under this threshold constraint.\nTraditional survey sampling design tools can then be used to plan appropriate\ndata collection using the resulting effective sample size target. This approach\nis illustrated in a case study on small area prevalence of life limiting health\nproblems for 6 age groups across 1,956 small areas in Northern England, using\nthe recently developed Integrated Nested Laplace Approximation method for\nspatial generalised linear mixed hierarchical models.", "category": "stat.ME"}, {"title": "One-step Targeted Maximum Likelihood for Time-to-event Outcomes", "abstract": "Current Targeted Maximum Likelihood Estimation (TMLE) methods used to analyze\ntime-to-event data estimate the survival probability for each time point\nseparately, which result in estimates that are not necessarily monotone. In\nthis paper, we present an extension of TMLE for observational time-to-event\ndata, the one-step Targeted Maximum Likelihood Estimator for the treatment-rule\nspecific survival curve. We construct a one-dimensional universal least\nfavorable submodel that targets the entire survival curve, and thereby requires\nminimal extra fitting with data to achieve its goal of solving the efficient\ninfluence curve equation. Through the use of a simulation study, we will show\nthat this method improves on previously proposed methods in both robustness and\nefficiency, and at the same time respects the monotone decreasing nature of the\nsurvival curve.", "category": "stat.ME"}, {"title": "A graph-theoretic framework for algorithmic design of experiments", "abstract": "In this paper, we demonstrate that considering experiments in a\ngraph-theoretic manner allows us to exploit automorphisms of the graph to\nreduce the number of evaluations of candidate designs for those experiments,\nand thus find optimal designs faster. We show that the use of automorphisms for\nreducing the number of evaluations required of an optimality criterion function\nis effective on designs where experimental units have a network structure.\nMoreover, we show that we can take block designs with no apparent network\nstructure, such as one-way blocked experiments, row-column experiments, and\ncrossover designs, and add block nodes to induce a network structure.\nConsidering automorphisms can thus reduce the amount of time it takes to find\noptimal designs for a wide class of experiments.", "category": "stat.ME"}, {"title": "A partial correlation vine based approach for modeling and forecasting multivariate volatility time-series", "abstract": "A novel approach for dynamic modeling and forecasting of realized covariance\nmatrices is proposed. Realized variances and realized correlation matrices are\njointly estimated. The one-to-one relationship between a positive definite\ncorrelation matrix and its associated set of partial correlations corresponding\nto any vine specification is used for data transformation. The model components\ntherefore are realized variances as well as realized standard and partial\ncorrelations corresponding to a daily log-return series. As such, they have a\nclear practical interpretation. A method to select a regular vine structure,\nwhich allows for parsimonious time-series and dependence modeling of the model\ncomponents, is introduced. Being algebraically independent the latter do not\nunderlie any algebraic constraint. The proposed model approach is outlined in\ndetail and motivated along with a real data example on six highly liquid\nstocks. The forecasting performance is evaluated both with respect to\nstatistical precision and in the context of portfolio optimization. Comparisons\nwith Cholesky decomposition based benchmark models support the excellent\nprediction ability of the proposed model approach.", "category": "stat.ME"}, {"title": "Selecting optimal subgroups for treatment using many covariates", "abstract": "We consider the problem of selecting the optimal subgroup to treat when data\non covariates is available from a randomized trial or observational study. We\ndistinguish between four different settings including (i) treatment selection\nwhen resources are constrained, (ii) treatment selection when resources are not\nconstrained, (iii) treatment selection in the presence of side effects and\ncosts, and (iv) treatment selection to maximize effect heterogeneity. We show\nthat, in each of these cases, the optimal treatment selection rule involves\ntreating those for whom the predicted mean difference in outcomes comparing\nthose with versus without treatment, conditional on covariates, exceeds a\ncertain threshold. The threshold varies across these four scenarios but the\nform of the optimal treatment selection rule does not. The results suggest a\nmove away from traditional subgroup analysis for personalized medicine. New\nrandomized trial designs are proposed so as to implement and make use of\noptimal treatment selection rules in health care practice.", "category": "stat.ME"}, {"title": "Sufficient variable screening via directional regression with censored response", "abstract": "We in this paper propose a directional regression based approach for\nultrahigh dimensional sufficient variable screening with censored responses.\nThe new method is designed in a model-free manner and thus can be adapted to\nvarious complex model structures. Under some commonly used assumptions, we show\nthat the proposed method enjoys the sure screening property when the dimension\np diverges at an exponential rate of the sample size n. To improve the marginal\nscreening method, the corresponding iterative screening algorithm and stability\nscreening algorithm are further equipped. We demonstrate the effectiveness of\nthe proposed method through simulation studies and a real data analysis.", "category": "stat.ME"}, {"title": "Identifying groups of variables with the potential of being large simultaneously", "abstract": "Identifying groups of variables that may be large simultaneously amounts to\nfinding out which joint tail dependence coefficients of a multivariate\ndistribution are positive. The asymptotic distribution of a vector of\nnonparametric, rank-based estimators of these coefficients justifies a stopping\ncriterion in an algorithm that searches the collection of all possible groups\nof variables in a systematic way, from smaller groups to larger ones. The issue\nthat the tolerance level in the stopping criterion should depend on the size of\nthe groups is circumvented by the use of a conditional tail dependence\ncoefficient. Alternatively, such stopping criteria can be based on limit\ndistributions of rank-based estimators of the coefficient of tail dependence,\nquantifying the speed of decay of joint survival functions. Numerical\nexperiments indicate that the algorithm's effectiveness for detecting\ntail-dependent groups of variables is highest when paired with a criterion\nbased on a Hill-type estimator of the coefficient of tail dependence.", "category": "stat.ME"}, {"title": "Exact Simulation of reciprocal Archimedean copulas", "abstract": "The decreasing enumeration of the points of a Poisson random measure whose\nmean measure has finite survival function on the positive half-axis can be\nrepresented as a non-increasing function of the jump times of a standard\nPoisson process. This observation allows to generalize the essential idea from\na well-known exact simulation algorithm for arbitrary extreme-value copulas to\ncopulas of a more general family of max-infinitely divisible distributions,\nwith reciprocal Archimedean copulas being a particular example.", "category": "stat.ME"}, {"title": "Extreme-value copulas associated with the expected scaled maximum of independent random variables", "abstract": "It is well-known that the expected scaled maximum of non-negative random\nvariables with unit mean defines a stable tail dependence function associated\nwith some extreme-value copula. In the special case when these random variables\nare independent and identically distributed, min-stable multivariate\nexponential random vectors with the associated survival extreme-value copulas\nare shown to arise as finite-dimensional margins of an infinite exchangeable\nsequence in the sense of De Finetti's Theorem. The associated latent factor is\na stochastic process which is strongly infinitely divisible with respect to\ntime, which induces a bijection from the set of distribution functions F of\nnon-negative random variables with finite mean to the set of L\\'evy measures on\nthe positive half-axis. Since the Gumbel and the Galambos copula are the most\npopular examples of this construction, the investigation of this bijection\ncontributes to a further understanding of their well-known analytical\nsimilarities. Furthermore, a simulation algorithm based on the latent factor\nrepresentation is developed, if the support of F is bounded. Especially in\nlarge dimensions, this algorithm is efficient because it makes use of the De\nFinetti structure.", "category": "stat.ME"}, {"title": "A flexible and computationally tractable discrete distribution derived from a stationary renewal process", "abstract": "A class of discrete distributions can be derived from stationary renewal\nprocesses. They have the useful property that the mean is a simple function of\nthe model parameters. Thus regressions of the distribution mean on covariates\ncan be carried out and marginal effects of covariates calculated. Probabilities\ncan be easily computed in closed form for only two such distributions, when the\nevent interarrival times in the renewal process follow either a gamma or an\ninverse Gaussian distribution. The gamma-based distribution has more attractive\nproperties and is described and fitted to data. The inverse-Gaussian based\ndistribution is also briefly discussed.", "category": "stat.ME"}, {"title": "A novel approach for fusion of heterogeneous sources of data", "abstract": "With advancements in sensor technology, a heterogeneous set of data,\ncontaining samples of scalar, waveform signal, image, or even structured point\ncloud are becoming increasingly popular. Developing a statistical model,\nrepresenting the behavior of the underlying system based upon such a\nheterogeneous set of data can be used in monitoring, control, and optimization\nof the system. Unfortunately, available methods only focus on the scalar and\ncurve data and do not provide a general framework that can integrate different\nsources of data to construct a model. This paper poses the problem of\nestimating a process output, measured by a scalar, curve, an image, or a point\ncloud by a set of heterogeneous process variables such as scalar process\nsetting, sensor readings, and images. We introduce a general approach in which\neach set of input data (predictor) as well as the output measurements are\nrepresented by tensors. We formulate a linear regression model between the\ninput and output tensors and estimate the parameters by minimizing a least\nsquare loss function. In order to avoid overfitting and to reduce the number of\nparameters to be estimated, we decompose the model parameters using several\nbases, spanning the input and output spaces. Next, we learn both the bases and\ntheir spanning coefficients when minimizing the loss function using an\nalternating least square (ALS) algorithm. We show that such a minimization has\na closed-form solution in each iteration and can be computed very efficiently.\nThrough several simulation and case studies, we evaluate the performance of the\nproposed method. The results reveal the advantage of the proposed method over\nsome benchmarks in the literature in terms of the mean square prediction error.", "category": "stat.ME"}, {"title": "Modeling Data Containing Outliers using ARIMA Additive Outlier (ARIMA-AO)", "abstract": "The aim this study is discussed on the detection and correction of data\ncontaining the additive outlier (AO) on the model ARIMA (p, d, q). The process\nof detection and correction of data using an iterative procedure popularized by\nBox, Jenkins, and Reinsel (1994). By using this method we obtained an ARIMA\nmodels were fit to the data containing AO, this model is added to the original\nmodel of ARIMA coefficients obtained from the iteration process using\nregression methods. This shows that there is an improvement of forecasting\nerror rate data.", "category": "stat.ME"}, {"title": "Banded Spatio-Temporal Autoregressions", "abstract": "We propose a new class of spatio-temporal models with unknown and banded\nautoregressive coefficient matrices. The setting represents a sparse structure\nfor high-dimensional spatial panel dynamic models when panel members represent\neconomic (or other type) individuals at many different locations. The structure\nis practically meaningful when the order of panel members is arranged\nappropriately. Note that the implied autocovariance matrices are unlikely to be\nbanded, and therefore, the proposal is radically different from the existing\nliterature on the inference for high-dimensional banded covariance matrices.\nDue to the innate endogeneity, we apply the least squares method based on a\nYule-Walker equation to estimate autoregressive coefficient matrices. The\nestimators based on multiple Yule-Walker equations are also studied. A\nratio-based method for determining the bandwidth of autoregressive matrices is\nalso proposed. Some asymptotic properties of the inference methods are\nestablished. The proposed methodology is further illustrated using both\nsimulated and real data sets.", "category": "stat.ME"}, {"title": "Bayesian Predictive Synthesis with Outcome-Dependent Pools", "abstract": "This paper reviews background and examples of Bayesian predictive synthesis\n(BPS), and develops details in a subset of BPS mixture models. BPS expands on\nstandard Bayesian model uncertainty analysis for model mixing to provide a\nbroader foundation for calibrating and combining predictive densities from\nmultiple models or other sources. One main focus here is BPS as a framework for\njustifying and understanding generalized \"linear opinion pools,\" where multiple\npredictive densities are combined with flexible mixing weights that depend on\nthe forecast outcome itself, i.e., the setting of outcome-dependent model\nmixing. BPS also defines approaches to incorporating and exploiting\ndependencies across models defining forecasts, and to formally addressing the\nproblem of model set incompleteness within the subjective Bayesian framework.\nIn addition to an overview of general mixture-based BPS, new methodological\ndevelopments for dynamic BPS -- involving calibration and pooling of sets of\npredictive distributions in a univariate time series setting -- are presented.\nThese developments are exemplified in summaries of an analysis in a univariate\nfinancial time series study.", "category": "stat.ME"}, {"title": "Randomization inference with general interference and censoring", "abstract": "Interference occurs between individuals when the treatment (or exposure) of\none individual affects the outcome of another individual. Previous work on\ncausal inference methods in the presence of interference has focused on the\nsetting where a priori it is assumed there is 'partial interference,' in the\nsense that individuals can be partitioned into groups wherein there is no\ninterference between individuals in different groups. Bowers, Fredrickson, and\nPanagopoulos (2012) and Bowers, Fredrickson, and Aronow (2016) consider\nrandomization-based inferential methods that allow for more general\ninterference structures in the context of randomized experiments. In this\npaper, extensions of Bowers et al. which allow for failure time outcomes\nsubject to right censoring are proposed. Permitting right censored outcomes is\nchallenging because standard randomization-based tests of the null hypothesis\nof no treatment effect assume that whether an individual is censored does not\ndepend on treatment. The proposed extension of Bowers et al. to allow for\ncensoring entails adapting the method of Wang, Lagakos, and Gray (2010) for two\nsample survival comparisons in the presence of unequal censoring. The methods\nare examined via simulation studies and utilized to assess the effects of\ncholera vaccination in an individually-randomized trial of 73,000 children and\nwomen in Matlab, Bangladesh.", "category": "stat.ME"}, {"title": "Estimation of subgraph density in noisy networks", "abstract": "While it is common practice in applied network analysis to report various\nstandard network summary statistics, these numbers are rarely accompanied by\nuncertainty quantification. Yet any error inherent in the measurements\nunderlying the construction of the network, or in the network construction\nprocedure itself, necessarily must propagate to any summary statistics\nreported. Here we study the problem of estimating the density of an arbitrary\nsubgraph, given a noisy version of some underlying network as data. Under a\nsimple model of network error, we show that consistent estimation of such\ndensities is impossible when the rates of error are unknown and only a single\nnetwork is observed. Accordingly, we develop method-of-moment estimators of\nnetwork subgraph densities and error rates for the case where a minimal number\nof network replicates are available. These estimators are shown to be\nasymptotically normal as the number of vertices increases to infinity. We also\nprovide confidence intervals for quantifying the uncertainty in these estimates\nbased on the asymptotic normality. To construct the confidence intervals, a new\nand non-standard bootstrap method is proposed to compute asymptotic variances,\nwhich is infeasible otherwise. We illustrate the proposed methods in the\ncontext of gene coexpression networks.", "category": "stat.ME"}, {"title": "Bayesian nonparametric regression using complex wavelets", "abstract": "In this paper we propose a new adaptive wavelet denoising methodology using\ncomplex wavelets. The method is based on a fully Bayesian hierarchical model in\nthe complex wavelet domain that uses a bivariate mixture prior on the wavelet\ncoefficients. The heart of the procedure is computational, where the posterior\nmean is computed through Markov chain Monte Carlo (MCMC) simulations. We show\nthat the method has good performance, as demonstrated by simulations on the\nwell-known test functions and by comparison to a well-established complex\nwavelet-based denoising procedure. An application to real-life data set is also\nconsidered.", "category": "stat.ME"}, {"title": "Scalable Stochastic Kriging with Markovian Covariances", "abstract": "Stochastic kriging is a popular technique for simulation metamodeling due to\nits exibility and analytical tractability. Its computational bottleneck is the\ninversion of a covariance matrix, which takes $O(n^3)$ time in general and\nbecomes prohibitive for large n, where n is the number of design points.\nMoreover, the covariance matrix is often ill-conditioned for large n, and thus\nthe inversion is prone to numerical instability, resulting in erroneous\nparameter estimation and prediction. These two numerical issues preclude the\nuse of stochastic kriging at a large scale. This paper presents a novel\napproach to address them. We construct a class of covariance functions, called\nMarkovian covariance functions (MCFs), which have two properties: (i) the\nassociated covariance matrices can be inverted analytically, and (ii) the\ninverse matrices are sparse. With the use of MCFs, the inversion-related\ncomputational time is reduced to $O(n^2)$ in general, and can be further\nreduced by orders of magnitude with additional assumptions on the simulation\nerrors and design points. The analytical invertibility also enhance the\nnumerical stability dramatically. The key in our approach is that we identify a\ngeneral functional form of covariance functions that can induce sparsity in the\ncorresponding inverse matrices. We also establish a connection between MCFs and\nlinear ordinary differential equations. Such a connection provides a flexible,\nprincipled approach to constructing a wide class of MCFs. Extensive numerical\nexperiments demonstrate that stochastic kriging with MCFs can handle\nlarge-scale problems in an both computationally efficient and numerically\nstable manner.", "category": "stat.ME"}, {"title": "Varying Coefficient Panel Data Model with Interactive Fixed Effects", "abstract": "In this paper, we propose a varying coefficient panel data model with\nunobservable multiple interactive fixed effects that are correlated with the\nregressors. We approximate each coefficient function by B-spline, and propose a\nrobust nonlinear iteration scheme based on the least squares method to estimate\nthe coefficient functions of interest. We also establish the asymptotic theory\nof the resulting estimators under certain regularity assumptions, including the\nconsistency, the convergence rate and the asymptotic distribution. Furthermore,\nwe develop a least squares dummy variable method to study an important special\ncase of the proposed model: the varying coefficient panel data model with\nadditive fixed effects. To construct the pointwise confidence intervals for the\ncoefficient functions, a residual-based block bootstrap method is proposed to\nreduce the computational burden as well as to avoid the accumulative errors.\nSimulation studies and a real data analysis are also carried out to assess the\nperformance of our proposed methods.", "category": "stat.ME"}, {"title": "Sklar's Omega: A Gaussian Copula-Based Framework for Assessing Agreement", "abstract": "The statistical measurement of agreement is important in a number of fields,\ne.g., content analysis, education, computational linguistics, biomedical\nimaging. We propose Sklar's Omega, a Gaussian copula-based framework for\nmeasuring intra-coder, inter-coder, and inter-method agreement as well as\nagreement relative to a gold standard. We demonstrate the efficacy and\nadvantages of our approach by applying it to both simulated and experimentally\nobserved datasets, including data from two medical imaging studies. Application\nof our proposed methodology is supported by our open-source R package,\nsklarsomega, which is available for download from the Comprehensive R Archive\nNetwork.", "category": "stat.ME"}, {"title": "Placebo inference on treatment effects when the number of clusters is small", "abstract": "I introduce a general, Fisher-style randomization testing framework to\nconduct nearly exact inference about the lack of effect of a binary treatment\nin the presence of very few, large clusters when the treatment effect is\nidentified across clusters. The proposed randomization test formalizes and\nextends the intuitive notion of generating null distributions by assigning\nplacebo treatments to untreated clusters. I show that under simple and easily\nverifiable conditions, the placebo test leads to asymptotically valid inference\nin a very large class of empirically relevant models. Examples discussed\nexplicitly are (i) least squares regression with cluster-level treatment, (ii)\ndifference-in-differences estimation, and (iii) binary choice models with\ncluster-level treatment. A simulation study and an empirical example are\nprovided. The proposed inference procedure is easy to implement and performs\nwell with as few as three treated and three untreated clusters.", "category": "stat.ME"}, {"title": "Optimizing cluster-based randomized experiments under a monotonicity assumption", "abstract": "Cluster-based randomized experiments are popular designs for mitigating the\nbias of standard estimators when interference is present and classical causal\ninference and experimental design assumptions (such as SUTVA or ITR) do not\nhold. Without an exact knowledge of the interference structure, it can be\nchallenging to understand which partitioning of the experimental units is\noptimal to minimize the estimation bias. In the paper, we introduce a\nmonotonicity condition under which a novel two-stage experimental design allows\nus to determine which of two cluster-based designs yields the least biased\nestimator. We then consider the setting of online advertising auctions and show\nthat reserve price experiments verify the monotonicity condition and the\nproposed framework and methodology applies. We validate our findings on an\nadvertising auction dataset.", "category": "stat.ME"}, {"title": "Algorithms and diagnostics for the analysis of preference rankings with the Extended Plackett-Luce model", "abstract": "Choice behavior and preferences typically involve numerous and subjective\naspects that are difficult to be identified and quantified. For this reason,\ntheir exploration is frequently conducted through the collection of ordinal\nevidence in the form of ranking data. A ranking is an ordered sequence\nresulting from the comparative evaluation of a given set of items according to\na specific criterion. Multistage ranking models, including the popular\nPlackett-Luce distribution (PL), rely on the assumption that the ranking\nprocess is performed sequentially, by assigning the positions from the top to\nthe bottom one (forward order). A recent contribution to the ranking literature\nrelaxed this assumption with the addition of the discrete reference order\nparameter, yielding the novel Extended Plackett-Luce model (EPL). Inference on\nthe EPL and its generalization into a finite mixture framework was originally\naddressed from the frequentist perspective. In this work, we propose the\nBayesian estimation of the EPL with order constraints on the reference order\nparameter. The restrictions for the discrete parameter reflect a meaningful\nrank assignment process and, in combination with the data augmentation strategy\nand the conjugacy of the Gamma prior distribution with the EPL, facilitate the\nconstruction of a tuned joint Metropolis-Hastings algorithm within Gibbs\nsampling to simulate from the posterior distribution. We additionally propose a\nnovel model diagnostic to assess the adequacy of the EPL parametric\nspecification. The usefulness of the proposal is illustrated with applications\nto simulated and real datasets.", "category": "stat.ME"}, {"title": "Generalized partially linear models on Riemannian manifolds", "abstract": "The generalized partially linear models on Riemannian manifolds are\nintroduced. These models, like ordinary generalized linear models, are a\ngeneralization of partially linear models on Riemannian manifolds that allow\nfor response variables with error distribution models other than a normal\ndistribution. Partially linear models are particularly useful when some of the\ncovariates of the model are elements of a Riemannian manifold, because the\ncurvature of these spaces makes it difficult to define parametric models. The\nmodel was developed to address an interesting application, the prediction of\nchildren's garment fit based on 3D scanning of their body. For this reason, we\nfocus on logistic and ordinal models and on the important and difficult case\nwhere the Riemannian manifold is the three-dimensional case of Kendall's shape\nspace. An experimental study with a well-known 3D database is carried out to\ncheck the goodness of the procedure. Finally it is applied to a 3D database\nobtained from an anthropometric survey of the Spanish child population. A\ncomparative study with related techniques is carried out.", "category": "stat.ME"}, {"title": "Towards replicability with confidence intervals for the exceedance probability", "abstract": "Several scientific fields including psychology are undergoing a replication\ncrisis. There are many reasons for this problem, one of which is a misuse of\np-values. There are several alternatives to p-values, and in this paper we\ndescribe a complement that is geared towards replication. In particular, we\nfocus on confidence intervals for the probability that a parameter estimate\nwill exceed a specified value in an exact replication study. These intervals\nconvey uncertainty in a way that p-values and standard confidence intervals do\nnot, and can help researchers to draw sounder scientific conclusions. After\nbriefly reviewing background on p-values and a few alternatives, we describe\nour approach and provide examples with simulated and real data. For linear\nmodels, we also describe how confidence intervals for the exceedance\nprobability are related to p-values and confidence intervals for parameters.", "category": "stat.ME"}, {"title": "The nonparametric location-scale mixture cure model", "abstract": "We propose completely nonparametric methodology to investigate location-scale\nmodelling of two-component mixture cure models, where the responses of interest\nare only indirectly observable due to the presence of censoring and the\npresence of so-called long-term survivors that are always censored. We use\ncovariate-localized nonparametric estimators, which depend on a bandwidth\nsequence, to propose an estimator of the error distribution function that has\nnot been considered before in the literature. When this bandwidth belongs to a\ncertain range of undersmoothing bandwidths, the asymptotic distribution of the\nproposed estimator of the error distribution function does not depend on this\nbandwidth, and this estimator is shown to be root-n consistent. This suggests\nthat a computationally costly bandwidth selection procedure is unnecessary to\nobtain an effective estimator of the error distribution, and that a simpler\nrule-of-thumb approach can be used instead. A simulation study investigates the\nfinite sample properties of our approach, and the methodology is illustrated\nusing data obtained to study the behavior of distant metastasis in\nlymph-node-negative breast cancer patients.", "category": "stat.ME"}, {"title": "A local depth measure for general data", "abstract": "We introduce the Integrated Dual Local Depth which is a local depth measure\nfor data in a Banach space based on the use of one-dimensional projections. The\nproperties of a depth measure are analyzed under this setting and a proper\ndefinition of local symmetry is given. Moreover, strong consistency results for\nthe local depth and also for the local depth regions are attained. Finally,\napplications to descriptive data analysis and classification are analyzed,\nmaking the special focus on multivariate functional data, where we obtain very\npromising results.", "category": "stat.ME"}, {"title": "Empirical Likelihood Based Summary ROC Curve for Meta-Analysis of Diagnostic Studies", "abstract": "Objectives: This study provides an effective model selection method based on\nthe empirical likelihood approach for constructing summary receiver operating\ncharacteristic (sROC) curves from meta-analyses of diagnostic studies.\n  Methods: We considered models from combinations of family indices and\nspecific pairs of transformations, which cover several widely used methods for\nbivariate summary of sensitivity and specificity. Then a final model was\nselected using the proposed empirical likelihood method. Simulation scenarios\nwere conducted based on different number of studies and different population\ndistributions for the disease and non-disease cases. The performance of our\nproposal and other model selection criteria was also compared.\n  Results: Although parametric likelihood-based methods are often applied in\npractice due to its asymptotic property, they fail to consistently choose\nappropriate models for summary under the limited number of studies. For these\nsituations, our proposed method almost always performs better.\n  Conclusion: When the number of studies is as small as 10 or 5, we recommend\nchoosing a summary model via the proposed empirical likelihood method.", "category": "stat.ME"}, {"title": "Partially Linear Spatial Probit Models", "abstract": "A partially linear probit model for spatially dependent data is considered. A\ntriangular array setting is used to cover various patterns of spatial data.\nConditional spatial heteroscedasticity and non-identically distributed\nobservations and a linear process for disturbances are assumed, allowing\nvarious spatial dependencies. The estimation procedure is a combination of a\nweighted likelihood and a generalized method of moments. The procedure first\nfixes the parametric components of the model and then estimates the\nnon-parametric part using weighted likelihood; the obtained estimate is then\nused to construct a GMM parametric component estimate. The consistency and\nasymptotic distribution of the estimators are established under sufficient\nconditions. Some simulation experiments are provided to investigate the finite\nsample performance of the estimators.", "category": "stat.ME"}, {"title": "Approximate Bayesian Computation in controlled branching processes: the role of summary statistics", "abstract": "Controlled branching processes are stochastic growth population models in\nwhich the number of individuals with reproductive capacity in each generation\nis controlled by a random control function. The purpose of this work is to\nexamine the Approximate Bayesian Computation (ABC) methods and to propose\nappropriate summary statistics for them in the context of these processes. This\nmethodology enables to approximate the posterior distribution of the parameters\nof interest satisfactorily without explicit likelihood calculations and under a\nminimal set of assumptions. In particular, the tolerance rejection algorithm,\nthe sequential Monte Carlo ABC algorithm, and a post-sampling correction method\nbased on local-linear regression are provided. The accuracy of the proposed\nmethods are illustrated and compared with a \"likelihood free\" Markov chain\nMonte Carlo technique by the way of a simulated example developed with the\nstatistical software R.", "category": "stat.ME"}, {"title": "An information-theoretic Phase I/II design for molecularly targeted agents that does not require an assumption of monotonicity", "abstract": "For many years Phase I and Phase II clinical trials were conducted\nseparately, but there was a recent shift to combine these Phases. While a\nvariety of Phase~I/II model-based designs for cytotoxic agents were proposed in\nthe literature, methods for molecularly targeted agents (TA) are just starting\nto develop. The main challenge of the TA setting is the unknown dose-efficacy\nrelation that can have either an increasing, plateau or umbrella shape. To\ncapture these, approaches with more parameters are needed to model the\ndose-efficacy relationship or, alternatively, more orderings of the\ndose-efficacy relationship are required to account for the uncertainty in the\ncurve shape. As a result, designs for more complex clinical trials, for\nexample, trials looking at schedules of a combination treatment involving TA,\nhave not been extensively studied yet. We propose a novel regimen-finding\ndesign which is based on a derived efficacy-toxicity trade-off function. Due to\nits special properties, an accurate regimen selection can be achieved without\nany parametric or monotonicity assumptions. We illustrate how this design can\nbe applied in the context of a complex combination-schedule clinical trial. We\ndiscuss practical and ethical issues such as coherence, delayed and missing\nefficacy responses, safety and futility constraints.", "category": "stat.ME"}, {"title": "Poisson Kernel-Based Clustering on the Sphere: Convergence Properties, Identifiability, and a Method of Sampling", "abstract": "Many applications of interest involve data that can be analyzed as unit\nvectors on a d-dimensional sphere. Specific examples include text mining, in\nparticular clustering of documents, biology, astronomy and medicine among\nothers. Previous work has proposed a clustering method using mixtures of\nPoisson kernel-based distributions (PKBD) on the sphere. We prove\nidentifiability of mixtures of the aforementioned model, convergence of the\nassociated EM-type algorithm and study its operational characteristics.\nFurthermore, we propose an empirical densities distance plot for estimating the\nnumber of clusters in a PKBD model. Finally, we propose a method to simulate\ndata from Poisson kernel-based densities and exemplify our methods via\napplication on real data sets and simulation experiments.", "category": "stat.ME"}, {"title": "On finite-population Bayesian inferences for $2^K$ factorial designs with binary outcomes", "abstract": "Inspired by the pioneering work of Rubin (1978), we employ the potential\noutcomes framework to develop a finite-population Bayesian causal inference\nframework for randomized controlled $2^K$ factorial designs with binary\noutcomes, which are common in medical research. As demonstrated by simulated\nand empirical examples, the proposed framework corrects the well-known variance\nover-estimation issue of the classic \"Neymanian\" inference framework, under\nvarious settings.", "category": "stat.ME"}, {"title": "Improved Neymanian analysis for $2^K$ factorial designs with binary outcomes", "abstract": "$2^K$ factorial designs are widely adopted by statisticians and the broader\nscientific community. In this short note, under the potential outcomes\nframework (Neyman, 1923; Rubin, 1974), we adopt the partial identification\napproach and derive the sharp lower bound of the sampling variance of the\nestimated factorial effects, which leads to an \"improved\" Neymanian variance\nestimator that mitigates the over-estimation issue suffered by the classic\nNeymanian variance estimator by Dasgupta et al. (2015).", "category": "stat.ME"}, {"title": "Weighted Bayesian Bootstrap for Scalable Bayes", "abstract": "We develop a weighted Bayesian Bootstrap (WBB) for machine learning and\nstatistics. WBB provides uncertainty quantification by sampling from a high\ndimensional posterior distribution. WBB is computationally fast and scalable\nusing only off-theshelf optimization software such as TensorFlow. We provide\nregularity conditions which apply to a wide range of machine learning and\nstatistical models. We illustrate our methodology in regularized regression,\ntrend filtering and deep learning. Finally, we conclude with directions for\nfuture research.", "category": "stat.ME"}, {"title": "Spiral arms, warping, and clumps formation in the Galactic center young stellar disk", "abstract": "The Galactic center of the Milky-Way harbors a massive black hole (BH)\norbited by a diverse population of young and old stars. A significant fraction\nof the youngest stars ($\\sim4-7$ Myr) reside in a thin stellar disk with\npuzzling properties; the disk appears to be warped, shows asymmetries, and\ncontains one or more clumpy structures (e.g. IRS 13). Models explaining the\nclumping invoked the existence of an intermediate-mass BH of $10^{3}-10^{4}$\nM$_{\\odot}$, but no kinematic evidence for such a BH has been found. Here we\nuse extended $N$-body simulations and hybrid self-consistent field method\nmodels to show that naturally formed residual temporal asphericity of the\nhosting nuclear star cluster gives rise to torques on the disk, which lead to\nchanges in its orientation over time, and to recurrent formation and\ndissolution of single spiral arm ($m=1$ modes) structures. The changing\norientation leads to a flapping-like behavior of the disk and to the formation\nof a warped disk structure. The spiral arms may explain the over-densities in\nthe disk (clumping) and its observed asymmetry, without invoking the existence\nof an intermediate-mass BH. The spiral arms are also important for the overall\ndisk evolution and can be used to constrain the structure and composition of\nthe nuclear stellar cluster.", "category": "astro-ph.GA"}, {"title": "Advancing the Velocity Gradient Technique: Using Gradient Amplitudes and handling thermal broadening", "abstract": "The recent development of the Velocity Gradient Technique allows observers to\nmap magnetic field orientations and magnetization using the direction of\nvelocity gradients. Aside from the directions, amplitudes of velocity gradients\nalso contain valuable information about the underlying properties of\nmagneto-hydrodynamic (MHD) turbulence. In this paper, we explore what physical\ninformation is contained in the amplitudes of velocity gradients and discuss\nhow this information can be used to diagnose properties of turbulence in both\ndiffuse and self-gravitating interstellar media. We identify the relations\nbetween amplitudes of both intensity and velocity centroid gradients and the\nsonic Mach number $M_s$ and they are consistent with the theory's predictions.\nWe test the robustness of the method and discuss how to utilize the amplitudes\nof gradients into self-gravitating media. To extend the velocity gradient\ntechnique we also discuss the usage of amplitude method to Position-Position\nVelocity (PPV) space as a possible way to retrieve the velocity channel maps\nbefore the contamination of thermal broadening. We discuss that the Velocity\nGradient Technique with these advancements could potentially give a\nsignificantly more accurate statistical insight into the properties magnetized\nturbulence.", "category": "astro-ph.GA"}, {"title": "Understanding the strong intervening OVI absorber at z$_{abs}$ ~0.93 towards PG1206+459", "abstract": "We have obtained new observations of the partial Lyman limit absorber at\n\\zabs$=0.93$ towards quasar PG~1206+459, and revisit its chemical and physical\nconditions. The absorber, with $ N(HI) \\sim 10^{17.0}$ ~\\sqcm\\ and absorption\nlines spread over $\\gtrsim$1000~\\kms\\ in velocity, is one of the strongest\nknown OVI absorbers at $\\log N(OVI)=$15.54$\\pm$0.17. Our analysis makes use of\nthe previously known low-(e.g. \\MgII), intermediate-(e.g. SiIV), and\nhigh-ionization (e.g., CIV, NV, NeVIII) metal lines along with new $HST/$COS\nobservations that cover OVI, and an $HST/$ACS image of the quasar field.\nConsistent with previous studies, we find that the absorber has a multiphase\nstructure. The low-ionization phase arises from gas with a density of $\\log\n(n_{\\rm H}/\\rm cm^{-3})\\sim-2.5$ and a solar to super-solar metallicity. The\nhigh-ionization phase stems from gas with a significantly lower density, i.e.\n$\\log (n_{\\rm H}/\\rm cm^{-3}) \\sim-3.8$, and a near-solar to solar metallicity.\nThe high-ionization phase accounts for all of the absorption seen in CIV, NV,\nand OVI. We find the the detected \\NeVIII, reported by \\cite{Tripp2011}, is\nbest explained as originating in a stand-alone collisionally ionized phase at\n$T\\sim10^{5.85}~\\rm K$, except in one component in which both OVI and NeVIII\ncan be produced via photoionization. We demonstrate that such strong OVI\nabsorption can easily arise from photoionization at $z\\gtrsim1$, but that, due\nto the decreasing extragalactic UV background radiation, only collisional\nionization can produce large OVI features at $z\\sim0$. The azimuthal angle of\n$\\sim88$\\degree\\ of the disk of the nearest ($\\rm 68~kpc$) luminous ($1.3L_*$)\ngalaxy at $z_{\\rm gal}=0.9289$, which shows signatures of recent merger,\nsuggests that the bulk of the absorption arises from metal enriched outflows.", "category": "astro-ph.GA"}, {"title": "Gradients of Synchrotron Polarization: Tracing 3D distribution of magnetic fields", "abstract": "We describe a new technique for probing galactic and extragalactic 2D and 3D\nmagnetic field distribution using gradients of polarized synchrotron emission.\nThe fluctuations of magnetic field are elongated along the ambient magnetic\nfield. Therefore, the field variations are maximal perpendicular to the\nB-field. This allows tracing B-field with synchrotron polarization gradients\n(SPGs). We demonstrate that the Faraday depolarization allows to map 3D B-field\nstructure by. The depolarization ensures that the polarization gradients sample\nthe regions close to the observer with the sampling depth controlled by the\nfrequency of radiation. We also analyze the B-field properties along the\nline-of-sight by applying the gradient technique to the wavelength derivative\nof synchrotron polarization. This Synchrotron Derivative Polarization Gradients\n(SDPGs) technique can recover the 3D vectors of the underlying B-fields. The\nnew techniques are different from the Faraday tomography as they provide a way\nto map the 3D distribution of B-fields components perpendicular to the line of\nsight. In addition, we find that the alignment of gradients of polarization\nwith the synchrotron polarization can be used to separate the contribution of\nthe foreground from the polarization of cosmological origin. We notice that the\nsame alignment is also present for the dust polarization.", "category": "astro-ph.GA"}, {"title": "Revealing the velocity structure of the filamentary nebula in NGC 1275 in its entirety", "abstract": "We have produced for the first time a detailed velocity map of the giant\nfilamentary nebula surrounding NGC 1275, the Perseus cluster's brightest\ngalaxy, and revealed a previously unknown rich velocity structure across the\nentire nebula. We present new observations of the low-velocity component of\nthis nebula with the optical imaging Fourier transform spectrometer SITELLE at\nCFHT. With its wide field of view ($\\sim$11'$\\times$11'), SITELLE is the only\nintegral field unit spectroscopy instrument able to cover the 80 kpc$\\times$55\nkpc (3.8'$\\times$2.6') large nebula in NGC 1275. Our analysis of these\nobservations shows a smooth radial gradient of the [N\nII]$\\lambda$6583/$\\text{H} \\alpha$ line ratio, suggesting a change in the\nionization mechanism and source across the nebula, while the dispersion profile\nshows a general decrease with increasing distance from the AGN at up to $\\sim\n10$ kpc. The velocity map shows no visible general trend or rotation,\nindicating that filaments are not falling uniformly onto the galaxy, nor being\npulled out from it. Comparison between the physical properties of the filaments\nand Hitomi measurements of the X-ray gas dynamics in Perseus are also explored.", "category": "astro-ph.GA"}, {"title": "The ALFALFA HI mass function: A dichotomy in the low-mass slope and a locally suppressed 'knee' mass", "abstract": "We present the most precise measurement of the $z = 0$ HI mass function\n(HIMF) to date based on the final catalogue of the ALFALFA (Arecibo Legacy Fast\nALFA) blind HI survey of the nearby Universe. The Schechter function fit has a\n`knee' mass $\\log (M_{*}\\,h^{2}_{70}/\\mathrm{M_{\\odot}}) = 9.94 \\pm 0.01 \\pm\n0.05$, a low-mass slope parameter $\\alpha = -1.25 \\pm 0.02 \\pm 0.1$, and a\nnormalisation $\\phi_{*} = (4.5 \\pm 0.2 \\pm 0.8) \\times 10^{-3} \\;\nh^{3}_{70}\\,\\mathrm{Mpc^{-3}\\,dex^{-1}}$, with both random and systematic\nuncertainties as quoted. Together these give an estimate of the HI content of\nthe $z = 0$ Universe as $\\Omega_{\\mathrm{HI}} = (3.9 \\pm 0.1 \\pm 0.6) \\times\n10^{-4} \\, h^{-1}_{70}$ (corrected for HI self-absorption). Our analysis of the\nuncertainties indicates that the `knee' mass is a cosmologically fair\nmeasurement of the $z = 0$ value, with its largest uncertainty originating from\nthe absolute flux calibration, but that the low-mass slope is only\nrepresentative of the local Universe. We also explore large scale trends in\n$\\alpha$ and $M_{*}$ across the ALFALFA volume. Unlike with the 40 per cent\nsample, there is now sufficient coverage in both of the survey fields to make\nan independent determination of the HIMF in each. We find a large discrepancy\nin the low-mass slope ($\\Delta \\alpha = 0.14 \\pm 0.03$) between the two\nregions, and argue that this is likely caused by the presence of a deep void in\none field and the Virgo cluster in the other. Furthermore, we find that the\nvalue of the `knee' mass within the Local Volume appears to be suppressed by\n$0.18 \\pm 0.04$ dex compared to the global ALFALFA value, which explains the\nlower value measured by the shallower HIPASS. We discuss possible explanations\nand interpretations of these results and how they can be expanded on with\nfuture surveys.", "category": "astro-ph.GA"}, {"title": "Asymmetric emission of the [OIII]$λ$5007 profile in narrow-line Seyfert 1 galaxies", "abstract": "Many active galactic nuclei (AGN) and particularly narrow-line Seyfert 1\n(NLS1) galaxies, usually exhibit blueshifts and blue wings in several emission\nlines, which are mainly associated with outflows and strong winds. In order to\nstudy the radial velocity difference between the narrow component of H$\\beta$\nand the core component of [OIII]$\\lambda$5007 and the asymmetric emission of\nthis forbidden line, we investigate a sample of NLS1 galaxies . One of the aims\nof this paper is to analyze the blue wings of the [OIII]$\\lambda$5007 profiles\nand their relation with the central engine. We have obtained and studied\nmedium-resolution spectra (190 km s$^{-1}$ FWHM at H$\\beta$) of a sample of 28\nNLS1 galaxies in the optical range 4300 - 5200\\AA. We performed Gaussian\ndecomposition to the H$\\beta$ and [OIII]$\\lambda\\lambda$4959,5007 emission\nprofiles in order to study the distinct components of these lines. A new blue\noutlier galaxy is found, in which the center of the core component of [OIII] is\nblueshifted by 405 km s$^{-1}$ relative to the center of the narrow component\nof H$\\beta$ line. We confirmed a previously known correlation between the\nblueshift and the full width half maximum (FWHM) of the core component of\n[OIII]$\\lambda$5007 line. We also corroborated the correlation between the\nlatter and the velocity of the centroid of the blue wing. On the other hand, by\nstudying the radial velocity difference between the blue end of the asymmetric\nemission and the centroid of the core component of [OIII], we found a\ncorrelation between it and the central black hole mass and, therefore, with the\nluminosity of the broad component of H$\\beta$. Finally, we found a moderate\ncorrelation between the luminosity of the [OIII] blue wing and the black hole\nmass.", "category": "astro-ph.GA"}, {"title": "Thirty-fold: Extreme gravitational lensing of a quiescent galaxy at $z=1.6$", "abstract": "We report the discovery of eMACSJ1341-QG-1, a quiescent galaxy at $z=1.594$\nlocated behind the massive galaxy cluster eMACSJ1341.9$-$2442 ($z=0.835$). The\nsystem was identified as a gravitationally lensed triple image in Hubble Space\nTelescope images obtained as part of a snapshot survey of the most X-ray\nluminous galaxy clusters at $z>0.5$ and spectroscopically confirmed in\nground-based follow-up observations with the ESO/X-Shooter spectrograph. From\nthe constraints provided by the triple image, we derive a first, crude model of\nthe mass distribution of the cluster lens, which predicts a gravitational\namplification of a factor of $\\sim$30 for the primary image and a factor of\n$\\sim$6 for the remaining two images of the source, making eMACSJ1341-QG-1 by\nfar the most strongly amplified quiescent galaxy discovered to date. Our\ndiscovery underlines the power of SNAPshot observations of massive, X-ray\nselected galaxy clusters for lensing-assisted studies of faint background\npopulations.", "category": "astro-ph.GA"}, {"title": "The population of single and binary white dwarfs of the Galactic bulge", "abstract": "Recent Hubble Space Telescope observations have unveiled the white dwarf\ncooling sequence of the Galactic bulge. Although the degenerate sequence can be\nwell fitted employing the most up-to-date theoretical cooling sequences,\nobservations show a systematic excess of red objects that cannot be explained\nby the theoretical models of single carbon-oxygen white dwarfs of the\nappropriate masses. Here we present a population synthesis study of the white\ndwarf cooling sequence of the Galactic bulge that takes into account the\npopulations of both single white dwarfs and binary systems containing at least\none white dwarf. These calculations incorporate state-of-the-art cooling\nsequences for white dwarfs with hydrogen-rich and hydrogen-deficient\natmospheres, for both white dwarfs with carbon-oxygen and helium cores, and\nalso take into account detailed prescriptions of the evolutionary history of\nbinary systems. Our Monte Carlo simulator also incorporates all the known\nobservational biases. This allows us to model with a high degree of realism the\nwhite dwarf population of the Galactic bulge. We find that the observed excess\nof red stars can be partially attributed to white dwarf plus main sequence\nbinaries, and to cataclysmic variables or dwarf novae. Our best fit is obtained\nwith a higher binary fraction and an initial mass function slope steeper than\nstandard values, as well as with the inclusion of differential reddening and\nblending. Our results also show that the possible contribution of double\ndegenerate systems or young and thick-disk bulge stars is negligible.", "category": "astro-ph.GA"}, {"title": "The Strong Gravitationally Lensed Herschel Galaxy HLock01: Optical Spectroscopy Reveals a Close Galaxy Merger with Evidence of Inflowing Gas", "abstract": "The submillimeter galaxy (SMG) HERMES J105751.1+573027 (hereafter HLock01) at\nz = 2.9574 +/- 0.0001 is one of the brightest gravitationally lensed sources\ndiscovered in the Herschel Multi-tiered Extragalactic Survey. Apart from the\nhigh flux densities in the far-infrared, it is also extremely bright in the\nrest-frame ultraviolet (UV), with a total apparent magnitude m_UV = 19.7 mag.\nWe report here deep spectroscopic observations with the Gran Telescopio\nCanarias of the optically bright lensed images of HLock01. Our results suggest\nthat HLock01 is a merger system composed of the Herschel-selected SMG and an\noptically bright Lyman break-like galaxy (LBG), separated by only 3.3 kpc in\nprojection. While the SMG appears very massive (M* = 5x10^11 Msun), with a\nhighly extinguished stellar component (A_V = 4.3), the LBG is a young,\nlower-mass (M* = 1x10^10 Msun), but still luminous (10xL*_UV) satellite galaxy.\nDetailed analysis of the high signal-to-noise (S/N) rest-frame UV spectrum of\nthe LBG shows complex kinematics of the gas, exhibiting both blueshifted and\nredshifted absorption components. While the blueshifted component is associated\nwith strong galactic outflows from the massive stars in the LBG, as is common\nin most star-forming galaxies, the redshifted component may be associated with\ngas inflow seen along a favorable sightline to the LBG. We also find evidence\nof an extended gas reservoir around HLock01 at an impact parameter of 110 kpc,\nthrough the detection of C II 1334$\\AA$ absorption in the red wing of a bright\nLy-alpha emitter at z = 3.327. The data presented here highlight the power of\ngravitational lensing in high S/N studies to probe deeply into the physics of\nhigh-z star forming galaxies.", "category": "astro-ph.GA"}, {"title": "EDIBLES II. On the detectability of C60+ bands", "abstract": "Gas phase spectroscopic laboratory experiments for the buckminsterfullerene\ncation C60+ resulted in accurate rest wavelengths for five C60+ transitions\nthat have been compared with diffuse interstellar bands (DIBs) in the near\ninfra-red. Detecting these in astronomical spectra is difficult due to the\nstrong contamination of ground-based spectra by atmospheric water vapor, to the\npresence of weak and shallow stellar lines and/or blending with other weak\nDIBs. The detection of the two strong bands has been claimed by several teams,\nand the three additional and weaker bands have been detected in a few sources.\nCertain recent papers have argued against the identification of C60+ based on\nspectral analyses claiming (i) a large variation in the ratio between the\nequivalent widths of the 9632 and 9577\\AA\\: bands, (ii) a large redshift of the\n9632\\AA\\: band for the Orion star HD 37022, and (iii) the non-detection of the\nweaker 9428\\AA~DIB. Here we address these three points. (i) We show that the\nmodel stellar line correction for the 9632\\AA~DIB overestimates the difference\nbetween the strengths of the lines in giant and dwarf star spectra, casting\ndoubts on the conclusions about the ratio variability. (ii) Using high quality\nstellar spectra from the ESO Diffuse Interstellar Bands Large Exploration\nSurvey (EDIBLES), recorded with the ESO/Paranal Ultraviolet Echelle\nSpectrograph (UVES) in about the same atmospheric conditions, we find no\nwavelength shift in the 9632\\AA\\ band towards HD 37022. (iii) Using EDIBLES\nspectra and data from the Echelle SpectroPolarimetric Device for the\nObservation of Stars (ESPaDOnS) at CFHT we show that the presence of a weak\n9428\\AA\\ band cannot be ruled out, even in the same observations that a\nprevious study claimed it was not present.", "category": "astro-ph.GA"}, {"title": "Outflows in the Narrow Line Region of Bright Seyfert Galaxies - I: GMOS-IFU Data", "abstract": "We present two-dimensional maps of emission-line fluxes and kinematics, as\nwell as of the stellar kinematics of the central few kpc of five bright nearby\nSeyfert galaxies -- Mrk\\,6, Mrk\\,79, Mrk\\,348, Mrk\\,607 and Mrk\\,1058 --\nobtained from observations with the Gemini Multi-Object Spectrograph (GMOS)\nIntegral Field Unit (IFU) on the Gemini North Telescope. The data cover the\ninner 3\\farcs5$\\times$5\\farcs0 -- corresponding to physical scales in the range\n0.6$\\times$0.9 to 1.5$\\times$2.2\\,kpc$^2$ -- at a spatial resolution ranging\nfrom 110 to 280 pc with a spectral coverage of 4300 -- 7100\\,\\AA\\ and velocity\nresolution of $\\approx$ 90\\,km\\,s$^{-1}$. The gas excitation is Seyfert like\neverywhere but show excitation, but show excitation gradients that are\ncorrelated with the gas kinematics, reddening and/or the gas density. The gas\nkinematics show in all cases two components: a rotation one similar to that\nobserved in the stellar velocity field, and an outflow component. In the case\nof Mrk607, the gas is counter-rotating relative to the stars. Enhanced gas\nvelocity dispersion is observed in association to the outflows according to two\npatterns: at the locations of the highest outflow velocities along the\nionization axis or perpendicularly to it in a strip centered at the nucleus\nthat we attribute to an equatorial outflow. Bipolar outflows are observed in\nMrk\\,348 and Mrk\\,79, while in Mrk\\,1058 only the blueshifted part is clearly\nobserved, while in the cases of Mrk\\,6 and Mrk\\,607 the geometry of the outflow\nneeds further constraints from modeling to be presented in a forthcoming study,\nwhere the mass flow rate and powers will also be obtained.", "category": "astro-ph.GA"}, {"title": "Origin of the Local Group satellite planes", "abstract": "We attempt to understand the planes of satellite galaxies orbiting the Milky\nWay (MW) and M31 in the context of Modified Newtonian Dynamics (MOND), which\nimplies a close MW-M31 flyby occurred ${\\approx 8}$ Gyr ago. Using the timing\nargument, we obtain MW-M31 trajectories consistent with cosmological initial\nconditions and present observations. We adjust the present M31 proper motion\nwithin its uncertainty in order to simulate a range of orbital geometries and\nclosest approach distances. Treating the MW and M31 as point masses, we follow\nthe trajectories of surrounding test particle disks, thereby mapping out the\ntidal debris distribution.\n  Around each galaxy, the resulting tidal debris tends to cluster around a\nparticular orbital pole. We find some models in which these preferred spin\nvectors align fairly well with those of the corresponding observed satellite\nplanes. The radial distributions of material in the simulated satellite planes\nare similar to what we observe. Around the MW, our best-fitting model yields a\nsignificant fraction (0.22) of counter-rotating material, perhaps explaining\nwhy Sculptor counter-rotates within the MW satellite plane. In contrast, our\nmodel yields no counter-rotating material around M31. This is testable with\nproper motions of M31 satellites.\n  In our best model, the MW disk is thickened by the flyby 7.65 Gyr ago to a\nroot mean square height of 0.75 kpc. This is similar to the observed age and\nthickness of the Galactic thick disk. Thus, the MW thick disk may have formed\ntogether with the MW and M31 satellite planes during a past MW-M31 flyby.", "category": "astro-ph.GA"}, {"title": "A simple model for molecular hydrogen chemistry coupled to radiation hydrodynamics", "abstract": "We introduce non-equilibrium molecular hydrogen chemistry into the radiation\nhydrodynamics code Ramses-RT. This is an adaptive mesh refinement grid code\nwith radiation hydrodynamics that couples the thermal chemistry of hydrogen and\nhelium to moment-based radiative transfer with the Eddington tensor closure\nmodel. The H2 physics that we include are formation on dust grains, gas phase\nformation, formation by three-body collisions, collisional destruction,\nphotodissociation, photoionization, cosmic ray ionization, and self-shielding.\nIn particular, we implement the first model for H2 self-shielding that is tied\nlocally to moment-based radiative transfer by enhancing photodestruction. This\nself-shielding from Lyman-Werner line overlap is critical to H2 formation and\ngas cooling. We can now track the non-equilibrium evolution of molecular,\natomic, and ionized hydrogen species with their corresponding dissociating and\nionizing photon groups. Over a series of tests we show that our model works\nwell compared to specialized photodissociation region codes. We successfully\nreproduce the transition depth between molecular and atomic hydrogen, molecular\ncooling of the gas, and a realistic Stromgren sphere embedded in a molecular\nmedium. In this paper we focus on test cases to demonstrate the validity of our\nmodel on small scales. Our ultimate goal is to implement this in large-scale\ngalactic simulations.", "category": "astro-ph.GA"}, {"title": "The disc origin of the Milky Way bulge: Dissecting the chemo-morphological relations using N-body simulations and APOGEE", "abstract": "There is a long-standing debate on the origin of the metal-poor stellar\npopulations of the Milky Way (MW) bulge, with the two leading scenarios being\nthat these populations are either i) part of a classical metal-poor spheroid or\nii) the same population as the chemically defined thick disc seen at the Solar\nneighbourhood. Here we test whether the latter scenario can reproduce the\nobserved chemical properties of the MW bulge. To do so we compare an N-body\nsimulation of a composite (thin+thick) stellar disc -- which evolves secularly\nto form a bar and a boxy/peanut (b/p) bulge -- to data from APOGEE DR13. This\nmodel, in which the thick disc is massive and centrally concentrated, can\nreproduce the morphology of the metal-rich and metal-poor stellar populations\nin the bulge, as well as the mean metallicity and [$\\alpha$/Fe] maps as\nobtained from the APOGEE data. It also reproduces the trends, in both longitude\nand latitude, of the bulge metallicity distribution function (MDF).\nAdditionally, we show that the model predicts small but measurable azimuthal\nmetallicity variations in the inner disc due to the differential mapping of the\nthin and thick disc in the bar. We therefore see that the chemo-morphological\nrelations of stellar populations in the MW bulge are naturally reproduced by\nmapping the thin and thick discs of the inner MW into a b/p.", "category": "astro-ph.GA"}, {"title": "Mapping UV Properties Throughout the Cosmic Horseshoe: Lessons from VLT-MUSE", "abstract": "We present the first spatially-resolved rest-frame UV study of the\ngravitationally lensed galaxy, the 'Cosmic Horseshoe' (J1148+1930) at z=2.38.\nOur gravitational lens model shows that the system is made up of four\nstar-forming regions, each ~4-8 kpc^2 in size, from which we extract four\nspatially exclusive regional spectra. We study the interstellar and wind\nabsorption lines, along with CIII] doublet emission lines, in each region to\ninvestigate any variation in emission/absorption line properties. The mapped\nCIII] emission shows distinct kinematical structure, with velocity offsets of\n~+/-50 km/s between regions suggestive of a merging system, and a variation in\nequivalent width that indicates a change in ionisation parameter and/or\nmetallicity between the regions. Absorption line velocities reveal a range of\noutflow strengths, with gas outflowing between -200<v(km/s)<-50 relative to the\nsystemic velocity of that region. Interestingly, the strongest gas outflow\nappears to emanate from the most diffuse star-forming region. The\nstar-formation rates remain relatively constant (~8-16 M_sol/yr), mostly due to\nlarge uncertainties in reddening estimates. As such, the outflows appear to be\n'global' rather than 'locally' sourced. We measure electron densities with a\nrange of log(Ne)=3.92-4.36 cm^-3, and point out that such high densities may be\ncommon when measured using the CIII] doublet due to its large critical density.\nOverall, our observations demonstrate that while it is possible to trace\nvariations in large scale gas kinematics, detecting inhomogeneities in physical\ngas properties and their effects on the outflowing gas may be more difficult.\nThis study provides important lessons for the spatially-resolved rest-frame UV\nstudies expected with future observatories, such as JWST.", "category": "astro-ph.GA"}, {"title": "Resolving the Disc-Halo Degeneracy I: A Look at NGC 628", "abstract": "The decomposition of the rotation curve of galaxies into contribution from\nthe disc and dark halo remains uncertain and depends on the adopted mass to\nlight ratio (M/L) of the disc. Given the vertical velocity dispersion of stars\nand disc scale height, the disc surface mass density and hence the M/L can be\nestimated. We address a conceptual problem with previous measurements of the\nscale height and dispersion. When using this method, the dispersion and scale\nheight must refer to the same population of stars. The scale height is obtained\nfrom near-IR studies of edge-on galaxies and is weighted towards older\nkinematically hotter stars, whereas the dispersion obtained from integrated\nlight in the optical bands includes stars of all ages. We aim to extract the\ndispersion for the hotter stars, so that it can then be used with the correct\nscale height to obtain the disc surface mass density. We use a sample of\nplanetary nebulae (PNe) as dynamical tracers in the face-on galaxy NGC 628. We\nextract two different dispersions from its velocity histogram -- representing\nthe older and younger PNe. We also present complementary stellar absorption\nspectra in the inner regions of this galaxy and use a direct pixel fitting\ntechnique to extract the two components. Our analysis concludes that previous\nstudies, which do not take account of the young disc, underestimate the disc\nsurface mass density by a factor of ~ 2. This is sufficient to make a maximal\ndisc for NGC 628 appear like a submaximal disc.", "category": "astro-ph.GA"}, {"title": "MALS-NOT: Identifying Radio-Bright Quasars for the MeerKAT Absorption Line Survey", "abstract": "We present a preparatory spectroscopic survey to identify radio-bright,\nhigh-redshift quasars for the MeerKAT Absorption Line Survey (MALS). The\ncandidates have been selected on the basis of a single flux density limit at\n1.4 GHz (>200 mJy) together with mid-infrared color criteria from the\nWide-field Infrared Survey Explorer (WISE). Through spectroscopic observations\nusing the Nordic Optical Telescope, we identify 72 quasars out of 99 candidates\ntargeted. We measure the spectroscopic redshifts based on characteristic, broad\nemission lines present in the spectra. Of these 72 quasars, 64 and 48 objects\nare at sufficiently high redshift (z>0.6 and z>1.4) to be used for the L-band\nand UHF-band spectroscopic follow-up with the Square Kilometre Array (SKA)\nprecursor in South Africa: the MeerKAT.", "category": "astro-ph.GA"}, {"title": "ALMA [CI] observations toward the central region of a Seyfert galaxy NGC 613", "abstract": "We report ALMA observations of [CI]($^3P_1-^3P_0$), C$^{13}$O, and CO$^{18}$\n($J=1-0$) toward the central region of a nearby Seyfert galaxy NGC 613. The\nvery high resolutions of $0.26\"\\times0.23\"(=22\\times20$ pc) for [CI] and\n$0.42\"\\times0.35\"(=36\\times30$ pc) for C$^{13}$O, and CO$^{18}$ resolve the\ncircum-nuclear disk (CND) and star-forming ring. The distribution of [CI] in\nthe ring resembles that of the CO emission, although [CI] is prominent in the\nCND. This can be caused by the low intensities of the CO isotopes due to the\nlow optical depths under the high temperature in the CND. We found that the\nintensity ratios of [CI] to C$^{12}$O(3-2) ($R_{\\rm CI/CO}$) and to\nC$^{13}$O(1-0) ($R_{\\rm CI/C^{13}O}$) are high at several positions around the\nedge of the ring. The spectral profiles of CO lines mostly correspond each\nother in the spots of the ring and high $R_{\\rm CI/CO}$, but those of [CI] at\nspots of high $R_{\\rm CI/CO}$ are different from CO. These results indicate\nthat [CI] at the high $R_{\\rm CI/CO}$ traces different gas from that traced by\nthe CO lines. The [CI] kinematics along the minor axis of NGC 613 could be\ninterpreted as a bubbly molecular outflow. The outflow rate of molecular gas is\nhigher than star formation rate in the CND. The flow could be mainly boosted by\nthe AGN through its radio jets.", "category": "astro-ph.GA"}, {"title": "The morphological evolution, AGN fractions, dust content, environments, and downsizing of massive green valley galaxies at 0.5<z<2.5 in 3D-HST/CANDELS", "abstract": "To explore the evolutionary connection among red, green, and blue galaxy\npopulations, based on a sample of massive ($M_* > 10^{10} M_{\\odot} $) galaxies\nat 0.5<z<2.5 in five 3D-HST/CANDELS fields, we investigate the dust content,\nmorphologies, structures, AGN fractions, and environments of these three galaxy\npopulations. Green valley galaxies are found to have intermediate dust\nattenuation, and reside in the middle of the regions occupied by quiescent and\nstar-forming galaxies in the UVJ diagram. Compared with blue and red galaxy\npopulations at z<2, green galaxies have intermediate compactness and\nmorphological parameters such as Sersic index, concentration, Gini coefficient,\nand the second order moment of the 20% brightest pixels of a galaxy. Above\nfindings seem to favor the scenario that green galaxies are at transitional\nphase when star-forming galaxies are being quenched into quiescent status. The\ngreen galaxies at z<2 show the highest AGN fraction, suggesting that AGN\nfeedback may have played an important role in star formation quenching. For the\nmassive galaxies at 2<z<2.5, both red and green galaxies are found to have a\nsimilarly higher AGN fraction than the blue ones, which implies that AGN\nfeedback may help to keep quiescence of red galaxies at z>2. A significant\nenvironmental difference is found between green and red galaxies at z<1.5.\nGreen and blue galaxies at z>0.5 seem to have similar local density\ndistributions, suggesting that environment quenching is not the major mechanism\nto cease star formation at z>0.5. The fractions of three populations as\nfunctions of mass support a \"downsizing\" quenching picture that the bulk of\nstar formation in more massive galaxies is completed earlier than that of lower\nmass galaxies.", "category": "astro-ph.GA"}, {"title": "The Density Profile and Kinematics of the Milky Way with RR Lyrae Stars", "abstract": "Most of known RR Lyraes are type ab RR Lyraes (RRLab), and they are the\nexcellent tool to map the Milky Way and its substructures. We find that 1148\nRRLab stars determined by Drake et al.(2013) have been observed by\nspectroscopic surveys of SDSS and LAMOST. We derived radial velocity\ndispersion, circular velocity and mass profile from 860 halo tracers in our\npaper I. Here, we present the stellar densities and radial velocity\ndistributions of thick disk and halo of the Milky Way. The 288 RRLab stars\nlocated in the thick disk have the mean metallicity of [Fe/H]$=-1.02$. Three\nthick disk tracers have the radial velocity lower than 215 km $\\rm s^{-1}$.\nWith 860 halo tracers which have a mean metallicity of [Fe/H]$=-1.33$, we find\na double power-law of $n(r) \\propto r^{-2.8}$ and $n(r) \\propto r^{-4.8}$ with\na break distance of 21 kpc to express the halo stellar density profile. The\nradial velocity dispersion at 50 kpc is around 78 km $\\rm s^{-1}$.", "category": "astro-ph.GA"}, {"title": "Emergent Viscosity: An alternative for Dark Matter in Galaxies", "abstract": "We assume that the individual stars which are located at the peripheral parts\nof the spiral galaxies are experiencing a drag force acting upon them radially.\nSuch a force might be produced by some sort of a dynamically generated viscous\nmedium, and as the stars are in the state of free fall toward the center of the\ngalaxy, then it would balance the centripetal force acting on the star, thus\nresulting in a terminal velocity. We make no attempt to explain the origin of\nthe assumed drag force or show how it could be generated, but we have tried to\ntest such an assumption by fitting the calculated velocity curves of 18 spiral\ngalaxies with rotation curves obtained from actual observations. Results show\nremarkable agreements.", "category": "astro-ph.GA"}, {"title": "MOCCA-SURVEY Database I: Assessing GW kick retention fractions for BH-BH mergers in globular clusters", "abstract": "Anisotropy of gravitational wave (GW) emission results in a net momentum\ngained by the black hole (BH) merger product, leading to a recoil velocity up\nto $\\sim10^3\\text{ km s}^{-1}$, which may kick it out of a globular cluster\n(GC). We estimate GW kick retention fractions of merger products assuming\ndifferent models for BH spin magnitude and orientation (MS0 - random, MS1 -\nspin as a function of mass and metalicity, MS2 - constant value of $0.5$). We\ncheck how they depend on BH-BH merger time and properties of the cluster. We\nanalyze the implications of GW kick retention fractions on intermediate massive\nBH (IMBH) formation by repeated mergers in a GC. We also calculate final spin\nof the merger product, and investigate how it correlates with effective spin of\nthe binary. We used data from MOCCA (MOnte Carlo Cluster simulAtor) GC\nsimulations to get a realistic sample of BH-BH mergers, assigned each BH spin\nvalue according to a studied model, and calculated recoil velocity and final\nspin based on most recent theoretical formulas. We discovered that for\nphysically motivated models, GW kick retention fractions are about $30\\%$ and\ndisplay small dependence on assumptions about spin, but are much more prone to\ncluster properties. In particular, we discovered a strong dependence of GW kick\nretention fractions on cluster density. We also show that GW kick retention\nfractions are high in final life stages of the cluster, but low at the\nbeginning. Finally, we derive formulas connecting final spin with effective\nspin for primordial binaries, and with maximal effective spin for dynamical\nbinaries.", "category": "astro-ph.GA"}, {"title": "Multidimensional Data Driven Classification of Emission-line Galaxies", "abstract": "We propose a new soft clustering scheme for classifying galaxies in different\nactivity classes using simultaneously 4 emission-line ratios; log([NII ]/Ha),\nlog([SII]/Ha), log([OI]/Ha) and log([OIII]/Hb). We fit 20 multivariate Gaussian\ndistributions to the 4-dimensional distribution of these lines obtained from\nthe Sloan Digital Sky Survey (SDSS) in order to capture local structures and\nsubsequently group the multivariate Gaussian distributions to represent the\ncomplex multi-dimensional structure of the joint distribution of galaxy spectra\nin the 4 dimensional line ratio space. The main advantages of this method are\nthe use of all four optical-line ratios simultaneously and the adoption of a\nclustering scheme. This maximises the available information, avoids\ncontradicting classifications, and treats each class as a distribution\nresulting in soft classification boundaries and providing the probability for\nan object to belong to each class. We also introduce linear multi-dimensional\ndecision surfaces using support vector machines based on the classification of\nour soft clustering scheme. This linear multi-dimensional hard clustering\ntechnique shows high classification accuracy with respect to our\nsoft-clustering scheme.", "category": "astro-ph.GA"}, {"title": "Exploring the making of a galactic wind in the star-bursting dwarf irregular galaxy IC 10 with LOFAR", "abstract": "Low-mass galaxies are subject to strong galactic outflows, in which cosmic\nrays may play an important role, they can be best traced with low-frequency\nradio continuum observations, which are less affected by spectral ageing. We\npresent a study of the nearby star burst dwarf irregular galaxy IC 10 using\nobservations at 140 MHz with the LOw-Frequency ARray (LOFAR), at 1580 MHz with\nthe Very Large Array (VLA) and at 6200 MHz with the VLA and the 100-m\nEffelsberg telescope. We find that IC 10 has a low-frequency radio halo, which\nmanifests itself as a second component (thick disc) in the minor axis profiles\nof the non-thermal radio continuum emission at 140 and 1580 MHz. These profiles\nare then fitted with 1D cosmic-ray transport models for pure diffusion and\nadvection. We find that a diffusion model fits best, with a diffusion\ncoefficient of $D=(0.4$-$0.8) \\times 10^{26}(E/{\\rm GeV})^{0.5}~{\\rm\ncm^2\\,s^{-1}}$, which is at least an order of magnitude smaller than estimates\nboth from anisotropic diffusion and the diffusion length. In contrast,\nadvection models, which cannot be ruled out due to the mild inclination, while\nproviding poorer fits, result in advection speeds close to the escape velocity\nof $\\approx$$50~\\rm km\\,s^{-1}$, as expected for a cosmic-ray driven wind. Our\nfavoured model with an accelerating wind provides a self-consistent solution,\nwhere the magnetic field is in energy equipartition with both the warm neutral\nand warm ionized medium with an important contribution from cosmic rays.\nConsequently, cosmic rays can play a vital role for the launching of galactic\nwinds in the disc--halo interface.", "category": "astro-ph.GA"}, {"title": "Characterising bars in low surface brightness galaxies", "abstract": "In this paper, we use $\\textit{B}$-band, $\\textit{I}$-band, and 3.6 $\\mu$m\nazimuthal light profiles of four low surface brightness (LSB) galaxies (UGC\n628, F568-1, F568-3, F563-V2) to characterise three bar parameters: length,\nstrength, and corotation radius. We employ three techniques to measure the\nradius of the bars, including a new method using the azimuthal light profiles.\nWe find comparable bar radii between the $\\textit{I}$-band and 3.6 $\\mu$m for\nall four galaxies when using our azimuthal light profile method, and that our\nbar lengths are comparable to those in high surface brightness galaxies (HSBs).\nIn addition, we find the bar strengths for our galaxies to be smaller than\nthose for HSBs. Finally, we use Fourier transforms of the $\\textit{B}$-band,\n$\\textit{I}$-band, and 3.6 $\\mu$m images to characterise the bars as either\n`fast' or `slow' by measuring the corotation radius via phase profiles. When\nusing the $\\textit{B}$ and $\\textit{I}$-band phase crossings, we find three of\nour galaxies have faster than expected relative bar pattern speeds for galaxies\nexpected to be embedded in centrally-dense cold dark matter haloes. When using\nthe $\\textit{B}$-band and 3.6 $\\mu$m phase crossings, we find more ambiguous\nresults, although the relative bar pattern speeds are still faster than\nexpected. Since we find a very slow bar in F563-V2, we are confident that we\nare able to differentiate between fast and slow bars. Finally, we find no\nrelation between bar strength and relative bar pattern speed when comparing our\nLSBs to HSBs.", "category": "astro-ph.GA"}, {"title": "Variable Modified Newtonian Mechanics II: Baryonic Tully Fisher Relation", "abstract": "Recently we find a single-metric solution for a point mass residing in an\nexpanding universe \\cite{wong}, which apart from the Newtonian acceleration,\ngives rise to an additional MOND-like acceleration in which the MOND\nacceleration $a_0$ is replaced by the cosmological acceleration. We study a\nMilky Way size protogalactic cloud in this acceleration, in which the growth of\nangular momentum can lead to an end of the over-density growth. Within\nrealistic redshifts, the over-density stops growing at a value where the\nMOND-like acceleration dominates over Newton and the largest mass shell\nrotational velocity obeys the Baryonic Tully Fisher Relation (BTFR) with a\nsmaller MOND acceleration. As the largest mass shell shrinks to a few scale\nlength distances, the rotational velocity BTFR persists due to the conservation\nof angular momentum and the MOND acceleration grows to the phenomenological\nMOND acceleration value $a_0$ at late time.", "category": "astro-ph.GA"}, {"title": "High-resolution IR absorption spectroscopy of polycyclic aromatic hydrocarbons in the 3 micron region: role of hydrogenation and alkylation", "abstract": "Aims. We aim to elucidate the spectral changes in the 3 micron region that\nresult from chemical changes in the molecular periphery of polycyclic aromatic\nhydrocarbons (PAHs) with extra hydrogens (H-PAHs) and methyl groups (Me-PAHs).\nMethods. Advanced laser spectroscopic techniques combined with mass\nspectrometry were applied on supersonically cooled\n1,2,3,4-tetrahydronaphthalene, 9,10-dihydroanthracene, 9,10-dihydrophenathrene,\n1,2,3,6,7,8-hexahydropyrene, 9-methylanthracene, and 9,10-dimethylanthracene,\nallowing us to record mass-selective and conformationally selective absorption\nspectra of the aromatic, aliphatic, and alkyl CH-stretches in the 3.175-3.636\nmicron region with laser-limited resolution. We compared the experimental\nabsorption spectra with standard harmonic calculations and with second-order\nvibrational perturbation theory anharmonic calculations that use the SPECTRO\nprogram for treating resonances. Results. We show that anharmonicity plays an\nimportant if not dominant role, affecting not only aromatic, but also aliphatic\nand alkyl CH-stretch vibrations. The experimental high-resolution data lead to\nthe conclusion that the variation in Me- and H-PAHs composition might well\naccount for the observed variations in the 3 micron emission spectra of\ncarbon-rich and star-forming regions. Our laboratory studies also suggest that\nheavily hydrogenated PAHs form a significant fraction of the carriers of IR\nemission in regions in which an anomalously strong 3 micron plateau is\nobserved.", "category": "astro-ph.GA"}, {"title": "Intermediate-mass black holes in dwarf galaxies out to redshift $\\sim$ 2.4 in the Chandra COSMOS Legacy Survey", "abstract": "We present a sample of 40 AGN in dwarf galaxies at redshifts $z \\lesssim$\n2.4. The galaxies are drawn from the \\textit{Chandra} COSMOS-Legacy survey as\nhaving stellar masses $10^{7}\\leq M_{*}\\leq3 \\times 10^{9}$ M$_{\\odot}$. Most\nof the dwarf galaxies are star-forming. After removing the contribution from\nstar formation to the X-ray emission, the AGN luminosities of the 40 dwarf\ngalaxies are in the range $L_\\mathrm{0.5-10 keV} \\sim10^{39} - 10^{44}$ erg\ns$^{-1}$. With 12 sources at $z > 0.5$, our sample constitutes the\nhighest-redshift discovery of AGN in dwarf galaxies. The record-holder is\ncid\\_1192, at $z = 2.39$ and with $L_\\mathrm{0.5-10 keV} \\sim 10^{44}$ erg\ns$^{-1}$. One of the dwarf galaxies has $M_\\mathrm{*} = 6.6 \\times 10^{7}$\nM$_{\\odot}$ and is the least massive galaxy found so far to host an AGN. All\nthe AGN are of type 2 and consistent with hosting intermediate-mass black holes\n(BHs) with masses $\\sim 10^{4} - 10^{5}$ M$_{\\odot}$ and typical Eddington\nratios $> 1\\%$. We also study the evolution, corrected for completeness, of AGN\nfraction with stellar mass, X-ray luminosity, and redshift in dwarf galaxies\nout to $z$ = 0.7. We find that the AGN fraction for $10^{9}< M_{*}\\leq3 \\times\n10^{9}$ M$_{\\odot}$ and $L_\\mathrm{X} \\sim 10^{41}-10^{42}$ erg s$^{-1}$ is\n$\\sim$0.4\\% for $z \\leq$ 0.3 and that it decreases with X-ray luminosity and\ndecreasing stellar mass. Unlike massive galaxies, the AGN fraction seems to\ndecrease with redshift, suggesting that AGN in dwarf galaxies evolve\ndifferently than those in high-mass galaxies. Mindful of potential caveats, the\nresults seem to favor a direct collapse formation mechanism for the seed BHs in\nthe early Universe.", "category": "astro-ph.GA"}, {"title": "Kinematics of Simulated Galaxies I: Connecting Dynamical and Morphological Properties of Early-Type Galaxies at Different Redshifts", "abstract": "State-of-the-art integral field surveys like $\\mathrm{ATLAS^{3D}}$, SLUGGS,\nCALIFA, SAMI, and MaNGA provide large data sets of kinematical observations of\nearly-type galaxies (ETGs), yielding constraints on the formation of ETGs.\nUsing the cosmological hydrodynamical \\textit{Magneticum Pathfinder}\nsimulations, we investigate the paradigm of fast and slow rotating ETGs in a\nfully cosmological context. We show that the ETGs within the\n\\textit{Magneticum} simulation are in remarkable agreement with the\nobservations, revealing fast and slow rotators quantified by the angular\nmomentum proxy $\\lambda_{\\mathrm{R}}$ and the flattening $\\epsilon$ with the\nobserved prevalence. Taking full advantage of the three-dimensional data, we\ndemonstrate that the dichotomy between fast and slow rotating galaxies gets\nenhanced, showing an upper and lower population separated by an underpopulated\nregion in the edge-on $\\lambda_{\\mathrm{R}}$-$\\epsilon$ plane. Following the\nevolution of the $\\lambda_{\\mathrm{R}}$-$\\epsilon$ plane through cosmic time,\nwe find that, while the upper population is already in place at $z=2$, the\nlower population gets statistically significant below $z=1$ with a gradual\nincrease. At least $50\\%$ of the galaxies transition from fast to slow rotators\non a short timescale, in most cases associated to a significant merger event.\nFurthermore, we connect the $M_{*}$-$j_{*}$ plane, quantified by the $b$-value,\nwith the $\\lambda_{\\mathrm{R}}$-$\\epsilon$ plane, revealing a strong\ncorrelation between the position of a galaxy in the\n$\\lambda_{\\mathrm{R}}$-$\\epsilon$ plane and the $b$-value. Going one step\nfurther, we classify our sample based on features in their velocity map,\nfinding all five common kinematic groups, also including the recently observed\ngroup of prolate rotators, populating distinct regions in the\n$\\lambda_{\\mathrm{R}}$-$b$ plane.", "category": "astro-ph.GA"}, {"title": "The First Detection of Neutral Hydrogen in Emission in a Strong Spiral Lens", "abstract": "We report HI observations of eight spiral galaxies that are strongly lensing\nbackground sources. Our targets were selected from the Sloan WFC (Wide Field\nCamera) Edge-on Late-type Lens Survey (SWELLS) using the Arecibo, Karl G.\nJansky Very Large Array, and Green Bank telescopes. We securely detect\nJ1703+2451 at z=0.063 with a signal-to-noise of 6.7 and W50=79+/-13 km/s,\nobtaining the first detection of HI emission in a strong spiral lens. We\nmeasure a mass of M(HI)= 1.77+/-0.06(+0.35/-0.75) x 10^9 M_(sol) for this\nsource. We find that this lens is a normal spiral, with observable properties\nthat are fairly typical of spiral galaxies. For three other sources we did not\nsecure a detection; however, we are able to place strong constraints on the HI\nmasses of those galaxies. The observations for four of our sources were\nrendered unusable due to strong radio frequency interference.", "category": "astro-ph.GA"}, {"title": "The enhancement of rapidly quenched galaxies in distant clusters at 0.5<z<1.0", "abstract": "We investigate the relationship between environment and galaxy evolution in\nthe redshift range $0.5 < z < 1.0$. Galaxy overdensities are selected using a\nFriends-of-Friends algorithm, applied to deep photometric data in the\nUltra-Deep Survey (UDS) field. A study of the resulting stellar mass functions\nreveals clear differences between cluster and field environments, with a strong\nexcess of low-mass rapidly quenched galaxies in cluster environments compared\nto the field. Cluster environments also show a corresponding deficit of young,\nlow-mass star-forming galaxies, which show a sharp radial decline towards\ncluster centres. By comparing mass functions and radial distributions, we\nconclude that young star-forming galaxies are rapidly quenched as they enter\noverdense environments, becoming post-starburst galaxies before joining the red\nsequence. Our results also point to the existence of two environmental\nquenching pathways operating in galaxy clusters, operating on different\ntimescales. Fast quenching acts on galaxies with high specific star-formation\nrates, operating on timescales shorter than the cluster dynamical time ($ < 1$\nGyr). In contrast, slow quenching affects galaxies with moderate specific\nstar-formation rates, regardless of their stellar mass, and acts on longer\ntimescales ($\\gtrsim 1$ Gyr). Of the cluster galaxies in the stellar mass range\n$9.0 < \\log(M_{*}/M_{\\odot}) < 10.5$ quenched during this epoch, we find that\n73% were transformed through fast quenching, while the remaining 27% followed\nthe slow quenching route.", "category": "astro-ph.GA"}, {"title": "The mass-size relation of LRGs from BOSS and DECaLS", "abstract": "We use the DECaLS DR3 survey photometry matched to the SDSS-III/BOSS DR12\nspectroscopic catalog to investigate the morphology and stellar mass-size\nrelation of luminous red galaxies (LRGs) within the CMASS and LOWZ galaxy\nsamples in the redshift range $0.2<z<0.7$. The large majority of both samples\nis composed of early-type galaxies with De Vaucouleurs profiles, while only\nless than 20% are late-type exponentials. We calibrate DECaLS effective radii\nusing the higher resolution CFHT/MegaCam observations and optimise the\ncorrection for each morphological type. By cross-matching the photometric\nproperties of the early-type population with the Portsmouth stellar mass\ncatalog, we are able to explore the high-mass end of the distribution using a\nlarge sample of 313,026 galaxies over 4380 deg$^{2}$. We find a clear\ncorrelation between the sizes and the stellar masses of these galaxies, which\nappears flatter than previous estimates at lower masses. The sizes of these\nearly-type galaxies do not exhibit significant evolution within the BOSS\nredshift range, but a slightly declining redshift trend is found when these\nresults are combined with $z\\sim0.1$ SDSS measurements at the high-mass end.\nThe synergy between BOSS and DECaLS has important applications in other fields,\nincluding galaxy clustering and weak lensing.", "category": "astro-ph.GA"}, {"title": "Mapping the core of the Tarantula Nebula with VLT-MUSE: I. Spectral and nebular content around R136", "abstract": "We introduce VLT-MUSE observations of the central 2$'\\times2'$ (30$\\times$30\npc) of the Tarantula Nebula in the Large Magellanic Cloud. The observations\nprovide an unprecedented spectroscopic census of the massive stars and ionised\ngas in the vicinity of R136, the young, dense star cluster located in NGC 2070,\nat the heart of the richest star-forming region in the Local Group.\nSpectrophotometry and radial-velocity estimates of the nebular gas\n(superimposed on the stellar spectra) are provided for 2255 point sources\nextracted from the MUSE datacubes, and we present estimates of stellar radial\nvelocities for 270 early-type stars (finding an average systemic velocity of\n271$\\pm$41 km/s). We present an extinction map constructed from the nebular\nBalmer lines, with electron densities and temperatures estimated from intensity\nratios of the [SII], [NII], and [SIII] lines. The interstellar medium, as\ntraced by H$\\alpha$ and [NII] $\\lambda$6583, provides new insights in regions\nwhere stars are probably forming. The gas kinematics are complex, but with a\nclear bi-modal, blue- and red-shifted distribution compared to the systemic\nvelocity of the gas centred on R136. Interesting point-like sources are also\nseen in the eastern cavity, western shell, and around R136; these might be\nrelated to phenomena such as runaway stars, jets, formation of new stars, or\nthe interaction of the gas with the population of Wolf--Rayet stars. Closer\ninspection of the core reveals red-shifted material surrounding the strongest\nX-ray sources, although we are unable to investigate the kinematics in detail\nas the stars are spatially unresolved in the MUSE data. Further papers in this\nseries will discuss the detailed stellar content of NGC 2070 and its integrated\nstellar and nebular properties.", "category": "astro-ph.GA"}, {"title": "Models of Tidally Induced Gas Filaments in the Magellanic Stream", "abstract": "The Magellanic Stream and Leading Arm of HI that stretches from the Large and\nSmall Magellanic Clouds (LMC and SMC) and over 200 degrees of the Southern sky\nis thought to be formed from multiple encounters between the LMC and SMC. In\nthis scenario, most of the gas in the Stream and Leading Arm is stripped from\nthe SMC, yet recent observations have shown a bifurcation of the Trailing Arm\nthat reveals LMC origins for some of the gas. Absorption measurements in the\nStream also reveal an order of magnitude more gas than in current tidal models.\nWe present hydrodynamical simulations of the multiple encounters between the\nLMC and SMC at their first pass around the Milky Way, assuming that the Clouds\nwere more extended and gas rich in the past. Our models create filamentary\nstructures of gas in the Trailing Stream from both the LMC and SMC. While the\nSMC trailing filament matches the observed Stream location, the LMC filament is\noffset. In addition, the total observed mass of the Stream in these models is\nunderestimated of a factor of four when the ionized component is accounted for.\nOur results suggest that there should also be gas stripped from both the LMC\nand SMC in the Leading Arm, mirroring the bifurcation in the Trailing Stream.\nThis prediction is consistent with recent measurements of spatial variation in\nchemical abundances in the Leading Arm, which show that gas from multiple\nsources is present, although the nature is still uncertain.", "category": "astro-ph.GA"}, {"title": "The KMOS Cluster Survey (KCS) II - The Effect of Environment on the Structural Properties of Massive Cluster Galaxies at Redshift $1.39 < z <1.61$", "abstract": "We present results on the structural properties of massive passive galaxies\nin three clusters at $1.39<z<1.61$ from the KMOS Cluster Survey. We measure\nlight-weighted and mass-weighted sizes from optical and near-infrared Hubble\nSpace Telescope imaging and spatially resolved stellar mass maps. The\nrest-frame $R$-band sizes of these galaxies are a factor of $\\sim2-3$ smaller\nthan their local counterparts. The slopes of the relation between the stellar\nmass and the light-weighted size are consistent with recent studies in clusters\nand the field. Their mass-weighted sizes are smaller than the rest frame\n$R$-band sizes, with an average mass-weighted to light-weighted size ratio that\nvaries between $\\sim0.45$ and $0.8$ among the clusters. We find that the median\nlight-weighted size of the passive galaxies in the two more evolved clusters is\n$\\sim24\\%$ larger than for field galaxies, independent of the use of\ncircularized effective radii or semi-major axes. These two clusters also show a\nsmaller size ratio than the less evolved cluster, which we investigate using\ncolor gradients to probe the underlying $M_{*}/L_{H_{160}}$ gradients. The\nmedian color gradients are $\\nabla{z-H} \\sim-0.4$ mag dex$^{-1}$, twice the\nlocal value. Using stellar populations models, these gradients are best\nreproduced by a combination of age and metallicity gradients. Our results favor\nthe minor merger scenario as the dominant process responsible for the observed\ngalaxy properties and the environmental differences at this redshift. The\nenvironmental differences support that clusters experience accelerated\nstructural evolution compared to the field, likely via an epoch of enhanced\nminor merger activity during cluster assembly.", "category": "astro-ph.GA"}, {"title": "Massive stars in the SDSS-IV/APOGEE SURVEY. I- OB stars", "abstract": "In this work we make use of DR14 APOGEE spectroscopic data to study a sample\nof 92 known OB stars. We developed a near-infrared semi-empirical spectral\nclassification method that was successfully used in case of four new exemplars,\npreviously classified as later B-type stars. Our results agree well with those\ndetermined independently from ECHELLE optical spectra, being in line with the\nspectral types derived from the \"canonical\" MK blue optical system. This\nconfirms that the APOGEE spectrograph can also be used as a powerful tool in\nsurveys aiming to unveil and study large number of moderately and highly\nobscured OB stars still hidden in the Galaxy.", "category": "astro-ph.GA"}, {"title": "SDSS-IV MaNGA: Global stellar population and gradients for about 2000 early-type and spiral galaxies on the mass-size plane", "abstract": "We perform full spectrum fitting stellar population analysis and Jeans\nAnisotropic modelling (JAM) of the stellar kinematics for about 2000 early-type\ngalaxies (ETGs) and spiral galaxies from the MaNGA DR14 sample. Galaxies with\ndifferent morphologies are found to be located on a remarkably tight mass plane\nwhich is close to the prediction of the virial theorem, extending previous\nresults for ETGs. By examining an inclined projection (`the mass-size' plane),\nwe find that spiral and early-type galaxies occupy different regions on the\nplane, and their stellar population properties (i.e. age, metallicity and\nstellar mass-to-light ratio) vary systematically along roughly the direction of\nvelocity dispersion, which is a proxy for the bulge fraction. Galaxies with\nhigher velocity dispersions have typically older ages, larger stellar\nmass-to-light ratios and are more metal rich, which indicates that galaxies\nincrease their bulge fractions as their stellar populations age and become\nenriched chemically. The age and stellar mass-to-light ratio gradients for\nlow-mass galaxies in our sample tend to be positive ($\\rm centre<outer$), while\nthe gradients for most massive galaxies are negative. The metallicity gradients\nshow a clear peak around velocity dispersion $\\log_{10} \\sigma_{\\rm e}\\approx\n2.0$, which corresponds to the critical mass $\\sim 3\\times 10^{10}M_{\\odot}$ of\nthe break in the mass-size relation. Spiral galaxies with large mass and size\nhave the steepest gradients, while the most massive ETGs, especially above the\ncritical mass $M_{\\rm crit}\\ge 2\\times 10^{11} M_{\\odot}$, where slow rotator\nETGs start dominating, have much flatter gradients. This may be due to\ndifferences in their evolution histories, e.g. mergers.", "category": "astro-ph.GA"}, {"title": "The spectral energy distribution of the hyperluminous, hot dust-obscured galaxy W2246$-$0526", "abstract": "Hot dust-obscured galaxies (Hot DOGs) are a luminous, dust-obscured\npopulation recently discovered in the WISE All-Sky survey. Multiwavelength\nfollow-up observations suggest that they are mainly powered by accreting\nsupermassive black holes (SMBHs), lying in dense environments, and being in the\ntransition phase between extreme starburst and UV-bright quasars. Therefore,\nthey are good candidates for studying the interplay between SMBHs, star\nformation and environment. W2246$-$0526 (thereafter, W2246), a Hot DOG at\n$z\\sim4.6$, has been taken as the most luminous galaxy known in the Universe.\nRevealed by the multiwavelength images, the previous Herschel SPIRE photometry\nof W2246 is contaminated by a foreground galaxy (W2246f), resulting in an\noverestimation of its total IR luminosity by a factor of about 2. We perform\nthe rest-frame UV/optical-to-far-IR spectral energy distribution (SED) analysis\nwith SED3FIT and re-estimate its physical properties. The derived stellar mass\n$M_\\star = 4.3\\times10^{11}~M_\\odot$ makes it be among the most massive\ngalaxies with spectroscopic redshift $z>4.5$. Its structure is extremely\ncompact and requires an effective mechanism to puff-up. Most of ($>95\\%$) its\nIR luminosity is from AGN torus emission, revealing the rapid growth of the\ncentral SMBH. We also predict that W2246 may have a significant molecular gas\nreservoir based on the dust mass estimation.", "category": "astro-ph.GA"}, {"title": "The contribution of faint AGNs to the ionizing background at z~4", "abstract": "Finding the sources responsible for the hydrogen reionization is one of the\nmost pressing issues in cosmology. Bright QSOs are known to ionize their\nsurrounding neighborhood, but they are too few to ensure the required HI\nionizing background. A significant contribution by faint AGNs, however, could\nsolve the problem, as recently advocated on the basis of a relatively large\nspace density of faint active nuclei at z>4. We have carried out an exploratory\nspectroscopic program to measure the HI ionizing emission of 16 faint AGNs\nspanning a broad U-I color interval, with I~21-23 and 3.6<z<4.2. These AGNs are\nthree magnitudes fainter than the typical SDSS QSOs (M1450<~-26) which are\nknown to ionize their surrounding IGM at z>~4. The LyC escape fraction has been\ndetected with S/N ratio of ~10-120 and is between 44 and 100% for all the\nobserved faint AGNs, with a mean value of 74% at 3.6<z<4.2 and\n-25.1<M1450<-23.3, in agreement with the value found in the literature for much\nbrighter QSOs (M1450<~-26) at the same redshifts. The LyC escape fraction of\nour faint AGNs does not show any dependence on the absolute luminosities or on\nthe observed U-I colors. Assuming that the LyC escape fraction remains close to\n~75% down to M1450~-18, we find that the AGN population can provide between 16\nand 73% (depending on the adopted luminosity function) of the whole ionizing UV\nbackground at z~4, measured through the Lyman forest. This contribution\nincreases to 25-100% if other determinations of the ionizing UV background are\nadopted. Extrapolating these results to z~5-7, there are possible indications\nthat bright QSOs and faint AGNs can provide a significant contribution to the\nreionization of the Universe, if their space density is high at M1450~-23.", "category": "astro-ph.GA"}, {"title": "A study of two dwarf irregular galaxies with asymmetrical star formation distributions", "abstract": "Two dwarf irregular galaxies DDO 187 and NGC 3738 exhibit a striking pattern\nof star formation: intense star formation is taking place in a large region\noccupying roughly half of the inner part of the optical galaxy. We use data on\nthe HI distribution and kinematics and stellar images and colors to examine the\nproperties of the environment in the high star formation rate (HSF) halves of\nthe galaxies in comparison with the low star formation rate (LSF) halves. We\nfind that the pressure and gas density are higher on the HSF sides by 30-70%.\nIn addition we find in both galaxies that the HI velocity fields exhibit\nsignificant deviations from ordered rotation and there are large regions of\nhigh velocity dispersion and multiple velocity components in the gas beyond the\ninner regions of the galaxies. The conditions in the HSF regions are likely the\nresult of large-scale external processes affecting the internal environment of\nthe galaxies and enabling the current star formation there.", "category": "astro-ph.GA"}, {"title": "Towards an improvement in the spectral description of central stars of planetary nebulae", "abstract": "Context. There are more than 3000 known Galactic planetary nebulae (PNe), but\nonly 492 central stars of Galactic planetary nebulae (CSPN) have known spectral\ntypes. It is vital to increase this number in order to have reliable\nstatistics, which will lead to an increase of our understanding of these\namazing objects.\n  Aims. We aim to contribute to the knowledge of central stars of planetary\nnebulae and stellar evolution.\n  Methods. This observational study is based on Gemini Multi-Object\nSpectrographs (GMOS) and with the Intermediate Dispersion Spectrograph (IDS) at\nthe Isaac Newton Telescope (INT) spectra of 78 CSPN. The objects were selected\nbecause they did not have any previous classification, or the present\nclassification is ambiguous. These new high quality spectra allowed us to\nidentify the key stellar lines for determining spectral classification in the\nMorgan-Keenan (MK) system.\n  Results. We have acquired optical spectra of a large sample of CSPN. From the\nobserved targets, 50 are classified here for the first time while for 28 the\nexisting classifications have been improved. In seven objects we have\nidentified a P-Cygni profile at the He i lines. Six of these CSPN are late\nO-type. The vast majority of the stars in the sample exhibit an absorption-type\nspectrum, and in one case we have found wide emission lines typical of [WR]\nstars. We give a complementary, and preliminary, classification criterion to\nobtain the sub-type of the O(H)-type CSPN. Finally, we give a more realistic\nvalue of the proportion of CSPN that are rich or poor in hydrogen.", "category": "astro-ph.GA"}, {"title": "Ionized and molecular gas kinematics in a z=1.4 star-forming galaxy", "abstract": "We present deep observations of a $z=1.4$ massive, star-forming galaxy in\nmolecular and ionized gas at comparable spatial resolution (CO 3-2, NOEMA;\nH$\\alpha$, LBT). The kinematic tracers agree well, indicating that both gas\nphases are subject to the same gravitational potential and physical processes\naffecting the gas dynamics. We combine the one-dimensional velocity and\nvelocity dispersion profiles in CO and H$\\alpha$ to forward-model the galaxy in\na Bayesian framework, combining a thick exponential disk, a bulge, and a dark\nmatter halo. We determine the dynamical support due to baryons and dark matter,\nand find a dark matter fraction within one effective radius of $f_{\\rm\nDM}(\\leq$$R_{e})=0.18^{+0.06}_{-0.04}$. Our result strengthens the evidence for\nstrong baryon-dominance on galactic scales of massive $z\\sim1-3$ star-forming\ngalaxies recently found based on ionized gas kinematics alone.", "category": "astro-ph.GA"}, {"title": "ALMA 26 Arcmin$^{2}$ Survey of GOODS-S at One-millimeter (ASAGAO): Average Morphology of High-$z$ Dusty Star-Forming Galaxies is an Exponential-Disk ($n \\simeq 1$)", "abstract": "We present morphological properties of dusty star-forming galaxies at z=1-3\ndetermined with high-resolution (FWHM~0\"19) Atacama Large\nMilllimeter/submilimeter Array (ALMA) 1-mm band maps of our ASAGAO survey\ncovering a 26-arcmin^2 area in GOODS-S. In conjunction with the ALMA archival\ndata, the present sample consists of 42 ALMA sources with a wide rest-frame\nfar-infrared (FIR) luminosity L_FIR range of ~10^11-10^13 Lo. To obtain an\naverage rest-frame FIR profile, we perform individual measurements and careful\nstacking of the ALMA sources using the uv-visibility method that includes\npositional-uncertainty and smoothing-effect evaluations through Monte-Carlo\nsimulations. We find that the dusty star-forming galaxies have the average\nFIR-wavelength Sersic index and effective radius of n_FIR=1.2+/-0.2 and\nR_e,FIR=1.0-1.3 kpc, respectively, additionally with a point source at the\ncenter, indicative of the existence of AGN. The average FIR profile agrees with\na morphology of an exponential-disk clearly distinguished from a spheroidal\nprofile (Sersic index of 4). We also examine the rest-frame optical Sersic\nindex n_opt and effective radius R_e,opt with the deep Hubble Space Telescope\n(HST) images. Interestingly, we obtain n_opt=0.9+/-0.3 (~n_FIR) and\nR_e,opt=3.2+/-0.6 kpc (>R_e,FIR), suggesting that the FIR-emitting disk is\nembedded within a larger stellar disk. The rest-frame UV and FIR data of HST\nand ALMA provide us a radial surface density profile of the total\nstar-formation rate (SFR), where the FIR SFR dominates over the UV SFR at the\ncenter. Under the simple assumption of a constant SFR, a compact stellar\ndistribution found in z~1-2 compact quiescent galaxies (cQGs) is well\nreproduced, while a spheroidal stellar morphology of cQGs (n_opt=4) cannot,\nsuggestive of other important mechanisms such as dynamical dissipation.", "category": "astro-ph.GA"}, {"title": "Blowing in the Milky Way wind: neutral hydrogen clouds tracing the Galactic nuclear outflow", "abstract": "We present the results of a new sensitive survey of neutral hydrogen above\nand below the Galactic Center with the Green Bank Telescope. The observations\nextend up to Galactic latitude | b | < 10 deg with an effective angular\nresolution of 9.5' and an average rms brightness temperature noise of 40 mK in\na 1 km/s channel. The survey reveals the existence of a population of anomalous\nhigh-velocity clouds extending up to heights of about 1.5 kpc from the Galactic\nPlane and showing no signature of Galactic rotation. These clouds have local\nstandard of rest velocities | Vlsr | < 360 km/s and, assuming a Galactic Center\norigin, they have sizes of a few tens of parsecs and neutral hydrogen masses\nspanning $10-10^5 \\, M_\\odot$. Accounting for selection effects, the cloud\npopulation is symmetric in longitude, latitude, and Vlsr. We model the cloud\nkinematics in terms of an outflow expanding from the Galactic Center and find\nthe population consistent with being material moving with radial velocity Vw ~\n330 km/s distributed throughout a bi-cone with opening angle $\\alpha>140$ deg.\nThis simple model implies an outflow luminosity $Lw > 3 \\times 10^{40}$ erg/s\nover the past 10 Myr, consistent with star formation feedback in the inner\nregion of the Milky Way, with a cold gas mass-loss rate $\\lesssim 0.1 \\,\nM_\\odot$/yr. These clouds may represent the cold gas component accelerated in\nthe nuclear wind driven by our Galaxy, although some of the derived properties\nchallenge current theoretical models of the entrainment process.", "category": "astro-ph.GA"}, {"title": "Galaxy pairs in the SDSS - XIII. The connection between enhanced star formation and molecular gas properties in galaxy mergers", "abstract": "We investigate the connection between star formation and molecular gas\nproperties in galaxy mergers at low redshift (z$\\leq$0.06). The study we\npresent is based on IRAM 30-m CO(1-0) observations of 11 galaxies with a close\ncompanion selected from the Sloan Digital Sky Survey (SDSS). The pairs have\nmass ratios $\\leq$4, projected separations r$_{\\mathrm{p}} \\leq$30 kpc and\nvelocity separations $\\Delta$V$\\leq$300 km s$^{-1}$, and have been selected to\nexhibit enhanced specific star formation rates (sSFR). We calculate molecular\ngas (H$_{2}$) masses, assigning to each galaxy a physically motivated\nconversion factor $\\alpha_{\\mathrm{CO}}$, and we derive molecular gas fractions\nand depletion times. We compare these quantities with those of isolated\ngalaxies from the extended CO Legacy Data base for the GALEX Arecibo SDSS\nSurvey sample (xCOLDGASS, Saintonge et al. 2017) with gas quantities computed\nin an identical way. Ours is the first study which directly compares the gas\nproperties of galaxy pairs and those of a control sample of normal galaxies\nwith rigorous control procedures and for which SFR and H$_{2}$ masses have been\nestimated using the same method. We find that the galaxy pairs have shorter\ndepletion times and an average molecular gas fraction enhancement of 0.4 dex\ncompared to the mass matched control sample drawn from xCOLDGASS. However, the\ngas masses (and fractions) in galaxy pairs and their depletion times are\nconsistent with those of non-mergers whose SFRs are similarly elevated. We\nconclude that both external interactions and internal processes may lead to\nmolecular gas enhancement and decreased depletion times.", "category": "astro-ph.GA"}, {"title": "The New Numerical Galaxy Catalogue (ν^2 GC): Properties of Active Galactic Nuclei and Their Host Galaxies", "abstract": "We present the latest results of a semi-analytic model of galaxy formation,\n\"New Numerical Galaxy Catalogue\", which is combined with large cosmological\nN-body simulations. This model can reproduce statistical properties of galaxies\nat z < 6.0. We focus on the properties of active galactic nuclei (AGNs) and\nsupermassive black holes, especially on the accretion timescale onto black\nholes. We find that the number density of AGNs at z < 1.5 and at hard X-ray\nluminosity 10^{ 44 }< erg/s is underestimated compared with recent\nobservational estimates when we assume the exponentially decreasing accretion\nrate and the accretion timescale which is proportional to the dynamical time of\nthe host halo or the bulge, as is often assumed in semi-analytic models. We\nshow that to solve this discrepancy, the accretion timescale of such less\nluminous AGNs instead should be a function of the black hole mass and the\naccreted gas mass. This timescale can be obtained from a phenomenological\nmodelling of the gas angular momentum loss in the circumnuclear torus and/or\nthe accretion disc. Such models predict a longer accretion timescale for less\nluminous AGNs at z < 1.0 than bright QSOs whose accretion timescale would be\n10^{ 7-8 } yr. With this newly introduced accretion timescale, our model can\nexplain the observed luminosity functions of AGNs at z < 6.0.", "category": "astro-ph.GA"}, {"title": "Spectrophotometric Redshifts In The Faint Infrared Grism Survey: Finding Overdensities Of Faint Galaxies", "abstract": "We improve the accuracy of photometric redshifts by including low-resolution\nspectral data from the G102 grism on the Hubble Space Telescope, which assists\nin redshift determination by further constraining the shape of the broadband\nSpectral Energy Disribution (SED) and identifying spectral features. The\nphotometry used in the redshift fits includes near-IR photometry from\nFIGS+CANDELS, as well as optical data from ground-based surveys and HST ACS,\nand mid-IR data from Spitzer. We calculated the redshifts through the\ncomparison of measured photometry with template galaxy models, using the EAZY\nphotometric redshift code. For objects with F105W $< 26.5$ AB mag with a\nredshift range of $0 < z < 6$, we find a typical error of $\\Delta z = 0.03 *\n(1+z)$ for the purely photometric redshifts; with the addition of FIGS spectra,\nthese become $\\Delta z = 0.02 * (1+z)$, an improvement of 50\\%. Addition of\ngrism data also reduces the outlier rate from 8\\% to 7\\% across all fields.\nWith the more-accurate spectrophotometric redshifts (SPZs), we searched the\nFIGS fields for galaxy overdensities. We identified 24 overdensities across the\n4 fields. The strongest overdensity, matching a spectroscopically identified\ncluster at $z=0.85$, has 28 potential member galaxies, of which 8 have previous\nspectroscopic confirmation, and features a corresponding X-ray signal. Another\ncorresponding to a cluster at $z=1.84$ has 22 members, 18 of which are\nspectroscopically confirmed. Additionally, we find 4 overdensities that are\ndetected at an equal or higher significance in at least one metric to the two\nconfirmed clusters.", "category": "astro-ph.GA"}, {"title": "Triggering the formation of the supergiant H II region NGC 604 in M33", "abstract": "Formation mechanism of a supergiant H II region NGC 604 is discussed in terms\nof collision of H I clouds in M33. An analysis of the archival H I data\nobtained with the Very Large Array (VLA) reveals complex velocity distributions\naround NGC 604. The H I clouds are composed of two velocity components\nseparated by ~ 20 km s^-1 for an extent of ~ 700 pc, beyond the size of the the\nH II region. Although the H I clouds are not easily separated in velocity with\nsome mixed component represented by merged line profiles, the atomic gas mass\namounts to 6 x 10^6 M_Sol and 9 x 10^6 M_Sol for each component. These\ncharacteristics of H I gas and the distributions of dense molecular gas in the\noverlapping regions of the two velocity components suggest that the formation\nof giant molecular clouds and the following massive cluster formation have been\ninduced by the collision of H I clouds with different velocities. Referring to\nthe existence of gas bridging feature connecting M33 with M31 reported by\nlarge-scale HI surveys, the disturbed atomic gas possibly represent the result\nof past tidal interaction between the two galaxies, which is analogous to the\nformation of the R136 cluster in the LMC.", "category": "astro-ph.GA"}, {"title": "Star-formation rate in compact star-forming galaxies", "abstract": "We use the data for the Hbeta emission-line, far-ultraviolet (FUV) and\nmid-infrared 22 micron continuum luminosities to estimate star formation rates\n<SFR> averaged over the galaxy lifetime for a sample of about 14000 bursting\ncompact star-forming galaxies (CSFGs) selected from the Data Release 12 (DR12)\nof the Sloan Digital Sky Survey (SDSS). The average coefficient linking <SFR>\nand the star formation rate SFR_0 derived from the Hbeta luminosity at zero\nstarburst age is found to be 0.04. We compare <SFR>s with some commonly used\nSFRs which are derived adopting a continuous star formation during a period of\n~100 Myr, and find that the latter ones are 2-3 times higher. It is shown that\nthe relations between SFRs derived using a geometric mean of two star-formation\nindicators in the UV and IR ranges and reduced to zero starburst age have\nconsiderably lower dispersion compared to those with single star-formation\nindicators. We suggest that our relations for <SFR> determination are more\nappropriate for CSFGs because they take into account a proper temporal\nevolution of their luminosities. On the other hand, we show that commonly used\nSFR relations can be applied for approximate estimation within a factor of ~2\nof the <SFR> averaged over the lifetime of the bursting compact galaxy.", "category": "astro-ph.GA"}, {"title": "LBT/MODS spectroscopy of globular clusters in the irregular galaxy NGC 4449", "abstract": "We present intermediate-resolution (R$\\sim$1000) spectra in the\n$\\sim$3500-10,000 A range of 14 globular clusters in the magellanic irregular\ngalaxy NGC 4449 acquired with the Multi Object Double Spectrograph on the Large\nBinocular Telescope. We derived Lick indices in the optical and the\nCaII-triplet index in the near-infrared in order to infer the clusters' stellar\npopulation properties. The inferred cluster ages are typically older than\n$\\sim$9 Gyr, although ages are derived with large uncertainties. The clusters\nexhibit intermediate metallicities, in the range\n$-1.2\\lesssim$[Fe/H]$\\lesssim-0.7$, and typically sub-solar [$\\alpha/Fe$]\nratios, with a peak at $\\sim-0.4$. These properties suggest that i) during the\nfirst few Gyrs NGC 4449 formed stars slowly and inefficiently, with galactic\nwinds having possibly contributed to the expulsion of the $\\alpha$-elements,\nand ii) globular clusters in NGC 4449 formed relatively \"late\", from a medium\nalready enriched in the products of type Ia supernovae. The majority of\nclusters appear also under-abundant in CN compared to Milky Way halo globular\nclusters, perhaps because of the lack of a conspicuous N-enriched,\nsecond-generation of stars like that observed in Galactic globular clusters.\nUsing the cluster velocities, we infer the dynamical mass of NGC 4449 inside\n2.88 kpc to be M($<$2.88 kpc)=$3.15^{+3.16}_{-0.75} \\times 10^9~M_\\odot$. We\nalso report the serendipitous discovery of a planetary nebula within one of the\ntargeted clusters, a rather rare event.", "category": "astro-ph.GA"}, {"title": "xGASS: Total cold gas scaling relations and molecular-to-atomic gas ratios of galaxies in the local Universe", "abstract": "We present the extended GALEX Arecibo SDSS Survey (xGASS), a gas\nfraction-limited census of the atomic (HI) gas content of 1179 galaxies\nselected only by stellar mass ($M_\\star =10^{9}-10^{11.5} M_\\odot$) and\nredshift ($0.01<z<0.05$). This includes new Arecibo observations of 208\ngalaxies, for which we release catalogs and HI spectra. In addition to\nextending the GASS HI scaling relations by one decade in stellar mass, we\nquantify total (atomic+molecular) cold gas fractions and molecular-to-atomic\ngas mass ratios, $R_{mol}$, for the subset of 477 galaxies observed with the\nIRAM 30 m telescope. We find that atomic gas fractions keep increasing with\ndecreasing stellar mass, with no sign of a plateau down to $\\log\nM_\\star/M_\\odot = 9$. Total gas reservoirs remain HI-dominated across our full\nstellar mass range, hence total gas fraction scaling relations closely resemble\natomic ones, but with a scatter that strongly correlates with $R_{mol}$,\nespecially at fixed specific star formation rate. On average, $R_{mol}$ weakly\nincreases with stellar mass and stellar surface density $\\mu_\\star$, but\nindividual values vary by almost two orders of magnitude at fixed $M_\\star$ or\n$\\mu_\\star$. We show that, for galaxies on the star-forming sequence,\nvariations of $R_{mol}$ are mostly driven by changes of the HI reservoirs, with\na clear dependence on $\\mu_\\star$. Establishing if galaxy mass or structure\nplays the most important role in regulating the cold gas content of galaxies\nrequires an accurate separation of bulge and disk components for the study of\ngas scaling relations.", "category": "astro-ph.GA"}, {"title": "The dragonfly nearby galaxies survey. Iv. A giant stellar disk in ngc 2841", "abstract": "Neutral gas is commonly believed to dominate over stars in the outskirts of\ngalaxies, and investigations of the disk-halo interface are generally\nconsidered to be in the domain of radio astronomy. This may simply be a\nconsequence of the fact that deep HI observations typically probe to a lower\nmass surface density than visible wavelength data. This paper presents low\nsurface brightness optimized visible wavelength observations of the extreme\noutskirts of the nearby spiral galaxy NGC 2841. We report the discovery of an\nenormous low-surface brightness stellar disk in this object. When azimuthally\naveraged, the stellar disk can be traced out to a radius of $\\sim$70 kpc (5\n$R_{25}$ or 23 inner disk scale lengths). The structure in the stellar disk\ntraces the morphology of HI emission and extended UV emission. Contrary to\nexpectations, the stellar mass surface density does not fall below that of the\ngas mass surface density at any radius. In fact, at all radii greater than\n$\\sim$20 kpc, the ratio of the stellar to gas mass surface density is a\nconstant 3:1. Beyond $\\sim$30 kpc, the low surface brightness stellar disk\nbegins to warp, which may be an indication of a physical connection between the\noutskirts of the galaxy and infall from the circumgalactic medium. A\ncombination of stellar migration, accretion and in-situ star formation might be\nresponsible for building up the outer stellar disk, but whatever mechanisms\nformed the outer disk must also explain the constant ratio between stellar and\ngas mass in the outskirts of this galaxy.", "category": "astro-ph.GA"}, {"title": "Panchromatic SED modelling of spatially-resolved galaxies", "abstract": "We test the efficacy of the energy-balance spectral energy distribution (SED)\nfitting code Magphys for recovering the spatially-resolved properties of a\nsimulated isolated disc galaxy, for which it was not designed. We perform\n226,950 Magphys SED fits to regions between 0.2kpc and 25kpc in size across the\ngalaxy's disc, viewed from three different sight-lines, to probe how well\nMagphys can recover key galaxy properties based on 21 bands of UV--far-infrared\nmodel photometry. Magphys yields statistically acceptable fits to $> 99$ per\ncent of the pixels within the $r$-band effective radius and between 59 and 77\nper cent of pixels within 20kpc of the nucleus. Magphys is able to recover the\ndistribution of stellar mass, star formation rate (SFR), specific SFR, dust\nluminosity, dust mass, and $V$-band attenuation reasonably well, especially\nwhen the pixel size is $> \\sim1$ kpc, whereas non-standard outputs (stellar\nmetallicity and mass-weighted age) are recovered less well. Accurate recovery\nis more challenging in the smallest sub-regions of the disc (pixel scale $<\n\\sim 1$ kpc), where the energy balance criterion becomes increasingly\nincorrect. Estimating integrated galaxy properties by summing the recovered\npixel values, the true integrated values of all parameters considered except\nmetallicity and age are well recovered at all spatial resolutions, ranging from\n0.2kpc to integrating across the disc, albeit with some evidence for\nresolution-dependent biases. These results must be considered when attempting\nto analyse the structure of real galaxies with actual observational data, for\nwhich the `ground truth' is unknown.", "category": "astro-ph.GA"}, {"title": "Climbing to the top of the galactic mass ladder: evidence for frequent prolate-like rotation among the most massive galaxies", "abstract": "We present the stellar velocity maps of 25 massive early type galaxies\nlocated in dense environments observed with MUSE. Galaxies are selected to be\nbrighter than M_K=-25.7 magnitude, reside in the core of the Shapley Super\nCluster or be the brightest galaxy in clusters richer than the Virgo Cluster.\nWe thus targeted galaxies more massive than 10^12 Msun and larger than 10 kpc\n(half-light radius). The velocity maps show a large variety of kinematic\nfeatures: oblate-like regular rotation, kinematically distinct cores and\nvarious types of non-regular rotation. The kinematic misalignment angles show\nthat massive galaxies can be divided into two categories: those with small or\nnegligible misalignment, and those with misalignment consistent with being 90\ndegrees. Galaxies in this latter group, comprising just under half of our\ngalaxies, have prolate-like rotation (rotation around the major axis). Among\nthe brightest cluster galaxies the incidence of prolate-like rotation is 50 per\ncent, while for a magnitude limited sub-sample of objects within the Shapley\nSuper Cluster (mostly satellites), 35 per cent of galaxies show prolate-like\nrotation. Placing our galaxies on the mass - size diagram, we show that they\nall fall on a branch extending almost an order of magnitude in mass and a\nfactor of 5 in size from the massive end early-type galaxies, previously\nrecognised as associated with major dissipation-less mergers. The presence of\ngalaxies with complex kinematics and, particularly, prolate-like rotators\nsuggests, according to current numerical simulations, that the most massive\ngalaxies grow predominantly through dissipation-less equal-mass mergers.", "category": "astro-ph.GA"}, {"title": "Action-based dynamical models of dwarf spheroidal galaxies: application to Fornax", "abstract": "We present new dynamical models of dwarf spheroidal galaxies (dSphs) in which\nboth the stellar component and the dark halo are described by analytic\ndistribution functions that depend on the action integrals. In their most\ngeneral form these distribution functions can represent axisymmetric and\npossibly rotating stellar systems. Here, as a first application, we model the\nFornax dSph, limiting ourselves, for simplicity, to the non rotating, spherical\ncase. The models are compared with state-of-the-art spectroscopic and\nphotometric observations of Fornax, exploiting the knowledge of the\nline-of-sight velocity distribution of the models and accounting for the\nforeground contamination from the Milky Way. The model that best fits the\nstructural and kinematic properties of Fornax has a cored dark halo, with core\nsize $r_{\\rm c}\\simeq1.03$ kpc. The dark-to-luminous mass ratio is $(M_{\\rm\ndm}/M_{\\star})|_{R_{\\rm eff}}\\simeq9.6$ within the effective radius $R_{\\rm\neff} \\simeq 0.62\\,$kpc and $(M_{\\rm dm}/M_{\\star})|_{3 {\\rm kpc}} \\simeq 144$\nwithin 3 kpc. The stellar velocity distribution is isotropic almost over the\nfull radial range covered by the spectroscopic data and slightly radially\nanisotropic in the outskirts of the stellar distribution. The dark-matter\nannihilation $J$-factor and decay $D$-factor are, respectively, $\\log_{10}(J$\n$[$GeV$^2$ cm$^{-5}])\\simeq18.34$ and $\\log_{10}(D$ $[$GeV\ncm$^{-2}])\\simeq18.55$, for integration angle $\\theta = 0.5^{\\circ}$. This\ncored halo model of Fornax is preferred, with high statistical significance, to\nboth models with a Navarro, Frenk and White dark halo and simple\nmass-follows-light models.", "category": "astro-ph.GA"}, {"title": "Is the Spiral Galaxy a Cosmic Hurricane?", "abstract": "It is discussed that the formation of the spiral galaxies is driven by the\ncosmic background rotation, not a result of an isolated evolution proposed by\nthe density wave theory. To analyze the motions of the galaxies, a simple\ndouble particle galaxy model is considered and the Coriolis force formed by the\nrotational background is introduced. The numerical analysis shows that not only\nthe trajectory of the particle is the spiral shape, but also the relationship\nbetween the velocity and the radius reveals both the existence of spiral arm\nand the change of the arm number. In addition, the results of the\nthree-dimensional simulation also give the warped structure of the spiral\ngalaxies, and shows that the disc surface of the warped galaxy, like a spinning\ncoins on the table, exists a whole overturning movement. Through the analysis,\nit can be concluded that the background environment of the spiral galaxies have\na large-scale rotation, and both the formation and evolution of hurricane-like\nspiral galaxies are driven by this background rotation.", "category": "astro-ph.GA"}, {"title": "The Infrared Medium-deep Survey. IV. Low Eddington Ratio of A Faint Quasar at $z\\sim6$: Not Every Supermassive Black Hole is Growing Fast in the Early Universe", "abstract": "To date, most of the luminous quasars known at $z\\sim6$ have been found to be\nin maximal accretion with the Eddington ratios, $\\lambda_{\\rm{Edd}}\\sim1$,\nsuggesting enhanced nuclear activities in the early universe. However, this may\nnot be the whole picture of supermassive black hole (SMBH) growth since\nprevious studies have not reached on faint quasars that are more likely to\nharbor SMBHs with low $\\lambda_{\\rm{Edd}}$. To gain a better understanding on\nthe accretion activities in quasars in the early universe, we obtained a deep\nnear-infrared (NIR) spectrum of a quasar, IMS J220417.92+011144.8 (hereafter\nIMS J2204+0112), one of the faintest quasars that have been identified at\n$z\\sim6$. From the redshifted C IV $\\lambda 1549$ emission line in the NIR\nspectrum, we find that IMS J2204+0112 harbors a SMBH with about a billion solar\nmass and $\\lambda_{\\rm{Edd}} \\sim 0.1$, but with a large uncertainty in both\nquantities (0.41 dex). IMS J2204+0112 has one of the lowest Eddington ratios\namong quasars at $z\\sim6$, but a common value among quasars at $z\\sim2$. Its\nlow $\\lambda_{\\rm{Edd}}$ can be explained with two scenarios; the SMBH growth\nfrom a stellar mass black hole through short-duration super-Eddington accretion\nevents or from a massive black hole seed ($\\sim10^{5}\\,M_{\\odot}$) with\nEddington-limited accretion. NIR spectra of more faint quasars are needed to\nbetter understand the accretion activities of SMBHs at $z \\sim 6$.", "category": "astro-ph.GA"}, {"title": "Chemical evolution with rotating massive star yields: I. The solar neighbourhood and the s-process elements", "abstract": "We present a comprehensive study of the abundance evolution of the elements\nfrom H to U in the Milky Way halo and local disk. We use a consistent chemical\nevolution model, metallicity dependent isotopic yields from low and\nintermediate mass stars and yields from massive stars which include, for the\nfirst time, the combined effect of metallicity, mass loss and rotation for a\nlarge grid of stellar masses and for all stages of stellar evolution. The\nyields of massive stars are weighted by a metallicity dependent function of the\nrotational velocities, constrained by observations as to obtain a primary-like\n$^{14}$N behavior at low metallicity and to avoid overproduction of s-elements\nat intermediate metallicities. We show that the solar system isotopic\ncomposition can be reproduced to better than a factor of two for isotopes up to\nthe Fe-peak, and at the 10\\% level for most pure s-isotopes, both light ones\n(resulting from the weak s-process in rotating massive stars) and the heavy\nones (resulting from the main s-process in low and intermediate mass stars). We\nconclude that the light element primary process (LEPP), invoked to explain the\napparent abundance deficiency of the s-elements with A< 100, is not necessary.\nWe also reproduce the evolution of the heavy to light s-elements abundance\nratio ([hs/ls]) - recently observed in unevolved thin disk stars - as a result\nof the contribution of rotating massive stars at sub-solar metallicities. We\nfind that those stars produce primary F and dominate its solar abundance and we\nconfirm their role in the observed primary behavior of N. In contrast, we show\nthat their action is insufficient to explain the small observed values of\nC12/C13 in halo red giants, which is rather due to internal processes in those\nstars.", "category": "astro-ph.GA"}, {"title": "A Virgo Environmental Survey Tracing Ionised Gas Emission (VESTIGE).I. Introduction to the Survey", "abstract": "The Virgo Environmental Survey Tracing Ionised Gas Emission (VESTIGE) is a\nblind narrow-band Halpha+[NII] imaging survey carried out with MegaCam at the\nCanada-France-Hawaii Telescope. The survey covers the whole Virgo cluster\nregion from its core to one virial radius (104 deg^2). The sensitivity of the\nsurvey is of f(Halpha) ~ 4 x 10^-17 erg sec-1 cm^-2 (5 sigma detection limit)\nfor point sources and Sigma (Halpha) ~ 2 x 10^-18 erg sec^-1 cm^-2 arcsec^-2 (1\nsigma detection limit at 3 arcsec resolution) for extended sources, making\nVESTIGE the deepest and largest blind narrow-band survey of a nearby cluster.\nThis paper presents the survey in all its technical aspects, including the\nsurvey design, the observing strategy, the achieved sensitivity in both the\nnarrow-band Halpha+[NII] and in the broad-band r filter used for the stellar\ncontinuum subtraction, the data reduction, calibration, and products, as well\nas its status after the first observing semester. We briefly describe the\nHalpha properties of galaxies located in a 4x1 deg^2 strip in the core of the\ncluster north of M87, where several extended tails of ionised gas are detected.\nThis paper also lists the main scientific motivations of VESTIGE, which include\nthe study of the effects of the environment on galaxy evolution, the fate of\nthe stripped gas in cluster objects, the star formation process in nearby\ngalaxies of different type and stellar mass, the determination of the Halpha\nluminosity function and of the Halpha scaling relations down to ~ 10^6 Mo\nstellar mass objects, and the reconstruction of the dynamical structure of the\nVirgo cluster. This unique set of data will also be used to study the HII\nluminosity function in hundreds of galaxies, the diffuse Halpha+[NII] emission\nof the Milky Way at high Galactic latitude, and the properties of emission line\ngalaxies at high redshift.", "category": "astro-ph.GA"}, {"title": "The GALAH Survey: Stellar streams and how stellar velocity distributions vary with Galactic longitude, hemisphere and metallicity", "abstract": "Using GALAH survey data of nearby stars, we look at how structure in the\nplanar (u,v) velocity distribution depends on metallicity and on viewing\ndirection within the Galaxy. In nearby stars, with distance d < 1 kpc, the\nHercules stream is most strongly seen in higher metallicity stars [Fe/H] > 0.2.\nThe Hercules stream peak v value depends on viewed galactic longitude, which we\ninterpret as due to the gap between the stellar stream and more circular orbits\nbeing associated with a specific angular momentum value of about 1640 km/s kpc.\nThe association of the gap with a particular angular momentum value supports a\nbar resonant model for the Hercules stream.\n  Moving groups previously identified in Hipparcos observations are easiest to\nsee in stars nearer than 250 pc, and their visibility and peak velocities in\nthe velocity distributions depends on both viewing direction (galactic\nlongitude and hemisphere) and metallicity. We infer that there is fine\nstructure in local velocity distributions that varies over distances of a few\nhundred pc in the Galaxy.", "category": "astro-ph.GA"}, {"title": "Environmental Quenching of Low-Mass Field Galaxies", "abstract": "In the local Universe, there is a strong division in the star-forming\nproperties of low-mass galaxies, with star formation largely ubiquitous amongst\nthe field population while satellite systems are predominantly quenched. This\ndichotomy implies that environmental processes play the dominant role in\nsuppressing star formation within this low-mass regime (${M}_{\\star} \\sim\n10^{5.5-8}~{\\rm M}_{\\odot}$). As shown by observations of the Local Volume,\nhowever, there is a non-negligible population of passive systems in the field,\nwhich challenges our understanding of quenching at low masses. By applying the\nsatellite quenching models of Fillingham et al. (2015) to subhalo populations\nin the Exploring the Local Volume In Simulations (ELVIS) suite, we investigate\nthe role of environmental processes in quenching star formation within the\nnearby field. Using model parameters that reproduce the satellite quenched\nfraction in the Local Group, we predict a quenched fraction -- due solely to\nenvironmental effects -- of $\\sim 0.52 \\pm 0.26$ within $1< R/R_{\\rm vir} < 2$\nof the Milky Way and M31. This is in good agreement with current observations\nof the Local Volume and suggests that the majority of the passive field systems\nobserved at these distances are quenched via environmental mechanisms. Beyond\n$2~R_{\\rm vir}$, however, dwarf galaxy quenching becomes difficult to explain\nthrough an interaction with either the Milky Way or M31, such that more\nisolated, field dwarfs may be self-quenched as a result of star-formation\nfeedback.", "category": "astro-ph.GA"}, {"title": "Reignition of Star Formation in Dwarf Galaxies", "abstract": "The Local Group hosts a number of star-forming dwarf galaxies that show\nevidence of periods of little to no star formation. We use a suite of\ncosmological simulations to study how star formation is reignited in such\ngalaxies. We focus on isolated galaxies at $z=0$ with halo masses between\n9.2$\\times$10$^8$ M$_\\odot$ and 8.4$\\times$10$^9$ M$_\\odot$, where star\nformation is typically shut off by reionization or by supernova feedback.\nNearly 20% of these simulated galaxies later restart star formation, due to\ninteractions with streams of gas in the intergalactic medium, indicating that\nthis mechanism is relatively common in this mass range and that many isolated\ndwarfs at $z=0$ may not have been isolated throughout their histories. The\nsource of this gas is not necessarily cosmic filaments. Rather, the dwarfs\ninteract with gas thrown off by nearby galaxy mergers or streams extending from\nneighboring galaxies. While high ram pressure interactions of this nature lead\nto stripping, the encounters that reignite star formation are low density\nand/or low velocity and thus low ram pressure, resulting in compression of the\nhot gas in the halos of our dwarfs. The gas mass bound up in hot halos can be\nsubstantial -- at least an order of magnitude greater than the mass contained\nin HI. Consequently, we find that dwarfs that have experienced reignition tend\nto be more HI-rich and have a higher M$_{HI}$/M$_{*}$ ratio at $z=0$ than\ngalaxies with continuous star formation. Using this fact, we identify galaxies\nin the Local Volume that might have \"gappy\" star formation histories, and can\nbe studied by the Hubble Space Telescope or the James Webb Space Telescope.", "category": "astro-ph.GA"}, {"title": "Supermassive Black Holes with High Accretion Rates in Active Galactic Nuclei. IX 10 New Observations of Reverberation Mapping and Shortened H$β$ Lags", "abstract": "As one of the series of papers reporting on a large reverberation mapping\ncampaign of super-Eddington accreting massive black holes (SEAMBHs) in active\ngalactic nuclei (AGNs), we present the results of 10 SEAMBHs monitored\nspectroscopically during 2015-2017. Six of them are observed for the first\ntime, and have generally higher 5100 \\AA\\ luminosities than the SEAMBHs\nmonitored in our campaign from 2012 to 2015; the remaining four are repeat\nobservations to check if their previous lags change. Similar to the previous\nSEAMBHs, the H$\\beta$ time lags of the newly observed objects are shorter than\nthe values predicted by the canonical $R_{\\mathrm{H\\beta}}$-$L_{5100}$ relation\nof sub-Eddington AGNs, by factors of $\\sim2-6$, depending on the accretion\nrate. The four previously observed objects have lags consistent with previous\nmeasurements. We provide linear regressions for the\n$R_{\\mathrm{H\\beta}}$-$L_{5100}$ relation, solely for the SEAMBH sample and for\nlow-accretion AGNs. We find that the relative strength of Fe II and the profile\nof the H$\\beta$ emission line can be used as proxies of accretion rate, showing\nthat the shortening of H$\\beta$ lags depends on accretion rates. The recent\nSDSS-RM discovery of shortened H$\\beta$ lags in AGNs with low accretion rates\nprovides compelling evidence for retrograde accretion onto the black hole.\nThese evidences show that the canonical $R_{\\mathrm{H\\beta}}$-$L_{5100}$\nrelation holds only in AGNs with moderate accretion rates. At low accretion\nrates, it should be revised to include the effects of black hole spin, whereas\nthe accretion rate itself becomes a key factor in the regime of high accretion\nrates.", "category": "astro-ph.GA"}, {"title": "A Multi-Frequency Study of the Milky Way-like Spiral Galaxy NGC 6744", "abstract": "We present a multi-frequency study of the intermediate spiral SAB(r)bc type\ngalaxy NGC 6744, using available data from the Chandra X-Ray telescope, radio\ncontinuum data from the Australia Telescope Compact Array and Murchison\nWidefield Array, and Wide-field Infrared Survey Explorer infrared observations.\nWe identify 117 X-ray sources and 280 radio sources. Of these, we find nine\nsources in common between the X-ray and radio catalogues, one of which is a\nfaint central black hole with a bolometric radio luminosity similar to the\nMilky Way's central black hole. We classify 5 objects as supernova remnant\ncandidates, 2 objects as likely supernova remnants, 17 as HII regions, 1 source\nas an AGN; the remaining 255 radio sources are categorised as background\nobjects and one X-ray source is classified as a foreground star. We find the\nstar-formation rate (SFR) of NGC 6744 to be in the range 2.8 - 4.7\n$\\rm{M_{\\odot}~yr^{-1}}$ signifying the galaxy is still actively forming stars.\nThe specific SFR of NGC 6744 is greater than that of late-type spirals such as\nthe Milky Way, but considerably less that that of a typical starburst galaxy.", "category": "astro-ph.GA"}, {"title": "The Maximum Flux of Star-Forming Galaxies", "abstract": "The importance of radiation pressure feedback in galaxy formation has been\nextensively debated over the last decade. The regime of greatest uncertainty is\nin the most actively star-forming galaxies, where large dust columns can\npotentially produce a dust-reprocessed infrared radiation field with enough\npressure to drive turbulence or eject material. Here we derive the conditions\nunder which a self-gravitating, mixed gas-star disc can remain hydrostatic\ndespite trapped radiation pressure. Consistently taking into account the\nself-gravity of the medium, the star- and dust-to-gas ratios, and the effects\nof turbulent motions not driven by radiation, we show that galaxies can achieve\na maximum Eddington-limited star formation rate per unit area\n$\\dot{\\Sigma}_{\\rm *,crit} \\sim 10^3 M_{\\odot}$ pc$^{-2}$ Myr$^{-1}$,\ncorresponding to a critical flux of $F_{\\rm *,crit} \\sim 10^{13} L_{\\odot}$\nkpc$^{-2}$ similar to previous estimates; higher fluxes eject mass in bulk,\nhalting further star formation. Conversely, we show that in galaxies below this\nlimit, our one-dimensional models imply simple vertical hydrostatic equilibrium\nand that radiation pressure is ineffective at driving turbulence or ejecting\nmatter. Because the vast majority of star-forming galaxies lie below the\nmaximum limit for typical dust-to-gas ratios, we conclude that infrared\nradiation pressure is likely unimportant for all but the most extreme systems\non galaxy-wide scales. Thus, while radiation pressure does not explain the\nKennicutt-Schmidt relation, it does impose an upper truncation on it. Our\npredicted truncation is in good agreement with the highest observed gas and\nstar formation rate surface densities found both locally and at high redshift.", "category": "astro-ph.GA"}, {"title": "Sub-arcsecond imaging of Arp\\,299-A at 150 MHz with LOFAR: Evidence for a starburst-driven outflow", "abstract": "We report on the first sub-arcsecond (0.44 $\\times$ 0.41 arcsec$\\rm ^2$)\nangular resolution image at 150 MHz of the A-nucleus in the Luminous Infrared\nGalaxy Arp$\\,$299, from International Low Frequency Array (LOFAR) Telescope\nobservations. The most remarkable finding is that of an intriguing two-sided,\nfilamentary structure emanating from A-nucleus, which we interpret as an\noutflow that extends up to at least 14 arcseconds from the A-nucleus in the N-S\ndirection ($\\approx$ 5 kpc deprojected size) and accounts for almost 40% of the\nextended emission of the entire galaxy system. We also discuss HST/NICMOS\n[FeII] 1.64 $\\rm \\mu m$ and H$\\rm_2$ 2.12 $\\rm \\mu m$ images of Arp$\\,$299-A,\nwhich show similar features to those unveiled by our 150 MHz LOFAR\nobservations, thus giving string morphological support for the outflow\nscenario. Finally, we discuss unpublished NaI D spectra that confirm the\noutflow nature of this structure. From energetic arguments, we rule out the\nlow-luminosity active galactic nucleus in Arp$\\,$299-A as a driver for the\noutflow. On the contrary, the powerful, compact starburst in the central\nregions of Arp$\\,$299-A provides plenty of mechanical energy to sustain an\noutflow, and we conclude that the intense supernova (SN) activity in the\nnuclear region of Arp299-A is driving the observed outflow. We estimate that\nthe starburst wind can support a mass-outflow rate in the range (11-63) $\\rm\nM_{\\odot} yr^{-1}$ at speeds of up to (370 - 890) $\\rm km \\, s^{-1}$, and is\nrelatively young, with an estimated kinematic age of (3 - 7) Myr. Those results\nopen an avenue to the use of low-frequency (150 MHz), sub-arcsecond imaging\nwith LOFAR to detect outflows in the central regions of local luminous infrared\ngalaxies.", "category": "astro-ph.GA"}, {"title": "The Milky Way Halo in Action Space", "abstract": "We analyse the structure of the local stellar halo of the Milky Way using\n$\\sim$ 60000 stars with full phase space coordinates extracted from the\nSDSS--{\\it Gaia} catalogue. We display stars in action space as a function of\nmetallicity in a realistic axisymmetric potential for the Milky Way Galaxy. The\nmetal-rich population is more distended towards high radial action $J_R$ as\ncompared to azimuthal or vertical action, $J_\\phi$ or $J_z$. It has a mild\nprograde rotation $(\\langle v_\\phi \\rangle \\approx 25$ km s$^{-1}$), is\nradially anisotropic and highly flattened with axis ratio $q \\approx 0.6 -\n0.7$. The metal-poor population is more evenly distributed in all three\nactions. It has larger prograde rotation $(\\langle v_\\phi \\rangle \\approx 50$\nkm s$^{-1}$), a mild radial anisotropy and a roundish morphology ($q\\approx\n0.9$). We identify two further components of the halo in action space. There is\na high energy, retrograde component that is only present in the metal-rich\nstars. This is suggestive of an origin in a retrograde encounter, possibly the\none that created the stripped dwarf galaxy nucleus, $\\omega$Centauri. Also\nvisible as a distinct entity in action space is a resonant component, which is\nflattened and prograde. It extends over a range of metallicities down to [Fe/H]\n$\\approx -3$. It has a net outward radial velocity $\\langle v_R \\rangle \\approx\n12$ km s$^{-1}$ within the Solar circle at $|z| <3.5$ kpc. The existence of\nresonant stars at such extremely low metallicities has not been seen before.", "category": "astro-ph.GA"}, {"title": "Extragalactic archaeology with the C, N, and O chemical abundances", "abstract": "We predict how the C, N, and O abundances within the interstellar medium of\ngalaxies evolve as functions of the galaxy star formation history (SFH). We\nadopt a hydrodynamical cosmological simulation, focusing on three star-forming\ndisc galaxies with different SFHs. By assuming failed supernovae, we can\npredict an increasing trend of the gas-phase N/O--O/H abundance diagram, which\nwas not produced in our previous simulations without failed supernovae. At high\nredshifts, contrary to the predictions of classical chemical evolution models\nwith instantaneous mixing approximation, we find almost flat trends in the\nN/O--O/H diagram, which are due to the contribution of intermediate-mass stars\ntogether with an inhomogeneous chemical enrichment. Finally, we also predict\nthat the average N/O and C/O steadily increase as functions of time, while the\naverage C/N decreases, due to the mass and metallicity dependence of the yields\nof asymptotic giant branch stars; such variations are more marked during more\nintense star formation episodes. Our predictions on the CNO abundance evolution\ncan be used to study the SFH of disc galaxies with the James Webb Space\nTelescope.", "category": "astro-ph.GA"}, {"title": "Co-formation of the Galactic disc and the stellar halo", "abstract": "Using a large sample of Main Sequence stars with 7-D measurements supplied by\nGaia and SDSS, we study the kinematic properties of the local (within ~10 kpc\nfrom the Sun) stellar halo. We demonstrate that the halo's velocity ellipsoid\nevolves strongly with metallicity. At the low [Fe/H] end, the orbital\nanisotropy (the amount of motion in the radial direction compared to the\ntangential one) is mildly radial with 0.2<beta<0.4. However, for stars with\n[Fe/H]>-1.7 we measure extreme values of beta~0.9. Across the metallicity range\nconsidered, i.e. -3<[Fe/H]<-1, the stellar halo's spin is minimal, at the level\nof 20<v_theta (km/s) <30. Using a suite of cosmological zoom-in simulations of\nhalo formation, we deduce that the observed acute anisotropy is inconsistent\nwith the continuous accretion of dwarf satellites. Instead, we argue, the\nstellar debris in the inner halo were deposited in a major accretion event by a\nsatellite with Mvir>10^10 Msun around the epoch of the Galactic disc formation,\ni.e. between 8 and 11 Gyr ago. The radical halo anisotropy is the result of the\ndramatic radialisation of the massive progenitor's orbit, amplified by the\naction of the growing disc.", "category": "astro-ph.GA"}, {"title": "The WISSH Quasars Project IV. BLR versus kpc-scale winds", "abstract": "We have undertaken a multi-band observing program aimed at obtaining a\ncomplete census of winds in a sample of WISE/SDSS selected hyper-luminous\n(WISSH) QSOs at z~2-4. We have analyzed the rest-frame optical (LBT/LUCI and\nVLT/SINFONI) and UV (SDSS) spectra of 18 randomly selected WISSH QSOs to\nmeasure the SMBH mass and study the properties of winds both in the NLR and BLR\ntraced by blueshifted/skewed [OIII] and CIV emission lines, respectively. These\nWISSH QSOs are powered by SMBH with masses $\\ge$10$^9$ Msun accreting at\n0.4<$\\lambda_{Edd}$<3.1. We have found the existence of two sub-populations\ncharacterized by the presence of outflows at different distances from the SMBH.\nOne population ([OIII] sources) exhibits powerful [OIII] outflows, rest-frame\nEW (REW) of the CIV emission REW$_{CIV}\\approx$20-40 A and modest CIV velocity\nshift (v$_{CIV}^{peak}$) with respect to the systemic redshift (<=2000 km/s).\nThe second population (Weak [OIII] sources), representing ~70% of the analyzed\nWISSH QSOs, shows weak/absent [OIII] emission and an extremely large\nv$_{CIV}^{peak}$ (up to ~8000 km/s and REW$_{CIV}$<=20 A). We propose two\nexplanations for the observed behavior of the strength of the [OIII] emission\nin terms of orientation effects of the line of sight and ionization cone. The\ndichotomy in the presence of BLR and NLR winds could be likely due to\ninclination effects considering a polar geometry scenario for the BLR winds. We\nfind a strong correlation with L$_{Bol}$ and an anti-correlation with\n$\\alpha_{ox}$, whereby the higher L$_{Bol}$, the steeper $\\alpha_{ox}$ and the\nlarger is the v$_{CIV}^{peak}$. Finally, the observed dependence\nv$_{CIV}^{peak}\\propto L_{Bol}^{0.28\\pm0.04}$ is consistent with radiatively\ndriven winds scenario, where strong UV continuum is necessary to launch the\nwind and a weakness of the X-ray emission is fundamental to prevent\noverionization of the wind itself.", "category": "astro-ph.GA"}, {"title": "Deconstructing a galaxy: colour distributions of point sources in Messier 83", "abstract": "What do we see when we look at a nearby, well-resolved galaxy? Thousands of\nindividual sources are detected in multiband imaging observations of even a\nfraction of a nearby galaxy, and characterizing those sources is a complex\nprocess. This work analyses a ten-band photometric catalogue of nearly 70 000\npoint sources in a 7.3 square arcmin region of the nearby spiral galaxy Messier\n83, made as part of the Early Release Science programme with the Hubble Space\nTelescope's Wide Field Camera 3. Colour distributions were measured for both\nbroad-band and broad-and-narrow-band colours; colours made from broad-bands\nwith large wavelength differences generally had broader distributions although\nB - V was an exception. Two- and three-dimensional colour spaces were generated\nusing various combinations of four bands and clustered with the K-Means and\nMean Shift algorithms. Neither algorithm was able to consistently segment the\ncolour distributions: while some distinct features in colour space were\napparent in visual examinations, these features were not compact or isolated\nenough to be recognized as clusters in colour space. K-Means clustering of the\nUBVI colour space was able to identify a group of objects more likely to be\nstar clusters. Mean Shift was successful in identifying outlying groups at the\nedges of colour distributions. For identifying objects whose emission is\ndominated by spectral lines, there was no clear benefit from combining\nnarrow-band photometry in multiple bands compared to a simple continuum\nsubtraction. The clustering analysis results are used to inform recommendations\nfor future surveys of nearby galaxies.", "category": "astro-ph.GA"}, {"title": "A 100 au-Wide Bipolar Rotating Shell Emanating From The HH 212Protostellar Disk: A Disk Wind?", "abstract": "HH 212 is a Class 0 protostellar system found to host a \"hamburger\"-shaped\ndusty disk with a rotating disk atmosphere and a collimated SiO jet at a\ndistance of ~ 400 pc. Recently, a compact rotating outflow has been detected in\nSO and SO2 toward the center along the jet axis at ~ 52 au (0.13\") resolution.\nHere we resolve the compact outflow into a small-scale wide-opening rotating\noutflow shell and a collimated jet, with the observations in the same S-bearing\nmolecules at ~ 16 au (0.04\") resolution. The collimated jet is aligned with the\nSiO jet, tracing the shock interactions in the jet. The wide-opening outflow\nshell is seen extending out from the inner disk around the SiO jet and has a\nwidth of ~ 100 au. It is not only expanding away from the center, but also\nrotating around the jet axis. The specific angular momentum of the outflow\nshell is ~ 40 au km/s. Simple modeling of the observed kinematics suggests that\nthe rotating outflow shell can trace either a disk wind or disk material pushed\naway by an unseen wind from the inner disk or protostar. We also resolve the\ndisk atmosphere in the same S-bearing molecules, confirming the Keplerian\nrotation there.", "category": "astro-ph.GA"}, {"title": "Evolution of spatially resolved star formation main sequence and surface density profiles in massive disc galaxies at $0\\lesssim z \\lesssim 1$: inside-out stellar mass buildup and quenching", "abstract": "We investigate a relation between surface densities of star formation rate\n(SFR) and stellar mass ($M_{*}$) at a $\\sim 1$ kpc scale namely spatially\nresolved star formation main sequence (SFMS) in massive\n($\\log(M_{*}/M_{\\odot})>10.5$) face-on disc galaxies at $0.01<z<0.02$ and\n$0.8<z<1.8$ and examine evolution of the relation. The spatially resolved SFMS\nof $z\\sim 0$ galaxies is discussed in a companion paper. For $z\\sim 1$ sample,\nwe use 8 bands imaging dataset from CANDELS and 3D-HST and perform a\npixel-to-pixel SED fitting to derive the spatially resolved SFR and $M_{*}$. We\nfind a linear spatially resolved SFMS in the $z\\sim 1$ galaxies that lie on the\nglobal SFMS, while a 'flattening' at high $\\Sigma_{*}$ end is found in that\nrelation for the galaxies that lie below the global SFMS. Comparison with the\nspatially resolved SFMS of the $z\\sim 0$ galaxies shows smaller difference in\nthe specific SFR (sSFR) at low $\\Sigma_{*}$ than that at high $\\Sigma_{*}$.\nThis trend is consistent with the evolution of the sSFR$(r)$ radial profile,\nwhich shows a faster decrease in the central region than in the outskirt,\nagrees with the inside-out quenching scenario. We then derive an empirical\nmodel for the evolution of the $\\Sigma_{*}(r)$, $\\Sigma_{\\rm SFR}(r)$ and\nsSFR$(r)$ radial profiles. Based on the empirical model, we estimate the radial\nprofile of the quenching timescale and reproduce the observed spatially\nresolved SFMS at $z\\sim 1$ and $z\\sim 0$.", "category": "astro-ph.GA"}, {"title": "The HIX galaxy survey II: HI kinematics of HI eXtreme galaxies", "abstract": "By analysing a sample of galaxies selected from the HI Parkes All Sky Survey\n(HIPASS) to contain more than 2.5 times their expected HI content based on\ntheir optical properties, we investigate what drives these HI eXtreme (HIX)\ngalaxies to be so HI-rich. We model the HI kinematics with the Tilted Ring\nFitting Code TiRiFiC and compare the observed HIX galaxies to a control sample\nof galaxies from HIPASS as well as simulated galaxies built with the\nsemi-analytic model Dark Sage. We find that (1) HI discs in HIX galaxies are\nmore likely to be warped and more likely to host HI arms and tails than in the\ncontrol galaxies, (2) the average HI and average stellar column density of HIX\ngalaxies is comparable to the control sample, (3) HIX galaxies have higher HI\nand baryonic specific angular momenta than control galaxies, (4) most HIX\ngalaxies live in higher-spin haloes than most control galaxies. These results\nsuggest that HIX galaxies are HI-rich because they can support more HI against\ngravitational instability due to their high specific angular momentum. The\nmajority of the HIX galaxies inherits their high specific angular momentum from\ntheir halo. The HI content of HIX galaxies might be further increased by\ngas-rich minor mergers. This paper is based on data obtained with the Australia\nTelescope Compact Array (ATCA) through the large program C 2705.", "category": "astro-ph.GA"}, {"title": "Kinematic Distances: A Monte Carlo Method", "abstract": "Distances to high mass star forming regions (HMSFRs) in the Milky Way are a\ncrucial constraint on the structure of the Galaxy. Only kinematic distances are\navailable for a majority of the HMSFRs in the Milky Way. Here we compare the\nkinematic and parallax distances of 75 Galactic HMSFRs to assess the accuracy\nof kinematic distances. We derive the kinematic distances using three different\nmethods: the traditional method using the Brand & Blitz (1993) rotation curve\n(Method A), the traditional method using the Reid et al. (2014) rotation curve\nand updated Solar motion parameters (Method B), and a Monte Carlo technique\n(Method C). Methods B and C produce kinematic distances closest to the parallax\ndistances, with median differences of 13% (0.43 kpc) and 17% (0.42 kpc),\nrespectively. Except in the vicinity of the tangent point, the kinematic\ndistance uncertainties derived by Method C are smaller than those of Methods A\nand B. In a large region of the Galaxy, the Method C kinematic distances\nconstrain both the distances and the Galactocentric positions of HMSFRs more\naccurately than parallax distances. Beyond the tangent point along longitude=30\ndegrees, for example, the Method C kinematic distance uncertainties reach a\nminimum of 10% of the parallax distance uncertainty at a distance of 14 kpc. We\ndevelop a prescription for deriving and applying the Method C kinematic\ndistances and distance uncertainties. The code to generate the Method C\nkinematic distances is publicly available and may be utilized through an\non-line tool.", "category": "astro-ph.GA"}, {"title": "Angular Sizes of $μ$Jy Radio Sources", "abstract": "We made two new sensitive (rms noise sigma_n ~ 1 microJy/beam) high\nresolution (theta = 3.0\" and theta = 0.66\" FWHM) S--band (2 < nu < 4 GHz)\nimages covering a single JVLA primary beam (FWHM ~ 14') centered on J2000 RA =\n10 46, Dec = 59 01 in the Lockman Hole. These images yielded a catalog of 792\nradio sources, 97.7 +/- 0.8% of which have infrared counterparts stronger than\nS ~ 2 microJy at lambda = 4.5 micron. About 91% of the radio sources found in\nour previously published, comparably sensitive low resolution (theta = 8\" FWHM)\nimage covering the same area were also detected at 0.66\" resolution, so most\nradio sources with S_3GHz >~ 5 microJy have angular structure phi <~ 0.66\". The\nratios of peak brightness in the 0.66\" and 3\" images have a distribution\nindicating that most microJy radio sources are quite compact, with a median\nGaussian angular diameter <phi> = 0.3\" +/- 0.1\" FWHM and an rms scatter\nsigma_phi <~ 0.3\" of individual sizes. Most of our microJy radio sources obey\nthe tight far-infrared/radio correlation, indicating that they are powered by\nstar formation. The median effective angular radius enclosing half the light\nemitted by an exponential disk is <rho_e> ~ <phi>/2.43 ~ 0.12\", so the median\neffective radius of star-forming galaxies at redshifts z~1 is <r_e> ~ 1.0 kpc.", "category": "astro-ph.GA"}, {"title": "The fraction of AGN in major merger galaxies and its luminosity dependence", "abstract": "We use a phenomenological model which connects the galaxy and AGN populations\nto investigate the process of AGN triggering through major galaxy mergers at\nz~0. The model uses stellar mass functions as input and allows the prediction\nof AGN luminosity functions based on assumed Eddington ratio distribution\nfunctions (ERDFs). We show that the number of AGN hosted by merger galaxies\nrelative to the total number of AGN increases as a function of AGN luminosity.\nThis is due to more massive galaxies being more likely to undergo a merger and\ndoes not require the assumption that mergers lead to higher Eddington ratios\nthan secular processes. Our qualitative analysis also shows that to match the\nobservations, the probability of a merger galaxy hosting an AGN and accreting\nat a given Eddington value has to be increased by a factor ~10 relative to the\ngeneral AGN population. An additional significant increase of the fraction of\nhigh Eddington ratio AGN among merger host galaxies leads to inconsistency with\nthe observed X-ray luminosity function. Physically our results imply that,\ncompared to the general galaxy population, the AGN fraction among merger\ngalaxies is ~10 times higher. On average, merger triggering does however not\nlead to significantly higher Eddington ratios.", "category": "astro-ph.GA"}, {"title": "Unlocking the Full Potential of Extragalactic Ly$α$ through Its Polarization Properties", "abstract": "Lyman-$\\alpha$ (Ly$\\alpha$) is a powerful astrophysical probe. Not only is it\nubiquitous at high redshifts, it is also a resonant line, making Ly$\\alpha$\nphotons scatter. This scattering process depends on the physical conditions of\nthe gas through which Ly$\\alpha$ propagates, and these conditions are imprinted\non observables such as the Ly$\\alpha$ spectrum and its surface brightness\nprofile. In this work, we focus on a less-used observable capable of probing\nany scattering process: polarization. We implement the density matrix formalism\nof polarization into the Monte Carlo radiative transfer code tlac. This allows\nus to treat it as a quantum mechanical process where single photons develop and\nlose polarization from scatterings in arbitrary gas geometries. We explore\nstatic and expanding ellipsoids, biconical outflows, and clumpy multiphase\nmedia. We find that photons become increasingly polarized as they scatter and\ndiffuse into the wings of the line profiles, making scattered Ly$\\alpha$\npolarized in general. The degree and orientation of Ly$\\alpha$ polarization\ndepends on the kinematics and distribution of the scattering HI gas. We find\nthat it generally probes spatial or velocity space asymmetries and aligns\nitself tangentially to the emission source. We show that the mentioned\nobservables, when studied separately, can leave similar signatures for\ndifferent source models. We conclude by revealing how a joint analysis of the\nLy$\\alpha$ spectra, surface brightness profiles, and polarization can break\nthese degeneracies and help us extract unique physical information on galaxies\nand their environments from their strongest, most prominent emission line.", "category": "astro-ph.GA"}, {"title": "HI Kinematics Along The Minor Axis of M82", "abstract": "M82 is one of the best studied starburst galaxies in the local universe, and\nis consequently a benchmark for studying star formation feedback at both low\nand high redshift. We present new VLA HI observations that reveal the cold gas\nkinematics along the minor axis in unprecedented detail. This includes the\ndetection of HI up to 10 kpc along the minor axis toward the South and beyond 5\nkpc to the North. A surprising aspect of these observations is that the\nline-of-sight HI velocity decreases substantially from about 120 km/s to 50\nkm/s from 1.5 to 10 kpc off the midplane. The velocity profile is not\nconsistent with the HI gas cooling from the hot wind. We demonstrate that the\nvelocity decrease is substantially greater than the deceleration expected from\ngravitational forces alone. If the HI consists of a continuous population of\ncold clouds, some additional drag force must be present, and the magnitude of\nthe drag force places a joint constraint on the ratio of the ambient medium to\nthe typical cloud size and density. We also show that the HI kinematics are\ninconsistent with a simple conical outflow centered on the nucleus, but instead\nrequire the more widespread launch of the HI over the ~1 kpc extent of the\nstarburst region. Regardless of the launch mechanism for the HI gas, the\nobserved velocity decrease along the minor axis is sufficiently great that the\nHI may not escape the halo of M82. We estimate the HI outflow rate is much less\nthan 1 M$_{\\odot}$ per year at 10 kpc off the midplane.", "category": "astro-ph.GA"}, {"title": "A self-consistent hydrostatic mass modelling of pressure supported dwarf galaxy Leo T", "abstract": "Assuming a hydrostatic equilibrium in an HI cloud, the joint Poisson's\nequation is set up and numerically solved to calculate the expected HI\ndistribution. Unlike previous studies, the cloud is considered to be\nnon-isothermal, and an {\\it iterative} method is employed to iteratively\nestimate the intrinsic velocity dispersion profile using the observed\nsecond-moment of the HI data. We apply our {\\it iterative} method to a recently\ndiscovered dwarf galaxy Leo T and find that its observed HI distribution does\nnot comply with the expected one if one assumes no dark matter in it. To model\nthe mass distribution in Leo T, we solve the Poisson's equation using a large\nnumber of trial dark matter halos and compare the model HI surface density\n($\\Sigma_{HI}$) profiles to the observed one to identify the best dark matter\nhalo parameters. For Leo T, we find a pseudo-isothermal halo with core density,\n$\\rho_0 \\sim 0.67$ $\\rm M_{\\odot} \\thinspace pc^{-3}$ and core radius, $r_s\n\\sim 37$ parsec explains the observation best. The resulting dark matter halo\nmass within the central 300 pc, $M_{300}$, found to be $\\sim 2.7 \\times 10^6$\n$\\rm M_{\\odot}$. We also find that a set of dark matter halos with similar\n$M_{300} \\sim 3.7 \\times 10^6$ $\\rm M_{\\odot}$ but very different $\\rho_0$ and\n$r_s$ values, can produce equally good $\\Sigma_{HI}$ profile within the\nobservational uncertainties. This, in turn, indicates a strong degeneracy\nbetween the halo parameters and the best fit values are not unique.\nInterestingly, it also implies that the mass of a dark matter halo, rather than\nits structure primarily directs the expected HI distribution under hydrostatic\nequilibrium.", "category": "astro-ph.GA"}, {"title": "Geometric Aspects and Testing of the Galactic Center Distance Determination from Spiral Arm Segments", "abstract": "We consider the problem of determining the geometric parameters of a Galactic\nspiral arm from its segment by including the distance to the spiral pole, i.e.,\nthe distance to the Galactic center ($R_0$). The question about the number of\npoints belonging to one turn of a logarithmic spiral and defining this spiral\nas a geometric figure has been investigated numerically and analytically by\nassuming the direction to the spiral pole (to the Galactic center) to be known.\nBased on the results obtained, in an effort to test the new approach, we have\nconstructed a simplified method of solving the problem that consists in finding\nthe median of the values for each parameter from all possible triplets of\nobjects in the spiral arm segment satisfying the condition for the angular\ndistance between objects. Applying the method to the data on the spatial\ndistribution of masers in the Perseus and Scutum arms (the catalogue by Reid et\nal. (2014)) has led to an estimate of $R_0 = 8.8 \\pm 0.5$ kpc. The parameters\nof five spiral arm segments have been determined from masers of the same\ncatalogue. We have confirmed the difference between the spiral arms in pitch\nangle. The pitch angles of the arms revealed by masers are shown to generally\ncorrelate with $R_0$ in the sense that an increase in $R_0$ leads to a growth\nin the absolute values of the pitch angles.", "category": "astro-ph.GA"}, {"title": "Extragalactic maser surveys", "abstract": "Since the IAU (maser-)Symposium 287 in Stellenbosch/South Africa (Jan. 2012),\ngreat progress has been achieved in studying extragalactic maser sources.\nSensitivity has reached a level allowing for dedicated maser surveys of\nextragalactic objects. These included, during the last years, water vapor\n(H2O), methanol (CH3OH), and formaldehyde (H2CO), while surveys related to\nhydroxyl (OH), cyanoacetylene (HC3N) and ammonia (NH3) may soon become (again)\nrelevant. Overall, with the upgraded Very Large Array (VLA), the Atacama Large\nMillimeter/submillimeter Array (ALMA), FAST (Five hundred meter Aperture\nSynthesis Telescope) and the low frequency arrays APERTIF (APERture Tile in\nFocus), ASKAP (Australian Square Kilometer Array Pathfinder) and MeerKAT (Meer\nKaroo Array Telescope), extragalactic maser studies are expected to flourish\nduring the upcoming years. The following article provides a brief sketch of\npast achievements, ongoing projects and future perspectives.", "category": "astro-ph.GA"}, {"title": "O/H-N/O: the curious case of NGC 4670", "abstract": "We use integral field spectroscopic (IFS) observations from Gemini North\nMulti-Object Spectrograph (GMOS-N) of a group of four H II regions and the\nsurrounding gas in the central region of the blue compact dwarf (BCD) galaxy\nNGC 4670. At spatial scales of $\\sim$ 9 pc, we map the spatial distribution of\na variety of physical properties of the ionised gas: internal dust attenuation,\nkinematics, stellar age, star-formation rate, emission line ratios and chemical\nabundances. The region of study is found to be photoionised. Using the robust\ndirect T$_e$-method, we estimate metallicity, nitrogen-to-oxygen ratio and\nhelium abundance of the four H II regions. The same parameters are also mapped\nfor the entire region using the HII-CHI-mistry code. We find that log(N/O) is\nincreased in the region where the Wolf-Rayet bump is detected.The region\ncoincides with the continuum region, around which we detect a slight increase\nin He abundance. We estimate the number of WC4, WN2-4 and WN7-9 stars from the\nintegrated spectrum of WR bump region. We study the relation between log(N/O)\nand 12 + log(O/H) using the spatially-resolved data of the FOV as well as the\nintegrated data of the H II regions from ten BCDs. We find an unexpected\nnegative trend between N/O and metallicity. Several scenarios are explored to\nexplain this trend, including nitrogen enrichment, and variations in star\nformation efficiency via chemical evolution models.", "category": "astro-ph.GA"}, {"title": "After The Fall: The Dust and Gas in E+A Post-Starburst Galaxies", "abstract": "The traditional picture of post-starburst galaxies as dust- and gas-poor\nmerger remnants, rapidly transitioning to quiescence, has been recently\nchallenged. Unexpected detections of a significant ISM in many post-starbursts\nraise important questions. Are they truly quiescent and, if so, what mechanisms\ninhibit further star formation? What processes dominate their ISM energetics?\nWe present an infrared spectroscopic and photometric survey of 33 SDSS-selected\nE+A post-starbursts, aimed at resolving these questions. We find compact, warm\ndust reservoirs with high PAH abundances, and total gas and dust masses\nsignificantly higher than expected from stellar recycling alone. Both PAH/TIR\nand dust-to-burst stellar mass ratios are seen to decrease with post-burst age,\nindicative of the accumulating effects of dust destruction and an incipient\ntransition to hot, early-type ISM properties. Their infrared spectral\nproperties are unique, with dominant PAH emission, very weak nebular lines,\nunusually strong H$_{2}$ rotational emission, and deep ${\\rm [C\\, II]}$\ndeficits. There is substantial scatter among SFR indicators, and both PAH and\nTIR luminosities provide overestimates. Even as potential upper limits, all\ntracers show that the SFR has typically experienced a more than two\norder-of-magnitude decline since the starburst, and that the SFR is\nconsiderably lower than expected given both their stellar masses and molecular\ngas densities. These results paint a coherent picture of systems in which star\nformation was, indeed, rapidly truncated, but in which the ISM was\n$\\textit{not}$ completely expelled, and is instead supported against collapse\nby latent or continued injection of turbulent or mechanical heating. The\nresulting aging burst populations provide a \"high-soft\" radiation field which\nseemingly dominates the E+As' unusual ISM energetics.", "category": "astro-ph.GA"}, {"title": "The SAMI Galaxy Survey: gravitational potential and surface density drive stellar populations -- I. early-type galaxies", "abstract": "The well-established correlations between the mass of a galaxy and the\nproperties of its stars are considered evidence for mass driving the evolution\nof the stellar population. However, for early-type galaxies (ETGs), we find\nthat $g-i$ color and stellar metallicity [Z/H] correlate more strongly with\ngravitational potential $\\Phi$ than with mass $M$, whereas stellar population\nage correlates best with surface density $\\Sigma$. Specifically, for our sample\nof 625 ETGs with integral-field spectroscopy from the SAMI Galaxy Survey,\ncompared to correlations with mass, the color--$\\Phi$, [Z/H]--$\\Phi$, and\nage--$\\Sigma$ relations show both smaller scatter and less residual trend with\ngalaxy size. For the star formation duration proxy [$\\alpha$/Fe], we find\ncomparable results for trends with $\\Phi$ and $\\Sigma$, with both being\nsignificantly stronger than the [$\\alpha$/Fe]-$M$ relation. In determining the\nstrength of a trend, we analyze both the overall scatter, and the observational\nuncertainty on the parameters, in order to compare the intrinsic scatter in\neach correlation. These results lead us to the following inferences and\ninterpretations: (1) the color--$\\Phi$ diagram is a more precise tool for\ndetermining the developmental stage of the stellar population than the\nconventional color--mass diagram; and (2) gravitational potential is the\nprimary regulator of global stellar metallicity, via its relation to the gas\nescape velocity. Furthermore, we propose the following two mechanisms for the\nage and [$\\alpha$/Fe] relations with $\\Sigma$: (a) the age--$\\Sigma$ and\n[$\\alpha$/Fe]--$\\Sigma$ correlations arise as results of compactness driven\nquenching mechanisms; and/or (b) as fossil records of the\n$\\Sigma_{SFR}\\propto\\Sigma_{gas}$ relation in their disk-dominated progenitors.", "category": "astro-ph.GA"}, {"title": "A new mechanical stellar wind feedback model for the Rosette Nebula", "abstract": "The famous Rosette Nebula has an evacuated central cavity formed from the\nstellar winds ejected from the 2-6 million-year-old co-distant and co-moving\ncentral star cluster NGC 2244. However, with upper age estimates of less than\n110,000 years, the central cavity is too young compared to NGC 2244 and\nexisting models do not reproduce its properties. A new proper motion study\nherein using Gaia data reveals the ejection of the most massive star in the\nRosette, HD46223, from NGC 2244 occurred 1.73 (+0.34,-0.25)Myr (1$\\sigma$\nuncertainty) in the past. Assuming this ejection was at the birth of the most\nmassive stars in NGC 2244, including the dominant centrally positioned HD46150,\nthe age is set for the famous ionised region at more than ten times that\nderived for the cavity. Here, we are able to reproduce the structure of the\nRosette Nebula, through simulation of mechanical stellar feedback from a\n40M$_{\\odot}$ star in a thin sheet-like molecular cloud. We form the\n135,000M$_{\\odot}$ cloud from thermally-unstable diffuse interstellar medium\nunder the influence of a realistic background magnetic field with\nthermal/magnetic pressure equilibrium. Properties derived from a snapshot of\nthe simulation at 1.5Myr, including cavity size, stellar age, magnetic field\nand resulting inclination to the line of sight, match those derived from\nobservations. An elegant explanation is thus provided for the stark contrast in\nage estimates based on realistic diffuse ISM properties, molecular cloud\nformation and stellar wind feedback.", "category": "astro-ph.GA"}, {"title": "Brightness temperatures of galactic masers observed in the RadioAstron project", "abstract": "We present estimates of brightness temperature for 5 galactic masers in\nstar-forming regions detected at space baselines. Very compact features with\nangular sizes of about 23-60 micro arcsec were detected in these regions with\ncorresponding linear sizes of about 4-10 million km. Brightness temperatures\nrange from 1e+14 up to 1e+16 K.", "category": "astro-ph.GA"}, {"title": "RadioAstron space-VLBI project: studies of masers in star forming regions of our Galaxy and megamasers in external galaxies", "abstract": "Observations of the masers in the course of RadioAstron mission yielded\ndetections of fringes for a number of sources in both water and hydroxyl maser\ntransitions. Several sources display numerous ultra-compact details. This\nproves that implementation of the space VLBI technique for maser studies is\npossible technically and is not always prevented by the interstellar\nscattering, maser beaming and other effects related to formation, transfer, and\ndetection of the cosmic maser emission. For the first time, cosmic water maser\nemission was detected with projected baselines exceeding Earth Diameter. It was\ndetected in a number of star-forming regions in the Galaxy and megamaser\ngalaxies NGC 4258 and NGC 3079. RadioAstron observations provided the absolute\nrecord of the angular resolution in astronomy. Fringes from the NGC 4258\nmegamaser were detected on baseline exceeding 25 Earth Diameters. This means\nthat the angular resolution sufficient to measure the parallax of the water\nmaser source in the nearby galaxy LMC was directly achieved in the cosmic maser\nobservations. Very compact features with angular sizes about 20 microarcsec\nhave been detected in star-forming regions of our Galaxy. Corresponding linear\nsizes are about 5-10 million kilometers. So, the major step from milli- to\nmicro-arcsecond resolution in maser studies is done in the RadioAstron mission.\nThe existence of the features with extremely small angular sizes is\nestablished. Further implementations of the space-VLBI maser instrument for\nstudies of the nature of cosmic objects, studies of the interaction of\nextremely high radiation field with molecular material and studies of the\nmatter on the line of sight are planned.", "category": "astro-ph.GA"}, {"title": "Study of diffuse HII regions potentially forming part of the gas streams around Sgr A*", "abstract": "We present a study of diffuse extended ionised gas toward three clouds\nlocated in the Galactic Centre (GC). One line of sight (LOS) is toward the 20\nkm s$^{-1}$ cloud (LOS$-$0.11) in the Sgr A region, another LOS is toward the\n50 km s$^{-1}$ cloud (LOS$-$0.02), also in Sgr A, while the third is toward the\nSgr B2 cloud (LOS+0.693). The emission from the ionised gas is detected from\nH$n\\alpha$ and H$m\\beta$ radio recombination lines (RRLs). He$n\\alpha$ and\nHe$m\\beta$ RRL emission is detected with the same $n$ and $m$ as those from the\nhydrogen RRLs only toward LOS+0.693. RRLs probe gas with positive and negative\nvelocities toward the two Sgr A sources. The H$m\\beta$ to H$n\\alpha$ ratios\nreveal that the ionised gas is emitted under local thermodynamic equilibrium\nconditions in these regions. We find a He to H mass fraction of 0.29$\\pm$0.01\nconsistent with the typical GC value, supporting the idea that massive stars\nhave increased the He abundance compared to its primordial value. Physical\nproperties are derived for the studied sources. We propose that the negative\nvelocity component of both Sgr A sources is part of gas streams considered\npreviously to model the GC cloud kinematics. Associated massive stars with what\nare presumably the closest HII regions to LOS$-$0.11 (positive velocity gas),\nLOS$-$0.02 and LOS+0.693 could be the main sources of UV photons ionising the\ngas. The negative velocity components of both Sgr A sources might be ionised by\nthe same massive stars, but only if they are in the same gas stream.", "category": "astro-ph.GA"}, {"title": "The JWST Extragalactic Mock Catalog: Modeling galaxy populations from the UV through the near-IR over thirteen billion years of cosmic history", "abstract": "We present an original phenomenological model to describe the evolution of\ngalaxy number counts, morphologies, and spectral energy distributions across a\nwide range of redshifts (0.2<z<15) and stellar masses [Log10 M/Msun >6]. Our\nmodel follows observed mass and luminosity functions of both star-forming and\nquiescent galaxies, and reproduces the redshift evolution of colors, sizes,\nstar-formation and chemical properties of the observed galaxy population.\nUnlike other existing approaches, our model includes a self-consistent\ntreatment of stellar and photoionized gas emission and dust attenuation based\non the BEAGLE tool. The mock galaxy catalogs generated with our new model can\nbe used to simulate and optimize extragalactic surveys with future facilities\nsuch as the James Webb Space Telescope (JWST), and to enable critical\nassessments of analysis procedures, interpretation tools, and measurement\nsystematics for both photometric and spectroscopic data. As a first application\nof this work, we make predictions for the upcoming JWST Advanced Deep\nExtragalactic Survey (JADES), a joint program of the JWST/NIRCam and NIRSpec\nGuaranteed Time Observations teams. We show that JADES will detect, with NIRCam\nimaging, thousands of galaxies at z>6, and tens at z>10 at m_AB<30 (5-sigma)\nwithin the 236 arcmin^2 of the survey. The JADES data will enable accurate\nconstraints on the evolution of the UV luminosity function at z>8, and resolve\nthe current debate about the rate of evolution of galaxies at z>8. Ready to use\nmock catalogs and software to generate new realizations are publicly available\nas the JAdes extraGalactic Ultradeep Artificial Realizations (JAGUAR) package.", "category": "astro-ph.GA"}, {"title": "Gemini Follow-up of two massive HI clouds discovered with the Australian Square Kilometer Array Pathfinder", "abstract": "Using the Gemini Multi Object Spectrograph (GMOS) we search for optical\ncounterparts of two massive (~10^9 solar masses) neutral hydrogen clouds near\nthe spiral galaxy IC 5270, located in the outskirts of the IC 1459 group. These\ntwo HI clouds were recently discovered using the Australian Square Kilometer\nArray Pathfinder (ASKAP). Two low surface brightness optical counterparts to\none of these HI clouds are identified in the new Gemini data that reaches down\nto magnitudes of ~27.5 mag in the g-band. The observed HI mass to light ratio\nderived with these new data, M_(HI)/L_g =242, is among the highest reported to\ndate. We are also able to rule out that the two HI clouds are dwarf companions\nof IC 5270. Tidal interactions and ram pressure stripping are plausible\nexplanations for the physical origin of these two clouds.", "category": "astro-ph.GA"}, {"title": "The properties of Planck Galactic cold clumps in the L1495 dark cloud", "abstract": "Planck Galactic Cold Clumps (PGCCs) possibly represent the early stages of\nstar formation. To understand better the properties of PGCCs, we studied 16\nPGCCs in the L1495 cloud with molecular lines and continuum data from Herschel,\nJCMT/SCUBA-2 and the PMO 13.7 m telescope. Thirty dense cores were identified\nin 16 PGCCs from 2-D Gaussian fitting. The dense cores have dust temperatures\nof $T_{\\rm d}$ = 11-14 K, and H$_{2}$ column densities of $N_{\\rm H_{2}}$ =\n0.36-2.5$\\times10^{22}$ cm$^{-2}$. We found that not all PGCCs contain\nprestellar objects. In general, the dense cores in PGCCs are usually at their\nearliest evolutionary stages. All the dense cores have non-thermal velocity\ndispersions larger than the thermal velocity dispersions from molecular line\ndata, suggesting that the dense cores may be turbulence-dominated. We have\ncalculated the virial parameter $\\alpha$ and found that 14 of the dense cores\nhave $\\alpha$ $<$ 2, while 16 of the dense cores have $\\alpha$ $>$ 2. This\nsuggests that some of the dense cores are not bound in the absence of external\npressure and magnetic fields. The column density profiles of dense cores were\nfitted. The sizes of the flat regions and core radii decrease with the\nevolution of dense cores. CO depletion was found to occur in all the dense\ncores, but is more significant in prestellar core candidates than in\nprotostellar or starless cores. The protostellar cores inside the PGCCs are\nstill at a very early evolutionary stage, sharing similar physical and chemical\nproperties with the prestellar core candidates.", "category": "astro-ph.GA"}, {"title": "Metallicity Distribution of Disk Stars and the Formation History of the Milky Way", "abstract": "We investigate the formation history of the stellar disk component in the\nMilky Way (MW) based on our new chemical evolution model. Our model considers\nseveral fundamental baryonic processes, including gas infall, re-accretion of\noutflowing gas, and radial migration of disk stars. Each of these baryonic\nprocesses in the disk evolution is characterized by model parameters, which are\ndetermined by fitting to various observational data of the stellar disk in the\nMW, including the radial dependence of the metallicity distribution function\n(MDF) of the disk stars, which has recently been derived in the APOGEE survey.\nWe succeeded to obtain the best set of model parameters, which well reproduces\nthe observed radial dependences of the mean, standard deviation, skewness, and\nkurtosis of the MDFs for the disk stars. We analyze the basic properties of our\nmodel results in detail to get new insights into the important baryonic\nprocesses in the formation history of the MW. One of the remarkable findings is\nthat outflowing gas, containing much heavy elements, preferentially re-accretes\nonto the outer disk parts, and this recycling process of metal-enriched gas is\na key ingredient to reproduce the observed narrower MDFs at larger radii.\nMoreover, important implications for the radial dependence of gas infall and\nthe influence of radial migration on the MDFs are also inferred from our model\ncalculation. Thus, the MDF of disk stars is a useful clue for studying the\nformation history of the MW.", "category": "astro-ph.GA"}, {"title": "The Next Generation Virgo Cluster Survey (NGVS). XVIII. Measurement and Calibration of Surface Brightness Fluctuation Distances for Bright Galaxies in Virgo (and Beyond)", "abstract": "We describe a program to measure surface brightness fluctuation (SBF)\ndistances to galaxies observed in the Next Generation Virgo Cluster Survey\n(NGVS), a photometric imaging survey covering $104~deg^2$ of the Virgo cluster\nin the ${u}^*,g,i,z$ bandpasses with the Canada-France Hawaii Telescope. We\ndescribe the selection of the sample galaxies, the procedures for measuring the\napparent $i$-band SBF magnitude $\\bar{i}$, and the calibration of the absolute\n$\\bar{M}_i$ as a function of observed stellar population properties. The\nmulti-band NGVS data set provides multiple options for calibrating the SBF\ndistances, and we explore various calibrations involving individual color\nindices as well as combinations of two different colors. Within the color range\nof the present sample, the two-color calibrations do not significantly improve\nthe scatter with respect to wide-baseline, single-color calibrations involving\n$u^{*}$. We adopt the ${u}^*{-}z$ calibration as reference for the present\ngalaxy sample, with an observed scatter of 0.11 mag. For a few cases that lack\ngood ${u}^*$ photometry, we use an alternative relation based on a combination\nof $g{-}i$ and $g{-}z$ colors, with only a slightly larger observed scatter of\n0.12 mag. The agreement of our measurements with the best existing distance\nestimates provides confidence that our measurements are accurate. We present a\npreliminary catalog of distances for 89 galaxies brighter than $B_T\\approx13.0$\nmag within the survey footprint, including members of the background M and W\nClouds at roughly twice the distance of the main body of the Virgo cluster. The\nextension of the present work to fainter and bluer galaxies is in progress.", "category": "astro-ph.GA"}, {"title": "A main sequence for quasars", "abstract": "The last 25 years saw a major step forward in the analysis of optical and UV\nspectroscopic data of large quasar samples. Multivariate statistical approaches\nhave led to the definition of systematic trends in observational properties\nthat are the basis of physical and dynamical modeling of quasar structure. We\ndiscuss the empirical correlates of the so-called \"main sequence\" associated\nwith the quasar Eigenvector 1, its governing physical parameters and several\nimplications on our view of the quasar structure, as well as some luminosity\neffects associated with the virialized component of the line emitting regions.\nWe also briefly discuss quasars in a segment of the main sequence that includes\nthe strongest FeII emitters. These sources show a small dispersion around a\nwell-defined Eddington ratio value, a property which makes them potential\nEddington standard candles.", "category": "astro-ph.GA"}, {"title": "The 500 ks Chandra observation of the z = 6.31 QSO SDSS J1030+0524", "abstract": "We present the results from a $\\sim500$ ks Chandra observation of the\n$z=6.31$ QSO SDSS J1030+0524. This is the deepest X-ray observation to date of\na $z\\sim6$ QSO. The QSO is detected with a total of 125 net counts in the full\n($0.5-7$ keV) band and its spectrum can be modeled by a single power-law model\nwith photon index of $\\Gamma = 1.81 \\pm 0.18$ and full band flux of\n$f=3.95\\times 10^{-15}$ erg s$^{-1}$ cm$^{-2}$. When compared with the data\nobtained by XMM-Newton in 2003, our Chandra observation in 2017 shows a harder\n($\\Delta \\Gamma \\approx -0.6$) spectrum and a 2.5 times fainter flux. Such a\nvariation, in a timespan of $\\sim2$ yrs rest-frame, is unexpected for such a\nluminous QSO powered by a $> 10^9 \\: M_{\\odot}$ black hole. The observed source\nhardening and weakening could be related to an intrinsic variation in the\naccretion rate. However, the limited photon statistics does not allow us to\ndiscriminate between an intrinsic luminosity and spectral change, and an\nabsorption event produced by an intervening gas cloud along the line of sight.\nWe also report the discovery of diffuse X-ray emission that extends for 30\"x20\"\nsouthward the QSO with a signal-to-noise ratio of $\\sim$6, hardness ratio of\n$HR=0.03_{-0.25}^{+0.20}$, and soft band flux of $f_{0.5-2 \\: keV}=\n1.1_{-0.3}^{+0.3} \\times 10^{-15}$ erg s$^{-1}$ cm$^{-2}$, that is not\nassociated to a group or cluster of galaxies. We discuss two possible\nexplanations for the extended emission, which may be either associated with the\nradio lobe of a nearby, foreground radio galaxy (at $z \\approx 1-2$), or\nascribed to the feedback from the QSO itself acting on its surrounding\nenvironment, as proposed by simulations of early black hole formation.", "category": "astro-ph.GA"}, {"title": "Alone on a wide wide sea. The origin of SECCO 1, an isolated star-forming gas cloud in the Virgo cluster", "abstract": "SECCO1 is an extremely dark, low-mass (M_star=10^5 M_sun), star-forming\nstellar system lying in the Low Velocity Cloud (LVC) substructure of the Virgo\ncluster of galaxies, and hosting several HII regions. Here we review our\nknowledge of this remarkable system, and present the results of (a) additional\nanalysis of our panoramic spectroscopic observations with MUSE, (b) the\ncombined analysis of Hubble Space Telescope and MUSE data, and (c) new\nnarrow-band observations obtained with OSIRIS@GTC to search for additional HII\nregions in the surroundings of the system. We provide new evidence supporting\nan age as young as 4 Myr for the stars that are currently ionising the gas in\nSECCO1. We identify only one new promising candidate HII region possibly\nassociated with SECCO1, thus confirming the extreme isolation of the system. We\nalso identify three additional candidate pressure-supported dark clouds in\nVirgo among the targets of the SECCO survey. Various possible hypotheses for\nthe nature and origin of SECCO1 are considered and discussed, also with the\nhelp of dedicated hydrodynamical simulations showing that a hydrogen cloud with\nthe characteristics of SECCO1 can likely survive for >1 Gyr while traveling\nwithin the LVC Intra Cluster Medium.", "category": "astro-ph.GA"}, {"title": "Obscured star-formation in bright z ~ 7 Lyman-break galaxies", "abstract": "We present Atacama Large Millimeter/Submillimeter Array observations of the\nrest-frame far-infrared (FIR) dust continuum emission of six bright Lyman-break\ngalaxies (LBGs) at $z \\simeq 7$. One LBG is detected ($5.2\\sigma$ at peak\nemission), while the others remain individually undetected at the $3\\sigma$\nlevel. The average FIR luminosity of the sample is found to be $L_{\\rm FIR}\n\\simeq 2 \\times 10^{11}\\,{\\rm L}_{\\odot}$, corresponding to an obscured\nstar-formation rate (SFR) that is comparable to that inferred from the\nunobscured UV emission. In comparison to the infrared excess (IRX$\\,=L_{\\rm\nFIR}/L_{\\rm UV}$)-$\\beta$ relation, our results are consistent with a\nCalzetti-like attenuation law (assuming a dust temperature of T = 40-50 K). We\nfind a physical offset of 3 kpc between the dust continuum emission and the\nrest-frame UV light probed by Hubble Space Telescope imaging for galaxy ID65666\nat $z = 7.17^{+0.09}_{-0.06}$. The offset is suggestive of an inhomogeneous\ndust distribution, where 75% of the total star formation activity (SFR$\n\\,\\simeq 70\\,{\\rm M}_{\\odot}/{\\rm yr}$) of the galaxy is completely obscured.\nOur results provide direct evidence that dust obscuration plays a key role in\nshaping the bright-end of the observed rest-frame UV luminosity function at $z\n\\simeq 7$, in agreement with cosmological galaxy formation simulations. The\nexistence of a heavily-obscured component of galaxy ID65666 indicates that\ndusty star-forming regions, or even entire galaxies, that are \"UV-dark\" are\nsignificant even in the $z \\simeq 7$ galaxy population.", "category": "astro-ph.GA"}, {"title": "Subaru High-z Exploration of Low-Luminosity Quasars (SHELLQs) III. Star formation properties of the host galaxies at $z \\gtrsim 6$ studied with ALMA", "abstract": "We present our ALMA Cycle 4 measurements of the [CII] emission line and the\nunderlying far-infrared (FIR) continuum emission from four optically\nlow-luminosity ($M_{\\rm 1450} > -25$) quasars at $z \\gtrsim 6$ discovered by\nthe Subaru Hyper Suprime Cam (HSC) survey. The [CII] line and FIR continuum\nluminosities lie in the ranges $L_{\\rm [CII]} = (3.8-10.2) \\times 10^8~L_\\odot$\nand $L_{\\rm FIR} = (1.2-2.0) \\times 10^{11}~L_\\odot$, which are at least one\norder of magnitude smaller than those of optically-luminous quasars at $z\n\\gtrsim 6$. We estimate the star formation rates (SFR) of our targets as\n$\\simeq 23-40~M_\\odot ~{\\rm yr}^{-1}$. Their line and continuum-emitting\nregions are marginally resolved, and found to be comparable in size to those of\noptically luminous quasars, indicating that their SFR or likely gas mass\nsurface densities (key controlling parameter of mass accretion) are accordingly\ndifferent. The $L_{\\rm [CII]}/L_{\\rm FIR}$ ratios of the hosts, $\\simeq\n(2.2-8.7) \\times 10^{-3}$, are fully consistent with local star-forming\ngalaxies. Using the [CII] dynamics, we derived their dynamical masses within a\nradius of 1.5-2.5 kpc as $\\simeq (1.4-8.2) \\times 10^{10}~M_\\odot$. By\ninterpreting these masses as stellar ones, we suggest that these faint quasar\nhosts are on or even below the star-forming main sequence at $z \\sim 6$, i.e.,\nthey appear to be transforming into quiescent galaxies. This is in contrast to\nthe optically luminous quasars at those redshifts, which show starburst-like\nproperties. Finally, we find that the ratios of black hole mass to host galaxy\ndynamical mass of the most of low-luminosity quasars including the HSC ones are\nconsistent with the local value. The mass ratios of the HSC quasars can be\nreproduced by a semi-analytical model that assumes merger-induced black\nhole-host galaxy evolution.", "category": "astro-ph.GA"}, {"title": "Photoemission Investigation of Oxygen Intercalated Epitaxial Graphene on Ru(0001)", "abstract": "We study the formation of epitaxial graphene on Ru(0001) using fast x-ray\nphotoelectron spectroscopy during the growth process. The assignment of\ndifferent C 1s and Ru 3d core level components and their evolution during the\ngrowth process gives a detailed insight into the graphene formation and the\nstrongly varying graphene-Ru interaction strength within the large moire unit\ncell. Subsequent intercalation of oxygen can be achieved at elevated\ntemperature and the core level spectra show a conversion of the strongly\ncorrugated to quasi free-standing graphene, characterised by a single narrow C\n1s component. This conversion and the accompanying flattening of the graphene\nlayer is also confirmed by x-ray photoelectron diffraction. The effect of\noxygen intercalation on the electronic structure is studied using\nangle-resolved photoemission of the valence band states. For graphene/Ru(0001),\nthe strong graphene-substrate hybridisation disrupts the {\\pi}-band dispersion\nbut oxygen intercalation fully restores the {\\pi}-band with a strong p-doping\nthat shifts the Dirac point 785 meV above the Fermi level. The doping of the\nsystem is highly tunable, as the additional exposure to rubidium can convert\nthe carrier filling to n-type with the Dirac point 970 meV below the Fermi\nlevel.", "category": "cond-mat.mtrl-sci"}, {"title": "Cubic anisotropy in high homogeneity thin (Ga,Mn)As layers", "abstract": "Historically, comprehensive studies of dilute ferromagnetic semiconductors,\ne.g., $p$-type (Cd,Mn)Te and (Ga,Mn)As, paved the way for a quantitative\ntheoretical description of effects associated with spin-orbit interactions in\nsolids, such as crystalline magnetic anisotropy. In particular, the theory was\nsuccessful in explaining {\\em uniaxial} magnetic anisotropies associated with\nbiaxial strain and non-random formation of magnetic dimers in epitaxial\n(Ga,Mn)As layers. However, the situation appears much less settled in the case\nof the {\\em cubic} term: the theory predicts switchings of the easy axis\nbetween in-plane $\\langle 100\\rangle$ and $\\langle 110\\rangle$ directions as a\nfunction of the hole concentration, whereas only the $\\langle 100\\rangle$\norientation has been found experimentally. Here, we report on the observation\nof such switchings by magnetization and ferromagnetic resonance studies on a\nseries of high-crystalline quality (Ga,Mn)As films. We describe our findings by\nthe mean-field $p$-$d$ Zener model augmented with three new ingredients. The\nfirst one is a scattering broadening of the hole density of states, which\nreduces significantly the amplitude of the alternating carrier-induced\ncontribution. This opens the way for the two other ingredients, namely the\nso-far disregarded single-ion magnetic anisotropy and disorder-driven\nnon-uniformities of the carrier density, both favoring the $\\langle 100\\rangle$\ndirection of the apparent easy axis. However, according to our results, when\nthe disorder gets reduced a switching to the $\\langle 110\\rangle$ orientation\nis possible in a certain temperature and hole concentration range.", "category": "cond-mat.mtrl-sci"}, {"title": "Wavelength-dependent reflectivity changes on gold at elevated electronic temperatures", "abstract": "Upon the excitation by an ultrashort laser pulse the conditions in a material\ncan drastically change, altering its optical properties and therefore the\nrelative amount of absorbed energy, a quan- tity relevant for determining the\ndamage threshold and for developing a detailed simulation of a structuring\nprocess. The subject of interest in this work is the d-band metal gold which\nhas an absorption edge marking the transition of free valence electrons and an\nabsorbing deep d-band with bound electrons. Reflectivity changes are observed\nin experiment over a broad spectral range at ablation conditions. To understand\nthe involved processes the laser excitation is modeled by a com- bination of\nfirst principle calculations with a two-temperature model. The description is\nkept most general and applied to realistically simulate the transfer of the\nabsorbed energy of a Gaussian laser pulse into the electronic system at every\npoint in space at every instance of time. An electronic temperature-dependent\nreflectivity map is calculated, describing the out of equilibrium reflectivity\nduring laser excitation for photon energies from 0.9 - 6.4 eV, including inter-\nand intra-band transi- tions and a temperature-dependent damping factor. The\nmain mechanisms are identified explaining the electronic temperature-dependent\nchange in reflectivity: broadening of the edge of the occu- pied/unoccupied\nstates around the chemical potential $\\mu$, also leading to a shift of the\n$\\mu$ and an increase of the collision rate of free s/p-band electrons with\nbound d-band holes.", "category": "cond-mat.mtrl-sci"}, {"title": "Investigation of La and Al substitution on the spontaneous polarization and lattice dynamics of the Pb(1-x)LaxTi(1-x)AlxO3 ceramics", "abstract": "The phase purity and crystal structure of PLTA samples (synthesized via\nsol-gel process) were confirmed using synchrotron x-ray powder diffraction\n(wavelength, lmbda= 0.44573 A. Rietveld analyses of powder x-ray diffraction\ndata confirmed the tetragonal structure for compositions with more than 0.18\nand cubic structure for the sample with 0.25 composition. Temperature-dependent\nXRD was performed to investigate the structural change from tetragonal to cubic\nstructure phase transition. Raman spectroscopy at room temperature also\nconfirmed this phase transition with composition. Field emission scanning\nelectron provided information about surface morphology while an energy\ndispersive x-ray spectrometer attached with FESEM confirmed the chemical\ncompositions of samples. Temperature and frequency dependent dielectric studies\nshowed that the tetragonal to cubic phase transition decreased from 680 K to\n175 K with the increase in the x from 0.03 to 0.25, respectively. This is\ncorrelated with the structural studies. Electric field dependent spontaneous\npolarization showed proper ferroelectric loop for 0.06 to 0.18 belonging to a\ntetragonal phase while after 0.25 composition the spontaneous polarization\nvanishes.Bipolar strain versus electric field revealed a butterfly loop for\n0.06 to 0.18 compositions. Energy storage efficiency initially increases\nnominally with substitution but beyond 0.18 composition enhances considerably.", "category": "cond-mat.mtrl-sci"}, {"title": "Direct observation of electron thermalization and electron-phonon coupling in photoexcited bismuth", "abstract": "We investigate the ultrafast response of the bismuth (111) surface by means\nof time resolved photoemission spectroscopy. The direct visualization of the\nelectronic structure allows us to gain insights on electron-electron and\nelectron-phonon interaction. Concerning electron-electron interaction, it is\nfound that electron thermalization is fluence dependent and can take as much as\nseveral hundreds of femtoseconds at low fluences. This behavior is in\nqualitative agreement with Landau's theory of Fermi liquids but the data show\ndeviations from the behavior of a common 3D degenerate electron gas. Concerning\nelectron-phonon interaction, our data allows us to directly observe the\ncoupling of individual Bloch state to the coherent $A_{1g}$ mode. It is found\nthat surface states are much less coupled to this mode when compared to bulk\nstates. This is confirmed by \\textit{ab initio} calculations of surface and\nbulk bismuth.", "category": "cond-mat.mtrl-sci"}, {"title": "Momentum-space and real-space Berry curvatures in Mn$_{3}$Sn", "abstract": "Mn$_{3}$X (X= Sn, Ge) are noncollinear antiferromagnets hosting a large\nanomalous Hall effect (AHE). Weyl nodes in the electronic dispersions are\nbelieved to cause this AHE, but their locus in the momentum space is yet to be\npinned down. We present a detailed study of the Hall conductivity tensor and\nmagnetization in Mn$_{3}$Sn crystals and find that in the presence of a\nmoderate magnetic field, spin texture sets the orientation of the $k$-space\nBerry curvature with no detectable in-plane anisotropy due to the $Z_6$\nsymmetry of the underlying lattice. We quantify the energy cost of domain\nnucleation and show that the multidomain regime is restricted to a narrow field\nwindow. Comparing the field dependence of AHE and magnetization, we find that\nthere is a distinct component in the AHE which does not scale with\nmagnetization when the domain walls are erected. This so-called `topological'\nHall effect provides indirect evidence for a non-coplanar spin components and\nreal-space Berry curvature in domain walls.", "category": "cond-mat.mtrl-sci"}, {"title": "Topological Weyl semimetals in $\\rm Bi$$_{1-x}$$\\rm Sb$$_{x}$ alloys", "abstract": "We have investigated the Weyl semimetal (WSM) phases in bismuth antimony\n($\\rm Bi$$_{1-x}$$\\rm Sb$$_{x}$) alloys by the combination of atomic\ncomposition and arrangement. Via first principles calculations, we have found\ntwo WSM states with the Sb concentration of $x=0.5$ and $x=0.83$ with specific\ninversion symmetry broken elemental arrangement. The Weyl points are close to\nthe Fermi level in both of these two WSM states. Therefore, it has a good\nopportunity to obtain Weyl points in Bi-Sb alloy. The WSM phase provides a\nreasonable explanation for the current transport study of BiSb alloy with the\nviolation of Ohm's law [Dongwoo Shin, et al., Nature Materials 16, 1096\n(2017)]. This work shows that the topological phases in Bi-Sb alloys depend on\nboth elemental composition and their specific arrangement.", "category": "cond-mat.mtrl-sci"}, {"title": "Metastable rocksalt ZnO is $p$-type dopable", "abstract": "Despite decades of efforts, achieving $p$-type conductivity in the wide band\ngap ZnO in its ground-state wurtzite structure continues to be a challenge.\nHere we detail how $p$-type ZnO can be realized in the metastable,\nhigh-pressure rocksalt phase (also wide-gap) with Li as an external dopant.\nUsing modern first-principles defect theory, we predict Li to dope the rocksalt\nphase $p$-type by preferentially substituting for Zn and introducing shallow\nacceptor levels. Formation of compensating donors like interstitial Li and/or\nhydrogen, ubiqutous in the wurtzite phase, is inhibited by the close-packed\nnature of the rocksalt structure, which also exhibits relatively high absolute\nvalence band edge that promotes low hole effective mass and hole\ndelocalization. Resulting concentrations of free holes are predicted to exceed\n$\\sim10^{19}$ cm$^{-3}$ under O-rich synthesis conditions while under O-poor\nconditions the system remains $n$-type dopable. In addition to revealing\ncompelling opportunities offered by the metastable rocksalt structure in\nrealizing a long-sought $p$-type ZnO our results present polymorphism as a\npromising route to overcoming strong doping asymmetry of wide-band gap oxides.", "category": "cond-mat.mtrl-sci"}, {"title": "Tuning the magnetodynamic properties of all-perpendicular spin valves using He+ irradiation", "abstract": "Using He+ ion irradiation, we demonstrate how the magnetodynamic properties\nof both ferromagnetic layers in all-perpendicular [Co/Pd]/Cu/[Co/Ni] spin\nvalves can be tuned by varying the He+ ion fluence. As the perpendicular\nmagnetic anisotropy of both layers is gradually reduced by the irradiation,\ndifferent magnetic configurations can be achieved from all-perpendicular,\nthrough orthogonal, to all in-plane. In addition, both the magnetic damping and\nthe inhomogeneous broadening of the Co/Ni layer improve substantially with\nincreasing fluence. GMR of the spin valve is negatively affected and decreases\nlinearly from an original value of 1.14% to 0.4% at the maximum fluence of\n50*10^14 He+/cm^2.", "category": "cond-mat.mtrl-sci"}, {"title": "Magneto-transport properties of proposed triply degenerate topological semimetal Pd$_{3}$Bi$_{2}$S$_{2}$", "abstract": "We report transport properties of single-crystalline Pd$_{3}$Bi$_{2}$S$_{2}$,\nwhich has been predicted to host an unconventional electronic phase of matter\nbeyond three-dimensional Dirac and Weyl semimetals. Similar to several\ntopological systems, the resistivity shows field induced\nmetal-semiconductor-like crossover at low temperature. Large, anisotropic and\nnon-saturating magnetoresistance (MR) has been observed in transverse\nexperimental configuration. At 2 K and 9 T, the MR value reaches as high as\n$\\sim$1.1$\\times$10$^{3}$ \\%. Hall resistivity reveals the presence of two\ntypes of charge carriers and has been analyzed using two-band model. In spite\nof the large density ($>$ 10$^{21}$ cm$^{-3}$), the mobility of charge carriers\nis found to be quite high ($\\sim$ 0.75$\\times$10$^{4}$ cm$^{2}$ V$^{-1}$\ns$^{-1}$ for hole and $\\sim$ 0.3$\\times$10$^{4}$ cm$^{2}$ V$^{-1}$ s$^{-1}$ for\nelectron). The observed magneto-electrical properties indicate that\nPd$_{3}$Bi$_{2}$S$_{2}$ may be a new member of the topological semimetal\nfamily, which can have a significant impact in technological applications.", "category": "cond-mat.mtrl-sci"}, {"title": "Etching of Photon Energy into Binding Energy in Depositing Carbon Films at Different Chamber Pressures", "abstract": "A hot filament chemical vapor deposition is an attractive technique to\ndeposit carbon films of different applications. In this technique, it is also\nfeasible to study the influence of chamber pressure in the deposition of carbon\nfilms. In the deposition chamber, having dissociated from the methane\nprecursor, gaseous carbon atoms first convert into the graphite state atoms and\nthen into the diamond state atoms. An increase in the chamber pressure changes\nthe morphology and structure of the deposited carbon films. The growth rate of\nthe deposited carbon film increases by increasing the chamber pressure from 3.3\nkPa to 8.6 kPa. The rate of converting gaseous carbon atoms into diamond atoms\nalso increases. At 11.3 kPa and 14 kPa chamber pressure, gaseous carbon atoms\nconvert into graphite state atoms at a high rate. The gas activation and gas\ncollision processes vary broadly at varying chamber pressure. The morphology\nand structure of carbon films got deposited at different growth rates. The\ndissociation of molecular hydrogen into atomic hydrogen varies by varying the\nchamber pressure. Atomic hydrogen etched the photons released from the hot\nfilaments. Thus, bits of differently shaped energy result. Gaseous carbon atoms\nconvert into graphite and diamond state atoms under suitably shaped bits of\nenergy. Graphite state atoms bind under the same involved bits, which is not\nthe case when the diamond state atoms bind. The study sets a new trend in\ndepositing, characterizing, and analyzing carbon films.", "category": "cond-mat.mtrl-sci"}, {"title": "Energetics of oxygen-octahedra rotations in perovskite oxides from first principles", "abstract": "We use first-principles methods to study oxygen-octahedra rotations in ABO3\nperovskite oxides. We focus on the short-period, perfectly antiphase or\nin-phase, tilt patterns that characterize most compounds and control their\nphysical (e.g., conductive, magnetic) properties. Based on an analytical form\nof the relevant potential energy surface, we discuss the conditions for the\nstability of polymorphs presenting different tilt patterns, and obtain\nnumerical results for a collection of thirty-five representative materials. Our\nresults reveal the mechanisms responsible for the frequent occurrence of a\nparticular structure that combines antiphase and in-phase rotations, i.e., the\northorhombic Pbnm phase displayed by about half of all perovskite oxides and by\nmany non-oxidic perovskites. The Pbnm phase benefits from the simultaneous\noccurrence of antiphase and in-phase tilt patterns that compete with each\nother, but not as strongly as to be mutually exclusive. We also find that\nsecondary antipolar modes, involving the A cations, contribute to weaken the\ncompetition between different tilts and play a key role in their coexistence.\nOur results thus confirm and better explain previous observations for\nparticular compounds. Interestingly, we also find that strain effects, which\nare known to be a major factor governing phase competition in related (e.g.,\nferroelectric) perovskite oxides, play no essential role as regards the\nrelative stability of different rotational polymorphs. Further, we discuss why\nthe Pbnm structure stops being the ground state in two opposite limits, for\nlarge and small A cations, showing that very different effects become relevant\nin each case. Our work thus provides a comprehensive discussion on these\nall-important and abundant materials, which will be useful to better understand\nexisting compounds as well as to identify new strategies for materials\nengineering.", "category": "cond-mat.mtrl-sci"}, {"title": "Separation of Charge Instability and Lattice Symmetry Breaking in an Organic Ferroelectric", "abstract": "We investigate the charge and lattice states in a quasi-one-dimensional\norganic ferroelectric material, TTF-QCl$_{4}$, under pressures of up to 35 kbar\nby nuclear quadrupole resonance experiments. The results reveal a global\npressure-temperature phase diagram, which spans the electronic and ionic\nregimes of ferroelectric transitions, which have so far been studied\nseparately, in a single material. The revealed phase diagram clearly shows that\nthe charge-transfer instability and the lattice symmetry breaking, which\ncoincide in the electronic ferroelectric regime at low pressures, bifurcate at\na certain pressure, leading to the conventional ferroelectric regime. The\npresent results reveal that the crossover from electronic to ionic\nferroelectricity occurs through the separation of charge and lattice\ninstabilities.", "category": "cond-mat.mtrl-sci"}, {"title": "Temperature-dependent magnetic properties of a magnetoactive elastomer: immobilization of the soft-magnetic filler", "abstract": "Magnetic properties of a magnetoactive elastomer (MAE) filled with\n{\\mu}m-sized soft-magnetic iron particles have been experimentally studied in\nthe temperature range between 150 K and 310 K. By changing the temperature, the\nelastic modulus of the elastomer matrix was modified and it was possible to\nobtain magnetization curves for an invariable arrangement of particles in the\nsample as well as in the case when the particles were able to change their\nposition within the MAE under the influence of magnetic forces. At low (less\nthan 220 K) temperatures, when the matrix becomes rigid, the magnetization of\nthe MAE does not show a hysteresis behavior and it is characterized by a\nnegative value of the Rayleigh constant. At room temperature, when the polymer\nmatrix is compliant, a magnetic hysteresis exists and exhibits local maxima of\nthe field dependence of the differential magnetic susceptibility. The\nappearance of these maxima is explained by the elastic resistance of the matrix\nto the displacement of particles under the action of magnetic forces.", "category": "cond-mat.mtrl-sci"}, {"title": "Structural, elastic, optoelectronic and transport properties of Sr3SnO under pressure", "abstract": "We have presented the structural, elastic, optoelectronic and transport\nproperties of Sr3SnO under pressure by using first principles method. The\napplication of hydrostatic pressure causes charge transfer from Sr(5s) orbital\nto Sn(5p) and O(2p) orbitals. The increasing trend of Pughs ratio under\npressure implies that the material tends to be ductile at high pressure. The\nsemiconductor-metal transition occurs at 14 GPa and the density of states at\nthe Fermi level is significantly increased at this pressure. The refractive\nindex, optical conductivity, and absorption of Sr3SnO have been found to be\nhigh and comparable to that for typical materials used in photovoltaic. The\nmaterial becomes n-type from 12 GPa and Hall coefficient also confirm it. Large\nSeebeck coefficient obtained at 12 GPa. Thus, Sr3SnO is a potential\nthermoelectric material possessing both p- and n-type nature. The detail\nphysics of these changes under pressure has been explained within the available\ntheory.", "category": "cond-mat.mtrl-sci"}, {"title": "Electronic Transport in Two-Dimensional Materials", "abstract": "Two-dimensional (2D) materials have captured the attention of the scientific\ncommunity due to the wide range of unique properties at nanometer-scale\nthicknesses. While significant exploratory research in 2D materials has been\nachieved, the understanding of 2D electronic transport and carrier dynamics\nremains in a nascent stage. Furthermore, since prior review articles have\nprovided general overviews of 2D materials or specifically focused on charge\ntransport in graphene, here we instead highlight charge transport mechanisms in\npost-graphene 2D materials with particular emphasis on transition metal\ndichalcogenides and black phosphorus. For these systems, we delineate the\nintricacies of electronic transport including bandstructure control with\nthickness and external fields, valley polarization, scattering mechanisms,\nelectrical contacts, and doping. In addition, electronic interactions between\n2D materials are considered in the form of van der Waals heterojunctions and\ncomposite films. This review concludes with a perspective on the most promising\nfuture directions in this fast-evolving field.", "category": "cond-mat.mtrl-sci"}, {"title": "A Parameter Free Double Shear Theory for Lath Martensite", "abstract": "A double shear theory is introduced that predicts the commonly observed {5 5\n7} habit planes in low-carbon steels. The novelty of this theory is that no\nparameter fitting is necessary. Instead, the shearing systems are chosen in\nanalogy to the original (single shear) phenomenological theory of martensite\ncrystallography as those that are macroscopically equivalent to twinning. Out\nof all the resulting double shear theories, the ones leading to certain {h h k}\nhabit planes naturally arise as those having small shape strain magnitude and\nsatisfying a condition of maximal compatibility, thus making any parameter\nfitting unnecessary. An interesting finding is that the precise coordinates of\nthe predicted {h h k} habit planes depend sensitively on the lattice parameters\nof the fcc (face-centered cubic) and bcc (body-centered cubic) phases.\nNonetheless, for various realistic lattice parameters in low carbon steels, the\npredicted habit planes are near {5 5 7}. The examples of Fe-0.252C and Fe-0.6C\nare analyzed in detail along with the resulting orientation relationships which\nare consistently close to the Kurdjumov-Sachs model. Furthermore, a MATLAB app\n(available at github.com/AntonMu/LathApp) is provided which allows the\napplication of this model to any other material undergoing an fcc to bcc\ntransformation.", "category": "cond-mat.mtrl-sci"}, {"title": "Observation of Topologically Protected States at Crystalline Phase Boundaries in Single-layer WSe2", "abstract": "Transition metal dichalcogenide (TMD) materials are unique in the wide\nvariety of structural and electronic phases they exhibit in the two-dimensional\n(2D) single-layer limit. Here we show how such polymorphic flexibility can be\nused to achieve topological states at highly ordered phase boundaries in a new\nquantum spin Hall insulator (QSHI), 1T'-WSe2. We observe helical states at the\ncrystallographically-aligned interface between quantum a spin Hall insulating\ndomain of 1T'-WSe2 and a semiconducting domain of 1H-WSe2 in contiguous single\nlayers grown using molecular beam epitaxy (MBE). The QSHI nature of\nsingle-layer 1T'-WSe2 was verified using ARPES to determine band inversion\naround a 120 meV energy gap, as well as STM spectroscopy to directly image\nhelical edge-state formation. Using this new edge-state geometry we are able to\ndirectly confirm the predicted penetration depth of a helical interface state\ninto the 2D bulk of a QSHI for a well-specified crystallographic direction. The\nclean, well-ordered topological/trivial interfaces observed here create new\nopportunities for testing predictions of the microscopic behavior of\ntopologically protected boundary states without the complication of structural\ndisorder.", "category": "cond-mat.mtrl-sci"}, {"title": "First-principles theory of giant Rashba-like spin-splitting in bulk ferroelectrics", "abstract": "Recently large Rashba-like spin splitting has been observed in certain bulk\nferroelectrics. In contrast with the relativistic Rashba effect, the chiral\nspin texture and large spin-splitting of the electronic bands depend strongly\non the character of the band and atomic spin-orbit coupling. We establish that\nthis can be traced back to the so-called orbital Rashba effect, also in the\nbulk. This leads to an additional dependence on the orbital composition of the\nbands, which is crucial for a complete picture of the effect. Results from\nfirst-principles calculations on ferroelectic GeTe verify the key predictions\nof the model.", "category": "cond-mat.mtrl-sci"}, {"title": "Atomic structure of intrinsic and electron-irradiation-induced defects in MoTe2", "abstract": "Studying the atomic structure of intrinsic defects in two-dimensional\ntransition metal dichalcogenides is difficult since they damage quickly under\nthe intense electron irradiation in transmission electron microscopy (TEM).\nHowever, this can also lead to insights into the creation of defects and their\natom-scale dynamics. We first show that MoTe 2 monolayers without protection\nindeed quickly degrade during scanning TEM (STEM) imaging, and discuss the\nobserved atomic-level dynamics, including a transformation from the 1H phase\ninto 1T', three-fold rotationally symmetric defects, and the migration of line\ndefects between two 1H grains with a 60{\\deg} misorientation. We then analyze\nthe atomic structure of MoTe2 encapsulated between two graphene sheets to\nmitigate damage, finding the as-prepared material to contain an unexpectedly\nlarge concentration of defects. These include similar point defects (or quantum\ndots, QDs) as those created in the non-encapsulated material, and two different\ntypes of line defects (or quantum wires, QWs) that can be transformed from one\nto the other under electron irradiation. Our density functional theory\nsimulations indicate that the QDs and QWs embedded in MoTe2 introduce new\nmidgap states into the semiconducting material, and may thus be used to control\nits electronic and optical properties. Finally, the edge of the encapsulated\nmaterial appears amorphous, possibly due to the pressure caused by the\nencapsulation.", "category": "cond-mat.mtrl-sci"}, {"title": "Electrical-current-induced magnetic hysteresis in self-assembled vertically aligned La_{2/3}Sr_{1/3}MnO_3:ZnO-nanopillar composites", "abstract": "Magnetoresistive random-access memory (MRAM) is poised to become a\nnext-generation information storage device. Yet, many materials challenges\nremain unsolved before it can become a widely used memory storage solution.\nAmong them, an urgent need is to identify a material system that is suitable\nfor downscaling and is compatible with low-power logic applications.\nSelf-assembled, vertically-aligned La_{2/3}Sr_{1/3}MnO_3:ZnO nanocomposites, in\nwhich La_{2/3}Sr_{1/3}MnO_3 (LSMO) matrix and ZnO nanopillars form an\nintertwined structure with coincident-site-matched growth occurring between the\nLSMO and ZnO vertical interfaces, may offer new MRAM applications by combining\ntheir superior electric, magnetic (B), and optical properties. In this paper,\nwe show the results of electrical current induced magnetic hysteresis in\nmagneto-resistance measurements in these nano-pillar composites. We observe\nthat when the current level is low, for example, 1 uA, the magneto-resistance\ndisplays a linear, negative, non-hysteretic B field dependence. Surprisingly,\nwhen a large current is used, I > 10 uA, a hysteretic behavior is observed when\nthe B field is swept in the up and down directions. This hysteresis weakens as\nthe sample temperature is increased. A possible spin-valve mechanism related to\nthis electrical current induced magnetic hysteresis is proposed and discussed.", "category": "cond-mat.mtrl-sci"}, {"title": "Giant electrocaloric response in the prototypical Pb(Mg,Nb)O$_{3}$ relaxor ferroelectric from atomistic simulations", "abstract": "An atomistic effective Hamiltonian is used to investigate electrocaloric (EC)\neffects of Pb(Mg$_{1/3}$Nb$_{2/3}$)O$_{3}$ (PMN) relaxor ferroelectrics in its\nergodic regime, and subject to electric fields applied along the pseudocubic\n[111] direction. Such Hamiltonian qualitatively reproduces (i) the electric\nfield-versus-temperature phase diagram, including the existence of a critical\npoint where first-order and second-order transitions meet each other; and (ii)\na giant EC response near such critical point. It also reveals that such giant\nresponse around this critical point is microscopically induced by field-induced\npercolation of polar nanoregions. Moreover, it is also found that, for any\ntemperature above the critical point, the EC coefficient-versus-electric field\ncurve adopts a maximum (and thus larger electrocaloric response too), that can\nbe well described by the general Landau-like model proposed in [Jiang et al,\nPhys. Rev. B 96, 014114 (2017)] and that is further correlated with specific\nmicroscopic features related to dipoles lying along different rhombohedral\ndirections. Furthermore, for temperatures being at least 40 K higher than the\ncritical temperature, the (electric field, temperature) line associated with\nthis maximal EC coefficient is below both the Widom line and the line\nrepresenting percolation of polar nanoregions.", "category": "cond-mat.mtrl-sci"}, {"title": "Spin transport in multilayer systems with fully epitaxial NiO thin films", "abstract": "We report on the generation and transport of thermal spin currents in fully\nepitaxial {\\gamma}-Fe$_2$O$_3$/NiO(001)/Pt and Fe$_3$O$_4$/NiO(001)/Pt\ntrilayers. A thermal gradient, perpendicular to the plane of the sample,\ngenerates a magnonic spin current in the ferrimagnetic maghemite\n({\\gamma}-Fe$_2$O$_3$) and magnetite (Fe$_3$O$_4$) thin films by means of the\nspin Seebeck effect. The spin current propagates across the epitaxial,\nantiferromagnetic insulating NiO layer, before being detected in the Pt layer\nby the inverse spin Hall effect. The transport of the spin signal is studied as\na function of the NiO thickness, temperature and ferrimagnetic material where\nthe spin current is generated. In epitaxial NiO grown on maghemite, the spin\nSeebeck signal decays exponentially as a function of the NiO thickness, with a\nspin-diffusion length for thermally-generated magnons of {\\lambda}$_{MSDL}$ =\n$1.6 \\pm 0.2$ nm, largely independent on temperature. We see no enhancement of\nthe spin current signal as previously reported for certain temperatures and\nthicknesses of the NiO. In epitaxial NiO grown on magnetite, the\ntemperature-averaged spin diffusion length is {\\lambda}$_{MSDL}$ = $3.8 \\pm\n0.3$ nm, and we observe an enhancement of the spin signal when the NiO\nthickness is 0.8 nm, demonstrating that the growth conditions dramatically\naffect the spin transport properties of the NiO even for full epitaxial growth.\nIn contrast to theoretical predictions for coherent spin transport, we do not\nsee vastly different spin diffusion lengths between epitaxial and\npolycrystalline NiO layers.", "category": "cond-mat.mtrl-sci"}, {"title": "Thermal conductivity of thin insulating films determined by tunnel magneto-Seebeck effect measurements and finite-element modeling", "abstract": "In general, it is difficult to access the thermal conductivity of thin\ninsulating films experimentally just by electrical means. Here, we present a\nnew approach utilizing the tunnel magneto-Seebeck effect (TMS) in combination\nwith finite-element modeling (FEM). We detect the laser-induced TMS and the\nabsolute thermovoltage of laser-heated magnetic tunnel junctions with 2.6 nm\nthin barriers of MgAl$_2$O$_4$ (MAO) and MgO, respectively. A second\nmeasurement of the absolute thermovoltage after a dielectric breakdown of the\nbarrier grants insight into the remaining thermovoltage of the stack. Thus, the\npure TMS without any parasitic Nernst contributions from the leads can be\nidentified. In combination with FEM via COMSOL, we are able to extract values\nfor the thermal conductivity of MAO ($0.7$ W/(K$\\cdot$m)) and MgO ($5.8$\nW/(K$\\cdot$m)), which are in very good agreement with theoretical predictions.\nOur method provides a new promising way to extract the experimentally\nchallenging parameter of the thermal conductivity of thin insulating films.", "category": "cond-mat.mtrl-sci"}, {"title": "Accurate optical properties from first principles: a Quasiparticle Self consistent GW plus Bethe-Salpeter Equation approach", "abstract": "We present an approach to calculate the optical absorption spectra that\ncombines the quasiparticle self-consistent GW method [Phys. Rev. B, 76 165106\n(2007)] for the electronic structure with the solution of the ladder\napproximation to the Bethe-Salpeter equation for the macroscopic dielectric\nfunction. The solution of the Bethe-Salpeter equation has been implemented\nwithin an all-electron framework, using a linear muffin-tin orbital basis set,\nwith the contribution from the non-local self-energy to the transition dipole\nmoments (in the optical limit) evaluated explicitly. This approach addresses\nthose systems whose electronic structure is poorly described within the\nstandard perturbative GW approaches with as a starting point density-functional\ntheory calculations. The merits of this approach have been exemplified by\ncalculating optical absorption spectra of a strongly correlated transition\nmetal oxide, NiO, and a narrow gap semiconductor, Ge. In both cases, the\ncalculated spectrum is in good agreement with the experiment. It is also shown\nthat for systems whose electronic structure is well-described within the\nstandard perturbative GW, such as Si, LiF and h-BN, the performance of the\npresent approach is in general comparable to the standard GW plus\nBethe-Salpeter equation. It is argued that both vertex corrections to the\nelectronic screening and the electron-phonon interaction are responsible for\nthe observed systematic overestimation of the fundamental bandgap and spectrum\nonset.", "category": "cond-mat.mtrl-sci"}, {"title": "Exploring the energy landscape of resistive switching in antiferromagnetic Sr(3)Ir(2)O(7)", "abstract": "We study the resistive switching triggered by an applied electrical bias in\nantiferromagnetic Mott insulator Sr(3)Ir(2)O(7). The switching was previously\nassociated with an electric-field driven structural transition. Here we use\ntime-resolved measurements of the switching to probe the energy barrier\nassociated with the transition. We quantify the changes in the energy barrier\nheight with respect to the applied bias and find a linear decrease of the\nbarrier with increasing bias. Our observations support the potential of\nantiferromagnetic transition metal oxides for spintronic applications.", "category": "cond-mat.mtrl-sci"}, {"title": "Synthesis of nanocrystalline d-MoN by thermal annealing of amorphous thin films grown on (100) Si by reactive DC sputtering at room temperature", "abstract": "We report on the synthesis and characterization of nanocrystalline delta-MoN\nby crystallization of amorphous thin films grown on (100) Si by reactive\nsputtering at room temperature. Films with chemical composition MoN were grown\nusing a deposition pressure of 5mTorr with a reactive mixture of\nAr/(Ar+N2)=0.5. The as-grown films display mostly amorphous structure.\nNanocrystalline delta-MoN phase is obtained after annealing at temperatures\nabove 600 {\\deg}C. The superconducting critical temperature Tc depends on film\nthickness. Thick films (170 nm) annealed at 700 {\\deg}C for 30 min display a Tc\n= 11.2 K (close to the one reported for bulk specimens: 13 K), which is\ngradually suppressed to 7.2 K for 40 nm thick delta-MoN films. Our results\nprovide a simple method to synthesize superconducting nitride thin films on\nsilicon wafers with Tc above the ones observed for conventional superconductors\nsuch as Nb.", "category": "cond-mat.mtrl-sci"}, {"title": "Co/Ni multilayers for spintronics: high spin-polarization and tunable magnetic anisotropy", "abstract": "In this paper we analyze in details the electronic properties of (Co/Ni)\nmultilayers, a model system for spintronics devices. We use magneto-optical\nKerr (MOKE), spin-polarized photoemission spectroscopy (SRPES), x-ray magnetic\ncircular dichroism (XMCD) and anomalous surface diffraction experiments to\ninvestigate the electronic properties and perpendicular magnetic anisotropy\n(PMA) in [Co(x)/Ni(y)] single-crystalline stacks grown by molecular beam\nepitaxy.", "category": "cond-mat.mtrl-sci"}, {"title": "Epitaxial Growth of Single-Orientation High-Quality MoS$_2$ Monolayers", "abstract": "We present a study on the growth and characterization of high-quality\nsingle-layer MoS$_2$ with a single orientation, i.e. without the presence of\nmirror domains. This single orientation of the MoS$_2$ layer is established by\nmeans of x-ray photoelectron diffraction. The high quality is evidenced by\ncombining scanning tunneling microscopy with x-ray photoelectron spectroscopy\nmeasurements. Spin- and angle-resolved photoemission experiments performed on\nthe sample revealed complete spin-polarization of the valence band states near\nthe K and -K points of the Brillouin zone. These findings open up the\npossibility to exploit the spin and valley degrees of freedom for encoding and\nprocessing information in devices that are based on epitaxially grown\nmaterials.", "category": "cond-mat.mtrl-sci"}, {"title": "Twelve Inequivalent Dirac Cones in Two-Dimensional ZrB2", "abstract": "Theoretical evidence of the existence of 12 inequivalent Dirac cones at the\nvicinity of the Fermi energy in monolayered ZrB$_2$ is presented.\nTwo-dimensional ZrB$_2$ is a mechanically stable d- and p-orbital compound\nexhibiting a unique electronic structure with two Dirac cones out of\nhigh-symmetry points in the irreducible Brillouin zone with a small\nelectron-pocket compensation. First-principles calculations demonstrate that\nwhile one of the cones is insensitive to lattice expansion, the second cone\nvanishes for small perturbation of the vertical Zr position. Internal symmetry\nbreaking with external physical stimuli, along with the relativistic effect of\nSOC, is able to remove selectively the Dirac cones. A rational explanation in\nterms of d- and p-orbital mixing is provided to elucidate the origin of the\ninfrequent amount of Dirac cones in a flat structure. The versatility of\ntransition metal d-orbitals combined with the honeycomb lattice provided by the\nB atoms yields novel features never observed in a two-dimensional material.", "category": "cond-mat.mtrl-sci"}, {"title": "Surface reconstruction, premelting, and collapse of open-cell nanoporous Cu via thermal annealing", "abstract": "We systematic investigate the collapse of a set of open-cell nanoporous Cu\n(np-Cu) with the same porosity and shapes, but different specific surface area,\nduring thermal annealing, via performing large-scale molecular dynamics\nsimulations. Surface premelting is dominated in their collapses, and surface\npremelting temperatures reduce linearly with the increase of specific surface\narea. The collapse mechanisms are different for np-Cu with different specific\nsurface area. If the specific surface area less than a critical value ($\\sim$\n2.38 nm$^{-1}$), direct surface premelting, giving rise to the transition of\nligaments from solid to liquid states, is the cause to facilitate falling-down\nof np-Cu during thermal annealing. While surface premelting and following\nrecrystallization, accelerating the sloughing of ligaments and annihilation of\npores, is the other mechanism, as exceeding the critical specific surface area.\nThe recrystallization occurs at the temperatures below supercooling, where\nliquid is instable and instantaneous. Thermal-induced surface reconstruction\nprompts surface premelting via facilitating local \"disordering\" and \"chaotic\"\nat the surface, which are the preferred sites for surface premelting.", "category": "cond-mat.mtrl-sci"}, {"title": "Stability and Carrier Transport Properties of Phosphorene Based Polymorphic Nanoribbons", "abstract": "A few-layer black phosphorene has recently gained significant interest in the\nscientific community. In this paper, we consider several polymorphs of\nphosphorene nanoribbons (PNRs) and employ deformation potential theory within\nthe effective mass approximation together with density functional theory to\ninvestigate their structural, mechanical and electronic properties. The results\nshow that stability of PNRs strongly depends on the direction along which they\ncan be cut from 2D counterpart. PNRs also exhibit a wide range of line\nstiffness ranging from 6x10^10 eV/m to 18x10^11 eV/m which has little\ndependence on the edge passivation. Likewise, the calculated electronic\nproperties of PNRs display them to be either narrow-gap semiconductor (Eg < 1\neV) or wide-gap semiconductor (Eg > 1 eV). The carrier mobility of PNRs is\nfound to be comparable to that of the black phosphorene. Some of the PNRs show\nn-type (p-type) semiconducting character owing to their higher electron (hole)\nmobility. Passivation of the edges leads to n-type <-> p-type transition in\nmany of the PNRs considered. The predicted novel characteristics of PNRs with a\nwide range of mechanical and electronic properties make PNRs to be potentially\nsuitable for the use in nanoscale devices.", "category": "cond-mat.mtrl-sci"}, {"title": "Organic crystalline polymers: structural properties and way to synthesis under high pressure", "abstract": "We consider different structures, which can be obtained by polymerization of\naromatic organic molecules under high pressures. These 2D and 3D covalently\nbonded organic polymers and their functionalization can pave the way to\nproduction of energy storage and conversion devices. High-pressure synthesis\nmight serve as a useful hint for production of these structures and their\nfunctionalized analogs by means of wet chemical synthesis.", "category": "cond-mat.mtrl-sci"}, {"title": "Depth dependant element analysis of PbMg$_{1/3}$Nb$_{2/3}$O$_{3}$ using muonic X-rays", "abstract": "The relaxor PbMg$_{1/3}$Nb$_{2/3}$O$_{3}$ (PMN) has received attention due to\nits potential applications as a piezoelectric when doped with PbTiO$_{3}$ (PT).\nPrevious results have found that there are two phases existing in the system,\none linked to the near-surface regions of the sample, the other in the bulk.\nHowever, the exact origin of these two phases is unclear. In this paper, depth\ndependant analysis results from negative muon implantation experiments are\npresented. It is shown that the Pb content is constant throughout all depths\nprobed in the sample, but the Mg and Nb content changes in the near-surface\nregion below 100$\\mu$m. At a implantation depth of 60$\\mu$m, it is found that\nthere is a 25% increase in Mg content, with a simultaneous 5% decrease in Nb\ncontent in order to maintain charge neutrality. These results show that the\npreviously observed skin effects in PMN are due to a change in concentration\nand unit cell.", "category": "cond-mat.mtrl-sci"}, {"title": "Structure, magnetic and transport properties of epitaxial thin films of equiatomic CoFeMnGe quaternary Heusler alloy", "abstract": "Future spintronics requires the realization of thin film of half-metallic\nferromagnets having high Curie temperature and 100\\% spin polarization at the\nFermi level for potential spintronics applications. In this paper, we report\nthe epitaxial thin films growth of half-metallic CoFeMnGe Heusler alloy on MgO\n(001) substrate using pulsed laser deposition system, along with the study of\nstructural, magnetic and transport properties. The magnetic property\nmeasurements of the thin film suggest a soft ferromagnetic state at room\ntemperature with an in-plane magnetic anisotropy and a Curie temperature well\nabove the room temperature. Anisotropic magnetoresistance (AMR) ratio and\ntemperature dependent electrical resistivity measurements of the thin film\nindicate the compound to be half-metallic in nature and therefore suitable for\nthe fabrications of spintronics devices.", "category": "cond-mat.mtrl-sci"}, {"title": "Control of surface potential at polar domain walls in a nonpolar oxide", "abstract": "Ferroic domain walls could play an important role in microelectronics, given\ntheir nanometric size and often distinct functional properties. Until now,\ndevices and device concepts were mostly based on mobile domain walls in\nferromagnetic and ferroelectric materials. A less explored path is to make use\nof polar domain walls in nonpolar ferroelastic materials. Indeed, while the\npolar character of ferroelastic domain walls has been demonstrated,\npolarization control has been elusive. Here, we report evidence for the\nelectrostatic signature of the domain-wall polarization in nonpolar calcium\ntitanate (CaTiO3). Macroscopic mechanical resonances excited by an ac electric\nfield are observed as a signature of a piezoelectric response caused by polar\nwalls. On the microscopic scale, the polarization in domain walls modifies the\nlocal surface potential of the sample. Through imaging of surface potential\nvariations, we show that the potential at the domain wall can be controlled by\nelectron injection. This could enable devices based on nondestructive\ninformation readout of surface potential.", "category": "cond-mat.mtrl-sci"}, {"title": "In aqua electrochemistry probed by XPEEM: experimental setup, examples, and challenges", "abstract": "Recent developments in environmental and liquid cells equipped with electron\ntransparent graphene windows have enabled traditional surface science\nspectromicroscopy tools, such as X-ray photoelectron spectroscopy (XPS),\nphotoemission electron microscopy (PEEM), and scanning electron microscopy\n(SEM) to be applied to study solid-liquid and liquid-gas interfaces. Here, we\nfocus on the experimental implementation of PEEM to probe electrified\ngraphene-liquid interfaces using electrolyte-filled microchannel arrays as a\nnew sample platform. We demonstrate the important methodological advantage of\nthese multi-sample arrays: they enable the combination of the wide field of\nview hyperspectral imaging capabilities from PEEM with the use of powerful data\nmining algorithms to reveal spectroscopic and temporal behaviors at the level\nof the individual microsample or the entire array ensemble", "category": "cond-mat.mtrl-sci"}, {"title": "Theory and Ab Initio Computation of the Anisotropic Light Emission in Monolayer Transition Metal Dichalcogenides", "abstract": "Monolayer transition metal dichalcogenides (TMDCs) are direct gap\nsemiconductors with unique potential for ultrathin light emitters. Yet, their\nphotoluminescence (PL) is not completely understood. We compute the radiative\nrecombination rate in monolayer TMDCs as a function of photon emission\ndirection and polarization, and obtain polar plots of the PL for different\nexcitation scenarios using the ab initio Bethe-Salpeter equation. We show that\nexcitons in a quantum superposition state of the K and K' inequivalent valleys\nemit light anisotropically upon recombination. Our results can explain the PL\nanisotropy and polarization dependence measured in recent experiments, and\npredict new light emission regimes. When averaged over emission angle and\nexciton momentum, our new treatment recovers the temperature dependent\nradiative lifetimes we previously derived. Our work provides a first-principles\napproach to study light emission in two-dimensional materials.", "category": "cond-mat.mtrl-sci"}, {"title": "Thermoelectric properties of polycrystalline palladium sulfide", "abstract": "A suite measurements of the electrical, thermal, and vibrational properties\nare conducted on palladium sulfide (PdS) in order to investigate its\nthermoelectric performance. The tetragonal structure with the space group\n$P$42/$m$ for PdS is determined from X-ray diffraction measurement. The unique\ntemperature dependence of mobility suggests that acoustic phonons and ion\nimpurity scattering are two dominant scattering mechanisms within the compound.\nThe obtained power factor of $27$ $\\mu$Wcm$^{-1}$K$^{-2}$ at 800 K is the\nlargest value in the remaining transition-metal sulfides studied so far. The\nmaximum value of the dimensionless figure of merit is 0.33 at 800 K. The\nobserved phonon softening with temperature indicates that the reduction of the\nlattice thermal conductivity is mainly controlled by the enhanced lattice\nanharmonicity. These results indicate that the binary bulk PdS has promising\npotential to have good thermoelectrical performance.", "category": "cond-mat.mtrl-sci"}, {"title": "Evolution of defect signatures at ferroelectric domain walls in Mg-doped LiNbO3", "abstract": "The domain structure of uniaxial ferroelectric lithium niobate single\ncrystals is investigated using Raman spectroscopy mapping. The influence of\ndoping with magnesium and poling at room temperature is studied by analysing\nfrequency shifts at domain walls and their variations with dopant concentration\nand annealing conditions. It is shown that defects are stabilized at domain\nwalls and that changes in the defect structures with Mg concentration can be\nprobed by the shift of Raman modes. We show that the signatures of polar\ndefects in the bulk and at the domain walls differ.", "category": "cond-mat.mtrl-sci"}, {"title": "Optoelectronics and defect levels in hydroxyapatite by first-principles", "abstract": "Hydroxyapatite (HAp) is an important component of mammal bones and teeth,\nbeing widely used in prosthetic implants. Despite the importance of HAp in\nmedicine, several promising applications involving this material e.g. in\nphoto-catalysis), depend on how well we understand its fundamental properties.\nAmong the ones that are either unknown or not known accurately we have the\nelectronic band structure and all that relates to it, including the band gap\nwidth. We employ state-of-the-art methodologies, including density\nhybrid-functional theory and many-body perturbation theory within the GW\napproximation, to look at the optoelectronic properties of HAp. These methods\nare also applied to the calculation of defect levels. We find that the use of a\nmix of (semi-)local and exact exchange in the exchange-correlation functional,\nbrings a drastic improvement to the band structure. Important side-effects\ninclude improvements in the description of dielectric and optical properties,\nnot only involving conduction band (excited) states, but also the valence. We\nfind that the highly dispersive conduction band bottom of HAp originates from\nanti-bonding $\\sigma^{*}$ states along the $\\cdots\\textrm{OH-OH-}\\cdots$\ninfinite chain, suggesting the formation of a conductive 1D-ice phase. The\nchoice of the exchange-correlation treatment to the calculation of defect\nlevels was also investigated by using the OH-vacancy as testing-model. We find\nthat donor and acceptor transitions obtained within semi-local DFT differ from\nthose of hybrid-DFT by almost 2 eV. Such a large discrepancy emphasizes the\nimportance of using a high-quality description of the electron-electron\ninteractions in the calculation of electronic and optical transitions of\ndefects in HAp.", "category": "cond-mat.mtrl-sci"}, {"title": "Characterization, optical properties and electron(exciton)-phonon interaction in bulk In2Se3 crystals and InSe nanocrystals in In2nSe3 confinement", "abstract": "Complex electron-microscopic, energy-dispersed and wide-temperature optical\nabsorption and photoluminescence (PL) investigations are carried out into\nBridgeman-grown layered In2Se3 crystals. It is shown that In2Se3 crystals as a\nwhole have a homogeneous concentration of In and Se atoms, corresponding with\nIn2Se3 stoichiometry. Nevertheless, In2Se3 crystals contain a significant\namount of dislocations, on which nano-sized interspersions of crystal phases of\npure InSe, In6Se7 and monoclinic red Se settle down. Optical wide-temperature\ninvestigations of In2Se3 allow us to do the following: establish the width of\nthe band-gap, the exciton binding energy; determine the frequency of a\nhalf-layer A-phonon, which takes part in electron (exciton)-phonon interaction;\nand to evaluate the effective masses of carriers and the dielectric\npermeability. Finally, blue shift of the band-gap and character of the electron\n(exciton)-phonon interaction of nano-sized 3D InSe crystals confined in an\nIn2Se3 crystal matrix; influence of an InSe nanocrystal radius and of an\nensemble of 3D InSe nanocrystals with different radii for an increase of the\nexciton emission/absorption half-width line with temperature and radii of InSe\nnanocrystals are discussed.", "category": "cond-mat.mtrl-sci"}, {"title": "First-principles study of the thermoelectric properties of quaternary tetradymite BiSbSeTe2", "abstract": "The electronic and phonon transport properties of quaternary tetradymite\nBiSbSeTe2 are investigated using first-principles approach and Boltzmann\ntransport theory. Unlike the binary counterpart Bi2Te3, we obtain a pair of\nRashba splitting bands induced by the absence of inversion center. Such unique\ncharacteristic could lead to a large Seebeck coefficient even at relatively\nhigher carrier concentration. Besides, we find an ultralow lattice thermal\nconductivity of BiSbSeTe2, especially along the interlayer direction, which can\nbe traced to the extremely small phonon relaxation time mainly induced by the\nmixed covalent bonds. As a consequence, a considerably large ZT value of ~2.0\ncan be obtained at 500 K, indicating that the unique lattice structure of\nBiSbSeTe2 caused by isoelectronic substitution could be an advantage to\nachieving high thermoelectric performance.", "category": "cond-mat.mtrl-sci"}, {"title": "Temperature-induced inversion of the spin-photogalvanic effect in WTe$_2$ and MoTe$_2$", "abstract": "We investigate the generation and temperature-induced evolution of\noptically-driven spin photocurrents in WTe$_2$ and MoTe$_2$. By correlating the\nscattering-plane dependence of the spin photocurrents with the symmetry\nanalysis, we find that a sizeable spin photocurrent can be controllably driven\nalong the chain direction by optically exciting the system in the high-symmetry\n$y$-$z$ plane. Temperature dependence measurements show that pronounced\nvariations in the spin photocurrent emerge at temperatures that coincide with\nthe onset of anomalies in their transport and optical properties. The\ndecreasing trend in the temperature dependence starting below 150 K is\nattributed to the temperature-induced Lifshitz transition. The sign inversion\nof the spin photocurrent, observed around 50 K in WTe$_2$ and around 120 K in\nMoTe$_2$, may have its origin in an interaction that involves multiple kinds of\ncarriers.", "category": "cond-mat.mtrl-sci"}, {"title": "Properties of Superconducting Nb and NbTi Coatings-films Deposited by New Ionic-Plasma Clusters method", "abstract": "Originally developed technique based on generation of plasma-cluster flux\nemitted from cathode spots at surface of an integrally cold cathode has been\napplied for deposition of niobium superconductive (thick) film materials.\nPossibility for depositing thick film coatings in homogeneous, heterogeneous\nand layered structures is shown to be feasible. Experimental results of\nmechanical tests including Tensile Testing resulting in stretching of coatings\nare presented. Critical temperature, current density and magnetic field of\ndeposited superconducting films with various types of structural compositions\nhave been investigated. Niobium-titanium layered coating films deposited by\nIonic-plasma clusters method are characterized by very high parameters of\ncritical current density. All results reveal coating material high value in\nterms of manufacturability. Low cost, high reliability and ease of\nimplementation of new technology for a wide-scale production of superconducting\nfilm materials have been demonstrated.", "category": "cond-mat.mtrl-sci"}, {"title": "Characterization of spin coated Zn doped cupric oxide thin films", "abstract": "Thin films of Zn2+ doped cupric oxide (CuO) were synthesized using spin\ncoating technique starting from a solution with Cu and Zn. The speed of spin\ncoating and time duration were varied to fabricate a film with required uniform\nthickness. Samples were subsequently annealed in air at different annealing\ntemperatures to crystallize the phase of CuO. Doping concentration of Zn2+ was\nvaried up to weight percentage of 10%. Structural properties of samples were\ndetermined using X-ray diffraction technique. Particle size, dislocation\ndensity and strain at different doping concentrations were determined using XRD\npatterns. Optical properties were measured by means of UV/Vis spectrometer.\nOptical band gap of CuO could be tailored by doping a trace amount of Zn2+. The\noptical band gap decreases with increase of particle size. The particle size,\ndislocation density, strain and optical band gap have a turning point close to\nthe doping concentration of 6%.", "category": "cond-mat.mtrl-sci"}, {"title": "Geometrodynamics of electrons in a crystal under position and time dependent deformation", "abstract": "Semiclassical dynamics of Bloch electrons in a crystal under slowly varying\ndeformation is developed in the geometric language of a lattice bundle. Berry\ncurvatures and gradients of energy are introduced in terms of lattice covariant\nderivatives, with the corresponding connections given by the gradient and rate\nof strain. A number of physical effects are discussed: an effective\npost-Newtonian gravity at band bottom, polarization induced by spatial gradient\nof strain, orbital magnetization induced by strain rate, and electron energy\nstress tensor.", "category": "cond-mat.mtrl-sci"}, {"title": "Semilocal Pauli-Gaussian Kinetic Functionals for Orbital-Free Density Functional Theory Calculations of Solids", "abstract": "Kinetic energy (KE) approximations are key elements in orbital-free density\nfunctional theory. To date, the use of non-local functionals, possibly\nemploying system dependent parameters, has been considered mandatory in order\nto obtain satisfactory accuracy for different solid-state systems, whereas\nsemilocal approximations are generally regarded as unfit to this aim. Here, we\nshow that instead properly constructed semilocal approximations, the\nPauli-Gaussian (PG) KE functionals, especially at the Laplacian-level of\ntheory, can indeed achieve similar accuracy as non-local functionals and can be\naccurate for both metals and semiconductors, without the need of\nsystem-dependent parameters.", "category": "cond-mat.mtrl-sci"}, {"title": "Anomalous phonon lifetime shortening in paramagnetic CrN caused by magneto-lattice coupling: A combined spin and ab initio molecular dynamics study", "abstract": "We study the mutual coupling of spin fluctuations and lattice vibrations in\nparamagnetic CrN by combining atomistic spin dynamics and ab initio molecular\ndynamics. The two degrees of freedom are dynamically coupled leading to\nnon-adiabatic effects. Those effects suppress the phonon life times at low\ntemperature compared to an adiabatic approach. The here identified dynamic\ncoupling provides an explanation for the experimentally observed unexpected\ntemperature dependence of the thermal conductivity of magnetic semiconductors\nabove the magnetic ordering temperature.", "category": "cond-mat.mtrl-sci"}, {"title": "A deep learning approach to identify local structures in atomic-resolution transmission electron microscopy images", "abstract": "Recording atomic-resolution transmission electron microscopy (TEM) images is\nbecoming increasingly routine. A new bottleneck is then analyzing this\ninformation, which often involves time-consuming manual structural\nidentification. We have developed a deep learning-based algorithm for\nrecognition of the local structure in TEM images, which is stable to microscope\nparameters and noise. The neural network is trained entirely from simulation\nbut is capable of making reliable predictions on experimental images. We apply\nthe method to single sheets of defected graphene, and to metallic nanoparticles\non an oxide support.", "category": "cond-mat.mtrl-sci"}, {"title": "Accelerating CALYPSO Structure Prediction by Data-driven Learning of Potential Energy Surface", "abstract": "Ab initio structure prediction methods have been nowadays widely used as\npowerful tools for structure searches and material discovery. However, they are\ngenerally restricted to small systems owing to the heavy computational cost of\nunderlying density functional theory (DFT) calculations. In this work, by\ncombining state-of-art machine learning (ML) potential with our in-house\ndeveloped CALYPSO structure prediction method, we developed two acceleration\nschemes for structure prediction toward large systems, in which ML potential is\npre-constructed to fully replace DFT calculations or trained in an on-the-fly\nmanner from scratch during the structure searches. The developed schemes have\nbeen applied to medium- and large-sized boron clusters, which are challenging\ncases for both construction of ML potentials and extensive structure searches.\nExperimental structures of B36 and B40 clusters can be readily reproduced, and\nthe putative global minimum structure for B84 cluster is proposed, where\nsubstantially less computational cost by several orders of magnitude is evident\nif compared with full DFT-based structure searches. Our results demonstrate a\nviable route for structure prediction toward large systems via the combination\nof state-of-art structure prediction methods and ML techniques.", "category": "cond-mat.mtrl-sci"}, {"title": "Thermal disorder in finite-length carbon nanowire", "abstract": "Chemisorption is one of the active research areas in carbon materials. The\noccurrence of the monoatomic carbon chain can be made by surrounding the double\nwalled carbon nanotube and meanwhile worldwide efforts have been made to create\nthe extraction technique for unlashing the carbon chains from the enclosure.\nHere we report an extensive study of the kink structure in the free standing\ncarbon nanowires. Our Monte Carlo simulation considers the multi-monoatomic\ncarbon chains laterally interacted by the Van der Waal force. Despite the\nlinearity of the carbon nanowires is independent of chain length at low\ntemperatures, the same situation does not hold at high temperatures. Disordered\nkink structure is observed in the short carbon chains especially above Peierls\ntransition temperature. For instance, the average kink angle of 50-atoms carbon\nnanowire is as large as 35 degree at 800K. We have provided an important\ninspection that any physical property of the finite-length carbon chain\npredicted by ab-initio calculation should reconsider the atomic rearrangement\ndue to the thermal instability. Apart from this, the kink structure in the\nnanowires likely increases the probability of attaching negatively charged\natoms which is an encouragement to find the next generation materials for\nchemisorption.", "category": "cond-mat.mtrl-sci"}, {"title": "Structural and electronic properties of V2O5 and their tuning by doping with 3d elements - Modelling with DFT+U method and dispersion correction", "abstract": "New electrode materials for alkaline-ion batteries are a timely topic. Among\nmany promising candidates, V2O5 is one of the most interesting cathode\nmaterials. While having very high theoretical capacity, in practice, its\nperformance is hindered by low stability and poor conductivity. As regards\ntheoretical descriptions of V2O5, common DFT-GGA calculations fail to reproduce\nboth the electronic and crystal structure. While the band gap is\nunderestimated, the interlayer spacing is overestimated as weak dispersion\ninteractions are not properly described within GGA. Here we show that the\ncombination of the DFT+U method and semi-empirical D2 correction can compensate\nfor the drawbacks of the GGA approximation when it comes to the modelling of\nV2O5. When compared to common PBE calculations, with a modest increase of the\ncomputational cost, PBE+U+D2 fully reproduced the experimental band gap of\nV2O5, while the errors in the lattice parameters are only a few percent. Using\nthe proposed PBE+U+D2 methodology we studied V2O5 doped with 3d elements (from\nSc to Zn). We show that both the structural and electronic parameters are\naffected by doping. Most importantly, a significant increase of conductivity is\nexpected upon doping, which is of great importance for the application of V2O5\nin metal-ion batteries.", "category": "cond-mat.mtrl-sci"}, {"title": "Analysis of the Robustness of Conventional and Topologically Protected Edge States in Phononic Crystal Plates", "abstract": "In this work we theoretically study the interface acoustic states of\nresonators on a thin plate with topologically protected and conventional\ndesigns. Topologically protected interface state is first analyzed by employing\nthe conception of breaking inversion symmetry within the unit cell of a\nhoneycomb lattice for cylindrical and spherical resonators; we further\ndemonstrate the robustness of the wave propagation along a zig-zag path\ncontaining sharp corners, defect and disorder. The wave propagation ceases to\nbe preserved if we increase the degree of disorder along the zig-zag path. In\nparallel, the conventional interface state is also designed and compared to the\nsame situations. We found that the conventional interface state suffers back\nscattering in the zig-zag path while it can show a more confined wave transport\nin some cases. The presence of a defect along the propagation path scatters the\nconventional interface wave and in particular can prohibit a full propagation\nin presence of a localized state at the defect. If the zig-zag path is made\ndisordered, the propagation of the conventional interface mode can be conserved\nat given frequencies for a low random degree and disappears for higher random\ndegree as the interface bands become flat in dispersion and turn to localized\nstates. Finally, we show that the immunity of the topologically protected\ndesign needs the interface to be surrounded by at least two hexagons of the\nphononic crystals on both sides, especially at the sharp corners in the zig-zag\npath, while the conventional design only needs one hexagon bulk media with the\nadvantage of compact wave transport. This work puts a step forward for the\ninterface states in micro-/nano-scale characterization and figures out the\nbehaviors for both topologically protected and conventional interface states.", "category": "cond-mat.mtrl-sci"}, {"title": "Antiferromagnetic ground state in the MnGa$_4$ intermetallic compound", "abstract": "Magnetism of the binary intermetallic compound MnGa$_4$ is re-investigated.\nBand-structure calculations predict antiferromagnetic behavior in contrast to\nPauli paramagnetism reported previously. Magnetic susceptibility measurements\non single crystals indeed reveal an antiferromagnetic transition at $T_N=393$\nK. Neutron powder diffraction and $^{69,71}$Ga nuclear quadrupole resonance\nspectroscopy show collinear antiferromagnetic order with magnetic moments\nalligned along the [111] direction of the cubic unit cell. The magnetic moment\nof 0.80(3)$\\mu_B$ at 1.5 K extracted from the neutron data is in good agreement\nwith the band-structure results.", "category": "cond-mat.mtrl-sci"}, {"title": "Luminescence of BaBrI and SrBrI single crystals doped with Eu2+", "abstract": "The crystal growth procedure and luminescence properties of pure and\nEu$^{2+}$-doped BaBrI and SrBrI crystals are reported. Emission and excitation\nspectra were recorded under ultraviolet and vacuum ultraviolet excitations. The\nenergy of the first Eu$^{2+}$ 4f-5d transition and SrBrI band gap are obtained.\nThe electronic structure calculations were performed within GW approximation as\nimplemented in the Vienna Ab Initio Simulation Package. The energy between\nlowest Eu$^{2+}$ 5d state and the bottom of conduction band are found based on\nluminescence quenching parameters. The vacuum referred binding energy diagram\nof lanthanide levels was constructed using the chemical shift model.", "category": "cond-mat.mtrl-sci"}, {"title": "The role of defects in the etching of graphene by intercalated oxygen", "abstract": "Graphene is one of the most promising 2D materials for various applications\ndue to its unique electronic properties and high thermal stability. In previous\nstudies, it was shown that when graphene is deposited onto some transition\nmetal substrates, small molecules, such as O$_2$, intercalate between the\ngraphene and the substrate and react to partially etch the graphene film when\nheated to desorb the intercalates. Here, carbon vacancy defects are\nintentionally formed on Gr/Ru(0001) and their effect on the intercalation of\noxygen and etching of the graphene layer are investigated. 50 eV Ar$^+$\nsputtering with a low fluence is used to create isolated single vacancy defects\nin the graphene overlayer and helium low energy ion scattering (LEIS) is\nemployed for surface analysis. It is found that the defects both ease the\nintercalation of the oxygen molecules and improve the etching efficiency of the\ngraphene during annealing.", "category": "cond-mat.mtrl-sci"}, {"title": "Three-dimensional modeling of chiral nematic texture evolution under electric switching", "abstract": "Chiral nematic liquid crystals exhibit both a helical planar ground state\nwith uniform twist and a metastable defect-rich focal conic texture, and can be\nswitched between the two microstructures via application of transient voltage\npulses. In this work, we model these electrically-induced texture transitions\nusing finite difference methods to examine resulting microstructural evolution,\nthe first time this transition has been modeled in three dimensions. We analyze\nthe planar to focal conic, focal conic to planar, and planar to planar\ntransitions depending on voltage pulse magnitude. We consider first the special\ncase of chiral nematics with matched twist and bend elastic constants. Results\nshow a variety of defect-rich morphologies in the disordered focal conic\ntexture and demonstrate a fast recovery of the planar ground state on switching\nwithout formation of a transient planar state. We evaluate both texture\nmicrostructural evolution as well as cell capacitance. Beyond the single\nelastic constant approximation, we evaluate the planar to transient-planar as\nwell as the planar to Helfrich-deformed transitions in simulations of a liquid\ncrystal compound with different elastic constants. Our methods represent the\nevolving microstructure as a uniaxial director field, with relaxation dynamics\ncalculated from a tensor representation so that half charge disclination\ndefects are not suppressed. We discuss potential application of these\ncomputationally efficient three-dimensional modeling approaches for design and\noptimization of chiral nematic devices.", "category": "cond-mat.mtrl-sci"}, {"title": "Interfacial properties of black phosphorus/transition metal carbide van der Waals heterostructures", "abstract": "Owing to its outstanding electronic properties, black phosphorus (BP) is\nconsidered as a promising material for next-generation optoelectronic devices.\nIn this work, devices based on BP/MXene (Zrn+1CnT2, T = O, F, OH, n = 1, 2) van\nder Waals (vdW) heterostructures are designed via first-principles\ncalculations. Zrn+1CnT2 compositions with appropriate work functions lead to\nthe formation of Ohmic contact with BP in the vertical direction. Low Schottky\nbarriers are found along the lateral direction in BP/Zr2CF2, BP/Zr2CO2H2,\nBP/Zr3C2F2, and BP/Zr3C2O2H2 bilayers, and BP/Zr3C2O2 even exhibits Ohmic\ncontact behavior. BP/Zr2CO2 is a semiconducting heterostructure with type-II\nband alignment, which facilitates the separation of electron-hole pairs. The\nband structure of BP/Zr2CO2 can be effectively tuned via a perpendicular\nelectric field, and BP is predicted to undergo a transition from donor to\nacceptor at a 0.4 V/{\\AA} electric field. The versatile electronic properties\nof the BP/MXene heterostructures examined in this work highlight their\npromising potential for applications in electronics.", "category": "cond-mat.mtrl-sci"}, {"title": "Electroforming Free Controlled Bipolar Resistive Switching in Al/CoFe2O4/FTO device with Self-Compliance Effect", "abstract": "Controlled bipolar resistive switching (BRS) has been observed in\nnanostructured CoFe2O4 films using Al(aluminum)/CoFe2O4/FTO(fluorine-doped tin\noxide) device. The fabricated device shows electroforming-free uniform BRS with\ntwo clearly distinguished and stable resistance states without any application\nof compliance current (CC), with a resistance ratio of high resistance state\n(HRS) and low resistance state (LRS) > 102. Small switching voltage (< 1 volt)\nand lower current in both the resistance states confirms the fabrication of low\npower consumption device. In the LRS, the conduction mechanism was found to be\nof Ohmic in nature, while the high-resistance state (HRS/OFF state) was\ngoverned by space charge-limited conduction mechanism, which indicates the\npresence of an interfacial layer with imperfect microstructure near the top\nAl/CFO interface. The device shows nonvolatile behavior with good endurance\nproperties, acceptable resistance ratio, uniform resistive switching due to\nstable, less random filament formation/rupture and a control over the resistive\nswitching properties by choosing different stop voltages, which makes the\ndevice suitable for its application in future nonvolatile resistive random\naccess memory (ReRAM).", "category": "cond-mat.mtrl-sci"}, {"title": "Two-dimensional Iron Monocarbide with Planar Hypercoordinate Iron and Carbon", "abstract": "We report on the theoretical discovery of Iron monocarbide binary sheets\nstabilized at two-dimensional confined space, which we call tetragonal-FeC\n(t-FeC) and orthorhombic-FeC (o-FeC), respectively. From the energy viewpoint,\nthe proposed t-FeC is the global minimum configuration in the 2D space, and\neach carbon atom is four-coordinated with ambient four Iron atoms. Strikingly,\nthe o-FeC monolayer is an orthorhombic phase with planar pentacoordinate carbon\nmoiety and planar seven-coordinate Fe moiety. To our knowledge, this monolayer\nis the first example of a simultaneously pentacoordinate carbon and planar\nseven-coordinate Fe-containing material. State-of-the-art theoretical\ncalculations confirm that all these monolayers have significantly dynamic,\nmechanical, and thermal stabilities. Among these two monolayers, t-FeC\nmonolayer shows a higher theoretical capacity (395 mAh g-1 ), and can stably\nadsorb Li up to t-FeCLi3 . Low migration energy barrier is predicted as small\nas 0.26 eV for Li, which result in the fast diffusion of Li atom on this\nmonolayer. Moreover, electron-phonon calculations coupled with\nBardeen-Cooper-Schrieffer arguments suggest t-FeC can be potential\ntwo-dimensional superconductors with 6.77 K superconducting transition\ntemperature.", "category": "cond-mat.mtrl-sci"}, {"title": "Comment on the stability of decorated C 48 B 12 heterofullerene", "abstract": "A good hydrogen storage material should adsorb hydrogen in high\nconcentrations and with optimal binding energies. Numerous mixed carbon boron\nfullerenes which are decorated with metal atoms were previously constructed by\nhand and proposed as a promising material in this context. We present a fully\nab-initio, unbiased structure search in the configurational space of decorated\nC48B12 and find that most of the hitherto postulated ground state structures\nare not ground states. We determine the energetically lowest configurations for\nBe, Ca, Li and Sc decorated C48B12 clusters.", "category": "cond-mat.mtrl-sci"}, {"title": "Heusler, Weyl, and Berry", "abstract": "Heusler materials, initially discovered by Fritz Heusler more than a century\nago, have grown into a family of more than 1000 compounds, synthesized from\ncombinations of more than 40 elements. These materials show a wide range of\nproperties, but new properties are constantly being found. Most recently, by\nincorporating heavy elements that can give rise to strong spin-orbit coupling\n(SOC), non-trivial topological phases of matter, such as topological insulators\n(TIs), have been discovered in Heusler materials. Moreover, the interplay of\nsymmetry, SOC and magnetic structure allows for the realization of a wide\nvariety of topological phases through Berry curvature design. Weyl points and\nnodal lines can be manipulated by various external perturbations, which results\nin exotic properties such as the chiral anomaly, and large anomalous spin and\ntopological Hall effects. The combination of a non-collinear magnetic structure\nand Berry curvature gives rise a non-zero anomalous Hall effect, which was\nfirst observed in the antiferromagnets Mn3Sn and Mn3Ge. Besides this k-space\nBerry curvature, Heusler compounds with non-collinear magnetic structures also\npossess real-space topological states in the form of magnetic antiskyrmions,\nwhich have not yet been observed in other materials. The possibility of\ndirectly manipulating the Berry curvature shows the importance of understanding\nboth the electronic and magnetic structures of Heusler compounds. Together,\nwith the new topological viewpoint and the high tunability, novel physical\nproperties and phenomena await discovery in Heusler compounds.", "category": "cond-mat.mtrl-sci"}, {"title": "Spontaneous decay of a soft optical phonon in the relaxor ferroelectric PbMg$_{1/3}$Nb$_{2/3}$O$_{3}$", "abstract": "We report the spontaneous decay of a soft, optical phonon in a solid. Using\nneutron spectroscopy, we find that specific phonon lifetimes in the relaxor\nPbMg$_{1/3}$Nb$_{2/3}$O$_{3}$ are anomalously short within well-defined ranges\nof energy and momentum. This behavior is independent of ferroelectric order and\noccurs when the optical phonon with a specific energy and momentum can\nkinematically decay into two acoustic phonons with lower phase velocity. We\ninterpret the well-known relaxor \"waterfall\" effect as a form of quasiparticle\ndecay analogous to that previously reported in quantum spin liquids and quantum\nfluids.", "category": "cond-mat.mtrl-sci"}, {"title": "Discovery of switchable weak topological insulator state in quasi-one-dimensional bismuth iodide", "abstract": "The major breakthroughs in the understanding of topological materials over\nthe past decade were all triggered by the discovery of the Z$_2$ topological\ninsulator (TI). In three dimensions (3D), the TI is classified as either\n\"strong\" or \"weak\", and experimental confirmations of the strong topological\ninsulator (STI) rapidly followed the theoretical predictions. In contrast, the\nweak topological insulator has so far eluded experimental verification, since\nthe topological surface states emerge only on particular side surfaces which\nare typically undetectable in real 3D crystals. Here we provide experimental\nevidence for the WTI state in a bismuth iodide, $\\beta$-Bi4I4. Significantly,\nthe crystal has naturally cleavable top and side planes both stacked via\nvan-der-Waals forces, which have long been desirable for the experimental\nrealization of the WTI state. As a definitive signature of it, we find quasi-1D\nDirac TSS at the side-surface (100) while the top-surface (001) is\ntopologically dark. Furthermore, a crystal transition from the $\\beta$- to\n$\\alpha$-phase drives a topological phase transition from a nontrivial WTI to\nthe trivial insulator around room temperature. This topological phase, viewed\nas quantum spin Hall (QSH) insulators stacked three-dimensionally, and\nexcellent functionality with on/off switching will lay a foundation for new\ntechnology benefiting from highly directional spin-currents with large density\nprotected against backscattering.", "category": "cond-mat.mtrl-sci"}, {"title": "Spin-orbit torque and spin pumping in YIG/Pt with interfacial insertion layers", "abstract": "We experimentally investigate spin-orbit torque and spin pumping in\nY$_3$Fe$_5$O$_{12}$(YIG)/Pt bilayers with ultrathin insertion layers at the\ninterface. An insertion layer of Cu suppresses both spin-orbit torque and spin\npumping, whereas an insertion layer of Ni$_{80}$Fe$_{20}$ (permalloy, Py)\nenhances them, in a quantitatively consistent manner with the reciprocity of\nthe two spin transmission processes. However, we observe a large enhancement of\nGilbert damping with the insertion of Py that cannot be accounted for solely by\nspin pumping, suggesting significant spin-memory loss due to the interfacial\nmagnetic layer. Our findings indicate that the magnetization at the YIG-metal\ninterface strongly influences the transmission and depolarization of pure spin\ncurrent.", "category": "cond-mat.mtrl-sci"}, {"title": "First-principles investigation of graphene/MoS2 bilayer heterostructures using Tkatchenko-Scheffler van der Waals method", "abstract": "Graphene/MoS$_2$ van der Waals (vdW) heterostructures have promising\ntechnological applications due to their unique properties and functionalities.\nMany experimental and theoretical research groups across the globe have made\noutstanding contributions to benchmark the properties of graphene/MoS$_2$\nheterostructures. Even though some research groups have already made an attempt\nto model the graphene/MoS$_2$ heterostructures using {\\it first-principles}\ncalculations, there exists several discrepancies in the results from different\ntheoretical research groups and the experimental findings. In the present work,\nwe revisit this problem by first principles approach and address the existing\ndiscrepancies about the interlayer spacing between graphene and MoS$_2$\nmonolayers in graphene/MoS$_2$ heterostructures, and the location of Dirac\npoints near Fermi-level. We find that the Tkatchenko--Scheffler method\nefficiently evaluates the long-range vdW interactions and accurately predicts\ninterlayer spacing between graphene and MoS$_2$ sheets. We further investigate\nthe electronic, mechanical and vibrational properties of the optimized\ngraphene/MoS$_2$ heterostructures created using 5$\\times$5/4$\\times$4 and\n4$\\times$4/3$\\times$3 supercell geometries having different magnitudes of\nlattice mismatch. The effect of the varying interlayer spacing on the\nelectronic properties of heterostructures is discussed. Our phonon calculations\nreveal that the interlayer shear and breathing phonon modes, which are very\nsensitive to the weak vdW interactions, play vital role in describing the\nthermal properties of the studied systems. The thermodynamic and elastic\nproperties of heterostructures are further discussed. A comparison between our\nresults and the results reported from other research groups is presented.", "category": "cond-mat.mtrl-sci"}, {"title": "Unravelling the origin of piezo/ferro-electric properties of metal-organic frameworks (MOFs) nanocrystals", "abstract": "Metal-organic framework (MOF) UiO-66 nanocrystals were previously believed to\nbe piezo/ferro-electrically inactive because of their centrosymmetric lattice\nsymmetries (Fm-3m (225)) revealed by Powder X-ray diffraction. However, via\ndelicate dual AC resonance tracking piezoresponse force microscopy and\npiezoresponse force spectroscopy characterizations, our nanoscale probing for\nthe first time demonstrate that UiO-66 nanocrystals show piezo/ferro-electric\nresponse. Our compelling experimental and theoretically analyses disclose that\nthe structure of UiO-66 should not be the highly centrosymmetric Fm-3m (225)\nbut a reduced symmetry form instead. UiO-66(Hf)-type MOFs possess stronger\npiezoresponse and better ferroelectric switching behaviours than their\ncounterparts UiO-66 (Zr)-type MOFs. Our study not only enriches the structural\nunderstanding of UiO-66 MOF, but also suggests possible modification of\nelectronic property of the MOFs by judicious selection of metal ions and\nfunctional ligands.", "category": "cond-mat.mtrl-sci"}, {"title": "Spectroscopic evidence of topological phase transition in 3D Dirac semimetal Cd$_3$(As$_{1-x}$P$_x$)$_2$", "abstract": "We study the low-energy electronic structure of three-dimensional Dirac\nsemimetal, Cd$_3$(As$_{1-x}$P$_x$)$_2$ [$x$ = 0 and 0.34(3)], by employing the\nangle-resolved photoemission spectroscopy (ARPES). We observe that the bulk\nDirac states in Cd$_3$(As$_{0.66}$P$_{0.34}$)$_2$ are gapped out with an energy\nof 0.23 eV, contrary to the parent Cd$_3$As$_2$ in which the gapless Dirac\nstates have been observed. Thus, our results confirm the earlier predicted\ntopological phase transition in Cd$_3$As$_2$ with perturbation. We further\nnotice that the critical P substitution concentration, at which the two Dirac\npoints that are spread along the $c$-axis in Cd$_3$As$_2$ form a single Dirac\npoint at $\\Gamma$, is much lower [x$_c$(P)$<$ 0.34(3)] than the predicted value\nof x$_c$(P)=0.9. Therefore, our results suggest that the nontrivial band\ntopology of Cd$_3$As$_2$ is remarkably sensitive to the P substitution and can\nonly survive over a narrow substitution range, i.e., 0 $\\leq$ x (P) $<$\n0.34(3).", "category": "cond-mat.mtrl-sci"}, {"title": "Elastic modeling of point-defects and their interaction", "abstract": "Different descriptions used to model a point-defect in an elastic continuum\nare reviewed. The emphasis is put on the elastic dipole approximation, which is\nshown to be equivalent to the infinitesimal Eshelby inclusion and to the\ninfinitesimal dislocation loop. Knowing this elastic dipole, a second rank\ntensor fully characterizing the point-defect, one can directly obtain the\nlong-range elastic field induced by the point-defect and its interaction with\nother elastic fields. The polarizability of the point-defect, resulting from\nthe elastic dipole dependence with the applied strain, is also introduced.\nParameterization of such an elastic model, either from experiments or from\natomic simulations, is discussed. Different examples, like elastodiffusion and\nbias calculations, are finally considered to illustrate the usefulness of such\nan elastic model to describe the evolution of a point-defect in a external\nelastic field.", "category": "cond-mat.mtrl-sci"}, {"title": "Indole moiety induced biological potency in pseudo- peptides derived from 2-amino-2-(1H-indole-2-yl) based acetamides: synthesis, structure and computational investigations", "abstract": "We report the synthesis and theoretical investigations of three novel\npseudo-peptide molecules derived from 2-amino-2-(1H-indole-2-yl) acetamides.\nThe compounds were subjected to spectroscopic characterization ($^1$H,\n$^{13}$C-NMR and MS) and their chemical, electronic, and optical properties\nhave been investigated. To ascertain their potential pharmacological\napplicability, the prospective reactive centers and molecular sites prone to\ninteraction with water were identified along with possible sensitivity to\nautoxidation. Further, we have studied the optical response in the presence of\ndifferent solvents and compared the electronic and optical properties of the\npristine molecules. We highlight the subtle dependence of the properties on the\nstructure and composition of these pseudo-peptides. Our results indicate that\nthese molecules have high pharmaceutical potential and could serve as lead\ncomponents in new drug formulations.", "category": "cond-mat.mtrl-sci"}, {"title": "High Mobility 2DEG in modulation-doped \\b{eta}-(AlxGa1-x)2O3/Ga2O3 heterostructures", "abstract": "Beta-phase Ga2O3 has emerged as a promising candidate for a wide range of\ndevice applications, including power electronic devices, radio-frequency\ndevices and solar-blind photodetectors. The wide bandgap energy and the\npredicted high breakdown field, together with the availability of low-cost\nnative substrates, make \\b{eta}-Ga2O3 a promising material compared to other\nconventional wide bandgap materials, such as GaN and SiC. Alloying of Al with\n\\b{eta}-Ga2O3 could enable even larger band gap materials, and provide more\nflexibility for electronic and optoelectronic device design. In this work, we\ndemonstrate a high mobility two-dimensional electron gas (2DEG) formed at the\n\\b{eta}-(AlxGa1-x)2O3/Ga2O3 interface through modulation doping. Shubnikov-de\nHaas oscillation was observed for the first time in the modulation-doped\n\\b{eta}-(AlxGa1-x)2O3/Ga2O3 structure, indicating a high-quality channel formed\nat the heterojunction interface. The formation of the 2DEG channel was further\nconfirmed by a weak temperature-dependence of the carrier density, and the peak\nlow temperature mobility was found to be 2790 cm2/Vs, which is significantly\nhigher than can be achieved in bulk-doped \\b{eta}-Ga2O3. The demonstrated\nmodulation-doped \\b{eta}-(AlxGa1-x)2O3/Ga2O3 structure lays the foundation for\nfuture exploration of quantum physical phenomena as well as new semiconductor\ndevice technologies based on the \\b{eta}-Ga2O3 material system.", "category": "cond-mat.mtrl-sci"}, {"title": "Multiple-Modes Scanning Probe Microscopy Characterization of Copper doped Zinc Oxide (ZnO:Cu) Thin Films", "abstract": "This paper presents multiple-modes Scanning Probe Microscopy (SPM) studies on\ncharacterize resistance switching (RS), polarization rotation (PO) and surface\npotential changes in copper doped ZnO (ZnO:Cu) thin films. The bipolar RS\nbehavior is confirmed by conductive Atomic Force Microscopy (c-AFM). The PO\nwith almost 180{\\deg} phase angle is confirmed by using the vertical and\nlateral Piezoresponse Force Microscopy (PFM). In addition, it elucidates that\nobvious polarization rotation behavior can be observed in the sample with\nincreasing Cu concentration. Furthermore, correlation of the RS behavior with\nPO behavior has been studied by performing various mode SPM measurements on the\nsame location. The electric field resulted from the opposite polarization\norientation are corresponded to the different resistance states. It is found\nthat the region with the polarization in downward direction has low resistance\nstate (LRS), whereas the region with upward polarization has high resistance\nstate (HRS). In addition, the Piezoresponse Force Spectroscopy (PFS) and\nSwitching Spectroscopy PFM (SS-PFM) measurements further confirm that the\nexistence of the built-in field due to the uncomplemented polarization may\naffect the depletion region and hence contribute to the RS behavior. In\naddition, Kelvin Probe Force Microscopy (KPFM) results show that, when\nZnO-based thin films is subjected to negative and then followed by positive\nsample bias, injection charge limit current is dominated.", "category": "cond-mat.mtrl-sci"}, {"title": "Effect of support on the vanadyl oxygen abstraction in supported vanadia", "abstract": "Supported vanadia catalysts are modeled within the cluster DFT approach to\nget an insight into the mechanism in which the support affects the activity of\nvanadia in the oxidation processes. The energy of the V=O group dissociation\nchosen as a descriptor of the oxidation activity is estimated using two aligned\ndivanadate V2O3(OH)4 particles at various distances. Separation between\nparticles allows to imitate (i) the various supporting materials (e.g. TiO2,\nSiO2, etc.), and (ii) the coverage of vanadia on a particular support. A\nsubstantial compensation of the energy loss upon the vanadyl oxygen abstraction\nvia bonding to the vanadyl oxygen of neighboring vanadate particle has been\npredicted. On account of such compensation the overall energy of the V=O\ndissociation reaches its minimal value of 36 kcal/mol (dropping from maximum of\n142 kcal/mol) at small separation of 3 {\\AA} between dimers when the nearest\nvanadyl oxygen occupies a bridge V-O-V position. For dimers separated by about\n4 {\\AA}, the dissociation energy achieves its maximal value for isolated dimers\nof about 143 kcal/mol. Thus, these findings allows one to conclude that the\noxygen mobility is a result of a compensation effect in a chain-like bonding\nbetween neighboring vanadyl groups on the surface of support.", "category": "cond-mat.mtrl-sci"}, {"title": "Excitation of coherent optical phonons in iron garnet by femtosecond laser pulses", "abstract": "We employed femtosecond pump probe technique to investigate the dynamics of\ncoherent optical phonons in iron garnet. A phenomenological symmetry-based\nconsideration reveals that oscillations of the terahertz T2g mode are excited.\nSelective excitation by a linearly polarized pump and detection by a circularly\npolarized probe confirm that impulsive stimulated Raman scattering (ISRS) is\nthe driving force for the coherent phonons. Experimental results obtained from\nISRS measurements reveal excellent agreement with spontaneous Raman\nspectroscopy data, analyzed by considering the symmetry of the phonon modes and\ncorresponding excitation and detection selection rules.", "category": "cond-mat.mtrl-sci"}, {"title": "Pressure-Induced Topological Phase Transitions in CdGeSb$_2$ and CdSnSb$_2$", "abstract": "Topological quantum phase transitions (TQPTs) in a material induced by\nexternal perturbations are often characterized by band touching points in the\nBrillouin zone. The low-energy excitations near the degenerate band touching\npoints host different types of fermions while preserving the topological\nprotection of surface states. An interplay of different tunable topological\nphases offers an insight into the evolution of the topological character. In\nthis paper, we study the occurrence of TQPTs as a function of hydrostatic\npressure in CdGeSb$_2$ and CdSnSb$_2$ chalcopyrites, using the first-principles\ncalculations. At ambient pressure, both materials are topological insulators\nhaving a finite band gap with inverted order of Sb-$s$ and Sb-$p_x$,$p_y$\norbitals of valence bands at the $\\Gamma$ point. On the application of\nhydrostatic pressure the band gap reduces, and at the critical point of the\nphase transition, these materials turn into Dirac semimetals. On further\nincreasing the pressure beyond the critical point, the band inversion is\nreverted making them trivial insulators. The pressure-induced change in band\ntopology from non-trivial to trivial phase is also captured by L\\\"{u}ttinger\nmodel Hamiltonian calculations. Our model demonstrates the critical role played\nby a pressure-induced anisotropy in frontier bands in driving the phase\ntransitions. These theoretical findings of peculiar coexistence of multiple\ntopological phases in the same material provide a realistic and promising\nplatform for the experimental realization of the TQPT.", "category": "cond-mat.mtrl-sci"}, {"title": "Hybrid mean field and real space model for vacancy diffusion-mediated annealing of radiation defects", "abstract": "In a fusion or advanced fission reactor, high energy neutrons induce the\nformation of extended defect clusters in structural component materials,\ndegrading their properties over time. Such damage can be partially recovered\nvia a thermal annealing treatment. Therefore, for the design and operation of\nfusion and advanced fission nuclear energy systems it is critical to estimate\nand predict the annealing timescales for arbitrary configurations of defect\nclusters. In our earlier paper [I. Rovelli, S. L. Dudarev, and A. P. Sutton, J.\nMech. Phys. Solids 103, 121 (2017)] we extended the Green function formulation\nby Gu, Xiang et al. [Y. Gu, Y. Xiang, S. S. Quek, and D. J. Srolovitz, J. Mech.\nPhys. Solids 83, 319 (2015)] for the climb of curved dislocations, to include\nthe evaporation and growth of cavities and vacancy clusters, and take into\naccount the effect of free surfaces. In this work, we further develop this\nmodel to include the effect of radiation defects that are below the\nexperimental detection limit, via a mean field approach coupled with an\nexplicit treatment of the evolution of discrete defect clusters distributed in\nreal space. We show that randomly distributed small defects screen diffusive\ninteractions between larger discrete clusters. The evolution of the coupled\nsystem is modelled self-consistently. We also simulate the evolution of defects\nin an infinite laterally extended thin film, using the Ewald summation of\nscreened Yukawa-type diffusive propagators.", "category": "cond-mat.mtrl-sci"}, {"title": "Approach combining the Rietveld method and pairs distribution function analysis to study crystalline materials under high-pressure and/or temperature", "abstract": "An approach combining the Rietveld method and pairs distribution function\nanalysis was developed and can help to understand the effect of temperature\nand/or high-pressure on crystalline materials. It was applied to orthorhombic\nTa2O5 compound, and the obtained results were compared with the experimental\npairs distribution function reported in the literature, and an excellent\nagreement was reached. The approach permitted to simulate average pairs\ndistribution functions GTa-Ta(R), GTa-O(R), and GO-O(R) and the average radial\ndistribution functions RDFTa-Ta(R), RDFTa-O(R), and RDFO-O(R). The coordination\nnumbers for the first neighbors were obtained, and used in the expression to\ncalculate the Cowley-Warren chemical short-range order parameter {\\alpha}CW .\nThe calculated value suggests a preference for forming homopolar pairs in the\nfirst coordination shell. Previous study on the effect of high-pressure on\northorhombic Ta2O5 showed a pressure-induced amorphization process. This\namorphization can be associated with the preference for forming homopolar pairs\nin the first coordination shell.", "category": "cond-mat.mtrl-sci"}, {"title": "Attosecond dispersive soft X-ray absorption fine structure spectroscopy in graphite", "abstract": "Phase transitions of solids and structural transformations of molecules are\ncanonical examples of important photo-induced processes, whose underlying\nmechanisms largely elude our comprehension due to our inability to correlate\nelectronic excitation with atomic position in real time. Here, we present a\ndecisive step towards such new methodology based on water-window-covering (284\neV to 543 eV) attosecond soft X-ray pulses that can simultaneously access\nelectronic and lattice parameters via dispersive X-ray absorption\nfine-structure (XAFS) spectroscopy. We validate attoXAFS with an identification\nof the {\\sigma}* and {\\pi}* orbital contributions to the density of states in\ngraphite simultaneously with its lattice's four characteristic bonding\ndistances. This work demonstrates the concept of attoXAFS as a powerful\nreal-time investigative tool which is equally applicable to gas-, liquid- and\ncondensed phase.", "category": "cond-mat.mtrl-sci"}, {"title": "Implanting germanium into graphene", "abstract": "Incorporating heteroatoms into the graphene lattice may be used to tailor its\nelectronic, mechanical and chemical properties. Direct substitutions have thus\nfar been limited to incidental Si impurities and P, N and B dopants introduced\nusing low-energy ion implantation. We present here the heaviest impurity to\ndate, namely $^{74}$Ge$^+$ ions implanted into monolayer graphene. Although\nsample contamination remains an issue, atomic resolution scanning transmission\nelectron microscopy imaging and quantitative image simulations show that Ge can\neither directly substitute single atoms, bonding to three carbon neighbors in a\nbuckled out-of-plane configuration, or occupy an in-plane position in a\ndivacancy. First principles molecular dynamics provides further atomistic\ninsight into the implantation process, revealing a strong chemical effect that\nenables implantation below the graphene displacement threshold energy. Our\nresults show that heavy atoms can be implanted into the graphene lattice,\npointing a way towards advanced applications such as single-atom catalysis with\ngraphene as the template.", "category": "cond-mat.mtrl-sci"}, {"title": "Designing and discovering a new family of semiconducting quaternary Heusler compounds based on the 18-electron rule", "abstract": "Intermetallic compounds with sizable band gaps are attractive for their\nunusual properties but rare. Here, we present a new family of stable\nsemiconducting quaternary Heusler compounds, designed and discovered by means\nof high-throughput \\textit{ab initio} calculations based on the 18-electron\nrule. The 99 new semiconductors reported here adopt the ordered quaternary\nHeusler structure with the prototype of LiMgSnPd (F$\\bar{\\mathbf{4}}$3m,\nNo.\\,216) and contain 18 valence electrons per formula unit. They are realized\nby filling the void in the half Heusler structure with a small and\nelectropositive atom, i.e., lithium. These new stable quaternary Heusler\nsemiconductors possess a range of band gaps from 0.3 to 2.5\\,eV, and exhibit\nsome unusual properties different from conventional semiconductors, such as\nstrong optical absorption, giant dielectric screening, and high Seebeck\ncoefficient, which suggest these semiconductors have potential applications as\nphotovoltaic and thermoelectric materials. While this study opens up avenues\nfor further exploration of this novel class of semiconducting quaternary\nHeuslers, the design strategy used herein is broadly applicable across a\npotentially wide array of chemistries to discover new stable materials.", "category": "cond-mat.mtrl-sci"}, {"title": "Material, size and environment dependence of plasmon-induced hot carriers in metallic nanoparticles", "abstract": "Harnessing hot electrons and holes resulting from the decay of localized\nsurface plasmons in nanomaterials has recently led to new devices for\nphotovoltaics, photocatalysis and optoelectronics. Properties of hot carriers\nare highly tunable and in this work we investigate their dependence on the\nmaterial, size and environment of spherical metallic nanoparticles. In\nparticular, we carry out theoretical calculations of hot carrier generation\nrates and energy distributions for six different plasmonic materials (Na, K,\nAl, Cu, Ag and Au). The plasmon decay into hot electron-hole pairs is described\nvia Fermi's Golden Rule using the quasistatic approximation for optical\nproperties and a spherical well potential for the electronic structure. We\npresent results for nanoparticles with diameters up to 40 nm, which are\nembedded in different dielectric media. We find that small nanoparticles with\ndiameters of 16 nm or less in media with large dielectric constants produce\nmost hot carriers. Among the different materials, Na, K and Au generate most\nhot carriers. We also investigate hot-carrier induced water splitting and find\nthat simple-metal nanoparticles are useful for initiating the hydrogen\nevolution reaction, while transition-metal nanoparticles produce dominantly\nholes for the oxygen evolution reaction.", "category": "cond-mat.mtrl-sci"}, {"title": "Engineering Dzyaloshinskii-Moriya interaction in B20 thin film chiral magnets", "abstract": "Chiral magnetic Mn$_x$Fe$_{1-x}$Ge compounds have an antisymmetric exchange\ninteraction that is tunable with the manganese stoichiometric fraction, $x$.\nAlthough millimeter-scale, polycrystalline bulk samples of this family of\ncompounds have been produced, thin-film versions of these materials will be\nnecessary for devices. In this study, we demonstrate the growth of epitaxial\nMn$_x$Fe$_{1-x}$Ge thin films on Si (111) substrates with a pure B20 crystal\nstructure in the stoichiometric fraction range x from 0 to 0.81. Following\nsystematic physical and magnetic characterization including microwave\nabsorption spectroscopy, we quantify the antisymmetric exchange interaction and\nhelical period as a function of $x$, which ranges from 200 nm to 8 nm. Our\nresults demonstrate an approach to engineering the size of magnetic skyrmions\nin epitaxial films that are grown using scalable techniques.", "category": "cond-mat.mtrl-sci"}, {"title": "Geometry- and field-diversified electronic and optical properties in bilayer silicene", "abstract": "The generalized tight-binding model has been developed to thoroughly explore\nthe essential electronic and optical properties of AB-bt bilayer silicene. They\nare greatly diversified by the buckled structure, stacking configuration,\nintralayer and interlayer hopping integrals, spin-orbital couplings; electric\nand magnetic fields (${E_z\\hat z}$ $\\&$ ${B_z\\hat z}$). There exist the linear,\nparabolic and constant-energy-loop dispersions, multi-valley band structure and\nsemiconductor-metal transition as $E_z$ varies. The $E_z$-dependent magnetic\nquantization exhibits the rich and unique Landau Levels (LLs) and\nmagneto-optical spectra. The LLs have the lower degeneracy, valley-created\nlocalization centers, unusual distributions of quantum numbers, well-behaved\nand abnormal energy spectra in $B_z$-dependences, and the absence of\nanti-crossing behavior. A lot of pronounced magneto-absorption peaks occur at a\nvery narrow frequency range, being attributed to diverse excitation categories.\nThey have no specific selection rules except that the Dirac-cone band\nstructures are driven by the critical electric fields. The optical gaps are\nreduced by $E_z$, but enhanced by $B_z$, in which the threshold channel might\ndramatically change in the formed case. The above-mentioned characteristics are\nin sharp contrast with those of layered graphenes.", "category": "cond-mat.mtrl-sci"}, {"title": "Performance of Tao-Mo semilocal density functional in projector-augmented-wave method", "abstract": "We assess the performance of Tao-Mo semilocal exchange correlation (TM)\nfunctional [J. Tao and Y. Mo, Phys. Rev. Lett. 117, 073001 (2016)] using\nprojector-augmented-wave method with the plane wave basis set in Vienna ab\ninitio simulation package (VASP). The meta-GGA level semilocal functional TM is\nan all purpose exchange-correlation functional which performs accurately for\nthe wide range of molecular and solid state properties. The exchange functional\npart of TM is designed from the density matrix expansion (DME) technique\ntogether with the slowly varying fourth order gradient expansion. The\ncorrelation functional of the corresponding exchange is based on\nTao-Perdew-Staroverov-Scuseria (TPSS) functional. We assess the performance of\nTM for solid state lattice constants, bulk moduli, band gaps, cohesive energies\nand magnetic moments of solids. It has been established that in plane wave\nbasis the TM functional performs accurately in predicting all the solid state\nproperties in semilocal level.", "category": "cond-mat.mtrl-sci"}, {"title": "Double Indirect Interlayer Exciton in a MoSe2/WSe2 van der Waals Heterostructure", "abstract": "An emerging class of semiconductor heterostructures involves stacking\ndiscrete monolayers such as the transition metal dichalcogenides (TMDs) to form\nvan der Waals heterostructures. In these structures, it is possible to create\ninterlayer excitons (ILEs), spatially indirect, bound electron-hole pairs with\nthe electron in one TMD layer and the hole in an adjacent layer. We are able to\nclearly resolve two distinct emission peaks separated by 24 meV from an ILE in\na MoSe2/WSe2 heterostructure fabricated using state-of-the-art preparation\ntechniques. These peaks have nearly equal intensity, indicating they are of\ncommon character, and have opposite circular polarizations when excited with\ncircularly polarized light. Ab initio calculations successfully account for\nthese observations - they show that both emission features originate from\nexcitonic transitions that are indirect in momentum space, are split by\nspin-orbit coupling, and that including interlayer hybridization is essential\nin correctly describing the ILE transition. Although well separated in momentum\nspace, we find that in real space the electron has significant weight in both\nthe MoSe2 and WSe2 layers, contrary to the commonly assumed model. This is a\nsignificant consideration for understanding the static and dynamic properties\nof TMD heterostructures.", "category": "cond-mat.mtrl-sci"}, {"title": "Dynamic Surface Modification due to Effusion of Na in Na$_2$IrO$_3$", "abstract": "The honeycomb lattice iridate Na$_2$IrO$_3$ shows frustrated magnetism and\ncan potentially display Kitaev-like exchange interactions. Recently, it was\nshown that the electronic properties of the surface of crystalline\nNa$_2$IrO$_3$ can be tuned by Ar plasma treatment in a controlled manner\nleading to various phases of matter ranging from a fully gapped to a metallic\nsurface, where the possibility of a charge-density wave (CDW) like transition\nis also expected. Here, through direct imaging with an atomic force microscope\n(AFM) in air, we show that the surface of crystalline Na$_2$IrO$_3$ evolves\nrapidly as elemental Na effuses out of the interleave planes to the surface and\nundergoes sublimation thereby disappearing from the surface gradually over\ntime. Using conductive AFM we recorded a series of topographs and surface\ncurrent maps simultaneously and found that the modification of the surface\nleads to change in the electronic properties in a dynamic fashion until the\nwhole system reaches a dynamic equilibrium. These observations are important in\nthe context of the exotic electronic and magnetic properties that the surface\nof Na$_2$IrO$_3$ displays.", "category": "cond-mat.mtrl-sci"}, {"title": "A Theory of Growing Crystalline Nanorods - Mode I", "abstract": "Nanorods grow in two modes through physical vapor deposition (PVD). In mode\nI, monolayer surface steps dictate the diameter of nanorods. In mode II,\nmultiple-layer surface steps dictate the diameter, which is the smallest\npossible under physical vapor deposition [X. B. Niu et al., Phys. Rev. Lett\n110, 136102 (2013) and F. Du & H. C. Huang, Phys. Rev. Materials. 1, 033401\n(2017)]. This paper reports closed-form theories of terrace lengths and nanorod\ndiameter during the growth in mode I, as a function of deposition conditions.\nThe accompanying lattice kinetic Monte Carlo simulations verify the theories.\nThis study reveals that (1) quasi-steady growth exists for each set of nanorod\ngrowth condition, (2) the characteristic length scales, including terrace\nlengths and nanorod diameter at the quasi-steady state, depend on the\ndeposition conditions - deposition rate F, substrate temperature T, and\nincidence angle .", "category": "cond-mat.mtrl-sci"}, {"title": "Establishing a microscopic model for nonfullerene organic solar cells: Self-accumulation effect of charges", "abstract": "A one-dimensional many-body model is established to mimic the charge\ndistribution and dynamics in nonfullerene organic solar cells. Two essential\nissues are taken into account in the model: The alternating donor and acceptor\nstructure and the local imbalance of the intrinsic electrons and holes. The\nalternating structure is beneficial for the direct generation of charge\ntransfer state which enhances the local imbalance of intrinsic charges. The\nmost remarkable outcome of the model is that, due to the strong Coulomb\nattractive potential energy, the intrinsic charges in the cells are\nself-accumulated in a small spatial region. Outside the self-accumulation\nregion, the charge density vanishes so that the recombination is regarded to be\nlargely suppressed. The photogenerated electrons are subsequently observed to\nspread freely outside the self-accumulation region implying the Coulomb\nattraction does not matter in the ultrafast charge separation dynamics. These\nfindings enable an appealing understanding of the high performance of emerging\nnonfullerene cells, and the designing rules of molecules and devices are then\ncomprehensively discussed.", "category": "cond-mat.mtrl-sci"}, {"title": "Origin of spin reorientation transitions in antiferromagnetic MnPt-based alloys", "abstract": "Antiferromagnetic MnPt exhibits a spin reorientation transition (SRT) as a\nfunction of temperature, and off-stoichiometric Mn-Pt alloys also display SRTs\nas a function of concentration. The magnetocrystalline anisotropy in these\nalloys is studied using first-principles calculations based on the coherent\npotential approximation and the disordered local moment method. The anisotropy\nis fairly small and sensitive to the variations in composition and temperature\ndue to the cancellation of large contributions from different parts of the\nBrillouin zone. Concentration and temperature-driven SRTs are found in\nreasonable agreement with experimental data. Contributions from specific\nband-structure features are identified and used to explain the origin of the\nSRTs.", "category": "cond-mat.mtrl-sci"}, {"title": "Dielectric properties of relaxor-ferroelectric ceramic and single crystal Pb(In$_{1/2}$Nb$_{1/2}$)O$_{3}$-Pb(Mg$_{1/3}$Nb$_{2/3}$)O$_{3}$-PbTiO$_{3}$ at cryogenic temperatures", "abstract": "We investigate the low temperature behaviour of\nPb(In$_{1/2}$Nb$_{1/2}$)O$_{3}$-Pb(Mg$_{1/3}$Nb$_{2/3}$)O$_{3}$-PbTiO$_{3}$\nusing dielectric permittivity measurements. We compare single crystal plates\nmeasured in the [001] and [111] directions with a polycrystalline ceramic of\nthe same composition. Poled crystals behave very differently to unpoled\ncrystals, whereas the dielectric spectrum of the ceramic changes very little on\npoling. A large, frequency dependent dielectric relaxation seen in the poled\n[001] crystal around 100 K is much less prominent in the [111] crystal, and\ndoesn't occur in the ceramic. Preparation conditions and the microstructure of\nthe material play a role in the low temperature dynamics of\nrelaxor-ferroelectric crystals.", "category": "cond-mat.mtrl-sci"}, {"title": "The mechanisms of hot salt stress corrosion cracking in titanium alloy Ti-6Al-2Sn-4Zr-6Mo", "abstract": "Hot salt stress corrosion cracking in Ti 6246 alloy has been investigated to\nelucidate the chemical mechanisms that occur. Cracking was found to initiate\nbeneath salt particles in the presence of oxidation. The observed transgranular\nfracture was suspected to be due to hydrogen charging; XRD and high-resolution\ntransmission electron microscopy detected the presence of hydrides that were\nprecipitated on cooling. SEM-EDS showed oxygen enrichment near salt particles,\nalongside chlorine and sodium. Aluminium and zirconium were also involved in\nthe oxidation reactions. The role of intermediate corrosion products such as\nNa2TiO3, Al2O3, ZrO2, TiCl2 and TiH are discussed.", "category": "cond-mat.mtrl-sci"}, {"title": "FeTaSb and FeMnTiSb as promising thermoelectric materials: An ab initio approach", "abstract": "Thermoelectricity in principle provides a pathway to put waste heat to good\nuse. Motivated by this we investigate thermal and electrical transport\nproperties of two new Fe-based Heusler alloys, FeTaSb and FeMnTiSb, by a first\nprinciples approach and semiclassical Boltzmann transport theory within the\nconstant relaxation-time approximation. We find a high power factor of\n\\textit{p}-doped FeTaSb, competitive with best performing Heusler alloy FeNbSb\nat 1100 K. The obtained power factor of \\textit{n}-doped FeMnTiSb at room\ntemperature is higher than that of both FeNbSb and FeTaSb. Remarkably, FeMnTiSb\ncan be used for both \\textit{n}-type and \\textit{p}-type legs in a\nthermoelectric module. The Seebeck coefficients of the two proposed systems are\nin line with those of earlier reported Heusler alloys. We also provide\nconservative estimates of the figure of merit for the two systems. Overall, our\nfindings suggest a high temperature thermoelectric potential of FeTaSb while\nthe low cost FeMnTiSb is a viable room temperature thermoelectric candidate\nmaterial.", "category": "cond-mat.mtrl-sci"}, {"title": "Large thermoelectric response in a diluted ferroelectric system: Ba0.7Eu0.3Ti1-xNbxO3", "abstract": "We investigated the electrical conductivity, thermal conductivity and\nthermopower as a function of Nb content (x) in Ba0.7Eu0.3Ti1-xNbxO3 (x = 0.001-\n0.10) in the temperature range T = 400-2 K. The substitution of Nb destabilizes\nthe ferroelectric insulating ground state of Ba0.7Eu0.3TiO3 and transforms into\na paramagnetic metal for x = 0.1. Thermopower is negative in the entire\ncomposition range (S = -613 microVolt/K at 400 K for x = 0.001) and its\nmagnitude decreases with increasing Nb content which suggests doping of\nelectrons into empty Ti-3d(t2g) conduction band. In this series, the\ndimensionless figure of merit (ZT) increases with temperature for all the\ncompositions and the x = 0.03 composition exhibits the maximum ZT (= 0.12 at\n400 K). The enhanced value of ZT is primarily due to the low thermal\nconductivity of samples in this series (~ 0.7 to 1 W/(m.K) at 400 K) compared\nto other potential high temperature n-type thermoelectric oxides such as\ncarrier doped SrTiO3 and CaMnO3. The low thermal conductivity in our compounds\nmost likely arises from heavy Eu2+ ion and lattice disorder introduced by Nb5+\nwhich scatter phonons effectively.", "category": "cond-mat.mtrl-sci"}, {"title": "Superior Structural, Elastic and Electronic Properties of 2D Titanium Nitride MXenes Over Carbide MXenes: A Comprehensive First Principles Study", "abstract": "The structural, elastic and electronic properties of two-dimensional (2D)\ntitanium carbide/nitride based pristine (Tin+1Cn/Tin+1Nn) and functionalized\nMXenes (Tin+1CnT2/Tin+1NnT2, T stands for the terminal groups: -F, -O and -OH,\nn = 1, 2, 3) are investigated by density functional theory calculations.\nCarbide-based MXenes possess larger lattice constants and monolayer thicknesses\nthan nitride-based MXenes. The in-plane Young's moduli of Tin+1Nn are larger\nthan those of Tin+1Cn, whereas in both systems they decrease with the increase\nof the monolayer thickness. Cohesive energy calculations indicate that MXenes\nwith a larger monolayer thickness have a better structural stability.\nAdsorption energy calculations imply that Tin+1Nn have stronger preference to\nadhere to the terminal groups, which suggests more active surfaces for\nnitride-based MXenes. More importantly, nearly free electron states are\nobserved to exist outside the surfaces of -OH functionalized carbide/nitride\nbased MXenes, especially in Tin+1Nn(OH)2, which provide almost perfect\ntransmission channels without nuclear scattering for electron transport. The\noverall electrical conductivity of nitride-based MXenes is determined to be\nhigher than that of carbide-based MXenes. The exceptional properties of\ntitanium nitride-based MXenes, including strong surface adsorption, high\nelastic constant and Young's modulus, and good metallic conductivity, make them\npromising materials for catalysis and energy storage applications.", "category": "cond-mat.mtrl-sci"}, {"title": "Dielectric Properties of Metal-Organic Frameworks Probed via Synchrotron Infrared Reflectivity", "abstract": "We present the frequency-dependant (dynamic) dielectric response of a group\nof topical polycrystalline zeolitic imidazolate-based metal-organic framework\n(MOF) materials in the extended infrared spectral region. Using\nsynchrotron-based FTIR spectroscopy in specular reflectance, in conjunction\nwith density functional theory (DFT) calculations, we have revealed detailed\nstructure-property trends linking the THz region dielectric response to\nframework porosity and structural density. The work demonstrates that MOFs are\npromising candidate materials not only for low-\\k{appa} electronics\napplications but could also be pioneering for terahertz (THz) applications,\nsuch as next-generation broadband communications technologies.", "category": "cond-mat.mtrl-sci"}, {"title": "Borderline Magnetism: How Does Adding Magnesium to Paramagnetic CeCo$_3$ Make a 450 K Ferromagnet with Large Magnetic Anisotropy?", "abstract": "A recent experimental study (Phys. Rev. Appl. 9, 024023, 2018) on\nparamagnetic CeCo$_3$ finds that Magnesium alloying induces a ferromagnetic\ntransition with intrinsic properties large enough for permanent magnet\napplications. Here we explain these surprising results \\textit{via} a first\nprinciples study of the electronic structure and magnetism of Magnesium-alloyed\nCeCo$_3$. We find the origin of this Magnesium-induced ferromagnetic transition\nto be Stoner physics - the substantial increase in the Fermi-level\ndensity-of-states $N(E_F)$ with Mg alloying. Our calculations suggest that both\nCe and Co atoms are important for generating large magnetic anisotropy\nsuggesting the viability of Co-3$d$, and Ce-4$f$ interaction for the generation\nof magnetic anisotropy in magnetic materials. These results offer a new route\nto the discovery of ferromagnetic materials and provide fundamental insight\ninto the magnetic properties of these alloys", "category": "cond-mat.mtrl-sci"}, {"title": "$GW$ self-screening error and its correction using a local density functional", "abstract": "The self-screening error in electronic structure theory is the part of the\nself-interaction error that would remain within the $GW$ approximation if the\nexact dynamically screened Coulomb interaction, $W$, were used, causing each\nelectron to artificially screen its own presence. This introduces error into\nthe electron density and ionization potential. We propose a simple,\ncomputationally efficient correction to $GW$ calculations in the form of a\nlocal density functional, obtained using a series of finite training systems;\nin tests, this eliminates the self-screening errors in the electron density and\nionization potential.", "category": "cond-mat.mtrl-sci"}, {"title": "Hill plot focusing on Ce compounds with high magnetic-ordering-temperatures and consequent study of Ce2AuP3", "abstract": "Hill plot is a well-known criterion of the f-electron element interatomic\nthreshold-distance separating the nonmagnetic state from the magnetic one in\nactinides or lanthanides. We have reinvestigated the Hill plot of Ce compounds\nusing a commercial crystallographic database CRYSTMET, focusing on a\nrelationship between the Ce-Ce distance and the magnetic ordering temperature,\nbecause a Ce compound with no other magnetic elements scarcely has a magnetic\nordering temperature higher than 20 K. The Hill plot of approximately 730\ncompounds has revealed that a Ce compound, especially for ferromagnet, showing\nthe high magnetic-ordering-temperature would require a short Ce-Ce distance\nwith a suppression of valence instability of Ce ion. Through the study, we had\ninterest in Ce2AuP3 with the Curie temperature of 31 K. The ferromagnetic\nnature has been examined by a doping effect, which suggests a possible increase\nof magnetic anisotropy energy.", "category": "cond-mat.mtrl-sci"}, {"title": "Exploring the high-pressure materials genome", "abstract": "A thorough in situ characterization of materials at extreme conditions is\nchallenging, and computational tools such as crystal structural search methods\nin combination with ab initio calculations are widely used to guide experiments\nby predicting the composition, structure, and properties of high-pressure\ncompounds. However, such techniques are usually computationally expensive and\nnot suitable for large-scale combinatorial exploration. On the other hand,\ndata-driven computational approaches using large materials databases are useful\nfor the analysis of energetics and stability of hundreds of thousands of\ncompounds, but their utility for materials discovery is largely limited to\nidealized conditions of zero temperature and pressure. Here, we present a novel\nframework combining the two computational approaches, using a simple linear\napproximation to the enthalpy of a compound in conjunction with\nambient-conditions data currently available in high-throughput databases of\ncalculated materials properties. We demonstrate its utility by explaining the\noccurrence of phases in nature that are not ground states at ambient conditions\nand estimating the pressures at which such ambient-metastable phases become\nthermodynamically accessible, as well as guiding the exploration of\nambient-immiscible binary systems via sophisticated structural search methods\nto discover new stable high-pressure phases.", "category": "cond-mat.mtrl-sci"}, {"title": "External and mutual synchronization of chimeras in a two layer network of nonlinear oscillators", "abstract": "We study numerically synchronization phenomena of spatiotemporal structures,\nincluding chimera states, in a two layer network of nonlocally coupled\nnonlinear chaotic discrete-time systems. Each of the interacting ensembles\nrepresents a one layer ring network of nonlocally coupled logistic maps in the\nchaotic regime. The coupled networks differ in their control parameters that\nenables one to observe distinct spatiotemporal dynamics in the networks when\nthere is no coupling between them. We explore in detail external and mutual\nsynchronization of chimera structures. The identity of synchronous structures\nand the estimation of synchronization regions are quantified by calculating the\ncross-correlation coefficient between relevant oscillators of the networks. We\nshow that for non-identical networks, unidirectional and symmetric couplings\nlead to external and mutual synchronization between the interacting ensembles,\nrespectively. This is confirmed by identical synchronous structures and by the\nexistence of finite regions of synchronization within which the\ncross-correlation coefficient is equal to 1. We also show that these findings\nare qualitatively equivalent to the results of the classical synchronization\ntheory of periodic self-sustained oscillations.", "category": "nlin.AO"}, {"title": "Global synchronization of partially forced Kuramoto oscillators on Networks", "abstract": "We study the synchronization of Kuramoto oscillators on networks where only a\nfraction of them is subjected to a periodic external force. When all\noscillators receive the external drive the system always synchronize with the\nperiodic force if its intensity is sufficiently large. Our goal is to\nunderstand the conditions for global synchronization as a function of the\nfraction of nodes being forced and how these conditions depend on network\ntopology, strength of internal couplings and intensity of external forcing.\nNumerical simulations show that the force required to synchronize the network\nwith the external drive increases as the inverse of the fraction of forced\nnodes. However, for a given coupling strength, synchronization does not occur\nbelow a critical fraction, no matter how large is the force. Network topology\nand properties of the forced nodes also affect the critical force for\nsynchronization. We develop analytical calculations for the critical force for\nsynchronization as a function of the fraction of forced oscillators and for the\ncritical fraction as a function of coupling strength. We also describe the\ntransition from synchronization with the external drive to spontaneous\nsynchronization.", "category": "nlin.AO"}, {"title": "Twisted states in low-dimensional hypercubic lattices", "abstract": "Twisted states with non-zero winding numbers composed of sinusoidally coupled\nidentical oscillators have been observed in a ring. The phase of each\noscillator in these states constantly shifts, following its preceding neighbor\nin a clockwise direction, and the summation of such phase shifts around the\nring over $2\\pi$ characterizes the winding number of each state. In this work,\nwe consider finite-sized $d$-dimensional hypercubic lattices, namely square\n($d=2$) and cubic ($d=3$) lattices with periodic boundary conditions. For\nidentical oscillators, we observe new states in which the oscillators belonging\nto each line (plane) for $d=2$ ($d=3$) are phase synchronized with non-zero\nwinding numbers along the perpendicular direction. These states can be reduced\ninto twisted states in a ring with the same winding number if we regard each\nsubset of phase-synchronized oscillators as one single oscillator. For\nnonidentical oscillators with heterogeneous natural frequencies, we observe\nsimilar patterns with slightly heterogeneous phases in each line $(d=2)$ and\nplane $(d=3)$. We show that these states generally appear for random\nconfigurations when the global coupling strength is larger than the critical\nvalues for the states.", "category": "nlin.AO"}, {"title": "Stable amplitude chimera states in a network of locally coupled Stuart-Landau oscillators", "abstract": "We investigate the occurrence of collective dynamical states such as\ntransient amplitude chimera, stable amplitude chimera and imperfect breathing\nchimera states in a \\textit{locally coupled} network of Stuart-Landau\noscillators. In an imperfect breathing chimera state, the synchronized group of\noscillators exhibits oscillations with large amplitudes while the\ndesynchronized group of oscillators oscillates with small amplitudes and this\nbehavior of coexistence of synchronized and desynchronized oscillations\nfluctuates with time. Then we analyze the stability of the amplitude chimera\nstates under various circumstances, including variations in system parameters\nand coupling strength, and perturbations in the initial states of the\noscillators. For an increase in the value of the system parameter, namely the\nnonisochronicity parameter, the transient chimera state becomes a stable\nchimera state for a sufficiently large value of coupling strength. In addition,\nwe also analyze the stability of these states by perturbing the initial states\nof the oscillators. We find that while a small perturbation allows one to\nperturb a large number of oscillators resulting in a stable amplitude chimera\nstate, a large perturbation allows one to perturb a small number of oscillators\nto get a stable amplitude chimera state. We also find the stability of the\ntransient and stable amplitude chimera states as well as traveling wave states\nfor appropriate number of oscillators using Floquet theory. In addition, we\nalso find the stability of the incoherent oscillation death states.", "category": "nlin.AO"}, {"title": "Distinct collective states due to the trade-off between attractive and repulsive couplings", "abstract": "We investigate the effect of repulsive coupling together with an attractive\ncoupling in a network of nonlocally coupled oscillators. To understand the\ncomplex interaction between these two couplings we introduce a control\nparameter in the repulsive coupling which plays a crucial role in inducing\ndistinct complex collective patterns. In particular, we show the emergence of\nvarious cluster chimera death states through a dynamically distinct transition\nroute, namely the oscillatory cluster state and coherent oscillation death\nstate as a function of the repulsive coupling in the presence of the attractive\ncoupling. In the oscillatory cluster state, the oscillators in the network are\ngrouped into two distinct dynamical states of homogeneous and inhomogeneous\noscillatory states. Further, the network of coupled oscillators follows the\nsame transition route in the entire coupling range. Depending upon distinct\ncoupling ranges the system displays a different number of clusters in the death\nstate and oscillatory state. We also observe that the number of coherent\ndomains in the oscillatory cluster state exponentially decreases with increase\nin coupling range and obeys a power law decay. Additionally, we show analytical\nstability for observed solitary state, synchronized state, and incoherent\noscillation death state.", "category": "nlin.AO"}, {"title": "Stochastic oscillations produce dragon king avalanches in self-organized quasi-critical systems", "abstract": "In the last decade, several models with network adaptive mechanisms (link\ndeletion-creation, dynamic synapses, dynamic gains) have been proposed as\nexamples of self-organized criticality (SOC) to explain neuronal avalanches.\nHowever, all these systems present stochastic oscillations hovering around the\ncritical region that are incompatible with standard SOC. This phenomenology has\nbeen called self-organized quasi-criticality (SOqC). Here we make a linear\nstability analysis of the mean field fixed points of two SOqC systems: a fully\nconnected network of discrete time stochastic spiking neurons with firing rate\nadaptation produced by dynamic neuronal gains and an excitable cellular\nautomata with depressing synapses. We find that the fixed point corresponds to\na stable focus that loses stability at criticality. We argue that when this\nfocus is close to become indifferent, demographic noise can elicit stochastic\noscillations that frequently fall into the absorbing state. This mechanism\ninterrupts the oscillations, producing both power law avalanches and dragon\nking events, which appear as bands of synchronized firings in raster plots. Our\napproach differs from standard SOC models in that it predicts the coexistence\nof these different types of neuronal activity.", "category": "nlin.AO"}, {"title": "The Dynamics of Interacting Swarms", "abstract": "Swarms are self-organized dynamical coupled agents which evolve from simple\nrules of communication. They are ubiquitous in nature, and be- coming more\nprominent in defense applications. Here we report on a preliminary study of\nswarm collisions for a swarm model in which each agent is self-propelling but\nglobally communicates with other agents. We generalize previous models by\ninvestigating the interacting dynamics when delay is introduced to the\ncommunicating agents. One of our major find- ings is that interacting swarms\nare far less likely to flock cohesively if they are coupled with delay. In\naddition, parameter ranges based on coupling strength, incidence angle of\ncollision, and delay change dramatically for other swarm interactions which\nresult in flocking, milling, and scattering.", "category": "nlin.AO"}, {"title": "Nonlocal coupling among oscillators mediated by a slowly diffusing substance", "abstract": "A general theory is presented for the coupling among nonlinear oscillators\nmediated by a diffusing chemical substance. We extend a model originally\ndeveloped by Kuramoto, who supposed that the diffusion characteristic time is\nmuch shorter than the oscillator main period, such that diffusion occurs very\nfast. We eliminate this constraint and consider diffusion to have an arbitrary\ncharacteristic time, by solving exactly the diffusion equation using suitable\nGreen functions. We present results in one, two and three dimension, with and\nwithout boundary conditions.", "category": "nlin.AO"}, {"title": "Synchronization Dynamics in the Presence of Coupling Delays and Phase Shifts", "abstract": "In systems of coupled oscillators, the effects of complex signaling can be\ncaptured by time delays and phase shifts. Here, we show how time delays and\nphase shifts lead to different oscillator dynamics and how synchronization\nrates can be regulated by substituting time delays by phase shifts at constant\ncollective frequency. For spatially extended systems with time delays, we show\nthat fastest synchronization can occur for intermediate wavelengths, giving\nrise to novel synchronization scenarios.", "category": "nlin.AO"}, {"title": "Stabilisation of dynamics of oscillatory systems by non-autonomous perturbation", "abstract": "Synchronisation and stability under periodic oscillatory driving are\nwell-understood, but little is known about the effects of aperiodic driving,\ndespite its abundance in nature. Here, we consider oscillators subject to\ndriving with slowly varying frequency, and investigate both short-term and\nlong-term stability properties. For a phase oscillator, we find that,\ncounter-intuitively, such variation is guaranteed to enlarge the Arnold tongue\nin parameter space. Using analytical and numerical methods that provide\ninformation on time-variable dynamical properties, we find that the growth of\nthe Arnold tongue is specifically due to the growth of a region of intermittent\nsynchronisation where trajectories alternate between short-term stability and\nshort-term neutral stability, giving rise to stability on average. We also\npresent examples of higher-dimensional nonlinear oscillators where a similar\nstabilisation phenomenon is numerically observed. Our findings help support the\ncase that in general, deterministic non-autonomous perturbation is a very good\ncandidate for stabilising complex dynamics.", "category": "nlin.AO"}, {"title": "Structure and dynamical behaviour of non-normal networks", "abstract": "We analyse a collection of empirical networks in a wide spectrum of\ndisciplines and show that strong non-normality is ubiquitous in network\nscience. Dynamical processes evolving on non-normal networks exhibit a peculiar\nbehaviour, as initial small disturbances may undergo a transient phase and be\nstrongly amplified in linearly stable systems. Additionally, eigenvalues may\nbecome extremely sensible to noise, and have a diminished physical meaning. We\nidentify structural properties of networks that are associated to non-normality\nand propose simple models to generate networks with a tuneable level of\nnon-normality. We also show the potential use of a variety of metrics capturing\ndifferent aspects of non-normality, and propose their potential use in the\ncontext of the stability of complex ecosystems.", "category": "nlin.AO"}, {"title": "Finite-time scaling in local bifurcations", "abstract": "Finite-size scaling is a key tool in statistical physics, used to infer\ncritical behavior in finite systems. Here we use the analogous concept of\nfinite-time scaling to describe the bifurcation diagram at finite times in\ndiscrete dynamical systems. We analytically derive finite-time scaling laws for\ntwo ubiquitous transitions given by the transcritical and the saddle-node\nbifurcation, obtaining exact expressions for the critical exponents and scaling\nfunctions. One of the scaling laws, corresponding to the distance of the\ndynamical variable to the attractor, turns out to be universal. Our work\nestablishes a new connection between thermodynamic phase transitions and\nbifurcations in low-dimensional dynamical systems, and opens new avenues to\nidentify the nature of dynamical shifts in systems for which only short time\nseries are available.", "category": "nlin.AO"}, {"title": "In-phase synchronization in complex oscillator networks by adaptive delayed feedback control", "abstract": "In-phase synchronization is a special case of synchronous behavior when\ncoupled oscillators have the same phases for any time moments. Such behavior\nappears naturally for nearly identical coupled limit-cycle oscillators when the\ncoupling strength is greatly above the synchronization threshold. We\ninvestigate the general class of nearly identical complex oscillators connected\ninto network in a context of a phase reduction approach. By treating each\noscillator as a black-box possessing a single-input single-output, we provide a\npractical and simply realizable control algorithm to attain the in-phase\nsynchrony of the network. For a general diffusive-type coupling law and any\nvalue of a coupling strength (even greatly below the synchronization threshold)\nthe delayed feedback control with a specially adjusted time-delays can provide\nin-phase synchronization. Such adjustment of the delay times performed in an\nautomatic fashion by the use of an adaptive version of the delayed feedback\nalgorithm when time-delays become time-dependent slowly varying control\nparameters. Analytical results show that there are many arrangements of the\ntime-delays for the in-phase synchronization, therefore we supplement the\nalgorithm by an additional requirement to choose appropriate set of the\ntime-delays, which minimize power of a control force. Performed numerical\nvalidations of the predictions highlights the usefulness of our approach.", "category": "nlin.AO"}, {"title": "Reducing the number of time delays in coupled dynamical systems", "abstract": "When several dynamical systems interact, the transmission of the information\nbetween them necessarily implies a time delay. When the time delay is not\nnegligible, the study of the dynamics of these interactions deserve a special\ntreatment. We will show here that under certain assumptions, it is possible to\nset to zero a significant amount of time-delayed connections without altering\nthe global dynamics. We will focus on graphs of interactions with identical\ntime delays and bidirectional connections. With these premises, it is possible\nto find a configuration where a number $n_z$ of time delays have been removed\nwith $n_v-1 \\leq n_z \\leq n_v^2/4$, where $n_v$ is the number of dynamical\nsystems on a connected graph.", "category": "nlin.AO"}, {"title": "Curing Braess' Paradox by Secondary Control in Power Grids", "abstract": "Robust operation of power transmission grids is essential for most of today's\ntechnical infrastructure and our daily life. Adding renewable generation to\npower grids requires grid extensions and sophisticated control actions on\ndifferent time scales to cope with short-term fluctuations and long-term power\nimbalance. Braess' paradox constitutes a counterintuitive collective phenomenon\nthat occurs if adding new transmission line capacity to a network increases\nloads on other lines, effectively reducing the system's performance and\npotentially even entirely removing its operating state. Combining simple\nanalytical considerations with numerical investigations on a small sample\nnetwork, we here study dynamical consequences of secondary control in AC power\ngrid models. We demonstrate that sufficiently strong control not only implies\ndynamical stability of the system but may also cure Braess' paradox. Our\nresults highlight the importance of demand control in conjunction with grid\ntopology for stable operation and reveal a new functional benefit of secondary\ncontrol.", "category": "nlin.AO"}, {"title": "Symmetry and symmetry breaking in coupled oscillator communities", "abstract": "With the recent development of analytical methods for studying the collective\ndynamics of coupled oscillator systems, the dynamics of communities of coupled\noscillators have received a great deal of attention in the nonlinear dynamics\ncommunity. However, the majority of these works treat systems with a number of\nsymmetries to simplify the analysis. In this work we study the role of symmetry\nand symmetry-breaking in the collective dynamics of coupled oscillator\ncommunities, allowing for a comparison between the macroscopic dynamics of\nsymmetric and asymmetric systems. We begin by treating the symmetric case,\nderiving the bifurcation diagram as a function of intra- and inter-community\ncoupling strengths. In particular we describe transitions between incoherence,\nstanding wave, and partially synchronized states and reveal bistability\nregions. When we turn our attention to the asymmetric case we find that the\nsymmetry-breaking complicates the bifurcation diagram. For instance, a\npitchfork bifurcation in the symmetric case is broken, giving rise to a Hopf\nbifurcation. Moreover, an additional partially synchronized state emerges, as\nwell as a new bistability region.", "category": "nlin.AO"}, {"title": "Power grid stability under perturbation of single nodes: Effects of heterogeneity and internal nodes", "abstract": "Non-linear equations describing the time evolution of frequencies and\nvoltages in power grids exhibit fixed points of stable grid operation. The\ndynamical behaviour after perturbations around these fixed points can be used\nto characterise the stability of the grid. We investigate both probabilities of\nreturn to a fixed point and times needed for this return after perturbation of\nsingle nodes. Our analysis is based on an IEEE test grid and the second-order\nswing equations for voltage phase angles $\\theta_j$ at nodes $j$ in the\nsynchronous machine model. The perturbations cover all possible changes\n$\\Delta\\theta$ of voltage angles and a wide range of frequency deviations in a\nrange $\\Delta f=\\pm1$~Hz around the common frequency $\\omega=2\\pi\nf=\\dot\\theta_j$ in a synchronous fixed point state. Extensive numerical\ncalculations are carried out to determine, for all node pairs $(j,k)$, the\nreturn times $t_{jk}(\\Delta\\theta,\\Delta \\omega)$ of node $k$ after a\nperturbation of node $j$. We find that for strong perturbations of some nodes,\nthe grid does not return to its synchronous state. If returning to the fixed\npoint, the times needed for the return are strongly different for different\ndisturbed nodes and can reach values up to 20 seconds and more. When\nhomogenising transmission line and node properties, the grid always returns to\na synchronous state for the considered perturbations, and the longest return\ntimes have a value of about 4 seconds for all nodes. The neglect of reactances\nbetween points of power generation (internal nodes) and injection (terminal\nnodes) leads to an underestimation of return probabilities.", "category": "nlin.AO"}, {"title": "Diverse Stochasticity Leads a Colony of Ants to Optimal Foraging", "abstract": "A mathematical model of garden ants (Laius japonicus) is introduced herein to\ninvestigate the relationship between the distribution of the degree of\nstochasticity in following pheromone trails and the group foraging efficiency.\nNumerical simulations of the model indicate that depending on the systematic\nchange of the feeding environment, the optimal distribution of stochasticity\nshifts from a mixture of almost deterministic and mildly stochastic ants to a\ncontrasted mixture of almost deterministic ants and highly stochastic ants. In\naddition, the interaction between the stochasticity and the pheromone path\nregulates the dynamics of the foraging efficiency optimization. Stochasticity\ncould strengthen the collective efficiency when stochasticity to the\nsensitivity of pheromone for ants is introduced in the model.", "category": "nlin.AO"}, {"title": "Coherence resonance in an excitable potential well", "abstract": "The excitable behaviour is considered as motion of a particle in a potential\nfield in the presence of dissipation. The dynamics of the oscillator proposed\nin the present paper corresponds to the excitable behaviour in a potential well\nunder condition of positive dissipation. Type-II excitability of the offered\nsystem results from intrinsic peculiarities of the potential well, whose shape\ndepends on a system state. Concept of an excitable potential well is\nintroduced. The effect of coherence resonance and self-oscillation excitation\nin a state-dependent potential well under condition of positive dissipation are\nexplored in numerical experiments.", "category": "nlin.AO"}, {"title": "Method of increasing the information capacity of associative memory of oscillator neural networks using high-order synchronization effect", "abstract": "Computational modelling of two- and three-oscillator schemes with thermally\ncoupled $VO_2$-switches is used to demonstrate a novel method of pattern\nstorage and recognition in an impulse oscillator neural network (ONN) based on\nthe high-order synchronization effect. The method ensures high information\ncapacity of associative memory, i.e. a large number of synchronous states\n$N_s$. Each state in the system is characterized by the synchronization order\ndetermined as the ratio of harmonics number at the common synchronization\nfrequency. The modelling demonstrates attainment of $N_s$ of several orders\nboth for a three-oscillator scheme $N_s$~650 and for a two-oscillator scheme\n$N_s$~260. A number of regularities are obtained, in particular, an optimal\nstrength of oscillator coupling is revealed when $N_s$ has a maximum. A general\ntendency toward information capacity decrease is shown when the coupling\nstrength and switch inner noise amplitude increase. An algorithm of pattern\nstorage and test vector recognition is suggested. It is also shown that the\ncoordinate number in each vector should be one less than the switch number to\nreduce recognition ambiguity. The demonstrated method of associative memory\nrealization is a general one and it may be applied in ONNs with various\nmechanisms and oscillator coupling topology.", "category": "nlin.AO"}, {"title": "Dynamics of Kuramoto oscillators with time-delayed positive and negative couplings", "abstract": "Many real-world examples of distributed oscillators involve not only time\ndelays but also attractive (positive) and repulsive (negative) influences in\ntheir network interactions. Here, considering such examples, we generalize the\nKuramoto model of globally coupled oscillators with time-delayed positive and\nnegative couplings to explore the effects of such couplings in collective phase\nsynchronization. We analytically derive the exact solutions for stable\nincoherent and coherent states in terms of the system parameters allowing us to\nprecisely understand the interplay of time delays and couplings in collective\nsynchronization. Dependent on these parameters, fully coherent, incoherent\nstates and mixed states are possible. Time-delays especially in the negative\ncoupling seem to facilitate collective synchronization. In case of a stronger\nnegative coupling than positive one, a stable synchronized state cannot be\nachieved without time delays. We discuss the implications of the model and the\nresults for natural systems, particularly neuronal network systems in the\nbrain.", "category": "nlin.AO"}, {"title": "Low Dimensional Dynamics of the Kuramoto Model with Rational Frequency Distributions", "abstract": "The Kuramoto model is a paradigmatic tool for studying the dynamics of\ncollective behavior in large ensembles of coupled dynamical systems. Over the\npast decade a great deal of progress has been made in analytical descriptions\nof the macroscopic dynamics of the Kuramoto mode, facilitated by the discovery\nof Ott and Antonsen's dimensionality reduction method. However, the vast\nmajority of these works relies on a critical assumption where the oscillators'\nnatural frequencies are drawn from a Cauchy, or Lorentzian, distribution, which\nallows for a convenient closure of the evolution equations from the\ndimensionality reduction. In this paper we investigate the low dimensional\ndynamics that emerge from a broader family of natural frequency distributions,\nin particular a family of rational distribution functions. We show that, as the\npolynomials that characterize the frequency distribution increase in order, the\nlow dimensional evolution equations become more complicated, but nonetheless\nthe system dynamics remain simple, displaying a transition from incoherence to\npartial synchronization at a critical coupling strength. Using the low\ndimensional equations we analytically calculate the critical coupling strength\ncorresponding to the onset of synchronization and investigate the scaling\nproperties of the order parameter near the onset of synchronization. These\nresults agree with calculations from Kuramoto's original self-consistency\nframework, but we emphasize that the low dimensional equations approach used\nhere allows for a true stability analysis categorizing the bifurcations.", "category": "nlin.AO"}, {"title": "Self-consistent Method and Steady States of Second-order Oscillators", "abstract": "The self-consistent method, first introduced by Kuramoto, is a powerful tool\nfor the analysis of the steady states of coupled oscillator networks. For\nsecond-order oscillator networks complications to the application of the\nself-consistent method arise because of the bistable behavior due to the\nco-existence of a stable fixed point and a stable limit cycle, and the\nresulting complicated boundary between the corresponding basins of attraction.\nIn this paper, we report on a self-consistent analysis of second-order\noscillators which is simpler compared to previous approaches while giving more\naccurate results in the small inertia regime and close to incoherence. We apply\nthe method to analyze the steady states of coupled second-order oscillators and\nwe introduce the concepts of margin region and scaled inertia. The improved\naccuracy of the self-consistent method close to incoherence leads to an\naccurate estimate of the critical coupling corresponding to transitions from\nincoherence.", "category": "nlin.AO"}, {"title": "Complexity Matching and Requisite Variety", "abstract": "Complexity matching characterizes the role of information in interactions\nbetween systems and can be traced back to the 1957 Introduction to Cybernetics\nby Ross Ashby. We argue that complexity can be expressed in terms of crucial\nevents, which are generated by the processes of spontaneous self-organization.\nComplex processes, ranging from biological to sociological, must satisfy the\nhomeodynamic condition and host crucial events that have recently been shown to\ndrive the information transport between complex systems. We adopt a\nphenomenological approach, based on the subordination to periodicity that makes\nit possible to combine homeodynamics and self-organization induced crucial\nevents. The complexity of crucial events is defined by the waiting-time\nprobability density function (PDF) of the intervals between consecutive crucial\nevents, which have an inverse power law (IPL) PDF $\\psi (\\tau )\\propto 1/(\\tau\n)^{\\mu }$ with $1<\\mu <3$. We show that the action of crucial events has an\neffect compatible with the shared notion of complexity-induced entropy\nreduction, while making the synchronization between systems sharing the same\ncomplexity different from chaos synchronization. We establish the coupling\nbetween two temporally complex systems using a phenomenological approach\ninspired by models of swarm cognition and prove that complexity matching,\nnamely sharing the same IPL index $\\mu $, facilitates the transport of\ninformation, generating perfect synchronization. This new form of complexity\nmatching is expected to contribute significantly to progress in understanding\nand improving biofeedback therapies.", "category": "nlin.AO"}, {"title": "Rethinking network reciprocity over social ties: local interactions make direct reciprocity possible and pave the rational way to cooperation", "abstract": "Since Nowak & May's (1992) influential paper, network reciprocity--the fact\nthat individuals' interactions repeated within a local neighborhood support the\nevolution of cooperation--has been confirmed in several theoretical models.\nEssentially, local interactions allow cooperators to stay protected from\nexploiters by assorting into clusters, and the heterogeneity of the network of\ncontacts--the co-presence of low- and high-connected nodes--has been shown to\nfurther favor cooperation. The few available large-scale experiments on humans\nhave however missed these effects. The reason is that, while models assume that\nindividuals update strategy by imitating better performing neighbors,\nexperiments showed that humans are more prone to reciprocate cooperation than\nto compare payoffs. Inspired by the empirical results, we rethink network\nreciprocity as a rational form of direct reciprocity on networks--networked\nrational reciprocity--indeed made possible by the locality of interactions. We\nshow that reciprocal altruism in a networked prisoner's dilemma can invade and\nfixate in any network of rational agents, profit-maximizing over an horizon of\nfuture interactions. We find that networked rational reciprocity works better\nat low average connectivity and we unveil the role of network heterogeneity.\nOnly if cooperating hubs invest in the initial cost of exploitation, the\ninvasion of cooperation is boosted; it is otherwise hindered. Although humans\nmight not be as rational as here assumed, our results could help the design and\ninterpretation of new experiments in social and economic networks", "category": "nlin.AO"}, {"title": "Bridging between Load-Flow and Kuramoto-like Power Grid Models: A Flexible Approach to Integrating Electrical Storage Units", "abstract": "In future power systems, electrical storage will be the key technology for\nbalancing feed-in fluctuations. With increasing share of renewables and\nreduction of system inertia, the focus of research expands towards short-term\ngrid dynamics and collective phenomena. Against this backdrop, Kuramoto-like\npower grids have been established as a sound mathematical modeling framework\nbridging between the simplified models from nonlinear dynamics and the more\ndetailed models used in electrical engineering. However, they have a blind spot\nconcerning grid components, which cannot be modeled by oscillator equations,\nand hence do not allow to investigate storage-related issues from scratch. We\nremove this shortcoming by bringing together Kuramoto-like and algebraic\nload-flow equations. This is a substantial extension of the current Kuramoto\nframework with arbitrary grid components. Based on this concept, we provide a\nsolid starting point for the integration of flexible storage units enabling to\naddress current problems like smart storage control, optimal siting and rough\ncost estimations. For demonstration purpose, we here consider a wind power\napplication with realistic feed-in conditions. We show how to implement basic\ncontrol strategies from electrical engineering, give insights into their\npotential with respect to frequency quality improvement and point out their\nlimitations by maximum capacity and finite-time response.", "category": "nlin.AO"}, {"title": "First-order synchronization transition in a large population of strongly coupled relaxation oscillators", "abstract": "Onset and loss of synchronization in coupled oscillators are of fundamental\nimportance in understanding emergent behavior in natural and man-made systems,\nwhich range from neural networks to power grids. We report on experiments with\nhundreds of strongly coupled photochemical relaxation oscillators that exhibit\na discontinuous synchronization transition with hysteresis, as opposed to the\nparadigmatic continuous transition expected from the widely used weak coupling\ntheory. The resulting first-order transition is robust with respect to changes\nin network connectivity and natural frequency distribution. This allows us to\nidentify the relaxation character of the oscillators as the essential parameter\nthat determines the nature of the synchronization transition. We further\nsupport this hypothesis by revealing the mechanism of the transition, which\ncannot be accounted for by standard phase reduction techniques.", "category": "nlin.AO"}, {"title": "Self adaptation of chimera states", "abstract": "Chimera states in spatiotemporal dynamical systems have been investigated in\nphysical, chemical, and biological systems, and have been shown to be robust\nagainst random perturbations. How do chimera states achieve their robustness?\nWe uncover a self-adaptation behavior by which, upon a spatially localized\nperturbation, the coherent component of the chimera state spontaneously drifts\nto an optimal location as far away from the perturbation as possible, exposing\nonly its incoherent component to the perturbation to minimize the disturbance.\nA systematic numerical analysis of the evolution of the spatiotemporal pattern\nof the chimera state towards the optimal stable state reveals an exponential\nrelaxation process independent of the spatial location of the perturbation,\nimplying that its effects can be modeled as restoring and damping forces in a\nmechanical system and enabling the articulation of a phenomenological model.\nNot only is the model able to reproduce the numerical results, it can also\npredict the trajectory of drifting. Our finding is striking as it reveals that,\ninherently, chimera states possess a kind of \"intelligence\" in achieving\nrobustness through self adaptation. The behavior can be exploited for\ncontrolled generation of chimera states with their coherent component placed in\nany desired spatial region of the system.", "category": "nlin.AO"}, {"title": "Sinusoidal-signal detection by active, noisy oscillators on the brink of self-oscillation", "abstract": "Determining the conditions under which an active system best detects\nsinusoidal signals is important for numerous fields. It is known that a\nquiescent, deterministic system possessing a supercritical Hopf bifurcation is\nmore sensitive to sinusoidal stimuli the closer it operates to the bifurcation.\nTo understand signal detection in many natural settings, however, noise must be\ntaken into account. We study the Fokker-Planck equation describing the\nsinusoidally forced dynamics of a noisy supercritical or subcritical Hopf\noscillator. To distinguish an oscillator's motion owing to sinusoidal forcing\nfrom that provoked by noise, we employ the phase-locked amplitude and vector\nstrength, which are zero in the absence of an external signal. The phase-locked\namplitude and entrainment to frequency-detuned forcing but not resonant forcing\npeak as functions of the control parameter. These peaks occur near but not at\nthe bifurcations. Moreover, an oscillator can detect stimuli over the broadest\nfrequency range when it spontaneously oscillates near a Hopf bifurcation.\nAlthough noise exerts the greatest effect on the phase-locked amplitude when a\nHopf oscillator is near a Hopf bifurcation, the oscillator nevertheless\nperforms best as a sinusoidal-signal detector when it operates close to the\nbifurcation. The oscillator's ability to differentiate detuned signals from\nnoise is greatest with it autonomously oscillates near to but not at the\nbifurcation.", "category": "nlin.AO"}, {"title": "Suppression of macroscopic oscillations in mixed populations of active and inactive oscillators coupled through lattice Laplacian", "abstract": "We consider suppression of macroscopic synchronized oscillations in mixed\npopulations of active and inactive oscillators with local diffusive coupling,\ndescribed by a lattice complex Ginzburg-Landau model with discrete Laplacian in\ngeneral dimensions. Approximate expression for the stability of the\nnon-oscillatory stationary state is derived on the basis of the generalized\nfree energy of the system. We show that an effective wavenumber of the system\ndetermined by the spatial arrangement of the active and inactive oscillators is\nan decisive factor in the suppression, in addition to the ratio of active\npopulation to inactive population and relative intensity of each population.\nThe effectiveness of the proposed theory is illustrated with a cortico-thalamic\nmodel of epileptic seizures, where active and inactive oscillators correspond\nto epileptic foci and healthy cerebral cortex tissue, respectively.", "category": "nlin.AO"}, {"title": "When is sync globally stable in sparse networks of identical Kuramoto oscillators?", "abstract": "Synchronization in systems of coupled Kuramoto oscillators may depend on\ntheir natural frequencies, coupling, and underlying networks. In this paper, we\nreduce the alternatives to only one by considering identical oscillators where\nthe only parameter that is allowed to change is the underlying network. While\nsuch a model was analyzed over the past few decades by studying the size of the\nbasin of attraction of the synchronized state on restricted families of graphs,\nhere we address a qualitative question on general graphs. In an analogy to\nresistive networks with current sources, we describe an algorithm that produces\ninitial conditions that are often outside of the basin of attraction of the\nsynchronized state. In particular, if a graph allows a cyclic graph clustering\nwith a sufficient number of clusters or contains a sufficiently long induced\nsubpath without cut vertices of the graph then there is a non-synchronous\nstable phase-locked solution. Thus, we provide a partial answer to when the\nsynchronized state is not globally stable.", "category": "nlin.AO"}, {"title": "Modeling cochlear two-tone suppression using a system of nonlinear oscillators with feed-forward coupling", "abstract": "Mechanism of two-tone suppression is studied using a coupled-oscillator model\nof the cochlea with feed-forward coupling. Local amplification of sound signals\nis modeled by using Stuart-Landau oscillators near the Hopf bifurcation, and\ntransmission of sound signals is described as feed-forward coupling between the\noscillators. Effect of suppressor signals on the response to probe signals is\nanalyzed by numerical simulations. It is found that the effect of suppression\nis qualitatively different depending on relative frequency between probe and\nsuppressor signals. By analyzing a simplified two-oscillator model, we explain\nthe mechanism of the suppression, where configuration of the oscillators plays\nan essential role.", "category": "nlin.AO"}, {"title": "Metastability and Multiscale Extinction Time on a Finite System of Interacting Stochastic Chains", "abstract": "We studied metastability and extinction time of a finite system with a large\nnumber of interacting components in discrete time by means of analytical and\nnumerical investigation. The system is markovian with respect to the potential\nprofile of the components, which are subject to leakage and gain effects\nsimultaneously. We show that the only invariant measure is the null\nconfiguration, that the system ceases activity almost surely in a finite time\nand that extinction time presents a cutoff behavior. Moreover, there is a\ncritical parameter determined by leakage and gain below which the extinction\ntime does not depend on the system size. Above such critical ratio, the\nextinction time depends on the number of components and the system tends to\nstabilize around a unique metastable state. Furthermore, the extinction time\npresents infinitely many scales with respect to the system size.", "category": "nlin.AO"}, {"title": "Simple model of complex dynamics of activity patterns in developing networks of neuronal cultures", "abstract": "Living neuronal networks in dissociated neuronal cultures are widely known\nfor their ability to generate highly robust spatiotemporal activity patterns in\nvarious experimental conditions. These include neuronal avalanches satisfying\nthe power scaling law and thereby exemplifying self-organized criticality in\nliving systems. A crucial question is how these patterns can be explained and\nmodeled in a way that is biologically meaningful, mathematically tractable and\nyet broad enough to account for neuronal heterogeneity and complexity. Here we\npropose a simple model which may offer an answer to this question. Our\nderivations are based on just few phenomenological observations concerning\ninput-output behavior of an isolated neuron. A distinctive feature of the model\nis that at the simplest level of description it comprises of only two\nvariables, a network activity variable and an exogenous variable corresponding\nto energy needed to sustain the activity and modulate the efficacy of signal\ntransmission. Strikingly, this simple model is already capable of explaining\nemergence of network spikes and bursts in developing neuronal cultures. The\nmodel behavior and predictions are supported by empirical observations and\npublished experimental evidence on cultured neurons behavior exposed to oxygen\nand energy deprivation. At the larger, network scale, introduction of the\nenergy-dependent regulatory mechanism enables the network to balance on the\nedge of the network percolation transition. Network activity in this state\nshows population bursts satisfying the scaling avalanche conditions. This\nnetwork state is self-sustainable and represents a balance between global\nnetwork-wide processes and spontaneous activity of individual elements.", "category": "nlin.AO"}, {"title": "Collective dynamics of globally delay-coupled complex Ginzburg-Landau oscillators", "abstract": "The effect of time-delayed coupling on the collective behavior of a\npopulation of globally coupled complex Ginzburg-Landau (GCCGL) oscillators is\ninvestigated. A detailed numerical study is carried out to study the impact of\ntime delay on various collective states that include synchronous states,\nmulticluster states, chaos, amplitude mediated chimeras and incoherent states.\nIt is found that time delay can bring about significant changes in the\ndynamical properties of these states including their regions of existence and\nstability. In general, an increase in time delay is seen to lower the threshold\nvalue of the coupling strength for the occurrence of such states and to shift\nthe existence domain towards more negative values of the linear dispersion\nparameter. Further insights into the numerical findings are provided, wherever\npossible, by exact equilibrium and stability analysis of these states in the\npresence of time delay.", "category": "nlin.AO"}, {"title": "Optimization of linear and nonlinear interaction schemes for stable synchronization of weakly coupled limit-cycle oscillators", "abstract": "Optimization of mutual synchronization between a pair of limit-cycle\noscillators with weak symmetric coupling is considered in the framework of the\nphase reduction theory. By generalizing a previous study on the optimization of\ncross-diffusion coupling matrices between the oscillators, we consider\noptimization of mutual coupling signals to maximize the linear stability of the\nsynchronized state, which are functionals of the past time sequences of the\noscillator states. For the case of linear coupling, optimization of the delay\ntime and linear filitering of coupling signals are considered. For the case of\nnonlinear coupling, general drive-response coupling is considered, and the\noptimal response and driving functions are derived. The theoretical results are\nexemplified by numerical simulations.", "category": "nlin.AO"}, {"title": "Microscopic Cross-Correlations in the Finite-Size Kuramoto Model of Coupled Oscillators", "abstract": "Super-critical Kuramoto oscillators with distributed frequencies separate\ninto two disjoint groups: an ordered one locked to the mean field, and a\ndisordered one consisting of effectively decoupled oscillators -- at least so\nin the thermodynamic limit. In finite ensembles, in contrast, such clear\nseparation fails: The mean field fluctuates due to finite-size effects and\nthereby induces order in the disordered group. To our best knowledge, this\npublication is the first to reveal such an effect, similar to noise-induced\nsynchronization, in a purely deterministic system. We start by modeling the\nsituation as a stationary mean field with additional white noise acting on a\npair of unlocked Kuramoto oscillators. An analytical expression shows that the\ncross-correlation between the two increases with decreasing ratio of natural\nfrequency difference and noise intensity. In a deterministic finite Kuramoto\nmodel, the strength of the mean field fluctuations is inextricably linked to\nthe typical natural frequency difference. Therefore, we let a fluctuating mean\nfield, generated by a finite ensemble of active oscillators, act on pairs of\npassive oscillators with a microscopic natural frequency difference between\nwhich we then measure the cross-correlation, at both super- and sub-critical\ncoupling.", "category": "nlin.AO"}, {"title": "Generative framework for dimensionality reduction of large scale network of non-linear dynamical systems driven by external input", "abstract": "Several studies have proposed constraints under which a low dimensional\nrepresentation can be derived from large-scale real-world networks exhibiting\ncomplex nonlinear dynamics. Typically, these representations are formulated\nunder certain assumptions, such as when solutions converge to attractor states\nusing linear stability analysis or using projections of large-scale dynamical\ndata into a set of lower dimensional modes that are selected heuristically.\nHere, we propose a generative framework for selection of lower dimensional\nmodes onto which the entire network dynamics can be projected based on the\nsymmetry of the input distribution for a large-scale network driven by external\ninputs, thus relaxing the heuristic selection of modes made in the earlier\nreduction approaches. The proposed mode reduction technique is tractable\nanalytically and applied to different kinds of real-world large-scale network\nscenarios with nodes comprising of a) Van der Pol oscillators b) Hindmarsh-Rose\nneurons. These two demonstrations elucidate how order parameter is conserved at\noriginal and reduced descriptions thus validating our proposition.", "category": "nlin.AO"}, {"title": "Hysteretic behavior of spatially coupled phase-oscillators", "abstract": "Motivated by phenomena related to biological systems such as the\nsynchronously flashing swarms of fireflies, we investigate a network of phase\noscillators evolving under the generalized Kuramoto model with inertia. A\ndistance-dependent, spatial coupling between the oscillators is considered.\nZeroth and first order kernel functions with finite kernel radii were chosen to\ninvestigate the effect of local interactions. The hysteretic dynamics of the\nsynchronization depending on the coupling parameter was analyzed for different\nkernel radii. Numerical investigations demonstrate that (1) locally locked\nclusters develop for small coupling strength values, (2) the hysteretic\nbehavior vanishes for small kernel radii, (3) the ratio of the kernel radius\nand the maximal distance between the oscillators characterizes the behavior of\nthe network.", "category": "nlin.AO"}, {"title": "Reduction of oscillator dynamics on complex networks to dynamics on complete graphs through virtual frequencies", "abstract": "We consider the synchronization of oscillators in complex networks where\nthere is an interplay between the oscillator dynamics and the network topology.\nThrough a remarkable transformation in parameter space and the introduction of\nvirtual frequencies we show that Kuramoto oscillators on annealed networks,\nwith or without frequency-degree correlation, and Kuramoto oscillators on\ncomplete graphs with frequency-weighted coupling can be transformed to Kuramoto\noscillators on complete graphs with a re-arranged, virtual frequency\ndistribution, and uniform coupling. The virtual frequency distribution encodes\nboth the natural frequency distribution (dynamics) and the degree distribution\n(topology). We apply this transformation to give direct explanations to a\nvariety of phenomena that have been observed in complex networks, such as\nexplosive synchronization and vanishing synchronization onset.", "category": "nlin.AO"}, {"title": "Cooperation dynamics in the networked geometric Brownian motion", "abstract": "Recent works suggest that pooling and sharing may constitute a fundamental\nmechanism for the evolution of cooperation in well-mixed fluctuating\nenvironments. The rationale is that, by reducing the amplitude of fluctuations,\npooling and sharing increases the steady-state growth rate at which the\nindividuals self-reproduce. However, in reality interactions are seldom\nrealized in a well-mixed structure, and the underlying topology is in general\ndescribed by a complex network. Motivated by this observation, we investigate\nthe role of the network structure on the cooperative dynamics in fluctuating\nenvironments, by developing a model for networked pooling and sharing of\nresources undergoing environmental fluctuations, represented through geometric\nBrownian motion. The study reveals that, while in general cooperation increases\nthe individual steady state growth rates (i.e. is evolutionary advantageous),\nthe interplay with the network structure may yield large discrepancies in the\nobserved individual resource endowments. We comment possible biological and\nsocial implications and discuss relations to econophysics.", "category": "nlin.AO"}, {"title": "Growth of a tree with allocations rules: Part 1 Kinematics", "abstract": "A non-local model describing the growth of a tree-like transportation network\nwith given allocation rules is proposed. In this model we focus on tree like\nnetworks, and the network transports the very resource it needs to build\nitself. Some general results are given on the viability tree-like networks that\nproduce an amount of resource based on its amount of leaves while having a\nmaintenance cost for each node. Some analytical studies and numerical surveys\nof the model in \"simple\" situations are made. The different outcomes are\ndiscussed and possible extensions of the model are then discussed.", "category": "nlin.AO"}, {"title": "Competitive percolation strategies for network recovery", "abstract": "Restoring operation of critical infrastructure systems after catastrophic\nevents is an important issue, inspiring work in multiple fields, including\nnetwork science, civil engineering, and operations research. We consider the\nproblem of finding the optimal order of repairing elements in power grids and\nsimilar infrastructure. Most existing methods either only consider system\nnetwork structure, potentially ignoring important features, or incorporate\ncomponent level details leading to complex optimization problems with limited\nscalability. We aim to narrow the gap between the two approaches. Analyzing\nrealistic recovery strategies, we identify over- and undersupply penalties of\ncommodities as primary contributions to reconstruction cost, and we demonstrate\ntraditional network science methods, which maximize the largest connected\ncomponent, are cost inefficient. We propose a novel competitive percolation\nrecovery model accounting for node demand and supply, and network structure.\nOur model well approximates realistic recovery strategies, suppressing growth\nof the largest connected component through a process analogous to explosive\npercolation. Using synthetic power grids, we investigate the effect of network\ncharacteristics on recovery process efficiency. We learn that high structural\nredundancy enables reduced total cost and faster recovery, however, requires\nmore information at each recovery step. We also confirm that decentralized\nsupply in networks generally benefits recovery efforts.", "category": "nlin.AO"}, {"title": "Synchronization Behavior in a Ternary Phase Model", "abstract": "Localized traveling-wave solutions to a nonlinear Schrodinger equation were\nrecently shown to be a consequence of Fourier mode synchronization. The reduced\ndynamics describing mode interaction take the form of a phase model with novel\nternary coupling. We analyze this model in the presence of quenched disorder\nand explore transitions to partial and complete synchronization. For both\nGaussian and uniform disorder, first-order transitions with hysteresis are\nobserved. These results are compared with the phenomenology of the Kuramoto\nmodel which exhibits starkly different behavior. An infinite-oscillator limit\nof the model is derived and solved to provide theoretical predictions for the\nobserved transitions. Treatment of the nonlocal ternary coupling in this limit\nsheds some light on the model's novel structure.", "category": "nlin.AO"}, {"title": "Long-range interaction induced collective dynamical behaviors", "abstract": "Long-range interacting systems are omnipresent in nature. We investigate here\nthe collective dynamical behavior in a long-range interacting system consisting\nof coupled Stuart-Landau limit cycle oscillators. In particular, we analyze the\nimpact of a repulsive coupling along with symmetry breaking coupling. We report\nthat the addition of repulsive coupling of sufficient strength can induce a\nswing of the synchronized state which will start disappearing with an\nincreasing disorder as a function of the repulsive coupling. We also deduce\nanalytical stability conditions for the oscillatory states including\nsynchronized state, solitary state, two-cluster state as well as oscillation\ndeath state. Finally, we have also analyzed the effect of power-law exponent on\nthe observed dynamical states.", "category": "nlin.AO"}, {"title": "A review of swarmalators and their potential in bio-inspired computing", "abstract": "From fireflies to heart cells, many systems in Nature show the remarkable\nability to spontaneously fall into synchrony. By imitating Nature's success at\nself-synchronizing, scientists have designed cost-effective methods to achieve\nsynchrony in the lab, with applications ranging from wireless sensor networks\nto radio transmission. A similar story has occurred in the study of swarms,\nwhere inspiration from the behavior flocks of birds and schools of fish has led\nto 'low-footprint' algorithms for multi-robot systems. Here, we continue this\n'bio-inspired' tradition, by speculating on the technological benefit of fusing\nswarming with synchronization. The subject of recent theoretical work, minimal\nmodels of so-called 'swarmalator' systems exhibit rich spatiotemporal patterns,\nhinting at utility in 'bottom-up' robotic swarms. We review the theoretical\nwork on swarmalators, identify possible realizations in Nature, and discuss\ntheir potential applications in technology.", "category": "nlin.AO"}, {"title": "Abrupt Desynchronization and Extensive Multistability in Globally Coupled Oscillator Simplices", "abstract": "Collective behavior in large ensembles of dynamical units with non-pairwise\ninteractions may play an important role in several systems ranging from brain\nfunction to social networks. Despite recent work pointing to simplicial\nstructure, i.e., higher-order interactions between three or more units at a\ntime, their dynamical characteristics remain poorly understood. Here we present\nan analysis of the collective dynamics of such a simplicial system, namely\ncoupled phase oscillators with three-way interactions. The simplicial structure\ngives rise to a number of novel phenomena, most notably a continuum of abrupt\ndesynchronization transitions with no abrupt synchronization transition\ncounterpart, as well as, extensive multistability whereby infinitely many\nstable partially synchronized states exist. Our analysis sheds light on the\ncomplexity that can arise in physical systems with simplicial interactions like\nthe human brain and the role that simplicial interactions play in storing\ninformation.", "category": "nlin.AO"}, {"title": "Synchronization of Network-Coupled Oscillators with Uncertain Dynamics", "abstract": "Synchronization of network-coupled dynamical units is important to a variety\nof natural and engineered processes including circadian rhythms, cardiac\nfunction, neural processing, and power grids. Despite this ubiquity, it remains\npoorly understood how complex network structures and heterogeneous local\ndynamics combine to either promote or inhibit synchronization. Moreover, for\nmost real-world applications it is impossible to obtain the exact\nspecifications of the system, and there is a lack of theory for how uncertainty\naffects synchronization. We address this open problem by studying the Synchrony\nAlignment Function (SAF), which is an objective measure for the synchronization\nproperties of a network of heterogeneous oscillators with given natural\nfrequencies. We extend the SAF framework to analyze network-coupled oscillators\nwith heterogeneous natural frequencies that are drawn as a multivariate random\nvector. Using probability theory for quadratic forms, we obtain expressions for\nthe expectation and variance of the SAF for given network structures. We\nconclude with numerical experiments that illustrate how the incorporation of\nuncertainty yields a more robust theoretical framework for enhancing\nsynchronization, and we provide new perspectives for why synchronization is\ngenerically promoted by network properties including degree-frequency\ncorrelations, link directedness, and link weight delocalization.", "category": "nlin.AO"}, {"title": "Modular structure in C. elegans neural network and its response to external localized stimuli", "abstract": "Synchronization plays a key role in information processing in neuronal\nnetworks. Response of specific groups of neurons are triggered by external\nstimuli, such as visual, tactile or olfactory inputs. Neurons, however, can be\ndivided into several categories, such as by physical location, functional role\nor topological clustering properties. Here we study the response of the\nelectric junction C. elegans network to external stimuli using the partially\nforced Kuramoto model and applying the force to specific groups of neurons.\nStimuli were applied to topological modules, obtained by the ModuLand\nprocedure, to a ganglion, specified by its anatomical localization, and to the\nfunctional group composed of all sensory neurons. We found that topological\nmodules do not contain purely anatomical groups or functional classes,\ncorroborating previous results, and that stimulating different classes of\nneurons lead to very different responses, measured in terms of synchronization\nand phase velocity correlations. In all cases, however, the modular structure\nhindered full synchronization, protecting the system from seizures. More\nimportantly, the responses to stimuli applied to topological and functional\nmodules showed pronounced patterns of correlation or anti-correlation with\nother modules that were not observed when the stimulus was applied to ganglia.", "category": "nlin.AO"}, {"title": "Inhibition induced explosive synchronization in multiplex networks", "abstract": "To date, explosive synchronization (ES) is shown to be originated from either\ndegree-frequency correlation or inertia of phase oscillators. Of late, it has\nbeen shown that ES can be induced in a network by adaptively controlled phase\noscillators. Here we show that ES is a generic phenomenon and can occur in any\nnetwork by appropriately multiplexing it with another layer. We devise an\napproach which leads to the occurrence of ES with hysteresis loop in a network\nupon its multiplexing with a negatively coupled (or inhibitory) layer. We\ndiscuss the impact of various structural properties of positively coupled (or\nexcitatory) and inhibitory layer along with the strength of multiplexing in\ngaining control over the induced ES transition. This investigation is a step\nforward in highlighting the importance of multiplex framework not only in\nbringing novel phenomena which are not possible in an isolated network but also\nin providing more structural control over the induced phenomena.", "category": "nlin.AO"}, {"title": "Optimal global synchronization of partially forced Kuramoto oscillators", "abstract": "We consider the problem of global synchronization in a large random network\nof Kuramoto oscillators where some of them are subject to an external\nperiodically driven force. We explore a recently proposed dimensional reduction\napproach and introduce an effective two-dimensional description for the\nproblem. From the dimensionally reduced model, we obtain analytical predictions\nfor some critical parameters necessary for the onset of a globally synchronized\nstate in the system. Moreover, the low dimensional model also allows us to\nintroduce an optimization scheme for the problem. Our main conclusion, which\nhas been corroborated by exhaustive numerical simulations, is that for a given\nlarge random network of Kuramoto oscillators, with random natural frequencies\n$\\omega_i$, such that a fraction of them is subject to an external periodic\nforce with frequency $\\Omega$, the best global synchronization properties\ncorrespond to the case where the fraction of the forced oscillators is chosen\nto be those ones such that $|\\omega_i-\\Omega|$ is maximal. Our results might\nshed some light on the structure and evolution of natural systems for which the\npresence or the absence of global synchronization are desired properties. Some\nproperties of the optimal forced networks and its relation to recent results in\nthe literature are also discussed.", "category": "nlin.AO"}, {"title": "Partial synchronization in empirical brain networks as a model for unihemispheric sleep", "abstract": "We analyze partial synchronization patterns in a network of FitzHugh-Nagumo\noscillators with empirical structural connectivity measured in healthy human\nsubjects. We report a dynamical asymmetry between the hemispheres, induced by\nthe natural structural asymmetry. We show that the dynamical asymmetry can be\nenhanced by introducing the inter-hemispheric coupling strength as a control\nparameter for partial synchronization patterns. We specify the possible\nmodalities for existence of unihemispheric sleep in human brain, where one\nhemisphere sleeps while the other remains awake. In fact, this state is common\namong migratory birds and mammals like aquatic species.", "category": "nlin.AO"}, {"title": "Bicycle flow dynamics on wide roads: Experiment and modeling", "abstract": "Cycling is a green transportation mode, and is promoted by many governments\nto mitigate traffic congestion. However, studies concerning the traffic\ndynamics of bicycle flow are very limited. This study experimentally\ninvestigated bicycle flow dynamics on a wide road, modeled using a 3-m-wide\ntrack. The results showed that the bicycle flow rate remained nearly constant\nacross a wide range of densities, in marked contrast to single-file bicycle\nflow, which exhibits a unimodal fundamental diagram. By studying the weight\ndensity of the radial locations of cyclists, we argue that this behavior arises\nfrom the formation of more lanes with the increase of global density. The extra\nlanes prevent the longitudinal density from increasing as quickly as in\nsingle-file bicycle flow. When the density is larger than 0.5 bicycles/m2, the\nflow rate begins to decrease, and stop-and-go traffic emerges. A\ncognitive-science-based model to reproduce bicycle dynamics is proposed, in\nwhich cyclists apply simple cognitive procedures to adapt their target\ndirections and desired riding speeds. To incorporate differences in\nacceleration, deceleration, and turning, different relaxation times are used.\nThe model can reproduce the experimental results acceptably well and may also\nprovide guidance on infrastructure design.", "category": "nlin.AO"}, {"title": "Phase oscillator model for noisy oscillators", "abstract": "The Kuramoto model has become a paradigm to describe the dynamics of\nnonlinear oscillator under the influence of external perturbations, both\ndeterministic and stochastic. It is based on the idea to describe the\noscillator dynamics by a scalar differential equation, that defines the time\nevolution for the phase of the oscillator. Starting from a phase and amplitude\ndescription of noisy oscillators, we discuss the reduction to a phase\noscillator model, analogous to the Kuramoto model. The model derived shows that\nthe phase noise problem is a drift-diffusion process. Even in the case where\nthe expected amplitude remains unchanged, the unavoidable amplitude\nfluctuations do change the expected frequency, and the frequency shift depends\non the amplitude variance. We discuss different degrees of approximation,\nyielding increasingly accurate phase reduced descriptions of noisy oscillators.", "category": "nlin.AO"}, {"title": "A mathematical framework for amplitude and phase noise analysis of coupled oscillators", "abstract": "Synchronization of coupled oscillators is a paradigm for complexity in many\nareas of science and engineering. Any realistic network model should include\nnoise effects. We present a description in terms of phase and amplitude\ndeviation for nonlinear oscillators coupled together through noisy\ninteractions. In particular, the coupling is assumed to be modulated by white\nGaussian noise. The equations derived for the amplitude deviation and the phase\nare rigorous, and their validity is not limited to the weak noise limit. We\nshow that using Floquet theory, a partial decoupling between the amplitude and\nthe phase is obtained. The decoupling can be exploited to describe the\noscillator's dynamics solely by the phase variable. We discuss to what extent\nthe reduced model is appropriate and some implications on the role of noise on\nthe frequency of the oscillators.", "category": "nlin.AO"}, {"title": "Competitive Suppression of Synchronization and Non-Monotonic Transitions in Oscillator Communities with Distributed Time Delay", "abstract": "Community structure and interaction delays are common features of ensembles\nof network coupled oscillators, but their combined effect on the emergence of\nsynchronization has not been studied in detail. We study the transitions\nbetween macroscopic states in coupled oscillator systems with community\nstructure and time delays. We show that the combination of these two properties\ngives rise to non-monotonic transitions, whereby increasing the global coupling\nstrength can both inhibit and promote synchronization, yielding both\ndesynchronization and synchronization transitions. For relatively wide\nparameter choices we also observe asymmetric suppression of synchronization,\nwhere communities compete to suppress one another's synchronization properties\nuntil one or more win, totally suppressing the others to effective incoherence.\nUsing the ansatz of Ott and Antonsen we provide analytical descriptions for\nthese transitions that confirm numerical simulations.", "category": "nlin.AO"}, {"title": "Ott-Antonsen reduction for the non-Abelian Kuramoto model on the 3-sphere", "abstract": "We are interested in low-dimensional dynamics in an ensemble of coupled\nnonidentical generalized oscillators on the 3-sphere. The system of governing\nequations for such an ensemble is referred to as non-Abelian Kuramoto model in\nthe literature. We establish an analogue (or an extension) of the Ott-Antonsen\n(OA) result for this model.", "category": "nlin.AO"}, {"title": "Chimera dynamics in nonlocally coupled moving phase oscillators", "abstract": "Chimera states, a symmetry-breaking spatiotemporal pattern in nonlocally\ncoupled dynamical units, prevail in a variety of systems. However, the\ninteraction structures among oscillators are static in most of studies on\nchimera state. In this work, we consider a population of agents. Each agent\ncarries a phase oscillator. We assume that agents perform Brownian motions on a\nring and interact with each other with a kernel function dependent on the\ndistance between them. When agents are motionless, the model allows for several\ndynamical states including two different chimera states (the type-I and the\ntype-II chimeras). The movement of agents changes the relative positions among\nthem and produces perpetual noise to impact on the model dynamics. We find that\nthe response of the coupled phase oscillators to the movement of agents depends\non both the phase lag $\\alpha$, determining the stabilities of chimera states,\nand the agent mobility $D$. For low mobility, the synchronous state transits to\nthe type-I chimera state for $\\alpha$ close to $\\pi/2$ and attracts other\ninitial states otherwise. For intermediate mobility, the coupled oscillators\nrandomly jump among different dynamical states and the jump dynamics depends on\n$\\alpha$. We investigate the statistical properties in these different\ndynamical regimes and present the scaling laws between the transient time and\nthe mobility for low mobility and relations between the mean lifetimes of\ndifferent dynamical states and the mobility for intermediate mobility.", "category": "nlin.AO"}, {"title": "Control of coherence resonance by self-induced stochastic resonance in a multiplex neural network", "abstract": "We consider a two-layer multiplex network of diffusively coupled\nFitzHugh-Nagumo (FHN) neurons in the excitable regime. It is shown, in contrast\nto SISR in a single isolated FHN neuron, that the maximum noise amplitude at\nwhich SISR occurs in the network of coupled FHN neurons is controllable,\nespecially in the regime of strong coupling forces and long time delays. In\norder to use SISR in the first layer of the multiplex network to control CR in\nthe second layer, we first choose the control parameters of the second layer in\nisolation such that in one case CR is poor and in another case, non-existent.\nIt is then shown that a pronounced SISR cannot only significantly improve a\npoor CR, but can also induce a pronounced CR, which was non-existent in the\nisolated second layer. In contrast to strong intra-layer coupling forces,\nstrong inter-layer coupling forces are found to enhance CR. While long\ninter-layer time delays just as long intra-layer time delays, deteriorates CR.\nMost importantly, we find that in a strong inter-layer coupling regime, SISR in\nthe first layer performs better than CR in enhancing CR in the second layer.\nBut in a weak inter-layer coupling regime, CR in the first layer performs\nbetter than SISR in enhancing CR in the second layer. Our results could find\nnovel applications in noisy neural network dynamics and engineering.", "category": "nlin.AO"}, {"title": "Colored noise in oscillators. Phase-amplitude analysis and a method to avoid the Ito-Stratonovich dilemma", "abstract": "We investigate the effect of time-correlated noise on the phase fluctuations\nof nonlinear oscillators. The analysis is based on a methodology that\ntransforms a system subject to colored noise, modeled as an Ornstein-Uhlenbeck\nprocess, into an equivalent system subject to white Gaussian noise. A\ndescription in terms of phase and amplitude deviation is given for the\ntransformed system. Using stochastic averaging technique, the equations are\nreduced to a phase model that can be analyzed to characterize phase noise. We\nfind that phase noise is a drift-diffusion process, with a noise-induced\nfrequency shift related to the variance and to the correlation time of colored\nnoise. The proposed approach improves the accuracy of previous phase reduced\nmodels.", "category": "nlin.AO"}, {"title": "Aging transition in the absence of inactive oscillators", "abstract": "The role of counter-rotating oscillators in an ensemble of coexisting co- and\ncounter-rotating oscillators is examined by increasing the proportion of the\nlatter. The phenomenon of aging transition was identified at a critical value\nof the ratio of the counter-rotating oscillators, which was otherwise realized\nonly by increasing the number of inactive oscillators to a large extent. The\neffect of the mean-field feedback strength in the symmetry preserving coupling\nis also explored. The parameter space of aging transition was increased\nabruptly even for a feeble decrease in the feedback strength and subsequently,\nthe aging transition was observed at a critical value of the feedback strength\nsurprisingly without any counter-rotating oscillators. Further, the study was\nextended to symmetry breaking coupling using conjugate variables and it was\nobserved that the symmetry breaking coupling can facilitating the onset of\naging transition even in the absence of counter-rotating oscillators and for\nthe unit value of the feedback strength. In general, the parameter space of\naging transition was found to increase by increasing the frequency of\noscillators and by increasing the proportion of the counter-rotating\noscillators in both the symmetry preserving and symmetry breaking couplings.\nFurther, the transition from oscillatory to aging transition occurs via a Hopf\nbifurcation, while the transition from aging transition to oscillation death\nstate emerges via Pitchfork bifurcation. Analytical expressions for the\ncritical ratio of the counter- rotating oscillators are deduced to find the\nstable boundaries of the aging transition.", "category": "nlin.AO"}, {"title": "Dynamic Vulnerability in Oscillatory Networks and Power Grids", "abstract": "Recent work found distributed resonances in driven oscillator networks and AC\npower grids. The emerging dynamic resonance patterns are highly heterogeneous\nand nontrivial, depending jointly on the driving frequency, the interaction\ntopology of the network and the node or nodes driven. Identifying which nodes\nare most susceptible to dynamic driving and may thus make the system as a whole\nvulnerable to external input signals, however, remains a challenge. Here we\npropose an easy-to-compute Dynamic Vulnerability Index (DVI) for identifying\nthose nodes that exhibit largest amplitude responses to dynamic driving signals\nwith given power spectra and thus are most vulnerable. The DVI is based on\nlinear response theory, as such generic, and enables robust predictions. It\nthus shows potential for a wide range of applications across dynamically driven\nnetworks, for instance for identifying the vulnerable nodes in power grids\ndriven by fluctuating inputs from renewable energy sources and fluctuating\npower output to households.", "category": "nlin.AO"}, {"title": "Hierarchical clusters in neuronal populations with plasticity", "abstract": "We report the phenomenon of frequency clustering in a network of\nHodgkin-Huxley neurons with spike timing-dependent plasticity. The clustering\nleads to a splitting of a neural population into a few groups synchronized at\ndifferent frequencies. In this regime, the amplitude of the mean field\nundergoes low-frequency modulations, which may contribute to the mechanism of\nthe emergence of slow oscillations of neural activity observed in spectral\npower of local field potentials or electroencephalographic signals at high\nfrequencies. In addition to numerical simulations of such multi-clusters, we\ninvestigate the mechanisms of the observed phenomena using the simplest case of\ntwo clusters. In particular, we propose a phenomenological model which\ndescribes the dynamics of two clusters taking into account the adaptation of\ncoupling weights. We also determine the set of plasticity functions (update\nrules), which lead to multi-clustering.", "category": "nlin.AO"}, {"title": "Some lattice models with hyperbolic chaotic attractors", "abstract": "Examples of one-dimensional lattice systems are considered, in which patterns\nof different spatial scales arise alternately, so that the spatial phase over a\nfull cycle undergo transformation according to expanding circle map that\nimplies occurrence of Smale-Williams attractors in the multidimensional state\nspace. These models can serve as a basis for design electronic generators of\nrobust chaos within a paradigm of coupled cellular networks. One of the\nexamples is a mechanical pendulum system interesting and demonstrative for\nresearch and educational experimental studies.", "category": "nlin.AO"}, {"title": "Emergence of global synchronization in directed excitatory networks of type I neurons", "abstract": "The collective behaviour of neural networks depends on the cellular and\nsynaptic properties of the neurons. The phase-response curve (PRC) is an\nexperimentally obtainable measure of cellular properties that quantifies the\nshift in the next spike time of a neuron as a function of the phase at which\nstimulus is delivered to that neuron. The neuronal PRCs can be classified as\nhaving either purely positive values (type I) or distinct positive and negative\nregions (type II). Networks of type 1 PRCs tend not to synchronize via mutual\nexcitatory synaptic connections. We study the synchronization properties of\nidentical type I and type II neurons, assuming unidirectional synapses.\nPerforming the linear stability analysis and the numerical simulation of the\nextended Kuramoto model, we show that feedforward loop motifs favour\nsynchronization of type I excitatory and inhibitory neurons, while feedback\nloop motifs destroy their synchronization tendency. Moreover, large directed\nnetworks, either without feedback motifs or with many of them, have been\nconstructed from the same undirected backbones, and a high synchronization\nlevel is observed for directed acyclic graphs with type I neurons. It has been\nshown that, the synchronizability of type I neurons depends on both the\ndirectionality of the network connectivity and the topology of its undirected\nbackbone. The abundance of feedforward motifs enhances the synchronizability of\nthe directed acyclic graphs.", "category": "nlin.AO"}, {"title": "Higher-order interactions in complex networks of phase oscillators promote abrupt synchronization switching", "abstract": "Synchronization processes play critical roles in the functionality of a wide\nrange of both natural and man-made systems. Recent work in physics and\nneuroscience highlights the importance of higher-order interactions between\ndynamical units, i.e., three- and four-way interactions in addition to pairwise\ninteractions, and their role in shaping collective behavior. Here we show that\nhigher-order interactions between coupled phase oscillators, encoded\nmicroscopically in a simplicial complex, give rise to added nonlinearity in the\nmacroscopic system dynamics that induces abrupt synchronization transitions via\nhysteresis and bistability of synchronized and incoherent states. Moreover,\nthese higher-order interactions can stabilize strongly synchronized states even\nwhen the pairwise coupling is repulsive. These findings reveal a self-organized\nphenomenon that may be responsible for the rapid switching to synchronization\nin many biological and other systems that exhibit synchronization without the\nneed of particular correlation mechanisms between the oscillators and the\ntopological structure.", "category": "nlin.AO"}, {"title": "Synchronization of globally coupled oscillators without symmetry in the distribution of natural frequencies", "abstract": "The collective behavior in a population of globally coupled oscillators with\nrandomly distributed frequencies is studied when the natural frequency\ndistribution does not possess an even symmetry with respect to the average\nnatural frequency of oscillators. We study the special case of absence of\nsymmetry induced by a group of scaling transformations of the continuous\ndistribution of frequencies. When coupling between oscillators is increased\nbeyond a critical threshold favoring spontaneous synchronization, we found that\nthe variation in the velocity of the traveling wave depends on the extent of\nasymmetry in the natural frequency distribution. In particular for large\ncoupling this velocity is the average natural frequency whereas at the onset of\nsynchronization it corresponds to the frequency where the Hilbert Transform of\nthe frequency distribution vanishes.", "category": "nlin.AO"}, {"title": "Stochastic properties of the frequency dynamics in real and synthetic power grids", "abstract": "The frequency constitutes a key state variable of electrical power grids.\nHowever, as the frequency is subject to several sources of fluctuations,\nranging from renewable volatility to demand fluctuations and dispatch, it is\nstrongly dynamic. Yet, the statistical and stochastic properties of the\nfrequency fluctuation dynamics are far from fully understood. Here, we analyse\nproperties of power grid frequency trajectories recorded from different\nsynchronous regions. We highlight the non-Gaussian and still approximately\nMarkovian nature of the frequency statistics. Further, we find that the\nfrequency displays significant fluctuations exactly at the time intervals of\nregulation and trading, confirming the need of having a regulatory and market\ndesign that respects the technical and dynamical constraints in future highly\nrenewable power grids. Finally, employing a recently proposed synthetic model\nfor the frequency dynamics, we combine our statistical and stochastic analysis\nand analyse in how far dynamically modelled frequency properties match the ones\nof real trajectories.", "category": "nlin.AO"}, {"title": "Intelligence of small groups", "abstract": "Dunbar hypothesized that $150$ is the maximal number of people with whom one\ncan maintain stable social relationships. We explain this effect as being a\nconsequence of a process of self-organization between $N$ units leading their\nsocial system to the edge of phase transition, usually termed criticality.\nCriticality generates events, with an inter-event time interval distribution\ncharacterized by an inverse power law (IPL) index $\\mu_{S}<2$. These events\nbreak ergodicity and we refer to them as crucial events. The group makes\ndecisions and the time persistence of each decision is given by another IPL\ndistribution with IPL index $\\mu_{R}$, which is different from $\\mu_{S}$ if\n$N\\neq 150$. We prove that when the number of interacting individuals is equal\nto $150$, these two different IPL indexes become identical, with the effect of\ngenerating the Kardar Parisi Zhang (KPZ) scaling $\\delta =1/3$. We argue this\nto be an enhanced form of intelligence, which generates efficient information\ntransmission within the group. We prove the inflrmation transmission efficiency\nis maximal when $N=150$, the Dunbar number.", "category": "nlin.AO"}, {"title": "Quasi-periodic dynamics and a Neimark-Sacker bifurcation in nonlinear random walks on complex networks", "abstract": "We study the dynamics of nonlinear random walks on complex networks. We\ninvestigate the role and effect of directed network topologies on long-term\ndynamics. While a period-doubling bifurcation to alternating patterns occurs at\na critical bias parameter value, we find that some directed structures give\nrise to a different kind of bifurcation that gives rise to quasi-periodic\ndynamics. This does not occur for all directed network structure, but only when\nthe network structure is sufficiently directed. We find that the onset of\nquasi-periodic dynamics is the result of a Neimark-Sacker bifurcation, where a\npair of complex-conjugate eigenvalues of the system Jacobian passes through the\nunit circle, destabilizing the stationary distribution with high-dimensional\nrotations. We investigate the nature of these bifurcations, study the onset of\nquasi-periodic dynamics as network structure is tuned to be more directed, and\npresent an analytically tractable case of a four-neighbor ring.", "category": "nlin.AO"}, {"title": "Measuring complexity", "abstract": "Complexity is a multi-faceted phenomenon, involving a variety of features\nincluding disorder, nonlinearity, and self-organisation. We use a recently\ndeveloped rigorous framework for complexity to understand measures of\ncomplexity. We illustrate, by example, how features of complexity can be\nquantified, and we analyse a selection of purported measures of complexity that\nhave found wide application and explain whether and how they measure\ncomplexity. We also discuss some of the classic information-theoretic measures\nfrom the 1980s and 1990s. This work gives the reader a tool kit for quantifying\nfeatures of complexity across the sciences.", "category": "nlin.AO"}, {"title": "Traffic flow on star graph: Nonlinear diffusion", "abstract": "We study the urban-scale macroscopic traffic flow in city networks. Star\ngraph is considered as traffic network. Star graphs with controlled traffic\nflow are transformed to various cell-transmission graphs by using the cell\ntransmission method. The dynamic equations of vehicular densities on all nodes\n(roads) are presented on cell-transmission graphs by using the speed-matching\nmodel. The density equations are given by nonlinear-diffusion equations. The\ntraffic flow on star graph is mapped to the nonlinear diffusion process on the\ncell-transmission graphs. At low mean density, the dynamic equations of\ndensities can be approximated by the conventional diffusion equations. At low\nand high mean densities, the analytical solutions of densities on all nodes\n(roads) are obtained on cell-transmission complete, cycle and star graphs. By\nsolving the dynamic equations numerically, the densities on all roads are\nderived at a steady state. The urban-scale macroscopic fundamental diagrams are\nobtained numerically on the cell-transmission graphs. The analytical solutions\nagree with the numerical solutions.", "category": "nlin.AO"}, {"title": "Towards synthetic neural networks: Can artificial electrochemical neurons be coupled with artificial memristive synapses?", "abstract": "The enormous amount of data generated nowadays worldwide is increasingly\ntriggering the search for unconventional and more efficient ways of processing\nand classifying information, eventually able to transcend the conventional\nvon-Neumann-Turing computational central dogma. It is, therefore, greatly\nappealing to draw inspiration from less conventional but computationally more\npowerful systems such as the neural architecture of the human brain. This\nneuromorphic route has the potential to become one of the most influential and\nlong-lasting paradigms in the field of unconventional computing. The\nmaterial-based workhorse for current hardware platforms is largely based on\nstandard CMOS technologies, intrinsically following the above mentioned\nvon-Neumann-Turing prescription; we do know, however, that the brain hardware\noperates in a massively parallel way through a densely interconnected physical\nnetwork of neurons. This requires challenging the intrinsic definition of the\nsingle units and the architecture of computing machines. (...)", "category": "nlin.AO"}, {"title": "Application of autonomous pathfinding system to kinematics and dynamics problems by implementing network constraints", "abstract": "A neural network system in an animal brain contains many modules and\ngenerates adaptive behavior by integrating the outputs from the modules. The\nmathematical modeling of such large systems to elucidate the mechanism of\nrapidly finding solutions is vital to develop control methods for robotics and\ndistributed computation algorithms. In this article, we present a network model\nto solve kinematics and dynamics problems for robot arm manipulation. This\nmodel represents the solution as an attractor in the phase space and also finds\na new solution automatically when perturbations such as variations in the end\nposition of the arm or obstacles occur. In the proposed model, the physical\nconstraints, target position, and the existence of obstacles are represented by\nnetwork connections. Therefore, the theoretical framework of the model remains\nalmost the same when the number of constraints increases. In addition, as the\nmodel is regarded as a distributed system, it can be applied toward the\ndevelopment of parallel computation algorithms.", "category": "nlin.AO"}, {"title": "Effect of repulsive links on frustration in attractively coupled networks", "abstract": "We investigate the impact of attractive-repulsive interaction in networks of\nlimit-cycle oscillators. Mainly we focus on the design principle for generating\nan anti-phase state between adjacent nodes in a complex network. We establish\nthat a partial negative control throughout the branches of a spanning tree\ninside the positively coupled limit-cycle oscillators works efficiently well in\ncomparison with randomly chosen negative links to establish zero frustration\n(anti-phase synchronization) in bipartite graphs. Based on the emergence of\nzero frustration, we develop a universal 0-$\\pi$ rule to understand the\nanti-phase synchronization in a bipartite graph. Further, this rule is used to\nconstruct a non-bipartite graph for a given non-zero frustrated value. We\nfinally show the generality of 0-$\\pi$ rule by implementing it in arbitrary\nundirected non-bipartite graphs of attractive-repulsively coupled limit-cycle\noscillators and successfully calculate the non-zero frustration value which\nmatches with numerical data. The validation of the rule is checked through the\nbifurcation analysis of small networks. Our work may unveil the underlying\nmechanism of several synchronization phenomena that exist in a network of\noscillators having a mixed type of coupling.", "category": "nlin.AO"}, {"title": "Adaptive stochastic continuation with a modified lifting procedure applied to complex systems", "abstract": "Many complex systems occurring in the natural or social sciences or economics\nare frequently described on a microscopic level, e.g., by lattice- or\nagent-based models. To analyze the states of such systems and their bifurcation\nstructure on the level of macroscopic observables, one has to rely on\nequation-free methods like stochastic continuation. Here, we investigate how to\nimprove stochastic continuation techniques by adaptively choosing the\nparameters of the algorithm. This allows one to obtain bifurcation diagrams\nquite accurately, especially near bifurcation points. We introduce lifting\ntechniques which generate microscopic states with a naturally grown structure,\nwhich can be crucial for a reliable evaluation of macroscopic quantities. We\nshow how to calculate fixed points of fluctuating functions by employing\nsuitable linear fits. This procedure offers a simple measure of the statistical\nerror. We demonstrate these improvements by applying the approach in analyses\nof (i) the Ising model in two dimensions, (ii) an active Ising model, and (iii)\na stochastic Swift-Hohenberg model. We conclude by discussing the abilities and\nremaining problems of the technique.", "category": "nlin.AO"}, {"title": "Bifurcation analysis and structural stability of simplicial oscillator populations", "abstract": "We present an analytical description for the collective dynamics of\noscillator ensembles with higher-order coupling encoded by simplicial\nstructure, which serves as an illustrative and insightful paradigm for brain\nfunction and information storage. The novel dynamics of the system, including\nabrupt desynchronization and multistability, are rigorously characterized and\nthe critical points that correspond to a continuum of first-order phase\ntransitions are found to satisfy universal scaling properties. More\nimportantly, the underlying bifurcation mechanism giving rise to multiple\nclusters with arbitrary ensemble size is characterized using a rigorous\nspectral analysis of the stable cluster states. As a consequence of $SO_2$\ngroup symmetry, we show that the continuum of abrupt desynchronization\ntransitions result from the instability of a collective mode under the\nnontrivial antisymmetric manifold in the high dimensional phase space.", "category": "nlin.AO"}, {"title": "A growth model driven by curvature reproduces geometric features of arboreal termite nests", "abstract": "We present a simple three-dimensional model to describe the autonomous\nexpansion of a substrate which grows driven by the local mean curvature of its\nsurface. The model aims to reproduce the nest construction process in arboreal\nNasutitermes termites, whose cooperation may similarly be mediated by the shape\nof the structure they are walking on, for example focusing the building\nactivity of termites where local mean curvature is high. We adopt a phase-field\nmodel where the nest is described by one continuous scalar field and its growth\nis governed by a single nonlinear equation with one adjustable parameter d.\nWhen d is large enough the equation is linearly unstable and fairly reproduces\na growth process where the initial walls expand, branch and merge, while\nprogressively invading all the available space, which is consistent with the\nintricate structures of real nests. Interestingly, the linear problem\nassociated to our growth equation is analogous to the buckling of a thin\nelastic plate under symmetric in-plane compression which is also known to\nproduce rich pattern through non linear and secondary instabilities. We\nvalidated our model by collecting nests of two species of arboreal Nasutitermes\nfrom the field and imaging their structure with a micro-CT scanner. We found a\nstrong resemblance between real and simulated nests, characterised by the\nemergence of a characteristic length-scale and by the abundance of\nsaddle-shaped surfaces with zero-mean curvature which validates the choice of\nthe driving mechanism of our growth model.", "category": "nlin.AO"}, {"title": "Synchronization of Coupled Kuramoto Oscillators under Resource Constraints", "abstract": "A fundamental understanding of synchronized behavior in multi-agent systems\ncan be acquired by studying analytically tractable Kuramoto models. However,\nsuch models typically diverge from many real systems whose dynamics evolve\nunder non-negligible resource constraints. Here we construct a system of\ncoupled Kuramoto oscillators that consume or produce resources as a function of\ntheir oscillation frequency. At high coupling, we observe strongly synchronized\ndynamics, whereas at low coupling we observe independent oscillator dynamics,\nas expected from standard Kuramoto models. For intermediate coupling, which\ntypically induces a partially synchronized state, we empirically observe that\n(and theoretically explain why) the system can exist in either (i) a state in\nwhich the order parameter oscillates in time, or (ii) a state in which multiple\nsynchronization states are simultaneously stable. Whether (i) or (ii) occurs\ndepends upon whether the oscillators consume or produce resources,\nrespectively. Relevant for systems as varied as coupled neurons and social\ngroups, our study lays important groundwork for future efforts to develop\nquantitative predictions of synchronized dynamics for systems embedded in\nenvironments marked by sparse resources.", "category": "nlin.AO"}, {"title": "Long-range connections and mixed diffusion in fractional networks", "abstract": "Networks with long-range connections obeying a distance-dependent power law\nof sufficiently small exponent display superdiffusion, L\\'evy flights and\nrobustness properties very different from the scale-free networks. It has been\nproposed that these networks, found both in society and biology, be classified\nas a new structure, the fractional networks. Particular important examples are\nthe social networks and the modular hierarchical brain networks where both\nshort- and long-range connections are present. The anomalous superdiffusive and\nthe mixed diffusion behavior of these networks is studied here as well as its\nrelation to the nature and density of the long-range connections.", "category": "nlin.AO"}, {"title": "Using reservoir computer to predict and prevent extreme events", "abstract": "We show that a reservoir computer is an effective tool for model-free\nprediction of extreme events in deterministic chaotic systems. This prediction\nallows us to suppress unwanted extreme events, by applying weak control\nperturbations to the system at times preceding expected extreme events. The\neffectiveness of such a prediction and prevention strategy is demonstrated for\na system of globally coupled FitzHugh-Nagumo neurons and for a system of two\nalmost identical unidirectionally coupled chaotic oscillators.", "category": "nlin.AO"}, {"title": "Chaotic Synchronization of memristive neurons: Lyapunov function versus Hamilton function", "abstract": "We study the dynamical behaviors of this improved memristive neuron model by\nchanging external harmonic current and the magnetic gain parameters. The model\nshows rich dynamics including periodic and chaotic spiking and bursting, and\nremarkably, chaotic super-bursting, which has greater information encoding\npotentials than a standard bursting activity. Based on Krasovskii-Lyapunov\nstability theory, the sufficient conditions (on the synaptic strengths and\nmagnetic gain parameters) for the chaotic synchronization of the improved model\nare obtained. Based on Helmholtz's theorem, the Hamilton function of the\ncorresponding error dynamical system is also obtained. It is shown that the\ntime variation of this Hamilton function along trajectories can play the role\nof the time variation of the Lyapunov function - in determining the asymptotic\nstability of the synchronization manifold. Numerical computations indicate that\nas the synaptic strengths and the magnetic gain parameters change, the time\nvariation of the Hamilton function is always non-zero (i.e., a relatively large\npositive or negative value) only when the time variation of the Lyapunov\nfunction is positive, and zero (or vanishingly small) only when the time\nvariation of the Lyapunov function is also zero. This clearly therefore paves\nan alternative way to determine the asymptotic stability of synchronization\nmanifolds, and can be particularly useful for systems whose Lyapunov function\nis difficult to construct, but whose Hamilton function corresponding to the\ndynamic error system is easier to calculate.", "category": "nlin.AO"}, {"title": "Comment on \"Adaptive modification of the delayed feedback control algorithm with a continuously varying time delay\" https://doi.org/10.1016/j.physleta.2011.08.072", "abstract": "In the paper https://doi.org/10.1016/j.physleta.2011.08.072 authors propose a\nmodification of the conventional delayed feedback control algorithm, where\ntime-delay is varied continuously to minimize the power of control force.\nMinimization is realized via gradient-descent method. However, the derivation\nof the gradient with respect to time-delay is not accurate. In particular, a\nscalar factor is omitted. The absolute value of the scalar factor is not\ncrucial, as it only changes the speed of the gradient method. On the other\nhand, the factor's sign changes the gradient direction, therefore for negative\nvalue of the multiplier the gradient-decent becomes gradient-ascent method and\nfail power minimization. Here the accurate derivation of the gradient is\npresented. We obtain an analytical expression for the missing factor and show\nan example of the Lorenz system where the negative factor occurs. We also\ndiscuss a relation between the negativeness of the factor and the odd number\nlimitation theorem.", "category": "nlin.AO"}, {"title": "Torus bifurcations of large-scale swarms having range dependent communication delay", "abstract": "Dynamical emergent patterns of swarms are now fairly well established in\nnature, and include flocking and rotational states. Recently, there has been\ngreat interest in engineering and physics to create artificial self-propelled\nagents that communicate over a network and operate with simple rules, with the\ngoal of creating emergent self-organizing swarm patterns. In this paper, we\nshow that when communicating networks have range dependent delays, rotational\nstates which are typically periodic, undergo a bifurcation and create swarm\ndynamics on a torus. The observed bifurcation yields additional frequencies\ninto the dynamics, which may lead to quasi-periodic behavior of the swarm.", "category": "nlin.AO"}, {"title": "Pattern in non-linearly coupled network of identical Thomas oscillators", "abstract": "We have investigated synchronized pattern in a network of Thomas oscillators\ncoupled with sinusoidal nonlinear coupling. Pattern like chimera states are not\nonly observed for many non-locally coupled oscillators but there is a signature\nof it even for locally coupled few oscillators. For certain range of\nintermediate coupling, clusters are also observed. These patterns do resemble\nwith motion of real self propelled coupled dynamical systems.", "category": "nlin.AO"}, {"title": "Delay Induced Swarm Pattern Bifurcations in Mixed Reality Experiments", "abstract": "Swarms of coupled mobile agents subject to inter-agent wireless communication\ndelays are known to exhibit multiple dynamic patterns in space that depend on\nthe strength of the interactions and the magnitude of the communication delays.\nWe experimentally demonstrate communication delay-induced bifurcations in the\nspatio-temporal patterns of robot swarms using two distinct hardware platforms\nin a mixed reality framework. Additionally, we make steps toward experimentally\nvalidating theoretically predicted parameter regions where transitions between\nswarm patterns occur. We show that multiple rotation patterns persist even when\ncollision-avoidance strategies are incorporated, and we show the existence of\nmulti-stable, co-existing rotational patterns not predicted by usual mean field\ndynamics. Our experiments are the first significant steps towards validating\nexisting theory and the existence and robustness of the delay-induced patterns\nin real robotic swarms.", "category": "nlin.AO"}, {"title": "Synchronization induced by external forces in modular networks", "abstract": "In this work we study the synchronization of Kuramoto oscillators driven by\nexternal forces in complex modular networks. The motivation is the neuronal\ndynamics that takes place during information processing in the neural cortex.\nThe neuron organization is modular, with clusters associated to different\nfunctions and brain structures, and need to constantly respond to external\nstimuli. We study the behavior of forced Kuramoto oscillators where only a\nfraction of them is subjected to a periodic external force. When all\noscillators receive the external drive the system always synchronize with the\nperiodic force if its intensity is sufficiently large. We show that the\nconditions for global synchronization depend on the fraction of nodes being\nforced and on network topology, strength of internal couplings and intensity of\nexternal forcing. We develop numerical and analytical calculations for the\ncritical force for global synchronization as a function of the fraction of\nforced oscillators. As an application we study the response of the electric\njunction \\textit{C. elegans} network to external stimuli using the partially\nforced Kuramoto model. Stimuli were applied to topological modules, to ganglia,\nspecified by their anatomical localization, and to the functional groups\n(sensory and motoneurons). We found that topological modules do not contain\npurely anamotical groups or functional classes, and that stimulating different\nclasses of neurons lead to very different responses, measured in terms of\nsynchronization and phase velocity correlations. In all cases the modular\nstructure hindered full synchronization, protecting the system from seizures.\nThe responses to stimuli applied to topological and functional modules showed\npronounced patterns of correlation or anti-correlation with other modules that\nwere not observed when the stimulus was applied to a ganglion with mixed\nfunctional neurons.", "category": "nlin.AO"}, {"title": "Degree assortativity in networks of spiking neurons", "abstract": "Degree assortativity refers to the increased or decreased probability of\nconnecting two neurons based on their in- or out-degrees, relative to what\nwould be expected by chance. We investigate the effects of such assortativity\nin a network of theta neurons. The Ott/Antonsen ansatz is used to derive\nequations for the expected state of each neuron, and these equations are then\ncoarse-grained in degree space. We generate families of effective connectivity\nmatrices parametrised by assortativity coefficient and use SVD decompositions\nof these to efficiently perform numerical bifurcation analysis of the\ncoarse-grained equations. We find that of the four possible types of degree\nassortativity, two have no effect on the networks' dynamics, while the other\ntwo can have a significant effect.", "category": "nlin.AO"}, {"title": "The effects of within-neuron degree correlations in networks of spiking neurons", "abstract": "We consider the effects of correlations between the in- and out-degrees of\nindividual neurons on the dynamics of a network of neurons. By using theta\nneurons, we can derive a set of coupled differential equations for the expected\ndynamics of neurons with the same in-degree. A Gaussian copula is used to\nintroduce correlations between a neuron's in- and out-degree and numerical\nbifurcation analysis is used determine the effects of these correlations on the\nnetwork's dynamics. For excitatory coupling we find that inducing positive\ncorrelations has a similar effect to increasing the coupling strength between\nneurons, while for inhibitory coupling it has the opposite effect. We also\ndetermine the propensity of various two- and three-neuron motifs to occur as\ncorrelations are varied and give a plausible explanation for the observed\nchanges in dynamics.", "category": "nlin.AO"}, {"title": "Moving bumps in theta neuron networks", "abstract": "We consider large networks of theta neurons on a ring, synaptically coupled\nwith an asymmetric kernel. Such networks support stable \"bumps\" of activity,\nwhich move along the ring if the coupling kernel is asymmetric. We investigate\nthe effects of the kernel asymmetry on the existence, stability and speed of\nthese moving bumps using continuum equations formally describing infinite\nnetworks. Depending on the level of heterogeneity within the network we find\ncomplex sequences of bifurcations as the amount of asymmetry is varied, in\nstrong contrast to the behaviour of a classical neural field model.", "category": "nlin.AO"}, {"title": "Greedy control of cascading failures in interdependent networks", "abstract": "Complex systems are challenging to control because the system responds to the\ncontroller in a nonlinear fashion, often incorporating feedback mechanisms.\nInterdependence of systems poses additional difficulties, as cross-system\nconnections enable malicious activity to spread between layers, increasing\nsystemic risk. In this paper we explore the conditions for an optimal control\nof cascading failures in a system of interdependent networks. Specifically, we\nstudy the Bak-Tang-Wiesenfeld sandpile model incorporating a control mechanism,\nwhich affects the frequency of cascades occurring in individual layers. This\nmodification allows us to explore sandpile-like dynamics near the critical\nstate, with supercritical region corresponding to infrequent large cascades and\nsubcritical zone being characterized by frequent small avalanches. Topological\ncoupling between networks introduces dependence of control settings adopted in\nrespective layers, causing the control strategy of a given layer to be\ninfluenced by choices made in other connected networks. We find that the\noptimal control strategy for a layer operating in a supercritical regime is to\nbe coupled to a layer operating in a subcritical zone, since such condition\ncorresponds to reduced probability of inflicted avalanches. However this\ncondition describes a parasitic relation, in which only one layer benefits.\nSecond optimal configuration is a mutualistic one, where both layers adopt the\nsame control strategy. This work demonstrates that control protocols in systems\nof interdependent networks need to take into account higher-order organization\nof the system and cannot be designed independently, maximizing benefits only\nfor their individual layers.", "category": "nlin.AO"}, {"title": "Dynamics and bifurcations in multistable 3-cell neural networks", "abstract": "We disclose the generality of the intrinsic mechanisms underlying\nmultistability in reciprocally inhibitory 3-cell circuits composed of\nsimplified, low-dimensional models of oscillatory neurons, as opposed to those\nof a detailed Hodgkin- Huxley type . The computational reduction to return maps\nfor the phase-lags between neurons reveals a rich multiplicity of rhythmic\npatterns in such circuits. We perform a detailed bifurcation analysis to show\nhow such rhythms can emerge, disappear, and gain or lose stability, as the\nparameters of the individual cells and the synapses are varied.", "category": "nlin.AO"}, {"title": "Threefold way to the dimension reduction of dynamics on networks: an application to synchronization", "abstract": "Several complex systems can be modeled as large networks in which the state\nof the nodes continuously evolves through interactions among neighboring nodes,\nforming a high-dimensional nonlinear dynamical system. One of the main\nchallenges of Network Science consists in predicting the impact of network\ntopology and dynamics on the evolution of the states and, especially, on the\nemergence of collective phenomena, such as synchronization. We address this\nproblem by proposing a Dynamics Approximate Reduction Technique (DART) that\nmaps high-dimensional (complete) dynamics unto low-dimensional (reduced)\ndynamics while preserving the most salient features, both topological and\ndynamical, of the original system. DART generalizes recent approaches for\ndimension reduction by allowing the treatment of complex-valued dynamical\nvariables, heterogeneities in the intrinsic properties of the nodes as well as\nmodular networks with strongly interacting communities. Most importantly, we\nidentify three major reduction procedures whose relative accuracy depends on\nwhether the evolution of the states is mainly determined by the intrinsic\ndynamics, the degree sequence, or the adjacency matrix. We use phase\nsynchronization of oscillator networks as a benchmark for our threefold method.\nWe successfully predict the synchronization curves for three phase dynamics\n(Winfree, Kuramoto, theta) on the stochastic block model. Moreover, we obtain\nthe bifurcations of the Kuramoto-Sakaguchi model on the mean stochastic block\nmodel with asymmetric blocks and we show numerically the existence of periphery\nchimera state on the two-star graph. This allows us to highlight the critical\nrole played by the asymmetry of community sizes on the existence of chimera\nstates. Finally, we systematically recover well-known analytical results on\nexplosive synchronization by using DART for the Kuramoto-Sakaguchi model on the\nstar graph.", "category": "nlin.AO"}, {"title": "Interplay between degree and Boolean rules in the stability of Boolean networks", "abstract": "Empirical evidence has revealed that biological regulatory systems are\ncontrolled by high-level coordination between topology and Boolean rules. In\nthis study, we study the joint effects of degree and Boolean functions on the\nstability of Boolean networks. To elucidate these effects, we focus on i) the\ncorrelation between the sensitivity of Boolean variables and the degree, and\nii) the coupling between canalizing inputs and degree. We find that negatively\ncorrelated sensitivity with respect to local degree enhances the stability of\nBoolean networks against external perturbations. We also demonstrate that the\neffects of canalizing inputs can be amplified when they coordinate with high\nin-degree nodes. Numerical simulations confirm the accuracy of our analytical\npredictions at both the node and network levels.", "category": "nlin.AO"}, {"title": "Decreased resilience in power grids under dynamically induced vulnerabilities", "abstract": "In this paper, a methodology inspired on bond and site percolation methods is\napplied to the estimation of the resilience against failures in power grids.\nOur approach includes vulnerability measures with both dynamical and structural\nfoundations as an attempt to find more insights about the relationships between\ntopology and dynamics in the second-order Kuramoto model on complex networks.\nAs test cases for numerical simulations, we use the real-world topology of the\nColombian power transmission system, as well as randomly generated networks\nwith spatial embedding. It is observed that, by focusing the attacks on those\ndynamical vulnerabilities, the power grid becomes, in general, more prone to\nreach a state of total blackout, which in the case of node removal procedures\nit is conditioned by the homogeneity of power distribution in the network.", "category": "nlin.AO"}, {"title": "Universal scaling and phase transitions of coupled phase oscillator populations", "abstract": "The Kuramoto model, which serves as a paradigm for investigating\nsynchronization phenomenon of oscillatory system, is known to exhibit\nsecond-order, i.e., continuous, phase transitions in the macroscopic order\nparameter. Here, we generalize a number of classical results by presenting a\ngeneral framework for capturing, analytically, the critical scaling of the\norder parameter at the onset of synchronization. Using a self-consistent\napproach and constructing a characteristic function, we identify various phase\ntransitions toward synchrony and establish scaling relations describing the\nasymptotic dependence of the order parameter on coupling strength near the\ncritical point. We find that the geometric properties of the characteristic\nfunction, which depends on the natural frequency distribution, determines the\nscaling properties of order parameter above the criticality.", "category": "nlin.AO"}, {"title": "Emergent stability in complex network dynamics", "abstract": "The stable functionality of networked systems is a hallmark of their natural\nability to coordinate between their multiple interacting components. Yet,\nstrikingly, real-world networks seem random and highly irregular, apparently\nlacking any design for stability. What then are the naturally emerging\norganizing principles of complex-system stability? Encoded within the system's\nstability matrix, the Jacobian, the answer is obscured by the scale and\ndiversity of the relevant systems, their broad parameter space, and their\nnonlinear interaction mechanisms. To make advances, here we uncover emergent\npatterns in the structure of the Jacobian, rooted in the interplay between the\nnetwork topology and the system's intrinsic nonlinear dynamics. These patterns\nhelp us analytically identify the few relevant control parameters that\ndetermine a system's dynamic stability. Complex systems, we find, exhibit\ndiscrete stability classes, from asymptotically unstable, where stability is\nunattainable, to sensitive, in which stability abides within a bounded range of\nthe system's parameters. Most crucially, alongside these two classes, we\nuncover a third class, asymptotically stable, in which a sufficiently large and\nheterogeneous network acquires a guaranteed stability, independent of\nparameters, and therefore insensitive to external perturbation. Hence, two of\nthe most ubiquitous characteristics of real-world networks - scale and\nheterogeneity - emerge as natural organizing principles to ensure stability in\nthe face of changing environmental conditions.", "category": "nlin.AO"}, {"title": "Success rate analysis of the response of an excitable laser to periodic perturbations", "abstract": "We use statistical tools to characterize the response of an excitable system\nto periodic perturbations. The system is an optically injected semiconductor\nlaser under pulsed perturbations of the phase of the injected field. We\ncharacterize the laser response by counting the number of pulses emitted by the\nlaser, within a time interval, $\\Delta$T , that starts when a perturbation is\napplied. The success rate, SR($\\Delta$T), is then defined as the number of\npulses emitted in the interval $\\Delta$T , relative to the number of\nperturbations. The analysis of the variation of SR with $\\Delta$T allows to\nseparate a constant lag of technical origin and a frequency-dependent lag of\nphysical and dynamical origin. Once the lag is accounted for, the success rate\nclearly captures locked and unlocked regimes and the transitions between them.\nWe anticipate that the success rate will be a practical tool for analyzing the\noutput of periodically forced systems, particularly when very regular\noscillations need to be generated via small periodic perturbations.", "category": "nlin.AO"}, {"title": "A stochastic phase model with reflective boundary and induced beating for the cardiac muscle cells", "abstract": "We consider the stochastic phase models for the community effect of cardiac\nmuscle cells. The model is the extension of the stochastic integrate-and-fire\nmodel in which we incorporate the irreversibility after beating, induced\nbeating and refractory. We focus on investigating the expectation and variance\nof (synchronized) beating interval. In particular, for the single-isolated\ncell, we obtain the closed-form expectation and variance of the beating\ninterval, and we discover that the coefficient of variance (CV) has upper limit\n$\\sqrt{2/3}$. For two-coupled cells, we derive the partial differential\nequations (PDEs) for the expected synchronized beating intervals and the\ndistribution density of phase. Moreover, we also consider the conventional\nKuramoto model for both two- and $N$-cells models, where we establish a new\nanalysis using stochastic calculus to obtain the CV of the ''synchronized''\nbeating interval, and make some improvement to the literature work.", "category": "nlin.AO"}, {"title": "Explosive synchronization in temporal networks: A comparative study", "abstract": "We present a comparative study on Explosive Synchronization (ES) in temporal\nnetworks consisting of phase oscillators. The temporal nature of the networks\nis modeled with two configurations: (1) oscillators are allowed to move in a\nclosed two dimensional box such that they couple with their neighbors, (2)\noscillators are static and they randomly switch their coupling partners.\nConfiguration (1) is further studied under two possible scenarios: in the first\ncase oscillators couple to fixed numbers of neighbors while in other they\ncouple to all oscillators lying in their circle of vision. Under these\ncircumstances, we monitor the degrees of temporal networks, velocities, and\nradius of circle of vision of the oscillators, and the probability of forming\nconnections in order to study and compare the critical values of the coupling\nrequired to induce ES in the population of phase oscillators.", "category": "nlin.AO"}]